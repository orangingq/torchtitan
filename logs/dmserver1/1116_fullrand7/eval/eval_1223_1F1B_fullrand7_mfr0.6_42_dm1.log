
❄️❄️❄️❄️❄️❄️❄️❄️❄️❄️❄️❄️❄️❄️❄️❄️❄️❄️❄️❄️❄️❄️❄️❄️❄️❄️❄️❄️
✔️Current Timestamp: 2025. 12. 24. (수) 02:01:26 KST
✔️SERVER: dmserver1 (143.248.135.95),  GPUs: 6
✔️SCRIPT: /home/shcho/torchtitan/logs/dmserver1/1116_fullrand7/eval/eval.sh
✔️OUTPUT: /home/shcho/torchtitan/logs/dmserver1/1116_fullrand7/eval/eval_1223_1F1B_fullrand7_mfr0.6_42_dm1.log
✔️RESULT: /data2/shcho/torchtitan/checkpoint/1223_1F1B_fullrand7_mfr0.6_42_dm1/step-800/eval_1223_1F1B_fullrand7_mfr0.6_42_dm1.json
✔️Main Table Experiment
☑️> python3 -m timelyfreeze.evaluation --model_path=/data2/shcho/torchtitan/checkpoint/1223_1F1B_fullrand7_mfr0.6_42_dm1/step-800 --dtype=float16 --model_type=Llama-3.2-1B --batch_size=16 --device_map=cuda --tasks=mmlu,hellaswag,arc_challenge,truthfulqa_mc1 --output_json=/data2/shcho/torchtitan/checkpoint/1223_1F1B_fullrand7_mfr0.6_42_dm1/step-800/eval_1223_1F1B_fullrand7_mfr0.6_42_dm1.json
❄️❄️❄️❄️❄️❄️❄️❄️❄️❄️❄️❄️❄️❄️❄️❄️❄️❄️❄️❄️❄️❄️❄️❄️❄️❄️❄️❄️
generation_kwargs: {'max_new_tokens': 512, 'temperature': 0.0} specified through cli, these settings will update set parameters in yaml tasks. Ensure 'do_sample=True' for non-greedy decoding!
Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
Traceback (most recent call last):
  File "/data2/shcho/miniforge3/envs/llm_eval/lib/python3.11/site-packages/transformers/configuration_utils.py", line 756, in _get_config_dict
    config_dict = cls._dict_from_json_file(resolved_config_file)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data2/shcho/miniforge3/envs/llm_eval/lib/python3.11/site-packages/transformers/configuration_utils.py", line 867, in _dict_from_json_file
    return json.loads(text)
           ^^^^^^^^^^^^^^^^
  File "/data2/shcho/miniforge3/envs/llm_eval/lib/python3.11/json/__init__.py", line 346, in loads
    return _default_decoder.decode(s)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data2/shcho/miniforge3/envs/llm_eval/lib/python3.11/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data2/shcho/miniforge3/envs/llm_eval/lib/python3.11/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "<frozen runpy>", line 198, in _run_module_as_main
  File "<frozen runpy>", line 88, in _run_code
  File "/home/shcho/torchtitan/timelyfreeze/evaluation.py", line 154, in <module>
    main()
  File "/home/shcho/torchtitan/timelyfreeze/evaluation.py", line 88, in main
    part = evaluator.simple_evaluate(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data2/shcho/miniforge3/envs/llm_eval/lib/python3.11/site-packages/lm_eval/utils.py", line 439, in _wrapper
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/data2/shcho/miniforge3/envs/llm_eval/lib/python3.11/site-packages/lm_eval/evaluator.py", line 230, in simple_evaluate
    lm = lm_eval.api.registry.get_model(model).create_from_arg_string(
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data2/shcho/miniforge3/envs/llm_eval/lib/python3.11/site-packages/lm_eval/api/model.py", line 151, in create_from_arg_string
    return cls(**args, **args2)
           ^^^^^^^^^^^^^^^^^^^^
  File "/data2/shcho/miniforge3/envs/llm_eval/lib/python3.11/site-packages/lm_eval/models/huggingface.py", line 168, in __init__
    self._get_config(
  File "/data2/shcho/miniforge3/envs/llm_eval/lib/python3.11/site-packages/lm_eval/models/huggingface.py", line 527, in _get_config
    self._config = transformers.AutoConfig.from_pretrained(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data2/shcho/miniforge3/envs/llm_eval/lib/python3.11/site-packages/transformers/models/auto/configuration_auto.py", line 1332, in from_pretrained
    config_dict, unused_kwargs = PretrainedConfig.get_config_dict(pretrained_model_name_or_path, **kwargs)
                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data2/shcho/miniforge3/envs/llm_eval/lib/python3.11/site-packages/transformers/configuration_utils.py", line 662, in get_config_dict
    config_dict, kwargs = cls._get_config_dict(pretrained_model_name_or_path, **kwargs)
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data2/shcho/miniforge3/envs/llm_eval/lib/python3.11/site-packages/transformers/configuration_utils.py", line 760, in _get_config_dict
    raise OSError(f"It looks like the config file at '{resolved_config_file}' is not a valid JSON file.")
OSError: It looks like the config file at '/data2/shcho/torchtitan/checkpoint/1223_1F1B_fullrand7_mfr0.6_42_dm1/step-800/config.json' is not a valid JSON file.
