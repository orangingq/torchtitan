
üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•
‚úîÔ∏èCurrent Timestamp: 2025. 10. 29. (Ïàò) 06:53:28 KST
‚úîÔ∏èSERVER: dmserver1 (143.248.135.95),  GPUs: 3,4,5,6
‚úîÔ∏èSCRIPT: /home/shcho/torchtitan/logs/dmserver1/1028_llama1b/run.sh
‚úîÔ∏èOUTPUT: /home/shcho/torchtitan/logs/dmserver1/1028_llama1b/1028_1F1B_timelyapf.log
‚úîÔ∏èMain Table Experiment, without streaming mode, sample-level with truncation, 2 epochs, with bf16 autocast
‚úîÔ∏èRunning with timelyapf x 1F1B ... 
‚òëÔ∏è> torchrun --standalone --nnodes=1 --nproc_per_node=4 --local_addr=127.0.0.1 --local-ranks-filter=0,1,2,3 --role=rank --tee=3 -m timelyfreeze.train --job.config_file=/home/shcho/torchtitan/logs/dmserver1/1028_llama1b/config.toml --job.description="Main Table Experiment, without streaming mode, sample-level with truncation, 2 epochs, with bf16 autocast" --parallelism.pipeline_parallel_degree=4  --freezing.freeze --freezing.metric_type=timelyapf
üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•
[rank0]:2025-10-29 06:53:35,051 - INFO - Starting job: "Main Table Experiment, without streaming mode, sample-level with truncation, 2 epochs, with bf16 autocast"
[rank1]:2025-10-29 06:53:35,096 - INFO - Starting job: "Main Table Experiment, without streaming mode, sample-level with truncation, 2 epochs, with bf16 autocast"
[rank0]:2025-10-29 06:53:35,274 - WARNING - ENV[TORCH_NCCL_ASYNC_ERROR_HANDLING] = 1 will be overridden to 3 based on job config
[rank0]:2025-10-29 06:53:35,277 - INFO - Building 1-D device mesh with ['pp'], [4]
[rank0]:2025-10-29 06:53:35,281 - INFO - [GC] Initial GC collection 0.00 seconds
[rank3]:2025-10-29 06:53:35,195 - INFO - Starting job: "Main Table Experiment, without streaming mode, sample-level with truncation, 2 epochs, with bf16 autocast"
[rank2]:2025-10-29 06:53:35,255 - INFO - Starting job: "Main Table Experiment, without streaming mode, sample-level with truncation, 2 epochs, with bf16 autocast"
[rank1]:2025-10-29 06:53:35,296 - WARNING - ENV[TORCH_NCCL_ASYNC_ERROR_HANDLING] = 1 will be overridden to 3 based on job config
[rank1]:2025-10-29 06:53:35,298 - INFO - Building 1-D device mesh with ['pp'], [4]
[rank3]:2025-10-29 06:53:35,415 - WARNING - ENV[TORCH_NCCL_ASYNC_ERROR_HANDLING] = 1 will be overridden to 3 based on job config
[rank3]:2025-10-29 06:53:35,418 - INFO - Building 1-D device mesh with ['pp'], [4]
[rank2]:2025-10-29 06:53:35,469 - WARNING - ENV[TORCH_NCCL_ASYNC_ERROR_HANDLING] = 1 will be overridden to 3 based on job config
[rank2]:2025-10-29 06:53:35,472 - INFO - Building 1-D device mesh with ['pp'], [4]
[rank0]:2025-10-29 06:53:36,564 - INFO - Loading tokenizer from tokenizer.json
[rank0]:2025-10-29 06:53:36,944 - INFO - Preparing alpaca dataset from tatsu-lab/alpaca
[rank0]:2025-10-29 06:53:39,698 - INFO - Building llama3 1B with TransformerModelArgs(_enforced='This field is used to enforce all fields have defaults.', dim=2048, n_layers=16, n_heads=32, n_kv_heads=8, vocab_size=128256, multiple_of=256, ffn_dim_multiplier=1.5, norm_eps=1e-05, rope_theta=500000, max_seq_len=1024, depth_init=True, use_flex_attn=False, attn_mask_type='causal', eos_id=0)
[rank1]:2025-10-29 06:53:39,969 - INFO - CUDA capacity: NVIDIA RTX 6000 Ada Generation with 47.51GiB memory
[rank0]:2025-10-29 06:53:39,969 - INFO - CUDA capacity: NVIDIA RTX 6000 Ada Generation with 47.51GiB memory
[rank1]:2025-10-29 06:53:40,016 - WARNING - Peak flops undefined for: NVIDIA RTX 6000 Ada Generation, fallback to A100
[rank1]:2025-10-29 06:53:40,017 - INFO - Compiling the loss function with torch.compile
[rank0]:2025-10-29 06:53:40,016 - WARNING - Peak flops undefined for: NVIDIA RTX 6000 Ada Generation, fallback to A100
[rank0]:2025-10-29 06:53:40,017 - INFO - Model llama3 1B size: 1,498,482,688 total parameters
[rank1]:2025-10-29 06:53:40,064 - INFO - PP rank 1 is building stage_idx 1 with modules ['layers.4', 'layers.5', 'layers.6', 'layers.7', 'layers.8']
[rank0]:2025-10-29 06:53:40,017 - INFO - Compiling the loss function with torch.compile
[rank0]:2025-10-29 06:53:40,064 - INFO - PP rank 0 is building stage_idx 0 with modules ['tok_embeddings', 'layers.0', 'layers.1', 'layers.2', 'layers.3']
[rank0]:2025-10-29 06:53:40,074 - INFO - Compiling each TransformerBlock with torch.compile
[rank0]:2025-10-29 06:53:40,074 - INFO - Using pipeline schedule 1F1B with 8 microbatches and 4 stages.
[rank1]:2025-10-29 06:53:40,074 - INFO - Compiling each TransformerBlock with torch.compile
[rank1]:2025-10-29 06:53:40,074 - INFO - Using pipeline schedule 1F1B with 8 microbatches and 4 stages.
[rank3]:/data2/shcho/miniforge3/envs/llm_eval/lib/python3.11/site-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
[rank3]:  warnings.warn(
[rank3]:/data2/shcho/miniforge3/envs/llm_eval/lib/python3.11/site-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
[rank3]:  warnings.warn(
[rank2]:2025-10-29 06:53:40,252 - INFO - CUDA capacity: NVIDIA RTX 6000 Ada Generation with 47.51GiB memory
[rank0]:2025-10-29 06:53:40,257 - WARNING - Peak flops undefined for: NVIDIA RTX 6000 Ada Generation, fallback to A100
[rank0]:2025-10-29 06:53:40,257 - INFO - Peak FLOPS used for computing MFU: 3.120e+14
[rank0]:2025-10-29 06:53:40,258 - INFO - CUDA memory usage for model: 1.90GiB(3.99%)
[rank1]:2025-10-29 06:53:40,257 - WARNING - Peak flops undefined for: NVIDIA RTX 6000 Ada Generation, fallback to A100
[rank1]:2025-10-29 06:53:40,257 - INFO - Peak FLOPS used for computing MFU: 3.120e+14
[rank1]:2025-10-29 06:53:40,258 - INFO - CUDA memory usage for model: 1.13GiB(2.39%)
[rank2]:2025-10-29 06:53:40,294 - WARNING - Peak flops undefined for: NVIDIA RTX 6000 Ada Generation, fallback to A100
[rank2]:2025-10-29 06:53:40,295 - INFO - Compiling the loss function with torch.compile
[rank2]:2025-10-29 06:53:40,344 - INFO - PP rank 2 is building stage_idx 2 with modules ['layers.9', 'layers.10', 'layers.11', 'layers.12']
[rank2]:2025-10-29 06:53:40,345 - INFO - Compiling each TransformerBlock with torch.compile
[rank2]:2025-10-29 06:53:40,345 - INFO - Using pipeline schedule 1F1B with 8 microbatches and 4 stages.
[rank2]:2025-10-29 06:53:40,514 - WARNING - Peak flops undefined for: NVIDIA RTX 6000 Ada Generation, fallback to A100
[rank2]:2025-10-29 06:53:40,514 - INFO - Peak FLOPS used for computing MFU: 3.120e+14
[rank2]:2025-10-29 06:53:40,514 - INFO - CUDA memory usage for model: 0.92GiB(1.94%)
[rank3]:wandb: Currently logged in as: orangingq to https://api.wandb.ai. Use `wandb login --relogin` to force relogin
[rank3]:wandb: setting up run xikukunx
[rank3]:wandb: Tracking run with wandb version 0.22.2
[rank3]:wandb: Run data is saved locally in /data2/shcho/torchtitan/tb/1028_1F1B_timelyapf_dm1/20251029-0653/wandb/run-20251029_065340-xikukunx
[rank3]:wandb: Run `wandb offline` to turn off syncing.
[rank3]:wandb: Syncing run 1028_1F1B_timelyapf_dm1
[rank3]:wandb: ‚≠êÔ∏è View project at https://wandb.ai/orangingq/torchtitan
[rank3]:wandb: üöÄ View run at https://wandb.ai/orangingq/torchtitan/runs/xikukunx
[rank3]:2025-10-29 06:53:42,568 - INFO - WandB logging enabled
[rank3]:2025-10-29 06:53:42,569 - INFO - CUDA capacity: NVIDIA RTX 6000 Ada Generation with 47.51GiB memory
[rank3]:2025-10-29 06:53:42,608 - WARNING - Peak flops undefined for: NVIDIA RTX 6000 Ada Generation, fallback to A100
[rank3]:2025-10-29 06:53:42,609 - INFO - Compiling the loss function with torch.compile
[rank3]:2025-10-29 06:53:42,657 - INFO - PP rank 3 is building stage_idx 3 with modules ['layers.13', 'layers.14', 'layers.15', 'norm', 'output']
[rank3]:2025-10-29 06:53:42,658 - INFO - Compiling each TransformerBlock with torch.compile
[rank3]:2025-10-29 06:53:42,659 - INFO - Using pipeline schedule 1F1B with 8 microbatches and 4 stages.
[rank3]:2025-10-29 06:53:42,843 - WARNING - Peak flops undefined for: NVIDIA RTX 6000 Ada Generation, fallback to A100
[rank3]:2025-10-29 06:53:42,844 - INFO - Peak FLOPS used for computing MFU: 3.120e+14
[rank3]:2025-10-29 06:53:42,845 - INFO - CUDA memory usage for model: 1.66GiB(3.50%)
[rank3]:2025-10-29 06:53:42,861 - INFO - Mixed precision training with TP or PP is handled by autocast
[rank3]:2025-10-29 06:53:42,861 - INFO - Compiling the loss function with torch.compile
[rank2]:2025-10-29 06:53:42,861 - INFO - Mixed precision training with TP or PP is handled by autocast
[rank2]:2025-10-29 06:53:42,861 - INFO - Compiling the loss function with torch.compile
[rank1]:2025-10-29 06:53:42,861 - INFO - Mixed precision training with TP or PP is handled by autocast
[rank1]:2025-10-29 06:53:42,861 - INFO - Compiling the loss function with torch.compile
[rank0]:2025-10-29 06:53:42,861 - INFO - Checkpointing active. Checkpoints will be loaded from and saved to /data2/shcho/torchtitan/checkpoint/1028_1F1B_timelyapf_dm1
[rank0]:2025-10-29 06:53:42,861 - INFO - Mixed precision training with TP or PP is handled by autocast
[rank0]:2025-10-29 06:53:42,861 - INFO - Compiling the loss function with torch.compile
[rank0]:2025-10-29 06:53:42,865 - INFO - Preparing c4_validation dataset from allenai/c4
[rank0]:2025-10-29 06:53:47,877 - INFO - Trainer is initialized with local batch size 16, global batch size 64, gradient accumulation steps 4, sequence length 1024, total steps 1600 (warmup 100)
[rank0]:2025-10-29 06:53:47,877 - INFO - Loading the checkpoint from /data2/shcho/torchtitan/base_model/Llama-3.2-1B-Instruct/original_dcp.
[rank0]:2025-10-29 06:53:51,017 - INFO - [GC] GC collection for checkpoint loading. 0.01 seconds
[rank0]:2025-10-29 06:53:51,017 - INFO - Finished loading the checkpoint in 3.14 seconds.
[rank0]:2025-10-29 06:53:51,017 - INFO - Training starts at step 1
[rank0]:/data2/shcho/miniforge3/envs/llm_eval/lib/python3.11/site-packages/torch/_inductor/lowering.py:2132: UserWarning: Torchinductor does not support code generation for complex operators. Performance may be worse than eager.
[rank0]:  warnings.warn(
[rank1]:/data2/shcho/miniforge3/envs/llm_eval/lib/python3.11/site-packages/torch/_inductor/lowering.py:2132: UserWarning: Torchinductor does not support code generation for complex operators. Performance may be worse than eager.
[rank1]:  warnings.warn(
[rank2]:/data2/shcho/miniforge3/envs/llm_eval/lib/python3.11/site-packages/torch/_inductor/lowering.py:2132: UserWarning: Torchinductor does not support code generation for complex operators. Performance may be worse than eager.
[rank2]:  warnings.warn(
[rank3]:/data2/shcho/miniforge3/envs/llm_eval/lib/python3.11/site-packages/torch/_inductor/lowering.py:2132: UserWarning: Torchinductor does not support code generation for complex operators. Performance may be worse than eager.
[rank3]:  warnings.warn(
[rank3]:2025-10-29 06:54:03,500 - INFO -  step:  1  loss:  9.8292  grad_norm: 53.4632  memory: 12.99GiB(27.34%)  tps: 784  tflops: 6.13  mfu: 1.97%
[rank3]:2025-10-29 06:54:03,500 - INFO - Synchronizing and adjusting timeout for all ProcessGroups to 0:05:00
[rank2]:2025-10-29 06:54:03,488 - INFO -  step:  1  loss: -4.0000  grad_norm: 53.4632  memory:  4.61GiB(9.71%)  tps: 706  tflops: 5.52  mfu: 1.77%
[rank2]:2025-10-29 06:54:03,489 - INFO - Synchronizing and adjusting timeout for all ProcessGroups to 0:05:00
[rank1]:2025-10-29 06:54:03,492 - INFO -  step:  1  loss: -4.0000  grad_norm: 53.4632  memory:  6.98GiB(14.69%)  tps: 698  tflops: 5.46  mfu: 1.75%
[rank1]:2025-10-29 06:54:03,492 - INFO - Synchronizing and adjusting timeout for all ProcessGroups to 0:05:00
[rank0]:2025-10-29 06:54:03,530 - INFO -  step:  1  loss: -4.0000  grad_norm: 53.4632  memory:  9.52GiB(20.03%)  tps: 697  tflops: 5.45  mfu: 1.75%
[rank0]:2025-10-29 06:54:03,531 - INFO - Synchronizing and adjusting timeout for all ProcessGroups to 0:05:00
[rank3]:2025-10-29 06:54:18,662 - WARNING - Batch index 1 is larger than log time length 0. Filling with zeros.
[rank3]:2025-10-29 06:54:18,663 - WARNING - Batch index 1 is larger than log time length 0. Filling with zeros.
[rank3]:2025-10-29 06:54:18,663 - WARNING - Batch index 1 is larger than log time length 0. Filling with zeros.
[rank3]:2025-10-29 06:54:18,663 - WARNING - Batch index 1 is larger than log time length 0. Filling with zeros.
[rank3]:2025-10-29 06:54:18,664 - WARNING - Batch index 1 is larger than log time length 0. Filling with zeros.
[rank3]:2025-10-29 06:54:18,664 - WARNING - Batch index 1 is larger than log time length 0. Filling with zeros.
[rank3]:2025-10-29 06:54:18,664 - WARNING - Batch index 1 is larger than log time length 0. Filling with zeros.
[rank3]:2025-10-29 06:54:18,664 - WARNING - Batch index 1 is larger than log time length 0. Filling with zeros.
[rank3]:2025-10-29 06:54:18,665 - WARNING - Batch index 1 is larger than log time length 0. Filling with zeros.
[rank3]:2025-10-29 06:54:18,665 - WARNING - Batch index 1 is larger than log time length 0. Filling with zeros.
[rank3]:2025-10-29 06:54:18,665 - WARNING - Batch index 1 is larger than log time length 0. Filling with zeros.
[rank3]:2025-10-29 06:54:18,666 - WARNING - Batch index 1 is larger than log time length 0. Filling with zeros.
[rank3]:2025-10-29 06:54:18,666 - WARNING - Batch index 1 is larger than log time length 0. Filling with zeros.
[rank3]:2025-10-29 06:54:18,666 - WARNING - Batch index 1 is larger than log time length 0. Filling with zeros.
[rank3]:2025-10-29 06:54:18,666 - WARNING - Batch index 1 is larger than log time length 0. Filling with zeros.
[rank3]:2025-10-29 06:54:18,667 - WARNING - Batch index 1 is larger than log time length 0. Filling with zeros.
[rank2]:2025-10-29 06:54:18,688 - WARNING - Batch index 1 is larger than log time length 0. Filling with zeros.
[rank2]:2025-10-29 06:54:18,689 - WARNING - Batch index 1 is larger than log time length 0. Filling with zeros.
[rank2]:2025-10-29 06:54:18,689 - WARNING - Batch index 1 is larger than log time length 0. Filling with zeros.
[rank2]:2025-10-29 06:54:18,689 - WARNING - Batch index 1 is larger than log time length 0. Filling with zeros.
[rank2]:2025-10-29 06:54:18,689 - WARNING - Batch index 1 is larger than log time length 0. Filling with zeros.
[rank2]:2025-10-29 06:54:18,689 - WARNING - Batch index 1 is larger than log time length 0. Filling with zeros.
[rank2]:2025-10-29 06:54:18,689 - WARNING - Batch index 1 is larger than log time length 0. Filling with zeros.
[rank2]:2025-10-29 06:54:18,689 - WARNING - Batch index 1 is larger than log time length 0. Filling with zeros.
[rank2]:2025-10-29 06:54:18,689 - WARNING - Batch index 1 is larger than log time length 0. Filling with zeros.
[rank2]:2025-10-29 06:54:18,689 - WARNING - Batch index 1 is larger than log time length 0. Filling with zeros.
[rank2]:2025-10-29 06:54:18,689 - WARNING - Batch index 1 is larger than log time length 0. Filling with zeros.
[rank2]:2025-10-29 06:54:18,690 - WARNING - Batch index 1 is larger than log time length 0. Filling with zeros.
[rank2]:2025-10-29 06:54:18,690 - WARNING - Batch index 1 is larger than log time length 0. Filling with zeros.
[rank2]:2025-10-29 06:54:18,690 - WARNING - Batch index 1 is larger than log time length 0. Filling with zeros.
[rank2]:2025-10-29 06:54:18,690 - WARNING - Batch index 1 is larger than log time length 0. Filling with zeros.
[rank2]:2025-10-29 06:54:18,690 - WARNING - Batch index 1 is larger than log time length 0. Filling with zeros.
[rank1]:2025-10-29 06:54:18,717 - WARNING - Batch index 1 is larger than log time length 0. Filling with zeros.
[rank1]:2025-10-29 06:54:18,717 - WARNING - Batch index 1 is larger than log time length 0. Filling with zeros.
[rank1]:2025-10-29 06:54:18,717 - WARNING - Batch index 1 is larger than log time length 0. Filling with zeros.
[rank1]:2025-10-29 06:54:18,717 - WARNING - Batch index 1 is larger than log time length 0. Filling with zeros.
[rank1]:2025-10-29 06:54:18,717 - WARNING - Batch index 1 is larger than log time length 0. Filling with zeros.
[rank1]:2025-10-29 06:54:18,717 - WARNING - Batch index 1 is larger than log time length 0. Filling with zeros.
[rank1]:2025-10-29 06:54:18,717 - WARNING - Batch index 1 is larger than log time length 0. Filling with zeros.
[rank1]:2025-10-29 06:54:18,717 - WARNING - Batch index 1 is larger than log time length 0. Filling with zeros.
[rank1]:2025-10-29 06:54:18,717 - WARNING - Batch index 1 is larger than log time length 0. Filling with zeros.
[rank1]:2025-10-29 06:54:18,718 - WARNING - Batch index 1 is larger than log time length 0. Filling with zeros.
[rank1]:2025-10-29 06:54:18,718 - WARNING - Batch index 1 is larger than log time length 0. Filling with zeros.
[rank1]:2025-10-29 06:54:18,718 - WARNING - Batch index 1 is larger than log time length 0. Filling with zeros.
[rank1]:2025-10-29 06:54:18,718 - WARNING - Batch index 1 is larger than log time length 0. Filling with zeros.
[rank1]:2025-10-29 06:54:18,718 - WARNING - Batch index 1 is larger than log time length 0. Filling with zeros.
[rank1]:2025-10-29 06:54:18,718 - WARNING - Batch index 1 is larger than log time length 0. Filling with zeros.
[rank1]:2025-10-29 06:54:18,718 - WARNING - Batch index 1 is larger than log time length 0. Filling with zeros.
[rank0]:2025-10-29 06:54:18,745 - WARNING - Batch index 1 is larger than log time length 0. Filling with zeros.
[rank0]:2025-10-29 06:54:18,745 - WARNING - Batch index 1 is larger than log time length 0. Filling with zeros.
[rank0]:2025-10-29 06:54:18,746 - WARNING - Batch index 1 is larger than log time length 0. Filling with zeros.
[rank0]:2025-10-29 06:54:18,746 - WARNING - Batch index 1 is larger than log time length 0. Filling with zeros.
[rank0]:2025-10-29 06:54:18,746 - WARNING - Batch index 1 is larger than log time length 0. Filling with zeros.
[rank0]:2025-10-29 06:54:18,746 - WARNING - Batch index 1 is larger than log time length 0. Filling with zeros.
[rank0]:2025-10-29 06:54:18,746 - WARNING - Batch index 1 is larger than log time length 0. Filling with zeros.
[rank0]:2025-10-29 06:54:18,746 - WARNING - Batch index 1 is larger than log time length 0. Filling with zeros.
[rank0]:2025-10-29 06:54:18,746 - WARNING - Batch index 1 is larger than log time length 0. Filling with zeros.
[rank0]:2025-10-29 06:54:18,746 - WARNING - Batch index 1 is larger than log time length 0. Filling with zeros.
[rank0]:2025-10-29 06:54:18,746 - WARNING - Batch index 1 is larger than log time length 0. Filling with zeros.
[rank0]:2025-10-29 06:54:18,746 - WARNING - Batch index 1 is larger than log time length 0. Filling with zeros.
[rank0]:2025-10-29 06:54:18,746 - WARNING - Batch index 1 is larger than log time length 0. Filling with zeros.
[rank0]:2025-10-29 06:54:18,747 - WARNING - Batch index 1 is larger than log time length 0. Filling with zeros.
[rank0]:2025-10-29 06:54:18,747 - WARNING - Batch index 1 is larger than log time length 0. Filling with zeros.
[rank0]:2025-10-29 06:54:18,747 - WARNING - Batch index 1 is larger than log time length 0. Filling with zeros.
[rank0]:2025-10-29 06:55:51,717 - INFO - [GC] Peforming periodical GC collection 0.00 seconds
[rank2]:2025-10-29 06:55:53,978 - INFO -  step: 50  loss: -4.0000  grad_norm: 21.7741  memory:  6.43GiB(13.53%)  tps: 7,266  tflops: 56.80  mfu: 18.21%
[rank3]:2025-10-29 06:55:53,990 - INFO -  step: 50  loss:  9.4553  grad_norm: 21.7741  memory: 16.43GiB(34.58%)  tps: 7,266  tflops: 56.80  mfu: 18.21%
[rank0]:2025-10-29 06:55:53,993 - INFO -  step: 50  loss: -4.0000  grad_norm: 21.7741  memory: 13.29GiB(27.97%)  tps: 7,268  tflops: 56.82  mfu: 18.21%
[rank1]:2025-10-29 06:55:53,982 - INFO -  step: 50  loss: -4.0000  grad_norm: 21.7741  memory:  9.26GiB(19.50%)  tps: 7,266  tflops: 56.80  mfu: 18.21%
[rank3]:2025-10-29 06:55:54,238 - INFO - Avg. fwd time: 13.9421 / Avg. bwd time: 36.6687 / Avg. batch time: 441.4306 (ms) / GPU bubble ratio: 8.28%
[rank2]:2025-10-29 06:55:54,298 - INFO - Avg. fwd time: 8.1915 / Avg. bwd time: 18.5460 / Avg. batch time: 472.1959 (ms) / GPU bubble ratio: 54.70%
[rank0]:2025-10-29 06:55:54,299 - INFO - Avg. fwd time: 8.6417 / Avg. bwd time: 23.8820 / Avg. batch time: 545.3391 (ms) / GPU bubble ratio: 52.29%
[rank1]:2025-10-29 06:55:54,333 - INFO - Avg. fwd time: 10.4535 / Avg. bwd time: 23.8563 / Avg. batch time: 509.4038 (ms) / GPU bubble ratio: 46.12%
[rank3]:2025-10-29 06:56:16,168 - INFO - [Step 60] „Ä∞Ô∏è Monitoring Upperbound
[rank3]:2025-10-29 06:56:39,453 - INFO - [Step 70] ‚úîÔ∏è  Setting Upperbound
[rank2]:2025-10-29 06:56:39,778 - WARNING - Batch index 281 is larger than freeze ratio history length 0. Filling with zeros.
[rank3]:2025-10-29 06:56:39,759 - INFO - [Step 70] „Ä∞Ô∏è Monitoring Lowerbound
[rank0]:2025-10-29 06:56:39,787 - WARNING - Batch index 281 is larger than freeze ratio history length 0. Filling with zeros.
[rank1]:2025-10-29 06:56:39,786 - WARNING - Batch index 281 is larger than freeze ratio history length 0. Filling with zeros.
[rank1]:2025-10-29 06:56:39,806 - WARNING - Batch index 281 is larger than freeze ratio history length 0. Filling with zeros.
[rank1]:2025-10-29 06:56:39,828 - WARNING - Batch index 281 is larger than freeze ratio history length 0. Filling with zeros.
[rank2]:2025-10-29 06:56:39,803 - WARNING - Batch index 281 is larger than freeze ratio history length 0. Filling with zeros.
[rank2]:2025-10-29 06:56:39,829 - WARNING - Batch index 281 is larger than freeze ratio history length 0. Filling with zeros.
[rank2]:2025-10-29 06:56:39,858 - WARNING - Batch index 281 is larger than freeze ratio history length 0. Filling with zeros.
[rank2]:2025-10-29 06:56:42,196 - WARNING - Batch index 281 is larger than freeze ratio history length 0. Filling with zeros.
[rank3]:2025-10-29 06:56:42,146 - WARNING - Batch index 281 is larger than freeze ratio history length 0. Filling with zeros.
[rank3]:2025-10-29 06:56:42,165 - WARNING - Batch index 281 is larger than freeze ratio history length 0. Filling with zeros.
[rank3]:2025-10-29 06:56:42,184 - WARNING - Batch index 281 is larger than freeze ratio history length 0. Filling with zeros.
[rank3]:2025-10-29 06:56:42,206 - WARNING - Batch index 281 is larger than freeze ratio history length 0. Filling with zeros.
[rank1]:2025-10-29 06:56:42,208 - WARNING - Batch index 281 is larger than freeze ratio history length 0. Filling with zeros.
[rank2]:2025-10-29 06:56:42,239 - WARNING - Batch index 281 is larger than freeze ratio history length 0. Filling with zeros.
[rank2]:2025-10-29 06:56:42,281 - WARNING - Batch index 281 is larger than freeze ratio history length 0. Filling with zeros.
[rank3]:2025-10-29 06:56:42,230 - WARNING - Batch index 281 is larger than freeze ratio history length 0. Filling with zeros.
[rank3]:2025-10-29 06:56:42,254 - WARNING - Batch index 281 is larger than freeze ratio history length 0. Filling with zeros.
[rank3]:2025-10-29 06:56:42,279 - WARNING - Batch index 281 is larger than freeze ratio history length 0. Filling with zeros.
[rank3]:2025-10-29 06:56:42,302 - WARNING - Batch index 281 is larger than freeze ratio history length 0. Filling with zeros.
[rank0]:2025-10-29 06:56:42,312 - WARNING - Batch index 281 is larger than freeze ratio history length 0. Filling with zeros.
[rank0]:2025-10-29 06:56:42,338 - WARNING - Batch index 281 is larger than freeze ratio history length 0. Filling with zeros.
[rank1]:2025-10-29 06:56:42,251 - WARNING - Batch index 281 is larger than freeze ratio history length 0. Filling with zeros.
[rank1]:2025-10-29 06:56:42,336 - WARNING - Batch index 281 is larger than freeze ratio history length 0. Filling with zeros.
[rank2]:2025-10-29 06:56:42,338 - WARNING - Batch index 281 is larger than freeze ratio history length 0. Filling with zeros.
[rank0]:2025-10-29 06:56:42,360 - WARNING - Batch index 281 is larger than freeze ratio history length 0. Filling with zeros.
[rank0]:2025-10-29 06:56:42,385 - WARNING - Batch index 281 is larger than freeze ratio history length 0. Filling with zeros.
[rank0]:2025-10-29 06:56:42,387 - WARNING - Batch index 281 is larger than freeze ratio history length 0. Filling with zeros.
[rank0]:2025-10-29 06:56:42,388 - WARNING - Batch index 281 is larger than freeze ratio history length 0. Filling with zeros.
[rank0]:2025-10-29 06:56:42,389 - WARNING - Batch index 281 is larger than freeze ratio history length 0. Filling with zeros.
[rank1]:2025-10-29 06:56:42,355 - WARNING - Batch index 281 is larger than freeze ratio history length 0. Filling with zeros.
[rank1]:2025-10-29 06:56:42,379 - WARNING - Batch index 281 is larger than freeze ratio history length 0. Filling with zeros.
[rank3]:2025-10-29 06:57:17,462 - INFO - [Step 90] ‚úîÔ∏è  Setting Lowerbound
[rank3]:2025-10-29 06:57:17,948 - INFO - Pipeline schedule is saved as: /data2/shcho/torchtitan/images/1028_1F1B_timelyapf_dm1/pipeline_schedule/251029_0657_max_batch_time.svg
[rank3]:> Batch Time: 514.14 ms, GPU Bubble Ratio: 49.18%, 46.50%, 58.41%, 18.26%
[rank3]:2025-10-29 06:57:18,137 - INFO - Pipeline schedule is saved as: /data2/shcho/torchtitan/images/1028_1F1B_timelyapf_dm1/pipeline_schedule/251029_0657_min_batch_time.svg
[rank3]:> Batch Time: 357.36 ms, GPU Bubble Ratio: 81.44%, 31.69%, 47.61%, 17.33%
[rank3]:2025-10-29 06:57:18,342 - INFO - Pipeline schedule is saved as: /data2/shcho/torchtitan/images/1028_1F1B_timelyapf_dm1/pipeline_schedule/251029_0657_frozen_pipeline_schedule.svg
[rank3]:> Batch Time: 357.36 ms, GPU Bubble Ratio: 33.70%, 24.18%, 41.14%, 17.33%
[rank3]:2025-10-29 06:57:18,342 - INFO - 	> Batch Time: 357.36 ms (Average Freeze Ratio: 0.34, Time Reduction Rate: 0.30)
[rank0]:2025-10-29 06:57:36,797 - INFO - [GC] Peforming periodical GC collection 0.00 seconds
[rank1]:2025-10-29 06:57:38,519 - INFO - Current/Expected Freeze Ratio per Block: [MB0] 0.00/0.00, [MB1] 0.00/0.00, [MB2] 0.00/0.00, [MB3] 0.00/0.00, [MB4] 0.00/0.00, [MB5] 0.00/0.00, [MB6] 0.00/0.00, [MB7] 0.33/1.00
[rank2]:2025-10-29 06:57:38,515 - INFO - Current/Expected Freeze Ratio per Block: [MB0] 0.00/0.00, [MB1] 0.00/0.00, [MB2] 0.00/0.00, [MB3] 0.00/0.00, [MB4] 0.00/0.00, [MB5] 0.00/0.00, [MB6] 0.00/0.00, [MB7] 0.33/1.00
[rank2]:2025-10-29 06:57:38,515 - INFO -  step: 100  loss: -4.0000  grad_norm:  9.3467  memory:  6.43GiB(13.53%)  tps: 7,836  tflops: 61.26  mfu: 19.64%
[rank1]:2025-10-29 06:57:38,519 - INFO -  step: 100  loss: -4.0000  grad_norm:  9.3467  memory:  9.26GiB(19.50%)  tps: 7,836  tflops: 61.26  mfu: 19.64%
[rank0]:2025-10-29 06:57:38,530 - INFO - Current/Expected Freeze Ratio per Block: [MB0] 0.00/0.00, [MB1] 0.00/0.00, [MB2] 0.00/0.00, [MB3] 0.00/0.00, [MB4] 0.00/0.00, [MB5] 0.00/0.00, [MB6] 0.00/0.00, [MB7] 0.33/1.00
[rank0]:2025-10-29 06:57:38,530 - INFO -  step: 100  loss: -4.0000  grad_norm:  9.3467  memory: 13.31GiB(28.01%)  tps: 7,836  tflops: 61.26  mfu: 19.64%
[rank3]:2025-10-29 06:57:40,869 - INFO - Current/Expected Freeze Ratio per Block: [MB0] 0.33/1.00, [MB1] 0.33/1.00, [MB2] 0.33/1.00, [MB3] 0.33/1.00, [MB4] 0.33/1.00, [MB5] 0.33/1.00, [MB6] 0.33/1.00, [MB7] 0.33/1.00
[rank3]:2025-10-29 06:57:40,872 - INFO -  step: 100  loss:  9.8714  grad_norm:  0.0000  memory: 16.43GiB(34.58%)  tps: 7,665  tflops: 59.92  mfu: 19.20%
[rank2]:2025-10-29 06:57:40,952 - INFO - Frozen Ratio History of Rank 2 (Stage 2)  is saved as: /data2/shcho/torchtitan/images/1028_1F1B_timelyapf_dm1/freeze_ratio_history/rank2/251029_0657_stage2_step100.svg
[rank1]:2025-10-29 06:57:40,953 - INFO - Frozen Ratio History of Rank 1 (Stage 1)  is saved as: /data2/shcho/torchtitan/images/1028_1F1B_timelyapf_dm1/freeze_ratio_history/rank1/251029_0657_stage1_step100.svg
[rank0]:2025-10-29 06:57:40,952 - INFO - Frozen Ratio History of Rank 0 (Stage 0)  is saved as: /data2/shcho/torchtitan/images/1028_1F1B_timelyapf_dm1/freeze_ratio_history/rank0/251029_0657_stage0_step100.svg
[rank3]:2025-10-29 06:57:41,053 - INFO - Pipeline schedule is saved as: /data2/shcho/torchtitan/images/1028_1F1B_timelyapf_dm1/pipeline_schedule/251029_0657_real_step100_rank3.svg
[rank3]:> Batch Time: 500.88 ms, GPU Bubble Ratio: 48.33%, 45.52%, 57.73%, 18.54%
[rank3]:2025-10-29 06:57:41,115 - INFO - Frozen Ratio History of Rank 3 (Stage 3)  is saved as: /data2/shcho/torchtitan/images/1028_1F1B_timelyapf_dm1/freeze_ratio_history/rank3/251029_0657_stage3_step100.svg
[rank0]:2025-10-29 06:57:41,247 - INFO - Avg. fwd time: 8.3784 / Avg. bwd time: 18.0568 / Avg. batch time: 530.1216 (ms) / GPU bubble ratio: 60.11%
[rank2]:2025-10-29 06:57:41,335 - INFO - Avg. fwd time: 7.9731 / Avg. bwd time: 17.9094 / Avg. batch time: 463.4302 (ms) / GPU bubble ratio: 55.32%
[rank3]:2025-10-29 06:57:41,298 - INFO - Avg. fwd time: 14.5131 / Avg. bwd time: 32.8010 / Avg. batch time: 412.4215 (ms) / GPU bubble ratio: 8.22%
[rank1]:2025-10-29 06:57:41,368 - INFO - Avg. fwd time: 10.3196 / Avg. bwd time: 23.1147 / Avg. batch time: 499.7195 (ms) / GPU bubble ratio: 46.48%
[rank0]:2025-10-29 06:59:18,037 - INFO - [GC] Peforming periodical GC collection 0.01 seconds
[rank1]:2025-10-29 06:59:19,820 - INFO - Current/Expected Freeze Ratio per Block: [MB0] 0.00/0.00, [MB1] 0.00/0.00, [MB2] 0.00/0.00, [MB3] 0.00/0.00, [MB4] 0.00/0.00, [MB5] 0.00/0.00, [MB6] 0.00/0.00, [MB7] 0.67/1.00
[rank1]:2025-10-29 06:59:19,821 - INFO -  step: 150  loss: -4.0000  grad_norm:  4.8879  memory:  9.26GiB(19.50%)  tps: 8,087  tflops: 63.22  mfu: 20.26%
[rank0]:2025-10-29 06:59:19,831 - INFO - Current/Expected Freeze Ratio per Block: [MB0] 0.00/0.00, [MB1] 0.00/0.00, [MB2] 0.00/0.00, [MB3] 0.00/0.00, [MB4] 0.00/0.00, [MB5] 0.00/0.00, [MB6] 0.00/0.00, [MB7] 0.67/1.00
[rank0]:2025-10-29 06:59:19,832 - INFO -  step: 150  loss: -4.0000  grad_norm:  4.8879  memory: 13.31GiB(28.01%)  tps: 8,087  tflops: 63.22  mfu: 20.26%
[rank2]:2025-10-29 06:59:19,816 - INFO - Current/Expected Freeze Ratio per Block: [MB0] 0.00/0.00, [MB1] 0.00/0.00, [MB2] 0.00/0.00, [MB3] 0.00/0.00, [MB4] 0.00/0.00, [MB5] 0.00/0.00, [MB6] 0.00/0.00, [MB7] 0.67/1.00
[rank2]:2025-10-29 06:59:19,817 - INFO -  step: 150  loss: -4.0000  grad_norm:  4.8879  memory:  6.45GiB(13.58%)  tps: 8,087  tflops: 63.22  mfu: 20.26%
[rank3]:2025-10-29 06:59:22,203 - INFO - Current/Expected Freeze Ratio per Block: [MB0] 0.67/1.00, [MB1] 0.67/1.00, [MB2] 0.67/1.00, [MB3] 0.67/1.00, [MB4] 0.67/1.00, [MB5] 0.67/1.00, [MB6] 0.67/1.00, [MB7] 0.67/1.00
[rank3]:2025-10-29 06:59:22,206 - INFO -  step: 150  loss:  5.7504  grad_norm:  4.8879  memory: 16.43GiB(34.58%)  tps: 8,084  tflops: 63.20  mfu: 20.26%
[rank2]:2025-10-29 06:59:22,574 - INFO - Avg. fwd time: 7.9064 / Avg. bwd time: 18.0452 / Avg. batch time: 447.0987 (ms) / GPU bubble ratio: 53.56%
[rank3]:2025-10-29 06:59:22,551 - INFO - Avg. fwd time: 14.7512 / Avg. bwd time: 29.2023 / Avg. batch time: 384.2632 (ms) / GPU bubble ratio: 8.49%
[rank0]:2025-10-29 06:59:22,623 - INFO - Avg. fwd time: 8.2958 / Avg. bwd time: 17.2379 / Avg. batch time: 514.0740 (ms) / GPU bubble ratio: 60.26%
[rank1]:2025-10-29 06:59:22,600 - INFO - Avg. fwd time: 10.2830 / Avg. bwd time: 23.2614 / Avg. batch time: 483.1773 (ms) / GPU bubble ratio: 44.46%
[rank0]:2025-10-29 07:00:57,843 - INFO - [GC] Peforming periodical GC collection 0.00 seconds
[rank2]:2025-10-29 07:00:59,603 - INFO - Current/Expected Freeze Ratio per Block: [MB0] 0.00/0.00, [MB1] 0.00/0.00, [MB2] 0.00/0.00, [MB3] 0.00/0.00, [MB4] 0.00/0.00, [MB5] 0.00/0.00, [MB6] 0.00/0.00, [MB7] 1.00/1.00
[rank2]:2025-10-29 07:00:59,603 - INFO -  step: 200  loss: -4.0000  grad_norm:  4.8573  memory:  6.45GiB(13.58%)  tps: 8,210  tflops: 64.18  mfu: 20.57%
[rank2]:2025-10-29 07:00:59,604 - INFO - üîé  Running validation at step 200
[rank0]:2025-10-29 07:00:59,618 - INFO - Current/Expected Freeze Ratio per Block: [MB0] 0.00/0.00, [MB1] 0.00/0.00, [MB2] 0.00/0.00, [MB3] 0.00/0.00, [MB4] 0.00/0.00, [MB5] 0.00/0.00, [MB6] 0.00/0.00, [MB7] 1.00/1.00
[rank1]:2025-10-29 07:00:59,607 - INFO - Current/Expected Freeze Ratio per Block: [MB0] 0.00/0.00, [MB1] 0.00/0.00, [MB2] 0.00/0.00, [MB3] 0.00/0.00, [MB4] 0.00/0.00, [MB5] 0.00/0.00, [MB6] 0.00/0.00, [MB7] 1.00/1.00
[rank1]:2025-10-29 07:00:59,607 - INFO -  step: 200  loss: -4.0000  grad_norm:  4.8573  memory:  9.26GiB(19.50%)  tps: 8,210  tflops: 64.18  mfu: 20.57%
[rank1]:2025-10-29 07:00:59,608 - INFO - üîé  Running validation at step 200
[rank0]:2025-10-29 07:00:59,618 - INFO -  step: 200  loss: -4.0000  grad_norm:  4.8573  memory: 13.31GiB(28.01%)  tps: 8,210  tflops: 64.18  mfu: 20.57%
[rank0]:2025-10-29 07:00:59,618 - INFO - üîé  Running validation at step 200
[rank3]:2025-10-29 07:01:01,979 - INFO - Current/Expected Freeze Ratio per Block: [MB0] 1.00/1.00, [MB1] 1.00/1.00, [MB2] 1.00/1.00, [MB3] 1.00/1.00, [MB4] 1.00/1.00, [MB5] 1.00/1.00, [MB6] 1.00/1.00, [MB7] 1.00/1.00
[rank3]:2025-10-29 07:01:01,981 - INFO -  step: 200  loss:  4.8522  grad_norm:  4.8573  memory: 16.43GiB(34.58%)  tps: 8,211  tflops: 64.19  mfu: 20.57%
[rank3]:2025-10-29 07:01:01,982 - INFO - üîé  Running validation at step 200
[rank0]:2025-10-29 07:01:20,195 - INFO - validate step: 200  loss: -1.0000  memory: 13.31GiB(28.01%)  tps: 19,906
[rank1]:2025-10-29 07:01:20,208 - INFO - validate step: 200  loss: -1.0000  memory:  9.26GiB(19.50%)  tps: 19,883
[rank2]:2025-10-29 07:01:20,223 - INFO - validate step: 200  loss: -1.0000  memory:  6.45GiB(13.58%)  tps: 19,866
[rank3]:2025-10-29 07:01:20,225 - INFO - validate step: 200  loss:  1.1342  memory: 16.43GiB(34.58%)  tps: 22,453
[rank0]:2025-10-29 07:01:20,300 - INFO - Frozen Ratio History of Rank 0 (Stage 0)  is saved as: /data2/shcho/torchtitan/images/1028_1F1B_timelyapf_dm1/freeze_ratio_history/rank0/251029_0701_stage0_step200.svg
[rank1]:2025-10-29 07:01:20,301 - INFO - Frozen Ratio History of Rank 1 (Stage 1)  is saved as: /data2/shcho/torchtitan/images/1028_1F1B_timelyapf_dm1/freeze_ratio_history/rank1/251029_0701_stage1_step200.svg
[rank2]:2025-10-29 07:01:20,302 - INFO - Frozen Ratio History of Rank 2 (Stage 2)  is saved as: /data2/shcho/torchtitan/images/1028_1F1B_timelyapf_dm1/freeze_ratio_history/rank2/251029_0701_stage2_step200.svg
[rank3]:2025-10-29 07:01:20,421 - INFO - Pipeline schedule is saved as: /data2/shcho/torchtitan/images/1028_1F1B_timelyapf_dm1/pipeline_schedule/251029_0701_real_step200_rank3.svg
[rank3]:> Batch Time: 391.36 ms, GPU Bubble Ratio: 38.22%, 31.70%, 46.90%, 22.34%
[rank3]:2025-10-29 07:01:20,487 - INFO - Frozen Ratio History of Rank 3 (Stage 3)  is saved as: /data2/shcho/torchtitan/images/1028_1F1B_timelyapf_dm1/freeze_ratio_history/rank3/251029_0701_stage3_step200.svg
[rank1]:[rank1]:W1029 07:01:22.216000 3710836 site-packages/torch/_dynamo/convert_frame.py:1515] [0/8] torch._dynamo hit config.recompile_limit (8)
[rank1]:[rank1]:W1029 07:01:22.216000 3710836 site-packages/torch/_dynamo/convert_frame.py:1515] [0/8]    function: 'forward' (/home/shcho/torchtitan/torchtitan/models/llama3/model/model.py:284)
[rank1]:[rank1]:W1029 07:01:22.216000 3710836 site-packages/torch/_dynamo/convert_frame.py:1515] [0/8]    last reason: 0/7: tensor 'self._modules['attention']._modules['wq']._parameters['weight']' requires_grad mismatch. expected requires_grad=1. Guard failed on a parameter, consider using torch._dynamo.config.force_parameter_static_shapes = False to allow dynamism on parameters.
[rank1]:[rank1]:W1029 07:01:22.216000 3710836 site-packages/torch/_dynamo/convert_frame.py:1515] [0/8] To log all recompilation reasons, use TORCH_LOGS="recompiles".
[rank1]:[rank1]:W1029 07:01:22.216000 3710836 site-packages/torch/_dynamo/convert_frame.py:1515] [0/8] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html
[rank1]:2025-10-29 07:01:22,220 - INFO - Destroying the purge thread.
[rank1]:[rank1]: Traceback (most recent call last):
[rank1]:[rank1]:   File "/data2/shcho/miniforge3/envs/llm_eval/lib/python3.11/site-packages/torch/distributed/pipelining/stage.py", line 693, in forward_one_chunk
[rank1]:[rank1]:     output = self.forward_maybe_with_nosync(*composite_args, **composite_kwargs)
[rank1]:[rank1]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank1]:[rank1]:   File "/data2/shcho/miniforge3/envs/llm_eval/lib/python3.11/site-packages/torch/distributed/pipelining/stage.py", line 567, in forward_maybe_with_nosync
[rank1]:[rank1]:     out_val = self.submod(*args, **kwargs)
[rank1]:[rank1]:               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank1]:[rank1]:   File "/data2/shcho/miniforge3/envs/llm_eval/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1780, in _wrapped_call_impl
[rank1]:[rank1]:     return self._call_impl(*args, **kwargs)
[rank1]:[rank1]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank1]:[rank1]:   File "/data2/shcho/miniforge3/envs/llm_eval/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1791, in _call_impl
[rank1]:[rank1]:     return forward_call(*args, **kwargs)
[rank1]:[rank1]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank1]:[rank1]:   File "/home/shcho/torchtitan/torchtitan/models/llama3/model/model.py", line 432, in forward
[rank1]:[rank1]:     h = layer(h, self.freqs_cis)
[rank1]:[rank1]:         ^^^^^^^^^^^^^^^^^^^^^^^^
[rank1]:[rank1]:   File "/data2/shcho/miniforge3/envs/llm_eval/lib/python3.11/site-packages/torch/_dynamo/eval_frame.py", line 418, in __call__
[rank1]:[rank1]:     return super().__call__(*args, **kwargs)
[rank1]:[rank1]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank1]:[rank1]:   File "/data2/shcho/miniforge3/envs/llm_eval/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1780, in _wrapped_call_impl
[rank1]:[rank1]:     return self._call_impl(*args, **kwargs)
[rank1]:[rank1]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank1]:[rank1]:   File "/data2/shcho/miniforge3/envs/llm_eval/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1791, in _call_impl
[rank1]:[rank1]:     return forward_call(*args, **kwargs)
[rank1]:[rank1]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank1]:[rank1]:   File "/data2/shcho/miniforge3/envs/llm_eval/lib/python3.11/site-packages/torch/_dynamo/eval_frame.py", line 895, in compile_wrapper
[rank1]:[rank1]:     return fn(*args, **kwargs)
[rank1]:[rank1]:            ^^^^^^^^^^^^^^^^^^^
[rank1]:[rank1]:   File "/data2/shcho/miniforge3/envs/llm_eval/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1780, in _wrapped_call_impl
[rank1]:[rank1]:     return self._call_impl(*args, **kwargs)
[rank1]:[rank1]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank1]:[rank1]:   File "/data2/shcho/miniforge3/envs/llm_eval/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1791, in _call_impl
[rank1]:[rank1]:     return forward_call(*args, **kwargs)
[rank1]:[rank1]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank1]:[rank1]:   File "/data2/shcho/miniforge3/envs/llm_eval/lib/python3.11/site-packages/torch/_dynamo/convert_frame.py", line 2034, in __call__
[rank1]:[rank1]:     result = self._torchdynamo_orig_backend(
[rank1]:[rank1]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank1]:[rank1]:   File "/data2/shcho/miniforge3/envs/llm_eval/lib/python3.11/site-packages/torch/_dynamo/convert_frame.py", line 701, in __call__
[rank1]:[rank1]:     result = _compile(
[rank1]:[rank1]:              ^^^^^^^^^
[rank1]:[rank1]:   File "/data2/shcho/miniforge3/envs/llm_eval/lib/python3.11/site-packages/torch/_dynamo/convert_frame.py", line 1532, in _compile
[rank1]:[rank1]:     raise FailOnRecompileLimitHit(
[rank1]:[rank1]: torch._dynamo.exc.FailOnRecompileLimitHit: recompile_limit reached with fullgraph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
[rank1]:
[rank1]:[rank1]: The above exception was the direct cause of the following exception:
[rank1]:
[rank1]:[rank1]: Traceback (most recent call last):
[rank1]:[rank1]:   File "<frozen runpy>", line 198, in _run_module_as_main
[rank1]:[rank1]:   File "<frozen runpy>", line 88, in _run_code
[rank1]:[rank1]:   File "/home/shcho/torchtitan/timelyfreeze/train.py", line 725, in <module>
[rank1]:[rank1]:     trainer.train()
[rank1]:[rank1]:   File "/data2/shcho/miniforge3/envs/llm_eval/lib/python3.11/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 362, in wrapper
[rank1]:[rank1]:     return f(*args, **kwargs)
[rank1]:[rank1]:            ^^^^^^^^^^^^^^^^^^
[rank1]:[rank1]:   File "/home/shcho/torchtitan/timelyfreeze/train.py", line 584, in train
[rank1]:[rank1]:     self.train_step(data_iterator)
[rank1]:[rank1]:   File "/home/shcho/torchtitan/timelyfreeze/train.py", line 490, in train_step
[rank1]:[rank1]:     loss = self.forward_backward_step(input_dict, labels)
[rank1]:[rank1]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank1]:[rank1]:   File "/home/shcho/torchtitan/timelyfreeze/train.py", line 447, in forward_backward_step
[rank1]:[rank1]:     self.pp_schedule.step(
[rank1]:[rank1]:   File "/data2/shcho/miniforge3/envs/llm_eval/lib/python3.11/site-packages/torch/distributed/pipelining/schedules.py", line 626, in step
[rank1]:[rank1]:     self._step_microbatches(args_split, kwargs_split, targets_split, losses)
[rank1]:[rank1]:   File "/data2/shcho/miniforge3/envs/llm_eval/lib/python3.11/site-packages/torch/distributed/pipelining/schedules.py", line 863, in _step_microbatches
[rank1]:[rank1]:     output = self._stage.forward_one_chunk(
[rank1]:[rank1]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank1]:[rank1]:   File "/data2/shcho/miniforge3/envs/llm_eval/lib/python3.11/site-packages/torch/distributed/pipelining/stage.py", line 701, in forward_one_chunk
[rank1]:[rank1]:     raise RuntimeError(exc_msg) from e
[rank1]:[rank1]: RuntimeError: 
[rank1]:[rank1]:             [Stage 1] failed to run forward:
[rank1]:[rank1]:             args: ('Tensor(torch.Size([2, 1024, 2048]), grad=True, dtype=torch.float32)',)
[rank1]:[rank1]:             kwargs: {'input_batch': 'Tensor(torch.Size([2, 1024]), grad=False, dtype=torch.int64)'}
[rank1]:[rank1]:             
W1029 07:01:24.723000 3710747 site-packages/torch/distributed/elastic/multiprocessing/api.py:940] Sending process 3710835 closing signal SIGTERM
W1029 07:01:24.726000 3710747 site-packages/torch/distributed/elastic/multiprocessing/api.py:940] Sending process 3710837 closing signal SIGTERM
W1029 07:01:24.728000 3710747 site-packages/torch/distributed/elastic/multiprocessing/api.py:940] Sending process 3710838 closing signal SIGTERM
E1029 07:01:25.286000 3710747 site-packages/torch/distributed/elastic/multiprocessing/api.py:914] failed (exitcode: 1) local_rank: 1 (pid: 3710836) of binary: /data2/shcho/miniforge3/envs/llm_eval/bin/python3.11
E1029 07:01:25.302000 3710747 site-packages/torch/distributed/elastic/multiprocessing/errors/error_handler.py:141] no error file defined for parent, to copy child error file (/tmp/torchelastic_97gacu5z/cce7ff06-ed91-4eab-9031-2c671393598b_nstczru4/attempt_0/1/error.json)
[rank0]:Stage 0: Modules to keep: {'layers.1', 'layers.0', 'layers.2', 'tok_embeddings', 'layers.3'}
[rank1]:Stage 1: Modules to keep: {'layers.8', 'layers.7', 'layers.4', 'layers.5', 'layers.6'}
[rank2]:Stage 2: Modules to keep: {'layers.9', 'layers.12', 'layers.11', 'layers.10'}
[rank3]:Stage 3: Modules to keep: {'layers.15', 'output', 'layers.13', 'norm', 'layers.14'}
[rank0]:[Gloo] Rank 0 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
[rank3]:----- TimelyFreeze‚è∞ Configuration:
[rank3]:	- job:
[rank3]:		- config_file: /home/shcho/torchtitan/logs/dmserver1/1028_llama1b/config.toml
[rank3]:		- dump_folder: /data2/shcho/torchtitan
[rank3]:		- description: "Main Table Experiment, without streaming mode, sample-level with truncation, 2 epochs, with bf16 autocast"
[rank3]:		- use_for_integration_test: False
[rank3]:		- print_args: False
[rank3]:		- basename: 1028_1F1B_timelyapf_dm1
[rank3]:	- profiling:
[rank3]:		- enable_profiling: False
[rank3]:		- save_traces_folder: /data2/shcho/torchtitan/profile_trace/1028_1F1B_timelyapf_dm1
[rank3]:		- profile_freq: 100
[rank3]:		- enable_memory_snapshot: False
[rank3]:		- save_memory_snapshot_folder: /data2/shcho/torchtitan/memory_snapshot/1028_1F1B_timelyapf_dm1
[rank3]:	- metrics:
[rank3]:		- log_freq: 50
[rank3]:		- enable_tensorboard: False
[rank3]:		- disable_color_printing: True
[rank3]:		- save_tb_folder: /data2/shcho/torchtitan/tb/1028_1F1B_timelyapf_dm1
[rank3]:		- save_for_all_ranks: False
[rank3]:		- enable_wandb: True
[rank3]:		- image_folder: /data2/shcho/torchtitan/images/1028_1F1B_timelyapf_dm1
[rank3]:		- pplog_freq: 200
[rank3]:		- draw_freq: 100
[rank3]:		- wandb_name: 1028_1F1B_timelyapf_dm1
[rank3]:		- draw_graph: True
[rank3]:	- model:
[rank3]:		- name: llama3
[rank3]:		- flavor: 1B
[rank3]:		- tokenizer_path: ./assets/tokenizer/Llama-3.2-1B-Instruct
[rank3]:		- converters: []
[rank3]:		- print_after_conversion: False
[rank3]:	- optimizer:
[rank3]:		- name: AdamW
[rank3]:		- lr: 1e-05
[rank3]:		- beta1: 0.9
[rank3]:		- beta2: 0.95
[rank3]:		- eps: 1e-08
[rank3]:		- weight_decay: 0.1
[rank3]:		- implementation: fused
[rank3]:		- early_step_in_backward: False
[rank3]:	- lr_scheduler:
[rank3]:		- warmup_steps: 100
[rank3]:		- decay_ratio: 0.8
[rank3]:		- decay_type: cosine
[rank3]:		- min_lr_factor: 0.0
[rank3]:	- training:
[rank3]:		- dataset: alpaca
[rank3]:		- dataset_path: None
[rank3]:		- local_batch_size: 16
[rank3]:		- global_batch_size: 64
[rank3]:		- seq_len: 1024
[rank3]:		- max_norm: 1.0
[rank3]:		- steps: 1600
[rank3]:		- enable_cpu_offload: False
[rank3]:		- mixed_precision_param: bfloat16
[rank3]:		- mixed_precision_reduce: float32
[rank3]:		- compile: True
[rank3]:		- gc_freq: 50
[rank3]:		- gc_debug: False
[rank3]:		- seed: None
[rank3]:		- deterministic: False
[rank3]:	- parallelism:
[rank3]:		- data_parallel_replicate_degree: 1
[rank3]:		- enable_compiled_autograd: False
[rank3]:		- data_parallel_shard_degree: -1
[rank3]:		- fsdp_reshard_after_forward: default
[rank3]:		- tensor_parallel_degree: 1
[rank3]:		- disable_loss_parallel: False
[rank3]:		- enable_async_tensor_parallel: False
[rank3]:		- pipeline_parallel_degree: 4
[rank3]:		- pipeline_parallel_split_points: []
[rank3]:		- module_fqns_per_model_part: None
[rank3]:		- pipeline_parallel_first_stage_less_layers: 1
[rank3]:		- pipeline_parallel_last_stage_less_layers: 1
[rank3]:		- pipeline_parallel_layers_per_stage: None
[rank3]:		- pipeline_parallel_schedule: 1F1B
[rank3]:		- pipeline_parallel_schedule_csv: 
[rank3]:		- pipeline_parallel_microbatch_size: 2
[rank3]:		- context_parallel_degree: 1
[rank3]:		- context_parallel_rotate_method: allgather
[rank3]:		- expert_parallel_degree: 1
[rank3]:		- pp: 4
[rank3]:		- stages_per_rank: 1
[rank3]:		- stages_list: [3]
[rank3]:		- microbatches: 8
[rank3]:	- checkpoint:
[rank3]:		- enable_checkpoint: True
[rank3]:		- checkpoint_folder: /data2/shcho/torchtitan/checkpoint/1028_1F1B_timelyapf_dm1
[rank3]:		- interval: 800
[rank3]:		- initial_load_path: /data2/shcho/torchtitan/base_model/Llama-3.2-1B-Instruct/original_dcp
[rank3]:		- initial_load_model_only: True
[rank3]:		- initial_load_in_hf: False
[rank3]:		- last_save_model_only: True
[rank3]:		- last_save_in_hf: False
[rank3]:		- export_dtype: float16
[rank3]:		- async_mode: async
[rank3]:		- keep_latest_k: 2
[rank3]:		- load_step: -1
[rank3]:		- exclude_from_loading: ['dataloader', 'lr_scheduler', 'optimizer', 'train_state']
[rank3]:		- enable_first_step_checkpoint: False
[rank3]:		- create_seed_checkpoint: False
[rank3]:	- activation_checkpoint:
[rank3]:		- mode: none
[rank3]:		- selective_ac_option: op
[rank3]:		- per_op_sac_force_recompute_mm_shapes_by_fqns: ['moe.router.gate']
[rank3]:	- float8:
[rank3]:		- enable_fsdp_float8_all_gather: False
[rank3]:		- precompute_float8_dynamic_scale_for_fsdp: False
[rank3]:		- recipe_name: None
[rank3]:		- filter_fqns: ['output']
[rank3]:		- emulate: False
[rank3]:		- moe_fqns_prototype: []
[rank3]:	- mx:
[rank3]:		- mxfp8_dim1_cast_kernel_choice: triton
[rank3]:		- recipe_name: mxfp8
[rank3]:		- filter_fqns: ['output']
[rank3]:		- moe_fqns_prototype: []
[rank3]:	- comm:
[rank3]:		- init_timeout_seconds: 300
[rank3]:		- train_timeout_seconds: 300
[rank3]:		- trace_buf_size: 20000
[rank3]:		- save_traces_folder: /data2/shcho/torchtitan/comm_traces/1028_1F1B_timelyapf_dm1
[rank3]:		- world_size: 4
[rank3]:		- global_rank: 3
[rank3]:		- local_rank: 3
[rank3]:		- dp: 1
[rank3]:		- pp: 4
[rank3]:		- pp_rank: 3
[rank3]:		- dp_rank: 0
[rank3]:		- master_dp_rank: 0
[rank3]:	- memory_estimation:
[rank3]:		- enabled: False
[rank3]:		- disable_fake_mode: False
[rank3]:	- fault_tolerance:
[rank3]:		- enable: False
[rank3]:		- process_group: gloo
[rank3]:		- process_group_timeout_ms: 10000
[rank3]:		- replica_id: 0
[rank3]:		- group_size: 0
[rank3]:		- min_replica_size: 1
[rank3]:		- semi_sync_method: None
[rank3]:		- sync_steps: 5
[rank3]:		- should_quantize: False
[rank3]:		- fragment_sync_delay: 0
[rank3]:		- fragment_update_alpha: 0.0
[rank3]:	- experimental:
[rank3]:		- custom_import: 
[rank3]:		- custom_args_module: 
[rank3]:	- validation:
[rank3]:		- enabled: True
[rank3]:		- dataset: c4_validation
[rank3]:		- dataset_path: None
[rank3]:		- local_batch_size: 16
[rank3]:		- seq_len: 1024
[rank3]:		- freq: 200
[rank3]:		- steps: 100
[rank3]:	- freezing:
[rank3]:		- freeze: True
[rank3]:		- metric_type: timelyapf
[rank3]:		- phase_unit: 50
[rank3]:		- stability_check_freq: 10
[rank3]:		- aggressiveness: 0
[rank3]:
[rank3]:[Gloo] Rank 3 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
[rank2]:[Gloo] Rank 2 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
[rank1]:[Gloo] Rank 1 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
Traceback (most recent call last):
  File "/data2/shcho/miniforge3/envs/llm_eval/bin/torchrun", line 7, in <module>
    sys.exit(main())
             ^^^^^^
  File "/data2/shcho/miniforge3/envs/llm_eval/lib/python3.11/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 362, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/data2/shcho/miniforge3/envs/llm_eval/lib/python3.11/site-packages/torch/distributed/run.py", line 946, in main
    run(args)
  File "/data2/shcho/miniforge3/envs/llm_eval/lib/python3.11/site-packages/torch/distributed/run.py", line 937, in run
    elastic_launch(
  File "/data2/shcho/miniforge3/envs/llm_eval/lib/python3.11/site-packages/torch/distributed/launcher/api.py", line 159, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data2/shcho/miniforge3/envs/llm_eval/lib/python3.11/site-packages/torch/distributed/launcher/api.py", line 300, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
timelyfreeze.train FAILED
------------------------------------------------------------
Failures:
[1]:
  time      : 2025-10-29_07:01:25
  host      : elga.kaist.ac.kr
  rank      : 0 (local_rank: 0)
  exitcode  : -15 (pid: 3710835)
  error_file: <N/A>
  traceback : Signal 15 (SIGTERM) received by PID 3710835
[2]:
  time      : 2025-10-29_07:01:25
  host      : elga.kaist.ac.kr
  rank      : 2 (local_rank: 2)
  exitcode  : -15 (pid: 3710837)
  error_file: <N/A>
  traceback : Signal 15 (SIGTERM) received by PID 3710837
[3]:
  time      : 2025-10-29_07:01:25
  host      : elga.kaist.ac.kr
  rank      : 3 (local_rank: 3)
  exitcode  : -15 (pid: 3710838)
  error_file: <N/A>
  traceback : Signal 15 (SIGTERM) received by PID 3710838
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2025-10-29_07:01:22
  host      : elga.kaist.ac.kr
  rank      : 1 (local_rank: 1)
  exitcode  : 1 (pid: 3710836)
  error_file: /tmp/torchelastic_97gacu5z/cce7ff06-ed91-4eab-9031-2c671393598b_nstczru4/attempt_0/1/error.json
  traceback : Traceback (most recent call last):
    File "/data2/shcho/miniforge3/envs/llm_eval/lib/python3.11/site-packages/torch/distributed/pipelining/stage.py", line 693, in forward_one_chunk
      output = self.forward_maybe_with_nosync(*composite_args, **composite_kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    File "/data2/shcho/miniforge3/envs/llm_eval/lib/python3.11/site-packages/torch/distributed/pipelining/stage.py", line 567, in forward_maybe_with_nosync
      out_val = self.submod(*args, **kwargs)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    File "/data2/shcho/miniforge3/envs/llm_eval/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1780, in _wrapped_call_impl
      return self._call_impl(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    File "/data2/shcho/miniforge3/envs/llm_eval/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1791, in _call_impl
      return forward_call(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    File "/home/shcho/torchtitan/torchtitan/models/llama3/model/model.py", line 432, in forward
      h = layer(h, self.freqs_cis)
          ^^^^^^^^^^^^^^^^^^^^^^^^
    File "/data2/shcho/miniforge3/envs/llm_eval/lib/python3.11/site-packages/torch/_dynamo/eval_frame.py", line 418, in __call__
      return super().__call__(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    File "/data2/shcho/miniforge3/envs/llm_eval/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1780, in _wrapped_call_impl
      return self._call_impl(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    File "/data2/shcho/miniforge3/envs/llm_eval/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1791, in _call_impl
      return forward_call(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    File "/data2/shcho/miniforge3/envs/llm_eval/lib/python3.11/site-packages/torch/_dynamo/eval_frame.py", line 895, in compile_wrapper
      return fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
    File "/data2/shcho/miniforge3/envs/llm_eval/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1780, in _wrapped_call_impl
      return self._call_impl(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    File "/data2/shcho/miniforge3/envs/llm_eval/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1791, in _call_impl
      return forward_call(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    File "/data2/shcho/miniforge3/envs/llm_eval/lib/python3.11/site-packages/torch/_dynamo/convert_frame.py", line 2034, in __call__
      result = self._torchdynamo_orig_backend(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    File "/data2/shcho/miniforge3/envs/llm_eval/lib/python3.11/site-packages/torch/_dynamo/convert_frame.py", line 701, in __call__
      result = _compile(
               ^^^^^^^^^
    File "/data2/shcho/miniforge3/envs/llm_eval/lib/python3.11/site-packages/torch/_dynamo/convert_frame.py", line 1532, in _compile
      raise FailOnRecompileLimitHit(
  torch._dynamo.exc.FailOnRecompileLimitHit: recompile_limit reached with fullgraph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
  
  The above exception was the direct cause of the following exception:
  
  Traceback (most recent call last):
    File "/data2/shcho/miniforge3/envs/llm_eval/lib/python3.11/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 362, in wrapper
      return f(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^
    File "/home/shcho/torchtitan/timelyfreeze/train.py", line 584, in train
      self.train_step(data_iterator)
    File "/home/shcho/torchtitan/timelyfreeze/train.py", line 490, in train_step
      loss = self.forward_backward_step(input_dict, labels)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    File "/home/shcho/torchtitan/timelyfreeze/train.py", line 447, in forward_backward_step
      self.pp_schedule.step(
    File "/data2/shcho/miniforge3/envs/llm_eval/lib/python3.11/site-packages/torch/distributed/pipelining/schedules.py", line 626, in step
      self._step_microbatches(args_split, kwargs_split, targets_split, losses)
    File "/data2/shcho/miniforge3/envs/llm_eval/lib/python3.11/site-packages/torch/distributed/pipelining/schedules.py", line 863, in _step_microbatches
      output = self._stage.forward_one_chunk(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    File "/data2/shcho/miniforge3/envs/llm_eval/lib/python3.11/site-packages/torch/distributed/pipelining/stage.py", line 701, in forward_one_chunk
      raise RuntimeError(exc_msg) from e
  RuntimeError: 
              [Stage 1] failed to run forward:
              args: ('Tensor(torch.Size([2, 1024, 2048]), grad=True, dtype=torch.float32)',)
              kwargs: {'input_batch': 'Tensor(torch.Size([2, 1024]), grad=False, dtype=torch.int64)'}
              
  
============================================================

üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•
‚úîÔ∏èCurrent Timestamp: 2025. 10. 29. (Ïàò) 15:46:30 KST
‚úîÔ∏èSERVER: dmserver1 (143.248.135.95),  GPUs: 3,4,5,6
‚úîÔ∏èSCRIPT: /home/shcho/torchtitan/logs/dmserver1/1028_llama1b/run.sh
‚úîÔ∏èOUTPUT: /home/shcho/torchtitan/logs/dmserver1/1028_llama1b/1028_1F1B_timelyapf.log
‚úîÔ∏èMain Table Experiment, without streaming mode, sample-level with truncation, 2 epochs, with bf16 autocast
‚úîÔ∏èRunning with timelyapf x 1F1B ... 
‚òëÔ∏è> torchrun --standalone --nnodes=1 --nproc_per_node=4 --local_addr=127.0.0.1 --local-ranks-filter=0,1,2,3 --role=rank --tee=3 -m timelyfreeze.train --job.config_file=/home/shcho/torchtitan/logs/dmserver1/1028_llama1b/config.toml --job.description="Main Table Experiment, without streaming mode, sample-level with truncation, 2 epochs, with bf16 autocast" --parallelism.pipeline_parallel_degree=4  --freezing.freeze --freezing.metric_type=timelyapf
üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•
[rank0]:2025-10-29 15:46:36,616 - INFO - Starting job: "Main Table Experiment, without streaming mode, sample-level with truncation, 2 epochs, with bf16 autocast"
[rank2]:2025-10-29 15:46:36,628 - INFO - Starting job: "Main Table Experiment, without streaming mode, sample-level with truncation, 2 epochs, with bf16 autocast"
[rank1]:2025-10-29 15:46:36,697 - INFO - Starting job: "Main Table Experiment, without streaming mode, sample-level with truncation, 2 epochs, with bf16 autocast"
[rank3]:2025-10-29 15:46:36,786 - INFO - Starting job: "Main Table Experiment, without streaming mode, sample-level with truncation, 2 epochs, with bf16 autocast"
[rank3]:2025-10-29 15:46:37,358 - WARNING - ENV[TORCH_NCCL_ASYNC_ERROR_HANDLING] = 1 will be overridden to 3 based on job config
[rank3]:2025-10-29 15:46:37,361 - INFO - Building 1-D device mesh with ['pp'], [4]
[rank0]:2025-10-29 15:46:37,337 - WARNING - ENV[TORCH_NCCL_ASYNC_ERROR_HANDLING] = 1 will be overridden to 3 based on job config
[rank0]:2025-10-29 15:46:37,340 - INFO - Building 1-D device mesh with ['pp'], [4]
[rank0]:2025-10-29 15:46:37,343 - INFO - [GC] Initial GC collection 0.00 seconds
[rank1]:2025-10-29 15:46:37,346 - WARNING - ENV[TORCH_NCCL_ASYNC_ERROR_HANDLING] = 1 will be overridden to 3 based on job config
[rank1]:2025-10-29 15:46:37,350 - INFO - Building 1-D device mesh with ['pp'], [4]
[rank2]:2025-10-29 15:46:37,360 - WARNING - ENV[TORCH_NCCL_ASYNC_ERROR_HANDLING] = 1 will be overridden to 3 based on job config
[rank2]:2025-10-29 15:46:37,362 - INFO - Building 1-D device mesh with ['pp'], [4]
[rank0]:2025-10-29 15:46:37,764 - INFO - Loading tokenizer from tokenizer.json
[rank0]:2025-10-29 15:46:38,176 - INFO - Preparing alpaca dataset from tatsu-lab/alpaca
[rank3]:/data2/shcho/miniforge3/envs/llm_eval/lib/python3.11/site-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
[rank3]:  warnings.warn(
[rank3]:/data2/shcho/miniforge3/envs/llm_eval/lib/python3.11/site-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
[rank3]:  warnings.warn(
[rank2]:2025-10-29 15:46:41,289 - INFO - CUDA capacity: NVIDIA RTX 6000 Ada Generation with 47.51GiB memory
[rank2]:2025-10-29 15:46:41,329 - WARNING - Peak flops undefined for: NVIDIA RTX 6000 Ada Generation, fallback to A100
[rank2]:2025-10-29 15:46:41,358 - INFO - PP rank 2 is building stage_idx 2 with modules ['layers.9', 'layers.10', 'layers.11', 'layers.12']
[rank2]:2025-10-29 15:46:41,359 - INFO - Using pipeline schedule 1F1B with 8 microbatches and 4 stages.
[rank1]:2025-10-29 15:46:41,480 - INFO - CUDA capacity: NVIDIA RTX 6000 Ada Generation with 47.51GiB memory
[rank1]:2025-10-29 15:46:41,527 - WARNING - Peak flops undefined for: NVIDIA RTX 6000 Ada Generation, fallback to A100
[rank2]:2025-10-29 15:46:41,533 - WARNING - Peak flops undefined for: NVIDIA RTX 6000 Ada Generation, fallback to A100
[rank2]:2025-10-29 15:46:41,534 - INFO - Peak FLOPS used for computing MFU: 3.120e+14
[rank2]:2025-10-29 15:46:41,534 - INFO - CUDA memory usage for model: 0.92GiB(1.94%)
[rank1]:2025-10-29 15:46:41,554 - INFO - PP rank 1 is building stage_idx 1 with modules ['layers.4', 'layers.5', 'layers.6', 'layers.7', 'layers.8']
[rank1]:2025-10-29 15:46:41,554 - INFO - Using pipeline schedule 1F1B with 8 microbatches and 4 stages.
[rank0]:2025-10-29 15:46:41,727 - INFO - Building llama3 1B with TransformerModelArgs(_enforced='This field is used to enforce all fields have defaults.', dim=2048, n_layers=16, n_heads=32, n_kv_heads=8, vocab_size=128256, multiple_of=256, ffn_dim_multiplier=1.5, norm_eps=1e-05, rope_theta=500000, max_seq_len=1024, depth_init=True, use_flex_attn=False, attn_mask_type='causal', eos_id=0)
[rank1]:2025-10-29 15:46:41,735 - WARNING - Peak flops undefined for: NVIDIA RTX 6000 Ada Generation, fallback to A100
[rank1]:2025-10-29 15:46:41,735 - INFO - Peak FLOPS used for computing MFU: 3.120e+14
[rank1]:2025-10-29 15:46:41,735 - INFO - CUDA memory usage for model: 1.13GiB(2.39%)
[rank0]:2025-10-29 15:46:42,017 - INFO - CUDA capacity: NVIDIA RTX 6000 Ada Generation with 47.51GiB memory
[rank3]:wandb: Currently logged in as: orangingq to https://api.wandb.ai. Use `wandb login --relogin` to force relogin
[rank0]:2025-10-29 15:46:42,056 - WARNING - Peak flops undefined for: NVIDIA RTX 6000 Ada Generation, fallback to A100
[rank0]:2025-10-29 15:46:42,058 - INFO - Model llama3 1B size: 1,498,482,688 total parameters
[rank0]:2025-10-29 15:46:42,084 - INFO - PP rank 0 is building stage_idx 0 with modules ['tok_embeddings', 'layers.0', 'layers.1', 'layers.2', 'layers.3']
[rank0]:2025-10-29 15:46:42,084 - INFO - Using pipeline schedule 1F1B with 8 microbatches and 4 stages.
[rank0]:2025-10-29 15:46:42,660 - WARNING - Peak flops undefined for: NVIDIA RTX 6000 Ada Generation, fallback to A100
[rank0]:2025-10-29 15:46:42,660 - INFO - Peak FLOPS used for computing MFU: 3.120e+14
[rank0]:2025-10-29 15:46:42,661 - INFO - CUDA memory usage for model: 1.90GiB(3.99%)
[rank3]:wandb: setting up run 6d9pp6jy
[rank3]:wandb: Tracking run with wandb version 0.22.2
[rank3]:wandb: Run data is saved locally in /data2/shcho/torchtitan/tb/1028_1F1B_timelyapf_dm1/20251029-1546/wandb/run-20251029_154642-6d9pp6jy
[rank3]:wandb: Run `wandb offline` to turn off syncing.
[rank3]:wandb: Syncing run 1028_1F1B_timelyapf_dm1
[rank3]:wandb: ‚≠êÔ∏è View project at https://wandb.ai/orangingq/torchtitan
[rank3]:wandb: üöÄ View run at https://wandb.ai/orangingq/torchtitan/runs/6d9pp6jy
[rank3]:2025-10-29 15:46:43,235 - INFO - WandB logging enabled
[rank3]:2025-10-29 15:46:43,237 - INFO - CUDA capacity: NVIDIA RTX 6000 Ada Generation with 47.51GiB memory
[rank3]:2025-10-29 15:46:43,278 - WARNING - Peak flops undefined for: NVIDIA RTX 6000 Ada Generation, fallback to A100
[rank3]:2025-10-29 15:46:43,307 - INFO - PP rank 3 is building stage_idx 3 with modules ['layers.13', 'layers.14', 'layers.15', 'norm', 'output']
[rank3]:2025-10-29 15:46:43,308 - INFO - Using pipeline schedule 1F1B with 8 microbatches and 4 stages.
[rank1]:2025-10-29 15:46:43,513 - INFO - Mixed precision training with TP or PP is handled by autocast
[rank0]:2025-10-29 15:46:43,513 - INFO - Checkpointing active. Checkpoints will be loaded from and saved to /data2/shcho/torchtitan/checkpoint/1028_1F1B_timelyapf_dm1
[rank0]:2025-10-29 15:46:43,513 - INFO - Mixed precision training with TP or PP is handled by autocast
[rank0]:2025-10-29 15:46:43,513 - INFO - Preparing c4_validation dataset from allenai/c4
[rank3]:2025-10-29 15:46:43,497 - WARNING - Peak flops undefined for: NVIDIA RTX 6000 Ada Generation, fallback to A100
[rank3]:2025-10-29 15:46:43,497 - INFO - Peak FLOPS used for computing MFU: 3.120e+14
[rank3]:2025-10-29 15:46:43,498 - INFO - CUDA memory usage for model: 1.66GiB(3.50%)
[rank3]:2025-10-29 15:46:43,512 - INFO - Mixed precision training with TP or PP is handled by autocast
[rank2]:2025-10-29 15:46:43,513 - INFO - Mixed precision training with TP or PP is handled by autocast
[rank0]:2025-10-29 15:46:50,106 - INFO - Trainer is initialized with local batch size 16, global batch size 64, gradient accumulation steps 4, sequence length 1024, total steps 1600 (warmup 100)
[rank0]:2025-10-29 15:46:50,106 - INFO - Loading the checkpoint from /data2/shcho/torchtitan/base_model/Llama-3.2-1B-Instruct/original_dcp.
[rank0]:2025-10-29 15:46:52,175 - INFO - [GC] GC collection for checkpoint loading. 0.00 seconds
[rank0]:2025-10-29 15:46:52,175 - INFO - Finished loading the checkpoint in 2.07 seconds.
[rank0]:2025-10-29 15:46:52,175 - INFO - Training starts at step 1
[rank1]:2025-10-29 15:46:56,348 - INFO -  step:  1  loss: -4.0000  grad_norm: 54.0701  memory:  6.76GiB(14.24%)  tps: 1,106  tflops: 8.64  mfu: 2.77%
[rank1]:2025-10-29 15:46:56,348 - INFO - Synchronizing and adjusting timeout for all ProcessGroups to 0:05:00
[rank2]:2025-10-29 15:46:56,344 - INFO -  step:  1  loss: -4.0000  grad_norm: 54.0701  memory:  4.63GiB(9.75%)  tps: 1,091  tflops: 8.53  mfu: 2.73%
[rank2]:2025-10-29 15:46:56,345 - INFO - Synchronizing and adjusting timeout for all ProcessGroups to 0:05:00
[rank3]:2025-10-29 15:46:56,355 - INFO -  step:  1  loss:  9.8313  grad_norm: 54.0701  memory: 12.97GiB(27.30%)  tps: 1,253  tflops: 9.80  mfu: 3.14%
[rank3]:2025-10-29 15:46:56,356 - INFO - Synchronizing and adjusting timeout for all ProcessGroups to 0:05:00
[rank0]:2025-10-29 15:46:56,384 - INFO -  step:  1  loss: -4.0000  grad_norm: 54.0701  memory:  9.19GiB(19.34%)  tps: 1,144  tflops: 8.94  mfu: 2.87%
[rank0]:2025-10-29 15:46:56,384 - INFO - Synchronizing and adjusting timeout for all ProcessGroups to 0:05:00
[rank3]:2025-10-29 15:47:12,743 - WARNING - Batch index 1 is larger than log time length 0. Filling with zeros.
[rank3]:2025-10-29 15:47:12,744 - WARNING - Batch index 1 is larger than log time length 0. Filling with zeros.
[rank3]:2025-10-29 15:47:12,744 - WARNING - Batch index 1 is larger than log time length 0. Filling with zeros.
[rank3]:2025-10-29 15:47:12,744 - WARNING - Batch index 1 is larger than log time length 0. Filling with zeros.
[rank3]:2025-10-29 15:47:12,745 - WARNING - Batch index 1 is larger than log time length 0. Filling with zeros.
[rank3]:2025-10-29 15:47:12,745 - WARNING - Batch index 1 is larger than log time length 0. Filling with zeros.
[rank3]:2025-10-29 15:47:12,745 - WARNING - Batch index 1 is larger than log time length 0. Filling with zeros.
[rank3]:2025-10-29 15:47:12,746 - WARNING - Batch index 1 is larger than log time length 0. Filling with zeros.
[rank3]:2025-10-29 15:47:12,746 - WARNING - Batch index 1 is larger than log time length 0. Filling with zeros.
[rank3]:2025-10-29 15:47:12,746 - WARNING - Batch index 1 is larger than log time length 0. Filling with zeros.
[rank3]:2025-10-29 15:47:12,747 - WARNING - Batch index 1 is larger than log time length 0. Filling with zeros.
[rank3]:2025-10-29 15:47:12,747 - WARNING - Batch index 1 is larger than log time length 0. Filling with zeros.
[rank3]:2025-10-29 15:47:12,747 - WARNING - Batch index 1 is larger than log time length 0. Filling with zeros.
[rank3]:2025-10-29 15:47:12,748 - WARNING - Batch index 1 is larger than log time length 0. Filling with zeros.
[rank3]:2025-10-29 15:47:12,748 - WARNING - Batch index 1 is larger than log time length 0. Filling with zeros.
[rank3]:2025-10-29 15:47:12,748 - WARNING - Batch index 1 is larger than log time length 0. Filling with zeros.
[rank2]:2025-10-29 15:47:12,770 - WARNING - Batch index 1 is larger than log time length 0. Filling with zeros.
[rank2]:2025-10-29 15:47:12,770 - WARNING - Batch index 1 is larger than log time length 0. Filling with zeros.
[rank2]:2025-10-29 15:47:12,770 - WARNING - Batch index 1 is larger than log time length 0. Filling with zeros.
[rank2]:2025-10-29 15:47:12,770 - WARNING - Batch index 1 is larger than log time length 0. Filling with zeros.
[rank2]:2025-10-29 15:47:12,770 - WARNING - Batch index 1 is larger than log time length 0. Filling with zeros.
[rank2]:2025-10-29 15:47:12,771 - WARNING - Batch index 1 is larger than log time length 0. Filling with zeros.
[rank2]:2025-10-29 15:47:12,771 - WARNING - Batch index 1 is larger than log time length 0. Filling with zeros.
[rank2]:2025-10-29 15:47:12,771 - WARNING - Batch index 1 is larger than log time length 0. Filling with zeros.
[rank2]:2025-10-29 15:47:12,771 - WARNING - Batch index 1 is larger than log time length 0. Filling with zeros.
[rank2]:2025-10-29 15:47:12,771 - WARNING - Batch index 1 is larger than log time length 0. Filling with zeros.
[rank2]:2025-10-29 15:47:12,771 - WARNING - Batch index 1 is larger than log time length 0. Filling with zeros.
[rank2]:2025-10-29 15:47:12,771 - WARNING - Batch index 1 is larger than log time length 0. Filling with zeros.
[rank2]:2025-10-29 15:47:12,771 - WARNING - Batch index 1 is larger than log time length 0. Filling with zeros.
[rank2]:2025-10-29 15:47:12,771 - WARNING - Batch index 1 is larger than log time length 0. Filling with zeros.
[rank2]:2025-10-29 15:47:12,771 - WARNING - Batch index 1 is larger than log time length 0. Filling with zeros.
[rank2]:2025-10-29 15:47:12,771 - WARNING - Batch index 1 is larger than log time length 0. Filling with zeros.
[rank1]:2025-10-29 15:47:12,798 - WARNING - Batch index 1 is larger than log time length 0. Filling with zeros.
[rank1]:2025-10-29 15:47:12,798 - WARNING - Batch index 1 is larger than log time length 0. Filling with zeros.
[rank1]:2025-10-29 15:47:12,798 - WARNING - Batch index 1 is larger than log time length 0. Filling with zeros.
[rank1]:2025-10-29 15:47:12,799 - WARNING - Batch index 1 is larger than log time length 0. Filling with zeros.
[rank1]:2025-10-29 15:47:12,799 - WARNING - Batch index 1 is larger than log time length 0. Filling with zeros.
[rank1]:2025-10-29 15:47:12,799 - WARNING - Batch index 1 is larger than log time length 0. Filling with zeros.
[rank1]:2025-10-29 15:47:12,799 - WARNING - Batch index 1 is larger than log time length 0. Filling with zeros.
[rank1]:2025-10-29 15:47:12,799 - WARNING - Batch index 1 is larger than log time length 0. Filling with zeros.
[rank1]:2025-10-29 15:47:12,799 - WARNING - Batch index 1 is larger than log time length 0. Filling with zeros.
[rank1]:2025-10-29 15:47:12,799 - WARNING - Batch index 1 is larger than log time length 0. Filling with zeros.
[rank1]:2025-10-29 15:47:12,799 - WARNING - Batch index 1 is larger than log time length 0. Filling with zeros.
[rank1]:2025-10-29 15:47:12,799 - WARNING - Batch index 1 is larger than log time length 0. Filling with zeros.
[rank1]:2025-10-29 15:47:12,799 - WARNING - Batch index 1 is larger than log time length 0. Filling with zeros.
[rank1]:2025-10-29 15:47:12,799 - WARNING - Batch index 1 is larger than log time length 0. Filling with zeros.
[rank1]:2025-10-29 15:47:12,800 - WARNING - Batch index 1 is larger than log time length 0. Filling with zeros.
[rank1]:2025-10-29 15:47:12,800 - WARNING - Batch index 1 is larger than log time length 0. Filling with zeros.
[rank0]:2025-10-29 15:47:12,827 - WARNING - Batch index 1 is larger than log time length 0. Filling with zeros.
[rank0]:2025-10-29 15:47:12,827 - WARNING - Batch index 1 is larger than log time length 0. Filling with zeros.
[rank0]:2025-10-29 15:47:12,827 - WARNING - Batch index 1 is larger than log time length 0. Filling with zeros.
[rank0]:2025-10-29 15:47:12,827 - WARNING - Batch index 1 is larger than log time length 0. Filling with zeros.
[rank0]:2025-10-29 15:47:12,827 - WARNING - Batch index 1 is larger than log time length 0. Filling with zeros.
[rank0]:2025-10-29 15:47:12,827 - WARNING - Batch index 1 is larger than log time length 0. Filling with zeros.
[rank0]:2025-10-29 15:47:12,827 - WARNING - Batch index 1 is larger than log time length 0. Filling with zeros.
[rank0]:2025-10-29 15:47:12,827 - WARNING - Batch index 1 is larger than log time length 0. Filling with zeros.
[rank0]:2025-10-29 15:47:12,827 - WARNING - Batch index 1 is larger than log time length 0. Filling with zeros.
[rank0]:2025-10-29 15:47:12,828 - WARNING - Batch index 1 is larger than log time length 0. Filling with zeros.
[rank0]:2025-10-29 15:47:12,828 - WARNING - Batch index 1 is larger than log time length 0. Filling with zeros.
[rank0]:2025-10-29 15:47:12,828 - WARNING - Batch index 1 is larger than log time length 0. Filling with zeros.
[rank0]:2025-10-29 15:47:12,828 - WARNING - Batch index 1 is larger than log time length 0. Filling with zeros.
[rank0]:2025-10-29 15:47:12,828 - WARNING - Batch index 1 is larger than log time length 0. Filling with zeros.
[rank0]:2025-10-29 15:47:12,828 - WARNING - Batch index 1 is larger than log time length 0. Filling with zeros.
[rank0]:2025-10-29 15:47:12,828 - WARNING - Batch index 1 is larger than log time length 0. Filling with zeros.
[rank0]:2025-10-29 15:48:54,646 - INFO - [GC] Peforming periodical GC collection 0.00 seconds
[rank2]:2025-10-29 15:48:57,104 - INFO -  step: 50  loss: -4.0000  grad_norm: 21.8000  memory:  6.43GiB(13.53%)  tps: 6,648  tflops: 51.97  mfu: 16.66%
[rank0]:2025-10-29 15:48:57,119 - INFO -  step: 50  loss: -4.0000  grad_norm: 21.8000  memory: 12.97GiB(27.31%)  tps: 6,649  tflops: 51.98  mfu: 16.66%
[rank1]:2025-10-29 15:48:57,108 - INFO -  step: 50  loss: -4.0000  grad_norm: 21.8000  memory:  9.03GiB(19.01%)  tps: 6,648  tflops: 51.97  mfu: 16.66%
[rank3]:2025-10-29 15:48:57,117 - INFO -  step: 50  loss:  9.4525  grad_norm: 21.8000  memory: 16.39GiB(34.50%)  tps: 6,648  tflops: 51.97  mfu: 16.66%
[rank3]:2025-10-29 15:48:57,445 - INFO - Avg. fwd time: 12.1707 / Avg. bwd time: 39.9480 / Avg. batch time: 493.1774 (ms) / GPU bubble ratio: 15.46%
[rank2]:2025-10-29 15:48:57,482 - INFO - Avg. fwd time: 6.9442 / Avg. bwd time: 18.3648 / Avg. batch time: 523.8917 (ms) / GPU bubble ratio: 61.35%
[rank0]:2025-10-29 15:48:57,513 - INFO - Avg. fwd time: 7.3972 / Avg. bwd time: 23.6696 / Avg. batch time: 598.3723 (ms) / GPU bubble ratio: 58.46%
[rank1]:2025-10-29 15:48:57,517 - INFO - Avg. fwd time: 9.0541 / Avg. bwd time: 23.8298 / Avg. batch time: 561.7948 (ms) / GPU bubble ratio: 53.17%
[rank3]:2025-10-29 15:49:21,255 - INFO - [Step 60] „Ä∞Ô∏è Monitoring Upperbound
[rank3]:2025-10-29 15:49:46,451 - INFO - [Step 70] ‚úîÔ∏è  Setting Upperbound
[rank3]:2025-10-29 15:49:46,743 - INFO - [Step 70] „Ä∞Ô∏è Monitoring Lowerbound
[rank2]:2025-10-29 15:49:46,764 - WARNING - Batch index 281 is larger than freeze ratio history length 0. Filling with zeros.
[rank2]:2025-10-29 15:49:46,777 - WARNING - Batch index 281 is larger than freeze ratio history length 0. Filling with zeros.
[rank0]:2025-10-29 15:49:46,773 - WARNING - Batch index 281 is larger than freeze ratio history length 0. Filling with zeros.
[rank1]:2025-10-29 15:49:46,772 - WARNING - Batch index 281 is larger than freeze ratio history length 0. Filling with zeros.
[rank2]:2025-10-29 15:49:46,791 - WARNING - Batch index 281 is larger than freeze ratio history length 0. Filling with zeros.
[rank0]:2025-10-29 15:49:46,799 - WARNING - Batch index 281 is larger than freeze ratio history length 0. Filling with zeros.
[rank0]:2025-10-29 15:49:46,828 - WARNING - Batch index 281 is larger than freeze ratio history length 0. Filling with zeros.
[rank1]:2025-10-29 15:49:46,799 - WARNING - Batch index 281 is larger than freeze ratio history length 0. Filling with zeros.
[rank3]:2025-10-29 15:49:49,161 - WARNING - Batch index 281 is larger than freeze ratio history length 0. Filling with zeros.
[rank1]:2025-10-29 15:49:49,164 - WARNING - Batch index 281 is larger than freeze ratio history length 0. Filling with zeros.
[rank3]:2025-10-29 15:49:49,185 - WARNING - Batch index 281 is larger than freeze ratio history length 0. Filling with zeros.
[rank3]:2025-10-29 15:49:49,204 - WARNING - Batch index 281 is larger than freeze ratio history length 0. Filling with zeros.
[rank3]:2025-10-29 15:49:49,228 - WARNING - Batch index 281 is larger than freeze ratio history length 0. Filling with zeros.
[rank3]:2025-10-29 15:49:49,252 - WARNING - Batch index 281 is larger than freeze ratio history length 0. Filling with zeros.
[rank3]:2025-10-29 15:49:49,275 - WARNING - Batch index 281 is larger than freeze ratio history length 0. Filling with zeros.
[rank2]:2025-10-29 15:49:49,217 - WARNING - Batch index 281 is larger than freeze ratio history length 0. Filling with zeros.
[rank2]:2025-10-29 15:49:49,239 - WARNING - Batch index 281 is larger than freeze ratio history length 0. Filling with zeros.
[rank2]:2025-10-29 15:49:49,279 - WARNING - Batch index 281 is larger than freeze ratio history length 0. Filling with zeros.
[rank0]:2025-10-29 15:49:49,264 - WARNING - Batch index 281 is larger than freeze ratio history length 0. Filling with zeros.
[rank1]:2025-10-29 15:49:49,265 - WARNING - Batch index 281 is larger than freeze ratio history length 0. Filling with zeros.
[rank3]:2025-10-29 15:49:49,300 - WARNING - Batch index 281 is larger than freeze ratio history length 0. Filling with zeros.
[rank3]:2025-10-29 15:49:49,323 - WARNING - Batch index 281 is larger than freeze ratio history length 0. Filling with zeros.
[rank2]:2025-10-29 15:49:49,318 - WARNING - Batch index 281 is larger than freeze ratio history length 0. Filling with zeros.
[rank2]:2025-10-29 15:49:49,350 - WARNING - Batch index 281 is larger than freeze ratio history length 0. Filling with zeros.
[rank0]:2025-10-29 15:49:49,308 - WARNING - Batch index 281 is larger than freeze ratio history length 0. Filling with zeros.
[rank0]:2025-10-29 15:49:49,309 - WARNING - Batch index 281 is larger than freeze ratio history length 0. Filling with zeros.
[rank0]:2025-10-29 15:49:49,309 - WARNING - Batch index 281 is larger than freeze ratio history length 0. Filling with zeros.
[rank0]:2025-10-29 15:49:49,310 - WARNING - Batch index 281 is larger than freeze ratio history length 0. Filling with zeros.
[rank1]:2025-10-29 15:49:49,304 - WARNING - Batch index 281 is larger than freeze ratio history length 0. Filling with zeros.
[rank1]:2025-10-29 15:49:49,336 - WARNING - Batch index 281 is larger than freeze ratio history length 0. Filling with zeros.
[rank1]:2025-10-29 15:49:49,353 - WARNING - Batch index 281 is larger than freeze ratio history length 0. Filling with zeros.
[rank1]:2025-10-29 15:49:49,369 - WARNING - Batch index 281 is larger than freeze ratio history length 0. Filling with zeros.
[rank3]:2025-10-29 15:50:24,273 - INFO - [Step 90] ‚úîÔ∏è  Setting Lowerbound
[rank3]:2025-10-29 15:50:24,500 - INFO - Pipeline schedule is saved as: /data2/shcho/torchtitan/images/1028_1F1B_timelyapf_dm1/pipeline_schedule/251029_1550_max_batch_time.svg
[rank3]:> Batch Time: 517.00 ms, GPU Bubble Ratio: 51.05%, 48.85%, 60.31%, 18.46%
[rank3]:2025-10-29 15:50:24,688 - INFO - Pipeline schedule is saved as: /data2/shcho/torchtitan/images/1028_1F1B_timelyapf_dm1/pipeline_schedule/251029_1550_min_batch_time.svg
[rank3]:> Batch Time: 310.94 ms, GPU Bubble Ratio: 80.66%, 48.82%, 60.58%, 15.45%
[rank3]:2025-10-29 15:50:24,893 - INFO - Pipeline schedule is saved as: /data2/shcho/torchtitan/images/1028_1F1B_timelyapf_dm1/pipeline_schedule/251029_1550_frozen_pipeline_schedule.svg
[rank3]:> Batch Time: 325.88 ms, GPU Bubble Ratio: 33.85%, 23.21%, 40.20%, 14.74%
[rank3]:2025-10-29 15:50:24,893 - INFO - 	> Batch Time: 325.88 ms (Average Freeze Ratio: 0.34, Time Reduction Rate: 0.37)
[rank0]:2025-10-29 15:50:44,515 - INFO - [GC] Peforming periodical GC collection 0.00 seconds
[rank1]:2025-10-29 15:50:46,339 - INFO - Current/Expected Freeze Ratio per Block: [MB0] 0.00/0.00, [MB1] 0.00/0.00, [MB2] 0.00/0.00, [MB3] 0.00/0.00, [MB4] 0.00/0.00, [MB5] 0.00/0.00, [MB6] 0.03/0.09, [MB7] 0.33/1.00
[rank1]:2025-10-29 15:50:46,340 - INFO -  step: 100  loss: -4.0000  grad_norm:  5.9457  memory:  9.36GiB(19.71%)  tps: 7,500  tflops: 58.63  mfu: 18.79%
[rank0]:2025-10-29 15:50:46,349 - INFO - Current/Expected Freeze Ratio per Block: [MB0] 0.00/0.00, [MB1] 0.00/0.00, [MB2] 0.00/0.00, [MB3] 0.00/0.00, [MB4] 0.00/0.00, [MB5] 0.00/0.00, [MB6] 0.19/0.56, [MB7] 0.33/1.00
[rank0]:2025-10-29 15:50:46,350 - INFO -  step: 100  loss: -4.0000  grad_norm:  5.9457  memory: 12.97GiB(27.31%)  tps: 7,500  tflops: 58.63  mfu: 18.79%
[rank2]:2025-10-29 15:50:46,335 - INFO - Current/Expected Freeze Ratio per Block: [MB0] 0.00/0.00, [MB1] 0.00/0.00, [MB2] 0.00/0.00, [MB3] 0.00/0.00, [MB4] 0.00/0.00, [MB5] 0.00/0.00, [MB6] 0.00/0.00, [MB7] 0.33/1.00
[rank2]:2025-10-29 15:50:46,336 - INFO -  step: 100  loss: -4.0000  grad_norm:  5.9457  memory:  6.51GiB(13.70%)  tps: 7,500  tflops: 58.63  mfu: 18.79%
[rank3]:2025-10-29 15:50:48,754 - INFO - Current/Expected Freeze Ratio per Block: [MB0] 0.07/0.20, [MB1] 0.33/1.00, [MB2] 0.33/1.00, [MB3] 0.33/1.00, [MB4] 0.33/1.00, [MB5] 0.33/1.00, [MB6] 0.33/1.00, [MB7] 0.33/1.00
[rank3]:2025-10-29 15:50:48,757 - INFO -  step: 100  loss:  9.8699  grad_norm:  0.0000  memory: 16.39GiB(34.50%)  tps: 7,338  tflops: 57.37  mfu: 18.39%
[rank1]:2025-10-29 15:50:48,837 - INFO - Frozen Ratio History of Rank 1 (Stage 1)  is saved as: /data2/shcho/torchtitan/images/1028_1F1B_timelyapf_dm1/freeze_ratio_history/rank1/251029_1550_stage1_step100.svg
[rank0]:2025-10-29 15:50:48,836 - INFO - Frozen Ratio History of Rank 0 (Stage 0)  is saved as: /data2/shcho/torchtitan/images/1028_1F1B_timelyapf_dm1/freeze_ratio_history/rank0/251029_1550_stage0_step100.svg
[rank2]:2025-10-29 15:50:48,836 - INFO - Frozen Ratio History of Rank 2 (Stage 2)  is saved as: /data2/shcho/torchtitan/images/1028_1F1B_timelyapf_dm1/freeze_ratio_history/rank2/251029_1550_stage2_step100.svg
[rank3]:2025-10-29 15:50:48,939 - INFO - Pipeline schedule is saved as: /data2/shcho/torchtitan/images/1028_1F1B_timelyapf_dm1/pipeline_schedule/251029_1550_real_step100_rank3.svg
[rank3]:> Batch Time: 513.57 ms, GPU Bubble Ratio: 51.05%, 48.84%, 60.36%, 18.42%
[rank3]:2025-10-29 15:50:49,001 - INFO - Frozen Ratio History of Rank 3 (Stage 3)  is saved as: /data2/shcho/torchtitan/images/1028_1F1B_timelyapf_dm1/freeze_ratio_history/rank3/251029_1550_stage3_step100.svg
[rank3]:2025-10-29 15:50:49,214 - INFO - Avg. fwd time: 12.5269 / Avg. bwd time: 34.6098 / Avg. batch time: 452.4000 (ms) / GPU bubble ratio: 16.65%
[rank0]:2025-10-29 15:50:49,247 - INFO - Avg. fwd time: 7.7502 / Avg. bwd time: 17.8357 / Avg. batch time: 568.4296 (ms) / GPU bubble ratio: 63.99%
[rank2]:2025-10-29 15:50:49,261 - INFO - Avg. fwd time: 7.3154 / Avg. bwd time: 16.2545 / Avg. batch time: 502.3582 (ms) / GPU bubble ratio: 62.47%
[rank1]:2025-10-29 15:50:49,297 - INFO - Avg. fwd time: 9.7177 / Avg. bwd time: 20.7235 / Avg. batch time: 537.3748 (ms) / GPU bubble ratio: 54.68%
[rank0]:2025-10-29 15:52:35,552 - INFO - [GC] Peforming periodical GC collection 0.00 seconds
[rank0]:2025-10-29 15:52:37,504 - INFO - Current/Expected Freeze Ratio per Block: [MB0] 0.00/0.00, [MB1] 0.00/0.00, [MB2] 0.00/0.00, [MB3] 0.00/0.00, [MB4] 0.00/0.00, [MB5] 0.00/0.00, [MB6] 0.37/0.56, [MB7] 0.67/1.00
[rank0]:2025-10-29 15:52:37,505 - INFO -  step: 150  loss: -4.0000  grad_norm:  2.2484  memory: 13.19GiB(27.76%)  tps: 7,370  tflops: 57.61  mfu: 18.47%
[rank2]:2025-10-29 15:52:37,490 - INFO - Current/Expected Freeze Ratio per Block: [MB0] 0.00/0.00, [MB1] 0.00/0.00, [MB2] 0.00/0.00, [MB3] 0.00/0.00, [MB4] 0.00/0.00, [MB5] 0.00/0.00, [MB6] 0.00/0.00, [MB7] 0.67/1.00
[rank2]:2025-10-29 15:52:37,490 - INFO -  step: 150  loss: -4.0000  grad_norm:  2.2484  memory:  6.51GiB(13.70%)  tps: 7,370  tflops: 57.61  mfu: 18.47%
[rank1]:2025-10-29 15:52:37,494 - INFO - Current/Expected Freeze Ratio per Block: [MB0] 0.00/0.00, [MB1] 0.00/0.00, [MB2] 0.00/0.00, [MB3] 0.00/0.00, [MB4] 0.00/0.00, [MB5] 0.00/0.00, [MB6] 0.06/0.09, [MB7] 0.67/1.00
[rank1]:2025-10-29 15:52:37,494 - INFO -  step: 150  loss: -4.0000  grad_norm:  2.2484  memory:  9.36GiB(19.71%)  tps: 7,370  tflops: 57.61  mfu: 18.47%
[rank3]:2025-10-29 15:52:39,931 - INFO - Current/Expected Freeze Ratio per Block: [MB0] 0.13/0.20, [MB1] 0.67/1.00, [MB2] 0.67/1.00, [MB3] 0.67/1.00, [MB4] 0.67/1.00, [MB5] 0.67/1.00, [MB6] 0.67/1.00, [MB7] 0.67/1.00
[rank3]:2025-10-29 15:52:39,936 - INFO -  step: 150  loss:  5.4639  grad_norm:  2.2484  memory: 16.39GiB(34.50%)  tps: 7,368  tflops: 57.60  mfu: 18.46%
[rank3]:2025-10-29 15:52:40,307 - INFO - Avg. fwd time: 12.7251 / Avg. bwd time: 31.0286 / Avg. batch time: 424.5437 (ms) / GPU bubble ratio: 17.55%
[rank1]:2025-10-29 15:52:40,356 - INFO - Avg. fwd time: 9.6382 / Avg. bwd time: 20.9074 / Avg. batch time: 523.9193 (ms) / GPU bubble ratio: 53.36%
[rank0]:2025-10-29 15:52:40,379 - INFO - Avg. fwd time: 7.7632 / Avg. bwd time: 18.5171 / Avg. batch time: 555.7397 (ms) / GPU bubble ratio: 62.17%
[rank2]:2025-10-29 15:52:40,329 - INFO - Avg. fwd time: 7.2773 / Avg. bwd time: 16.5469 / Avg. batch time: 488.3803 (ms) / GPU bubble ratio: 60.97%
[rank0]:2025-10-29 15:54:21,933 - INFO - [GC] Peforming periodical GC collection 0.00 seconds
[rank1]:2025-10-29 15:54:23,782 - INFO - Current/Expected Freeze Ratio per Block: [MB0] 0.00/0.00, [MB1] 0.00/0.00, [MB2] 0.00/0.00, [MB3] 0.00/0.00, [MB4] 0.00/0.00, [MB5] 0.00/0.00, [MB6] 0.09/0.09, [MB7] 1.00/1.00
[rank1]:2025-10-29 15:54:23,782 - INFO -  step: 200  loss: -4.0000  grad_norm:  1.7087  memory:  9.40GiB(19.79%)  tps: 7,707  tflops: 60.25  mfu: 19.31%
[rank1]:2025-10-29 15:54:23,782 - INFO - üîé  Running validation at step 200
[rank0]:2025-10-29 15:54:23,793 - INFO - Current/Expected Freeze Ratio per Block: [MB0] 0.00/0.00, [MB1] 0.00/0.00, [MB2] 0.00/0.00, [MB3] 0.00/0.00, [MB4] 0.00/0.00, [MB5] 0.00/0.00, [MB6] 0.56/0.56, [MB7] 1.00/1.00
[rank0]:2025-10-29 15:54:23,793 - INFO -  step: 200  loss: -4.0000  grad_norm:  1.7087  memory: 13.42GiB(28.26%)  tps: 7,707  tflops: 60.25  mfu: 19.31%
[rank0]:2025-10-29 15:54:23,793 - INFO - üîé  Running validation at step 200
[rank2]:2025-10-29 15:54:23,778 - INFO - Current/Expected Freeze Ratio per Block: [MB0] 0.00/0.00, [MB1] 0.00/0.00, [MB2] 0.00/0.00, [MB3] 0.00/0.00, [MB4] 0.00/0.00, [MB5] 0.00/0.00, [MB6] 0.00/0.00, [MB7] 1.00/1.00
[rank2]:2025-10-29 15:54:23,778 - INFO -  step: 200  loss: -4.0000  grad_norm:  1.7087  memory:  6.51GiB(13.70%)  tps: 7,707  tflops: 60.25  mfu: 19.31%
[rank2]:2025-10-29 15:54:23,778 - INFO - üîé  Running validation at step 200
[rank3]:2025-10-29 15:54:26,304 - INFO - Current/Expected Freeze Ratio per Block: [MB0] 0.20/0.20, [MB1] 1.00/1.00, [MB2] 1.00/1.00, [MB3] 1.00/1.00, [MB4] 1.00/1.00, [MB5] 1.00/1.00, [MB6] 1.00/1.00, [MB7] 1.00/1.00
[rank3]:2025-10-29 15:54:26,308 - INFO -  step: 200  loss:  4.7645  grad_norm:  1.7087  memory: 16.39GiB(34.50%)  tps: 7,701  tflops: 60.21  mfu: 19.30%
[rank3]:2025-10-29 15:54:26,308 - INFO - üîé  Running validation at step 200
[rank0]:2025-10-29 15:54:46,676 - INFO - validate step: 200  loss: -1.0000  memory: 13.42GiB(28.26%)  tps: 17,900
[rank1]:2025-10-29 15:54:46,694 - INFO - validate step: 200  loss: -1.0000  memory:  9.40GiB(19.79%)  tps: 17,878
[rank3]:2025-10-29 15:54:46,720 - INFO - validate step: 200  loss:  1.1249  memory: 16.39GiB(34.50%)  tps: 20,069
[rank2]:2025-10-29 15:54:46,712 - INFO - validate step: 200  loss: -1.0000  memory:  6.51GiB(13.70%)  tps: 17,860
[rank1]:2025-10-29 15:54:46,800 - INFO - Frozen Ratio History of Rank 1 (Stage 1)  is saved as: /data2/shcho/torchtitan/images/1028_1F1B_timelyapf_dm1/freeze_ratio_history/rank1/251029_1554_stage1_step200.svg
[rank0]:2025-10-29 15:54:46,801 - INFO - Frozen Ratio History of Rank 0 (Stage 0)  is saved as: /data2/shcho/torchtitan/images/1028_1F1B_timelyapf_dm1/freeze_ratio_history/rank0/251029_1554_stage0_step200.svg
[rank2]:2025-10-29 15:54:46,801 - INFO - Frozen Ratio History of Rank 2 (Stage 2)  is saved as: /data2/shcho/torchtitan/images/1028_1F1B_timelyapf_dm1/freeze_ratio_history/rank2/251029_1554_stage2_step200.svg
[rank3]:2025-10-29 15:54:46,923 - INFO - Pipeline schedule is saved as: /data2/shcho/torchtitan/images/1028_1F1B_timelyapf_dm1/pipeline_schedule/251029_1554_real_step200_rank3.svg
[rank3]:> Batch Time: 387.05 ms, GPU Bubble Ratio: 44.23%, 36.57%, 49.74%, 22.62%
[rank3]:2025-10-29 15:54:46,988 - INFO - Frozen Ratio History of Rank 3 (Stage 3)  is saved as: /data2/shcho/torchtitan/images/1028_1F1B_timelyapf_dm1/freeze_ratio_history/rank3/251029_1554_stage3_step200.svg
[rank3]:2025-10-29 15:54:47,172 - INFO - Avg. fwd time: 12.8456 / Avg. bwd time: 29.0685 / Avg. batch time: 409.2542 (ms) / GPU bubble ratio: 18.07%
[rank0]:2025-10-29 15:54:47,231 - INFO - Avg. fwd time: 7.8645 / Avg. bwd time: 17.8579 / Avg. batch time: 544.6044 (ms) / GPU bubble ratio: 62.21%
[rank2]:2025-10-29 15:54:47,235 - INFO - Avg. fwd time: 7.2828 / Avg. bwd time: 16.5610 / Avg. batch time: 477.5580 (ms) / GPU bubble ratio: 60.06%
[rank1]:2025-10-29 15:54:47,271 - INFO - Avg. fwd time: 9.6633 / Avg. bwd time: 20.6405 / Avg. batch time: 513.1115 (ms) / GPU bubble ratio: 52.75%
[rank0]:2025-10-29 15:56:26,588 - INFO - [GC] Peforming periodical GC collection 0.01 seconds
[rank2]:2025-10-29 15:56:28,419 - INFO - Current/Expected Freeze Ratio per Block: [MB0] 0.00/0.00, [MB1] 0.00/0.00, [MB2] 0.00/0.00, [MB3] 0.00/0.00, [MB4] 0.00/0.00, [MB5] 0.00/0.00, [MB6] 0.00/0.00, [MB7] 1.00/1.00
[rank2]:2025-10-29 15:56:28,419 - INFO -  step: 250  loss: -4.0000  grad_norm:  0.8767  memory:  6.51GiB(13.70%)  tps: 8,055  tflops: 62.97  mfu: 20.18%
[rank1]:2025-10-29 15:56:28,423 - INFO - Current/Expected Freeze Ratio per Block: [MB0] 0.00/0.00, [MB1] 0.00/0.00, [MB2] 0.00/0.00, [MB3] 0.00/0.00, [MB4] 0.00/0.00, [MB5] 0.00/0.00, [MB6] 0.09/0.09, [MB7] 1.00/1.00
[rank1]:2025-10-29 15:56:28,423 - INFO -  step: 250  loss: -4.0000  grad_norm:  0.8767  memory:  9.40GiB(19.79%)  tps: 8,053  tflops: 62.95  mfu: 20.18%
[rank0]:2025-10-29 15:56:28,434 - INFO - Current/Expected Freeze Ratio per Block: [MB0] 0.00/0.00, [MB1] 0.00/0.00, [MB2] 0.00/0.00, [MB3] 0.00/0.00, [MB4] 0.00/0.00, [MB5] 0.00/0.00, [MB6] 0.56/0.56, [MB7] 1.00/1.00
[rank0]:2025-10-29 15:56:28,434 - INFO -  step: 250  loss: -4.0000  grad_norm:  0.8767  memory: 13.42GiB(28.26%)  tps: 8,050  tflops: 62.93  mfu: 20.17%
[rank3]:2025-10-29 15:56:30,838 - INFO - Current/Expected Freeze Ratio per Block: [MB0] 0.20/0.20, [MB1] 1.00/1.00, [MB2] 1.00/1.00, [MB3] 1.00/1.00, [MB4] 1.00/1.00, [MB5] 1.00/1.00, [MB6] 1.00/1.00, [MB7] 1.00/1.00
[rank3]:2025-10-29 15:56:30,843 - INFO -  step: 250  loss:  4.6484  grad_norm:  0.0000  memory: 16.39GiB(34.50%)  tps: 7,868  tflops: 61.51  mfu: 19.71%
[rank3]:2025-10-29 15:56:31,030 - INFO - Avg. fwd time: 12.9610 / Avg. bwd time: 27.3652 / Avg. batch time: 396.1312 (ms) / GPU bubble ratio: 18.56%
[rank0]:2025-10-29 15:56:31,081 - INFO - Avg. fwd time: 7.9368 / Avg. bwd time: 16.3461 / Avg. batch time: 532.4147 (ms) / GPU bubble ratio: 63.51%
[rank2]:2025-10-29 15:56:31,092 - INFO - Avg. fwd time: 7.3107 / Avg. bwd time: 16.3815 / Avg. batch time: 465.8854 (ms) / GPU bubble ratio: 59.32%
[rank1]:2025-10-29 15:56:31,129 - INFO - Avg. fwd time: 9.7051 / Avg. bwd time: 20.2173 / Avg. batch time: 501.3289 (ms) / GPU bubble ratio: 52.25%
[rank0]:2025-10-29 15:58:10,111 - INFO - [GC] Peforming periodical GC collection 0.00 seconds
[rank3]:2025-10-29 15:58:12,091 - INFO - Observed values (freeze ratio vs time) with Trend Line is saved as: /data2/shcho/torchtitan/images/1028_1F1B_timelyapf_dm1/pipeline_schedule_adjustment/251029_1558_rank3_trend_line.svg
[rank3]:2025-10-29 15:58:12,137 - INFO - Destroying the purge thread.
[rank2]:2025-10-29 15:58:12,107 - INFO - Observed values (freeze ratio vs time) with Trend Line is saved as: /data2/shcho/torchtitan/images/1028_1F1B_timelyapf_dm1/pipeline_schedule_adjustment/251029_1558_rank2_trend_line.svg
[rank2]:2025-10-29 15:58:12,137 - INFO - Destroying the purge thread.
[rank2]:[rank2]: Traceback (most recent call last):
[rank2]:[rank2]:   File "<frozen runpy>", line 198, in _run_module_as_main
[rank2]:[rank2]:   File "<frozen runpy>", line 88, in _run_code
[rank2]:[rank2]:   File "/home/shcho/torchtitan/timelyfreeze/train.py", line 725, in <module>
[rank2]:[rank2]:     trainer.train()
[rank2]:[rank2]:   File "/data2/shcho/miniforge3/envs/llm_eval/lib/python3.11/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 362, in wrapper
[rank2]:[rank2]:     return f(*args, **kwargs)
[rank2]:[rank2]:            ^^^^^^^^^^^^^^^^^^
[rank2]:[rank2]:   File "/home/shcho/torchtitan/timelyfreeze/train.py", line 584, in train
[rank2]:[rank2]:     self.train_step(data_iterator)
[rank2]:[rank2]:   File "/home/shcho/torchtitan/timelyfreeze/train.py", line 509, in train_step
[rank2]:[rank2]:     self.freezer.freeze_update(self.step) # this should be called after optimizer.step()
[rank2]:[rank2]:     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank2]:[rank2]:   File "/home/shcho/torchtitan/timelyfreeze/core/freezer.py", line 687, in freeze_update
[rank2]:[rank2]:     self.set_expected_freeze_ratio()
[rank2]:[rank2]:   File "/home/shcho/torchtitan/timelyfreeze/core/freezer.py", line 700, in set_expected_freeze_ratio
[rank2]:[rank2]:     super().set_expected_freeze_ratio()
[rank2]:[rank2]:   File "/home/shcho/torchtitan/timelyfreeze/core/freezer.py", line 184, in set_expected_freeze_ratio
[rank2]:[rank2]:     self.pipeline_schedule = adjust_freeze_ratio(self.pipeline_schedule, monitored_values_dict, self.config)
[rank2]:[rank2]:                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank2]:[rank2]:   File "/home/shcho/torchtitan/timelyfreeze/core/schedule.py", line 428, in adjust_freeze_ratio
[rank2]:[rank2]:     pipeline_schedule = solve_dag_lp(pipeline_schedule) # solve the DAG LP problem to find the optimal schedule
[rank2]:[rank2]:                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank2]:[rank2]:   File "/home/shcho/torchtitan/timelyfreeze/core/schedule.py", line 171, in solve_dag_lp
[rank2]:[rank2]:     row[n + idx] = -1.0 / (w_max - w_min)
[rank2]:[rank2]:                    ~~~~~^~~~~~~~~~~~~~~~~
[rank2]:[rank2]: ZeroDivisionError: float division by zero
[rank0]:2025-10-29 15:58:12,133 - INFO - Observed values (freeze ratio vs time) with Trend Line is saved as: /data2/shcho/torchtitan/images/1028_1F1B_timelyapf_dm1/pipeline_schedule_adjustment/251029_1558_rank0_trend_line.svg
[rank0]:2025-10-29 15:58:12,137 - INFO - Destroying the purge thread.
[rank0]:[rank0]: Traceback (most recent call last):
[rank0]:[rank0]:   File "<frozen runpy>", line 198, in _run_module_as_main
[rank0]:[rank0]:   File "<frozen runpy>", line 88, in _run_code
[rank0]:[rank0]:   File "/home/shcho/torchtitan/timelyfreeze/train.py", line 725, in <module>
[rank0]:[rank0]:     trainer.train()
[rank0]:[rank0]:   File "/data2/shcho/miniforge3/envs/llm_eval/lib/python3.11/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 362, in wrapper
[rank0]:[rank0]:     return f(*args, **kwargs)
[rank0]:[rank0]:            ^^^^^^^^^^^^^^^^^^
[rank0]:[rank0]:   File "/home/shcho/torchtitan/timelyfreeze/train.py", line 584, in train
[rank0]:[rank0]:     self.train_step(data_iterator)
[rank0]:[rank0]:   File "/home/shcho/torchtitan/timelyfreeze/train.py", line 509, in train_step
[rank0]:[rank0]:     self.freezer.freeze_update(self.step) # this should be called after optimizer.step()
[rank0]:[rank0]:     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank0]:[rank0]:   File "/home/shcho/torchtitan/timelyfreeze/core/freezer.py", line 687, in freeze_update
[rank0]:[rank0]:     self.set_expected_freeze_ratio()
[rank0]:[rank0]:   File "/home/shcho/torchtitan/timelyfreeze/core/freezer.py", line 700, in set_expected_freeze_ratio
[rank0]:[rank0]:     super().set_expected_freeze_ratio()
[rank0]:[rank0]:   File "/home/shcho/torchtitan/timelyfreeze/core/freezer.py", line 184, in set_expected_freeze_ratio
[rank0]:[rank0]:     self.pipeline_schedule = adjust_freeze_ratio(self.pipeline_schedule, monitored_values_dict, self.config)
[rank0]:[rank0]:                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank0]:[rank0]:   File "/home/shcho/torchtitan/timelyfreeze/core/schedule.py", line 428, in adjust_freeze_ratio
[rank0]:[rank0]:     pipeline_schedule = solve_dag_lp(pipeline_schedule) # solve the DAG LP problem to find the optimal schedule
[rank0]:[rank0]:                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank0]:[rank0]:   File "/home/shcho/torchtitan/timelyfreeze/core/schedule.py", line 171, in solve_dag_lp
[rank0]:[rank0]:     row[n + idx] = -1.0 / (w_max - w_min)
[rank0]:[rank0]:                    ~~~~~^~~~~~~~~~~~~~~~~
[rank0]:[rank0]: ZeroDivisionError: float division by zero
[rank1]:2025-10-29 15:58:12,112 - INFO - Observed values (freeze ratio vs time) with Trend Line is saved as: /data2/shcho/torchtitan/images/1028_1F1B_timelyapf_dm1/pipeline_schedule_adjustment/251029_1558_rank1_trend_line.svg
[rank1]:2025-10-29 15:58:12,137 - INFO - Destroying the purge thread.
[rank1]:[rank1]: Traceback (most recent call last):
[rank1]:[rank1]:   File "<frozen runpy>", line 198, in _run_module_as_main
[rank1]:[rank1]:   File "<frozen runpy>", line 88, in _run_code
[rank1]:[rank1]:   File "/home/shcho/torchtitan/timelyfreeze/train.py", line 725, in <module>
[rank1]:[rank1]:     trainer.train()
[rank1]:[rank1]:   File "/data2/shcho/miniforge3/envs/llm_eval/lib/python3.11/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 362, in wrapper
[rank1]:[rank1]:     return f(*args, **kwargs)
[rank1]:[rank1]:            ^^^^^^^^^^^^^^^^^^
[rank1]:[rank1]:   File "/home/shcho/torchtitan/timelyfreeze/train.py", line 584, in train
[rank1]:[rank1]:     self.train_step(data_iterator)
[rank1]:[rank1]:   File "/home/shcho/torchtitan/timelyfreeze/train.py", line 509, in train_step
[rank1]:[rank1]:     self.freezer.freeze_update(self.step) # this should be called after optimizer.step()
[rank1]:[rank1]:     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank1]:[rank1]:   File "/home/shcho/torchtitan/timelyfreeze/core/freezer.py", line 687, in freeze_update
[rank1]:[rank1]:     self.set_expected_freeze_ratio()
[rank1]:[rank1]:   File "/home/shcho/torchtitan/timelyfreeze/core/freezer.py", line 700, in set_expected_freeze_ratio
[rank1]:[rank1]:     super().set_expected_freeze_ratio()
[rank1]:[rank1]:   File "/home/shcho/torchtitan/timelyfreeze/core/freezer.py", line 184, in set_expected_freeze_ratio
[rank1]:[rank1]:     self.pipeline_schedule = adjust_freeze_ratio(self.pipeline_schedule, monitored_values_dict, self.config)
[rank1]:[rank1]:                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank1]:[rank1]:   File "/home/shcho/torchtitan/timelyfreeze/core/schedule.py", line 428, in adjust_freeze_ratio
[rank1]:[rank1]:     pipeline_schedule = solve_dag_lp(pipeline_schedule) # solve the DAG LP problem to find the optimal schedule
[rank1]:[rank1]:                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank1]:[rank1]:   File "/home/shcho/torchtitan/timelyfreeze/core/schedule.py", line 171, in solve_dag_lp
[rank1]:[rank1]:     row[n + idx] = -1.0 / (w_max - w_min)
[rank1]:[rank1]:                    ~~~~~^~~~~~~~~~~~~~~~~
[rank1]:[rank1]: ZeroDivisionError: float division by zero
[rank3]:wandb: updating run metadata
[rank0]:[rank0]:[W1029 15:58:12.400547717 ProcessGroupNCCL.cpp:1552] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
[rank3]:wandb: uploading history steps 5-5, summary, console lines 232-233
W1029 15:58:14.112000 4135512 site-packages/torch/distributed/elastic/multiprocessing/api.py:940] Sending process 4135547 closing signal SIGTERM
E1029 15:58:14.546000 4135512 site-packages/torch/distributed/elastic/multiprocessing/api.py:914] failed (exitcode: 1) local_rank: 0 (pid: 4135544) of binary: /data2/shcho/miniforge3/envs/llm_eval/bin/python3.11
E1029 15:58:14.562000 4135512 site-packages/torch/distributed/elastic/multiprocessing/errors/error_handler.py:141] no error file defined for parent, to copy child error file (/tmp/torchelastic_t5anwztw/30cbc7b7-536a-4cd4-a033-545f85b52a3a_6xw4nouo/attempt_0/0/error.json)
[rank2]:Stage 2: Modules to keep: {'layers.11', 'layers.12', 'layers.10', 'layers.9'}
[rank1]:Stage 1: Modules to keep: {'layers.4', 'layers.5', 'layers.7', 'layers.8', 'layers.6'}
[rank0]:Stage 0: Modules to keep: {'layers.1', 'layers.3', 'layers.0', 'layers.2', 'tok_embeddings'}
[rank3]:Stage 3: Modules to keep: {'output', 'norm', 'layers.15', 'layers.13', 'layers.14'}
[rank3]:----- TimelyFreeze‚è∞ Configuration:
[rank3]:	- job:
[rank3]:		- config_file: /home/shcho/torchtitan/logs/dmserver1/1028_llama1b/config.toml
[rank3]:		- dump_folder: /data2/shcho/torchtitan
[rank3]:		- description: "Main Table Experiment, without streaming mode, sample-level with truncation, 2 epochs, with bf16 autocast"
[rank3]:		- use_for_integration_test: False
[rank3]:		- print_args: False
[rank3]:		- basename: 1028_1F1B_timelyapf_dm1
[rank3]:	- profiling:
[rank3]:		- enable_profiling: False
[rank3]:		- save_traces_folder: /data2/shcho/torchtitan/profile_trace/1028_1F1B_timelyapf_dm1
[rank3]:		- profile_freq: 100
[rank3]:		- enable_memory_snapshot: False
[rank3]:		- save_memory_snapshot_folder: /data2/shcho/torchtitan/memory_snapshot/1028_1F1B_timelyapf_dm1
[rank3]:	- metrics:
[rank3]:		- log_freq: 50
[rank3]:		- enable_tensorboard: False
[rank3]:		- disable_color_printing: True
[rank3]:		- save_tb_folder: /data2/shcho/torchtitan/tb/1028_1F1B_timelyapf_dm1
[rank3]:		- save_for_all_ranks: False
[rank3]:		- enable_wandb: True
[rank3]:		- image_folder: /data2/shcho/torchtitan/images/1028_1F1B_timelyapf_dm1
[rank3]:		- pplog_freq: 200
[rank3]:		- draw_freq: 100
[rank3]:		- wandb_name: 1028_1F1B_timelyapf_dm1
[rank3]:		- draw_graph: True
[rank3]:	- model:
[rank3]:		- name: llama3
[rank3]:		- flavor: 1B
[rank3]:		- tokenizer_path: ./assets/tokenizer/Llama-3.2-1B-Instruct
[rank3]:		- converters: []
[rank3]:		- print_after_conversion: False
[rank3]:	- optimizer:
[rank3]:		- name: AdamW
[rank3]:		- lr: 1e-05
[rank3]:		- beta1: 0.9
[rank3]:		- beta2: 0.95
[rank3]:		- eps: 1e-08
[rank3]:		- weight_decay: 0.1
[rank3]:		- implementation: fused
[rank3]:		- early_step_in_backward: False
[rank3]:	- lr_scheduler:
[rank3]:		- warmup_steps: 100
[rank3]:		- decay_ratio: 0.8
[rank3]:		- decay_type: cosine
[rank3]:		- min_lr_factor: 0.0
[rank3]:	- training:
[rank3]:		- dataset: alpaca
[rank3]:		- dataset_path: None
[rank3]:		- local_batch_size: 16
[rank3]:		- global_batch_size: 64
[rank3]:		- seq_len: 1024
[rank3]:		- max_norm: 1.0
[rank3]:		- steps: 1600
[rank3]:		- enable_cpu_offload: False
[rank3]:		- mixed_precision_param: bfloat16
[rank3]:		- mixed_precision_reduce: float32
[rank3]:		- compile: False
[rank3]:		- gc_freq: 50
[rank3]:		- gc_debug: False
[rank3]:		- seed: None
[rank3]:		- deterministic: False
[rank3]:	- parallelism:
[rank3]:		- data_parallel_replicate_degree: 1
[rank3]:		- enable_compiled_autograd: False
[rank3]:		- data_parallel_shard_degree: -1
[rank3]:		- fsdp_reshard_after_forward: default
[rank3]:		- tensor_parallel_degree: 1
[rank3]:		- disable_loss_parallel: False
[rank3]:		- enable_async_tensor_parallel: False
[rank3]:		- pipeline_parallel_degree: 4
[rank3]:		- pipeline_parallel_split_points: []
[rank3]:		- module_fqns_per_model_part: None
[rank3]:		- pipeline_parallel_first_stage_less_layers: 1
[rank3]:		- pipeline_parallel_last_stage_less_layers: 1
[rank3]:		- pipeline_parallel_layers_per_stage: None
[rank3]:		- pipeline_parallel_schedule: 1F1B
[rank3]:		- pipeline_parallel_schedule_csv: 
[rank3]:		- pipeline_parallel_microbatch_size: 2
[rank3]:		- context_parallel_degree: 1
[rank3]:		- context_parallel_rotate_method: allgather
[rank3]:		- expert_parallel_degree: 1
[rank3]:		- pp: 4
[rank3]:		- stages_per_rank: 1
[rank3]:		- stages_list: [3]
[rank3]:		- microbatches: 8
[rank3]:	- checkpoint:
[rank3]:		- enable_checkpoint: True
[rank3]:		- checkpoint_folder: /data2/shcho/torchtitan/checkpoint/1028_1F1B_timelyapf_dm1
[rank3]:		- interval: 800
[rank3]:		- initial_load_path: /data2/shcho/torchtitan/base_model/Llama-3.2-1B-Instruct/original_dcp
[rank3]:		- initial_load_model_only: True
[rank3]:		- initial_load_in_hf: False
[rank3]:		- last_save_model_only: True
[rank3]:		- last_save_in_hf: False
[rank3]:		- export_dtype: float16
[rank3]:		- async_mode: async
[rank3]:		- keep_latest_k: 2
[rank3]:		- load_step: -1
[rank3]:		- exclude_from_loading: ['dataloader', 'lr_scheduler', 'optimizer', 'train_state']
[rank3]:		- enable_first_step_checkpoint: False
[rank3]:		- create_seed_checkpoint: False
[rank3]:	- activation_checkpoint:
[rank3]:		- mode: none
[rank3]:		- selective_ac_option: op
[rank3]:		- per_op_sac_force_recompute_mm_shapes_by_fqns: ['moe.router.gate']
[rank3]:	- float8:
[rank3]:		- enable_fsdp_float8_all_gather: False
[rank3]:		- precompute_float8_dynamic_scale_for_fsdp: False
[rank3]:		- recipe_name: None
[rank3]:		- filter_fqns: ['output']
[rank3]:		- emulate: False
[rank3]:		- moe_fqns_prototype: []
[rank3]:	- mx:
[rank3]:		- mxfp8_dim1_cast_kernel_choice: triton
[rank3]:		- recipe_name: mxfp8
[rank3]:		- filter_fqns: ['output']
[rank3]:		- moe_fqns_prototype: []
[rank3]:	- comm:
[rank3]:		- init_timeout_seconds: 300
[rank3]:		- train_timeout_seconds: 300
[rank3]:		- trace_buf_size: 20000
[rank3]:		- save_traces_folder: /data2/shcho/torchtitan/comm_traces/1028_1F1B_timelyapf_dm1
[rank3]:		- world_size: 4
[rank3]:		- global_rank: 3
[rank3]:		- local_rank: 3
[rank3]:		- dp: 1
[rank3]:		- pp: 4
[rank3]:		- pp_rank: 3
[rank3]:		- dp_rank: 0
[rank3]:		- master_dp_rank: 0
[rank3]:	- memory_estimation:
[rank3]:		- enabled: False
[rank3]:		- disable_fake_mode: False
[rank3]:	- fault_tolerance:
[rank3]:		- enable: False
[rank3]:		- process_group: gloo
[rank3]:		- process_group_timeout_ms: 10000
[rank3]:		- replica_id: 0
[rank3]:		- group_size: 0
[rank3]:		- min_replica_size: 1
[rank3]:		- semi_sync_method: None
[rank3]:		- sync_steps: 5
[rank3]:		- should_quantize: False
[rank3]:		- fragment_sync_delay: 0
[rank3]:		- fragment_update_alpha: 0.0
[rank3]:	- experimental:
[rank3]:		- custom_import: 
[rank3]:		- custom_args_module: 
[rank3]:	- validation:
[rank3]:		- enabled: True
[rank3]:		- dataset: c4_validation
[rank3]:		- dataset_path: None
[rank3]:		- local_batch_size: 16
[rank3]:		- seq_len: 1024
[rank3]:		- freq: 200
[rank3]:		- steps: 100
[rank3]:	- freezing:
[rank3]:		- freeze: True
[rank3]:		- metric_type: timelyapf
[rank3]:		- phase_unit: 50
[rank3]:		- stability_check_freq: 10
[rank3]:		- aggressiveness: 0
[rank3]:
[rank3]:[Gloo] Rank 3 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
[rank0]:[Gloo] Rank 0 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
[rank1]:[Gloo] Rank 1 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
[rank2]:[Gloo] Rank 2 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
Traceback (most recent call last):
  File "/data2/shcho/miniforge3/envs/llm_eval/bin/torchrun", line 7, in <module>
    sys.exit(main())
             ^^^^^^
  File "/data2/shcho/miniforge3/envs/llm_eval/lib/python3.11/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 362, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/data2/shcho/miniforge3/envs/llm_eval/lib/python3.11/site-packages/torch/distributed/run.py", line 946, in main
    run(args)
  File "/data2/shcho/miniforge3/envs/llm_eval/lib/python3.11/site-packages/torch/distributed/run.py", line 937, in run
    elastic_launch(
  File "/data2/shcho/miniforge3/envs/llm_eval/lib/python3.11/site-packages/torch/distributed/launcher/api.py", line 159, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data2/shcho/miniforge3/envs/llm_eval/lib/python3.11/site-packages/torch/distributed/launcher/api.py", line 300, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
timelyfreeze.train FAILED
------------------------------------------------------------
Failures:
[1]:
  time      : 2025-10-29_15:58:12
  host      : elga.kaist.ac.kr
  rank      : 1 (local_rank: 1)
  exitcode  : 1 (pid: 4135545)
  error_file: /tmp/torchelastic_t5anwztw/30cbc7b7-536a-4cd4-a033-545f85b52a3a_6xw4nouo/attempt_0/1/error.json
  traceback : Traceback (most recent call last):
    File "/data2/shcho/miniforge3/envs/llm_eval/lib/python3.11/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 362, in wrapper
      return f(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^
    File "/home/shcho/torchtitan/timelyfreeze/train.py", line 584, in train
      self.train_step(data_iterator)
    File "/home/shcho/torchtitan/timelyfreeze/train.py", line 509, in train_step
      self.freezer.freeze_update(self.step) # this should be called after optimizer.step()
      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    File "/home/shcho/torchtitan/timelyfreeze/core/freezer.py", line 687, in freeze_update
      self.set_expected_freeze_ratio()
    File "/home/shcho/torchtitan/timelyfreeze/core/freezer.py", line 700, in set_expected_freeze_ratio
      super().set_expected_freeze_ratio()
    File "/home/shcho/torchtitan/timelyfreeze/core/freezer.py", line 184, in set_expected_freeze_ratio
      self.pipeline_schedule = adjust_freeze_ratio(self.pipeline_schedule, monitored_values_dict, self.config)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    File "/home/shcho/torchtitan/timelyfreeze/core/schedule.py", line 428, in adjust_freeze_ratio
      pipeline_schedule = solve_dag_lp(pipeline_schedule) # solve the DAG LP problem to find the optimal schedule
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    File "/home/shcho/torchtitan/timelyfreeze/core/schedule.py", line 171, in solve_dag_lp
      row[n + idx] = -1.0 / (w_max - w_min)
                     ~~~~~^~~~~~~~~~~~~~~~~
  ZeroDivisionError: float division by zero
  
[2]:
  time      : 2025-10-29_15:58:12
  host      : elga.kaist.ac.kr
  rank      : 2 (local_rank: 2)
  exitcode  : 1 (pid: 4135546)
  error_file: /tmp/torchelastic_t5anwztw/30cbc7b7-536a-4cd4-a033-545f85b52a3a_6xw4nouo/attempt_0/2/error.json
  traceback : Traceback (most recent call last):
    File "/data2/shcho/miniforge3/envs/llm_eval/lib/python3.11/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 362, in wrapper
      return f(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^
    File "/home/shcho/torchtitan/timelyfreeze/train.py", line 584, in train
      self.train_step(data_iterator)
    File "/home/shcho/torchtitan/timelyfreeze/train.py", line 509, in train_step
      self.freezer.freeze_update(self.step) # this should be called after optimizer.step()
      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    File "/home/shcho/torchtitan/timelyfreeze/core/freezer.py", line 687, in freeze_update
      self.set_expected_freeze_ratio()
    File "/home/shcho/torchtitan/timelyfreeze/core/freezer.py", line 700, in set_expected_freeze_ratio
      super().set_expected_freeze_ratio()
    File "/home/shcho/torchtitan/timelyfreeze/core/freezer.py", line 184, in set_expected_freeze_ratio
      self.pipeline_schedule = adjust_freeze_ratio(self.pipeline_schedule, monitored_values_dict, self.config)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    File "/home/shcho/torchtitan/timelyfreeze/core/schedule.py", line 428, in adjust_freeze_ratio
      pipeline_schedule = solve_dag_lp(pipeline_schedule) # solve the DAG LP problem to find the optimal schedule
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    File "/home/shcho/torchtitan/timelyfreeze/core/schedule.py", line 171, in solve_dag_lp
      row[n + idx] = -1.0 / (w_max - w_min)
                     ~~~~~^~~~~~~~~~~~~~~~~
  ZeroDivisionError: float division by zero
  
[3]:
  time      : 2025-10-29_15:58:12
  host      : elga.kaist.ac.kr
  rank      : 3 (local_rank: 3)
  exitcode  : -15 (pid: 4135547)
  error_file: /tmp/torchelastic_t5anwztw/30cbc7b7-536a-4cd4-a033-545f85b52a3a_6xw4nouo/attempt_0/3/error.json
  traceback : Traceback (most recent call last):
    File "/data2/shcho/miniforge3/envs/llm_eval/lib/python3.11/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 362, in wrapper
      return f(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^
    File "/home/shcho/torchtitan/timelyfreeze/train.py", line 584, in train
      self.train_step(data_iterator)
    File "/home/shcho/torchtitan/timelyfreeze/train.py", line 509, in train_step
      self.freezer.freeze_update(self.step) # this should be called after optimizer.step()
      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    File "/home/shcho/torchtitan/timelyfreeze/core/freezer.py", line 687, in freeze_update
      self.set_expected_freeze_ratio()
    File "/home/shcho/torchtitan/timelyfreeze/core/freezer.py", line 700, in set_expected_freeze_ratio
      super().set_expected_freeze_ratio()
    File "/home/shcho/torchtitan/timelyfreeze/core/freezer.py", line 184, in set_expected_freeze_ratio
      self.pipeline_schedule = adjust_freeze_ratio(self.pipeline_schedule, monitored_values_dict, self.config)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    File "/home/shcho/torchtitan/timelyfreeze/core/schedule.py", line 428, in adjust_freeze_ratio
      pipeline_schedule = solve_dag_lp(pipeline_schedule) # solve the DAG LP problem to find the optimal schedule
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    File "/home/shcho/torchtitan/timelyfreeze/core/schedule.py", line 171, in solve_dag_lp
      row[n + idx] = -1.0 / (w_max - w_min)
                     ~~~~~^~~~~~~~~~~~~~~~~
  ZeroDivisionError: float division by zero
  
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2025-10-29_15:58:12
  host      : elga.kaist.ac.kr
  rank      : 0 (local_rank: 0)
  exitcode  : 1 (pid: 4135544)
  error_file: /tmp/torchelastic_t5anwztw/30cbc7b7-536a-4cd4-a033-545f85b52a3a_6xw4nouo/attempt_0/0/error.json
  traceback : Traceback (most recent call last):
    File "/data2/shcho/miniforge3/envs/llm_eval/lib/python3.11/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 362, in wrapper
      return f(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^
    File "/home/shcho/torchtitan/timelyfreeze/train.py", line 584, in train
      self.train_step(data_iterator)
    File "/home/shcho/torchtitan/timelyfreeze/train.py", line 509, in train_step
      self.freezer.freeze_update(self.step) # this should be called after optimizer.step()
      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    File "/home/shcho/torchtitan/timelyfreeze/core/freezer.py", line 687, in freeze_update
      self.set_expected_freeze_ratio()
    File "/home/shcho/torchtitan/timelyfreeze/core/freezer.py", line 700, in set_expected_freeze_ratio
      super().set_expected_freeze_ratio()
    File "/home/shcho/torchtitan/timelyfreeze/core/freezer.py", line 184, in set_expected_freeze_ratio
      self.pipeline_schedule = adjust_freeze_ratio(self.pipeline_schedule, monitored_values_dict, self.config)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    File "/home/shcho/torchtitan/timelyfreeze/core/schedule.py", line 428, in adjust_freeze_ratio
      pipeline_schedule = solve_dag_lp(pipeline_schedule) # solve the DAG LP problem to find the optimal schedule
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    File "/home/shcho/torchtitan/timelyfreeze/core/schedule.py", line 171, in solve_dag_lp
      row[n + idx] = -1.0 / (w_max - w_min)
                     ~~~~~^~~~~~~~~~~~~~~~~
  ZeroDivisionError: float division by zero
  
============================================================
