
üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•
‚úîÔ∏èCurrent Timestamp: 2025. 10. 29. (Ïàò) 15:58:14 KST
‚úîÔ∏èSERVER: dmserver1 (143.248.135.95),  GPUs: 3,4,5,6
‚úîÔ∏èSCRIPT: /home/shcho/torchtitan/logs/dmserver1/1028_llama1b/run.sh
‚úîÔ∏èOUTPUT: /home/shcho/torchtitan/logs/dmserver1/1028_llama1b/1028_1F1B_fullrand7.log
‚úîÔ∏èMain Table Experiment, without streaming mode, sample-level with truncation, 2 epochs, with bf16 autocast
‚úîÔ∏èRunning with fullrand7 x 1F1B ... 
‚òëÔ∏è> torchrun --standalone --nnodes=1 --nproc_per_node=4 --local_addr=127.0.0.1 --local-ranks-filter=0,1,2,3 --role=rank --tee=3 -m timelyfreeze.train --job.config_file=/home/shcho/torchtitan/logs/dmserver1/1028_llama1b/config.toml --job.description="Main Table Experiment, without streaming mode, sample-level with truncation, 2 epochs, with bf16 autocast" --parallelism.pipeline_parallel_degree=4  --freezing.freeze --freezing.metric_type=fullrand7
üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•
[rank1]:2025-10-29 15:58:21,059 - INFO - Starting job: "Main Table Experiment, without streaming mode, sample-level with truncation, 2 epochs, with bf16 autocast"
[rank2]:2025-10-29 15:58:21,059 - INFO - Starting job: "Main Table Experiment, without streaming mode, sample-level with truncation, 2 epochs, with bf16 autocast"
[rank0]:2025-10-29 15:58:21,274 - INFO - Starting job: "Main Table Experiment, without streaming mode, sample-level with truncation, 2 epochs, with bf16 autocast"
[rank3]:2025-10-29 15:58:21,217 - INFO - Starting job: "Main Table Experiment, without streaming mode, sample-level with truncation, 2 epochs, with bf16 autocast"
[rank1]:2025-10-29 15:58:21,312 - WARNING - ENV[TORCH_NCCL_ASYNC_ERROR_HANDLING] = 1 will be overridden to 3 based on job config
[rank1]:2025-10-29 15:58:21,314 - INFO - Building 1-D device mesh with ['pp'], [4]
[rank2]:2025-10-29 15:58:21,308 - WARNING - ENV[TORCH_NCCL_ASYNC_ERROR_HANDLING] = 1 will be overridden to 3 based on job config
[rank2]:2025-10-29 15:58:21,310 - INFO - Building 1-D device mesh with ['pp'], [4]
[rank3]:2025-10-29 15:58:21,473 - WARNING - ENV[TORCH_NCCL_ASYNC_ERROR_HANDLING] = 1 will be overridden to 3 based on job config
[rank3]:2025-10-29 15:58:21,476 - INFO - Building 1-D device mesh with ['pp'], [4]
[rank0]:2025-10-29 15:58:21,496 - WARNING - ENV[TORCH_NCCL_ASYNC_ERROR_HANDLING] = 1 will be overridden to 3 based on job config
[rank0]:2025-10-29 15:58:21,498 - INFO - Building 1-D device mesh with ['pp'], [4]
[rank0]:2025-10-29 15:58:21,502 - INFO - [GC] Initial GC collection 0.00 seconds
[rank0]:2025-10-29 15:58:22,588 - INFO - Loading tokenizer from tokenizer.json
[rank0]:2025-10-29 15:58:22,997 - INFO - Preparing alpaca dataset from tatsu-lab/alpaca
[rank1]:2025-10-29 15:58:26,138 - INFO - CUDA capacity: NVIDIA RTX 6000 Ada Generation with 47.51GiB memory
[rank1]:2025-10-29 15:58:26,184 - WARNING - Peak flops undefined for: NVIDIA RTX 6000 Ada Generation, fallback to A100
[rank1]:2025-10-29 15:58:26,211 - INFO - PP rank 1 is building stage_idx 1 with modules ['layers.4', 'layers.5', 'layers.6', 'layers.7', 'layers.8']
[rank1]:2025-10-29 15:58:26,211 - INFO - Using pipeline schedule 1F1B with 8 microbatches and 4 stages.
[rank2]:2025-10-29 15:58:26,220 - INFO - CUDA capacity: NVIDIA RTX 6000 Ada Generation with 47.51GiB memory
[rank3]:/data2/shcho/miniforge3/envs/llm_eval/lib/python3.11/site-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
[rank3]:  warnings.warn(
[rank2]:2025-10-29 15:58:26,258 - WARNING - Peak flops undefined for: NVIDIA RTX 6000 Ada Generation, fallback to A100
[rank3]:/data2/shcho/miniforge3/envs/llm_eval/lib/python3.11/site-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
[rank3]:  warnings.warn(
[rank2]:2025-10-29 15:58:26,291 - INFO - PP rank 2 is building stage_idx 2 with modules ['layers.9', 'layers.10', 'layers.11', 'layers.12']
[rank2]:2025-10-29 15:58:26,292 - INFO - Using pipeline schedule 1F1B with 8 microbatches and 4 stages.
[rank1]:2025-10-29 15:58:26,426 - WARNING - Peak flops undefined for: NVIDIA RTX 6000 Ada Generation, fallback to A100
[rank1]:2025-10-29 15:58:26,426 - INFO - Peak FLOPS used for computing MFU: 3.120e+14
[rank1]:2025-10-29 15:58:26,427 - INFO - CUDA memory usage for model: 1.13GiB(2.39%)
[rank2]:2025-10-29 15:58:26,487 - WARNING - Peak flops undefined for: NVIDIA RTX 6000 Ada Generation, fallback to A100
[rank2]:2025-10-29 15:58:26,487 - INFO - Peak FLOPS used for computing MFU: 3.120e+14
[rank2]:2025-10-29 15:58:26,488 - INFO - CUDA memory usage for model: 0.92GiB(1.94%)
[rank3]:wandb: Currently logged in as: orangingq to https://api.wandb.ai. Use `wandb login --relogin` to force relogin
[rank3]:wandb: setting up run sy8qkvi8
[rank3]:wandb: Tracking run with wandb version 0.22.2
[rank3]:wandb: Run data is saved locally in /data2/shcho/torchtitan/tb/1028_1F1B_fullrand7_dm1/20251029-1558/wandb/run-20251029_155826-sy8qkvi8
[rank3]:wandb: Run `wandb offline` to turn off syncing.
[rank3]:wandb: Syncing run 1028_1F1B_fullrand7_dm1
[rank3]:wandb: ‚≠êÔ∏è View project at https://wandb.ai/orangingq/torchtitan
[rank3]:wandb: üöÄ View run at https://wandb.ai/orangingq/torchtitan/runs/sy8qkvi8
[rank3]:2025-10-29 15:58:27,933 - INFO - WandB logging enabled
[rank3]:2025-10-29 15:58:27,958 - INFO - CUDA capacity: NVIDIA RTX 6000 Ada Generation with 47.51GiB memory
[rank3]:2025-10-29 15:58:27,997 - WARNING - Peak flops undefined for: NVIDIA RTX 6000 Ada Generation, fallback to A100
[rank3]:2025-10-29 15:58:28,023 - INFO - PP rank 3 is building stage_idx 3 with modules ['layers.13', 'layers.14', 'layers.15', 'norm', 'output']
[rank3]:2025-10-29 15:58:28,024 - INFO - Using pipeline schedule 1F1B with 8 microbatches and 4 stages.
[rank3]:2025-10-29 15:58:28,207 - WARNING - Peak flops undefined for: NVIDIA RTX 6000 Ada Generation, fallback to A100
[rank3]:2025-10-29 15:58:28,208 - INFO - Peak FLOPS used for computing MFU: 3.120e+14
[rank3]:2025-10-29 15:58:28,209 - INFO - CUDA memory usage for model: 1.66GiB(3.50%)
[rank0]:2025-10-29 15:58:28,828 - INFO - Building llama3 1B with TransformerModelArgs(_enforced='This field is used to enforce all fields have defaults.', dim=2048, n_layers=16, n_heads=32, n_kv_heads=8, vocab_size=128256, multiple_of=256, ffn_dim_multiplier=1.5, norm_eps=1e-05, rope_theta=500000, max_seq_len=1024, depth_init=True, use_flex_attn=False, attn_mask_type='causal', eos_id=0)
[rank0]:2025-10-29 15:58:28,985 - INFO - CUDA capacity: NVIDIA RTX 6000 Ada Generation with 47.51GiB memory
[rank0]:2025-10-29 15:58:29,022 - WARNING - Peak flops undefined for: NVIDIA RTX 6000 Ada Generation, fallback to A100
[rank0]:2025-10-29 15:58:29,023 - INFO - Model llama3 1B size: 1,498,482,688 total parameters
[rank0]:2025-10-29 15:58:29,056 - INFO - PP rank 0 is building stage_idx 0 with modules ['tok_embeddings', 'layers.0', 'layers.1', 'layers.2', 'layers.3']
[rank0]:2025-10-29 15:58:29,057 - INFO - Using pipeline schedule 1F1B with 8 microbatches and 4 stages.
[rank1]:2025-10-29 15:58:29,250 - INFO - Mixed precision training with TP or PP is handled by autocast
[rank2]:2025-10-29 15:58:29,250 - INFO - Mixed precision training with TP or PP is handled by autocast
[rank3]:2025-10-29 15:58:29,250 - INFO - Mixed precision training with TP or PP is handled by autocast
[rank0]:2025-10-29 15:58:29,232 - WARNING - Peak flops undefined for: NVIDIA RTX 6000 Ada Generation, fallback to A100
[rank0]:2025-10-29 15:58:29,232 - INFO - Peak FLOPS used for computing MFU: 3.120e+14
[rank0]:2025-10-29 15:58:29,233 - INFO - CUDA memory usage for model: 1.90GiB(3.99%)
[rank0]:2025-10-29 15:58:29,250 - INFO - Checkpointing active. Checkpoints will be loaded from and saved to /data2/shcho/torchtitan/checkpoint/1028_1F1B_fullrand7_dm1
[rank0]:2025-10-29 15:58:29,250 - INFO - Mixed precision training with TP or PP is handled by autocast
[rank0]:2025-10-29 15:58:29,250 - INFO - Preparing c4_validation dataset from allenai/c4
[rank0]:2025-10-29 15:58:34,366 - INFO - Trainer is initialized with local batch size 16, global batch size 64, gradient accumulation steps 4, sequence length 1024, total steps 1600 (warmup 100)
[rank0]:2025-10-29 15:58:34,366 - INFO - Loading the checkpoint from /data2/shcho/torchtitan/base_model/Llama-3.2-1B-Instruct/original_dcp.
[rank0]:2025-10-29 15:58:37,570 - INFO - [GC] GC collection for checkpoint loading. 0.01 seconds
[rank0]:2025-10-29 15:58:37,570 - INFO - Finished loading the checkpoint in 3.20 seconds.
[rank0]:2025-10-29 15:58:37,570 - INFO - Training starts at step 1
[rank0]:2025-10-29 15:58:41,595 - INFO -  step:  1  loss: -4.0000  grad_norm: 54.0697  memory:  9.19GiB(19.34%)  tps: 1,303  tflops: 10.19  mfu: 3.27%
[rank0]:2025-10-29 15:58:41,596 - INFO - Synchronizing and adjusting timeout for all ProcessGroups to 0:05:00
[rank3]:2025-10-29 15:58:41,570 - INFO -  step:  1  loss:  9.8313  grad_norm: 54.0697  memory: 12.97GiB(27.30%)  tps: 1,207  tflops: 9.44  mfu: 3.03%
[rank3]:2025-10-29 15:58:41,571 - INFO - Synchronizing and adjusting timeout for all ProcessGroups to 0:05:00
[rank2]:2025-10-29 15:58:41,559 - INFO -  step:  1  loss: -4.0000  grad_norm: 54.0697  memory:  4.63GiB(9.75%)  tps: 1,071  tflops: 8.37  mfu: 2.68%
[rank2]:2025-10-29 15:58:41,560 - INFO - Synchronizing and adjusting timeout for all ProcessGroups to 0:05:00
[rank1]:2025-10-29 15:58:41,563 - INFO -  step:  1  loss: -4.0000  grad_norm: 54.0697  memory:  6.76GiB(14.24%)  tps: 1,065  tflops: 8.33  mfu: 2.67%
[rank1]:2025-10-29 15:58:41,564 - INFO - Synchronizing and adjusting timeout for all ProcessGroups to 0:05:00
[rank3]:2025-10-29 15:58:57,805 - WARNING - Batch index 1 is larger than log time length 0. Filling with zeros.
[rank3]:2025-10-29 15:58:57,807 - WARNING - Batch index 1 is larger than log time length 0. Filling with zeros.
[rank3]:2025-10-29 15:58:57,814 - WARNING - Batch index 1 is larger than log time length 0. Filling with zeros.
[rank3]:2025-10-29 15:58:57,815 - WARNING - Batch index 1 is larger than log time length 0. Filling with zeros.
[rank3]:2025-10-29 15:58:57,815 - WARNING - Batch index 1 is larger than log time length 0. Filling with zeros.
[rank3]:2025-10-29 15:58:57,815 - WARNING - Batch index 1 is larger than log time length 0. Filling with zeros.
[rank3]:2025-10-29 15:58:57,816 - WARNING - Batch index 1 is larger than log time length 0. Filling with zeros.
[rank3]:2025-10-29 15:58:57,816 - WARNING - Batch index 1 is larger than log time length 0. Filling with zeros.
[rank3]:2025-10-29 15:58:57,816 - WARNING - Batch index 1 is larger than log time length 0. Filling with zeros.
[rank3]:2025-10-29 15:58:57,816 - WARNING - Batch index 1 is larger than log time length 0. Filling with zeros.
[rank3]:2025-10-29 15:58:57,817 - WARNING - Batch index 1 is larger than log time length 0. Filling with zeros.
[rank3]:2025-10-29 15:58:57,817 - WARNING - Batch index 1 is larger than log time length 0. Filling with zeros.
[rank3]:2025-10-29 15:58:57,817 - WARNING - Batch index 1 is larger than log time length 0. Filling with zeros.
[rank3]:2025-10-29 15:58:57,818 - WARNING - Batch index 1 is larger than log time length 0. Filling with zeros.
[rank3]:2025-10-29 15:58:57,818 - WARNING - Batch index 1 is larger than log time length 0. Filling with zeros.
[rank3]:2025-10-29 15:58:57,818 - WARNING - Batch index 1 is larger than log time length 0. Filling with zeros.
[rank0]:2025-10-29 15:58:57,896 - WARNING - Batch index 1 is larger than log time length 0. Filling with zeros.
[rank0]:2025-10-29 15:58:57,896 - WARNING - Batch index 1 is larger than log time length 0. Filling with zeros.
[rank0]:2025-10-29 15:58:57,896 - WARNING - Batch index 1 is larger than log time length 0. Filling with zeros.
[rank0]:2025-10-29 15:58:57,896 - WARNING - Batch index 1 is larger than log time length 0. Filling with zeros.
[rank0]:2025-10-29 15:58:57,896 - WARNING - Batch index 1 is larger than log time length 0. Filling with zeros.
[rank0]:2025-10-29 15:58:57,897 - WARNING - Batch index 1 is larger than log time length 0. Filling with zeros.
[rank0]:2025-10-29 15:58:57,897 - WARNING - Batch index 1 is larger than log time length 0. Filling with zeros.
[rank0]:2025-10-29 15:58:57,897 - WARNING - Batch index 1 is larger than log time length 0. Filling with zeros.
[rank0]:2025-10-29 15:58:57,897 - WARNING - Batch index 1 is larger than log time length 0. Filling with zeros.
[rank0]:2025-10-29 15:58:57,897 - WARNING - Batch index 1 is larger than log time length 0. Filling with zeros.
[rank0]:2025-10-29 15:58:57,897 - WARNING - Batch index 1 is larger than log time length 0. Filling with zeros.
[rank0]:2025-10-29 15:58:57,897 - WARNING - Batch index 1 is larger than log time length 0. Filling with zeros.
[rank0]:2025-10-29 15:58:57,897 - WARNING - Batch index 1 is larger than log time length 0. Filling with zeros.
[rank0]:2025-10-29 15:58:57,897 - WARNING - Batch index 1 is larger than log time length 0. Filling with zeros.
[rank0]:2025-10-29 15:58:57,897 - WARNING - Batch index 1 is larger than log time length 0. Filling with zeros.
[rank0]:2025-10-29 15:58:57,897 - WARNING - Batch index 1 is larger than log time length 0. Filling with zeros.
[rank2]:2025-10-29 15:58:57,840 - WARNING - Batch index 1 is larger than log time length 0. Filling with zeros.
[rank2]:2025-10-29 15:58:57,840 - WARNING - Batch index 1 is larger than log time length 0. Filling with zeros.
[rank2]:2025-10-29 15:58:57,840 - WARNING - Batch index 1 is larger than log time length 0. Filling with zeros.
[rank2]:2025-10-29 15:58:57,840 - WARNING - Batch index 1 is larger than log time length 0. Filling with zeros.
[rank2]:2025-10-29 15:58:57,840 - WARNING - Batch index 1 is larger than log time length 0. Filling with zeros.
[rank2]:2025-10-29 15:58:57,840 - WARNING - Batch index 1 is larger than log time length 0. Filling with zeros.
[rank2]:2025-10-29 15:58:57,840 - WARNING - Batch index 1 is larger than log time length 0. Filling with zeros.
[rank2]:2025-10-29 15:58:57,841 - WARNING - Batch index 1 is larger than log time length 0. Filling with zeros.
[rank2]:2025-10-29 15:58:57,841 - WARNING - Batch index 1 is larger than log time length 0. Filling with zeros.
[rank2]:2025-10-29 15:58:57,841 - WARNING - Batch index 1 is larger than log time length 0. Filling with zeros.
[rank2]:2025-10-29 15:58:57,841 - WARNING - Batch index 1 is larger than log time length 0. Filling with zeros.
[rank2]:2025-10-29 15:58:57,841 - WARNING - Batch index 1 is larger than log time length 0. Filling with zeros.
[rank2]:2025-10-29 15:58:57,841 - WARNING - Batch index 1 is larger than log time length 0. Filling with zeros.
[rank2]:2025-10-29 15:58:57,841 - WARNING - Batch index 1 is larger than log time length 0. Filling with zeros.
[rank2]:2025-10-29 15:58:57,841 - WARNING - Batch index 1 is larger than log time length 0. Filling with zeros.
[rank2]:2025-10-29 15:58:57,841 - WARNING - Batch index 1 is larger than log time length 0. Filling with zeros.
[rank1]:2025-10-29 15:58:57,868 - WARNING - Batch index 1 is larger than log time length 0. Filling with zeros.
[rank1]:2025-10-29 15:58:57,868 - WARNING - Batch index 1 is larger than log time length 0. Filling with zeros.
[rank1]:2025-10-29 15:58:57,868 - WARNING - Batch index 1 is larger than log time length 0. Filling with zeros.
[rank1]:2025-10-29 15:58:57,868 - WARNING - Batch index 1 is larger than log time length 0. Filling with zeros.
[rank1]:2025-10-29 15:58:57,868 - WARNING - Batch index 1 is larger than log time length 0. Filling with zeros.
[rank1]:2025-10-29 15:58:57,868 - WARNING - Batch index 1 is larger than log time length 0. Filling with zeros.
[rank1]:2025-10-29 15:58:57,868 - WARNING - Batch index 1 is larger than log time length 0. Filling with zeros.
[rank1]:2025-10-29 15:58:57,868 - WARNING - Batch index 1 is larger than log time length 0. Filling with zeros.
[rank1]:2025-10-29 15:58:57,869 - WARNING - Batch index 1 is larger than log time length 0. Filling with zeros.
[rank1]:2025-10-29 15:58:57,869 - WARNING - Batch index 1 is larger than log time length 0. Filling with zeros.
[rank1]:2025-10-29 15:58:57,869 - WARNING - Batch index 1 is larger than log time length 0. Filling with zeros.
[rank1]:2025-10-29 15:58:57,869 - WARNING - Batch index 1 is larger than log time length 0. Filling with zeros.
[rank1]:2025-10-29 15:58:57,869 - WARNING - Batch index 1 is larger than log time length 0. Filling with zeros.
[rank1]:2025-10-29 15:58:57,869 - WARNING - Batch index 1 is larger than log time length 0. Filling with zeros.
[rank1]:2025-10-29 15:58:57,869 - WARNING - Batch index 1 is larger than log time length 0. Filling with zeros.
[rank1]:2025-10-29 15:58:57,869 - WARNING - Batch index 1 is larger than log time length 0. Filling with zeros.
[rank0]:2025-10-29 16:00:39,487 - INFO - [GC] Peforming periodical GC collection 0.00 seconds
[rank3]:2025-10-29 16:00:41,961 - INFO -  step: 50  loss:  9.4572  grad_norm: 21.2763  memory: 16.39GiB(34.50%)  tps: 6,669  tflops: 52.13  mfu: 16.71%
[rank1]:2025-10-29 16:00:41,952 - INFO -  step: 50  loss: -4.0000  grad_norm: 21.2763  memory:  9.03GiB(19.01%)  tps: 6,669  tflops: 52.13  mfu: 16.71%
[rank2]:2025-10-29 16:00:41,948 - INFO -  step: 50  loss: -4.0000  grad_norm: 21.2763  memory:  6.43GiB(13.53%)  tps: 6,669  tflops: 52.13  mfu: 16.71%
[rank0]:2025-10-29 16:00:41,962 - INFO -  step: 50  loss: -4.0000  grad_norm: 21.2763  memory: 12.97GiB(27.31%)  tps: 6,670  tflops: 52.14  mfu: 16.71%
[rank0]:2025-10-29 16:00:42,349 - INFO - Avg. fwd time: 7.3930 / Avg. bwd time: 23.7799 / Avg. batch time: 595.2621 (ms) / GPU bubble ratio: 58.11%
[rank3]:2025-10-29 16:00:42,281 - INFO - Avg. fwd time: 12.0686 / Avg. bwd time: 39.8798 / Avg. batch time: 490.5674 (ms) / GPU bubble ratio: 15.28%
[rank1]:2025-10-29 16:00:42,353 - INFO - Avg. fwd time: 9.0834 / Avg. bwd time: 23.5311 / Avg. batch time: 558.7535 (ms) / GPU bubble ratio: 53.30%
[rank2]:2025-10-29 16:00:42,320 - INFO - Avg. fwd time: 6.9429 / Avg. bwd time: 18.2817 / Avg. batch time: 520.8865 (ms) / GPU bubble ratio: 61.26%
[rank3]:2025-10-29 16:01:06,169 - INFO - [Step 60] „Ä∞Ô∏è Monitoring Upperbound
[rank3]:2025-10-29 16:01:30,879 - INFO - [Step 70] ‚úîÔ∏è  Setting Upperbound
[rank1]:2025-10-29 16:01:31,201 - WARNING - Batch index 281 is larger than freeze ratio history length 0. Filling with zeros.
[rank3]:2025-10-29 16:01:31,173 - INFO - [Step 70] „Ä∞Ô∏è Monitoring Lowerbound
[rank3]:2025-10-29 16:01:31,187 - WARNING - Batch index 281 is larger than freeze ratio history length 0. Filling with zeros.
[rank3]:2025-10-29 16:01:31,212 - WARNING - Batch index 281 is larger than freeze ratio history length 0. Filling with zeros.
[rank2]:2025-10-29 16:01:31,192 - WARNING - Batch index 281 is larger than freeze ratio history length 0. Filling with zeros.
[rank2]:2025-10-29 16:01:31,218 - WARNING - Batch index 281 is larger than freeze ratio history length 0. Filling with zeros.
[rank0]:2025-10-29 16:01:31,216 - WARNING - Batch index 281 is larger than freeze ratio history length 0. Filling with zeros.
[rank0]:2025-10-29 16:01:31,244 - WARNING - Batch index 281 is larger than freeze ratio history length 0. Filling with zeros.
[rank0]:2025-10-29 16:01:31,269 - WARNING - Batch index 281 is larger than freeze ratio history length 0. Filling with zeros.
[rank1]:2025-10-29 16:01:31,234 - WARNING - Batch index 281 is larger than freeze ratio history length 0. Filling with zeros.
[rank1]:2025-10-29 16:01:31,263 - WARNING - Batch index 281 is larger than freeze ratio history length 0. Filling with zeros.
[rank3]:2025-10-29 16:01:31,230 - WARNING - Batch index 281 is larger than freeze ratio history length 0. Filling with zeros.
[rank3]:2025-10-29 16:01:31,253 - WARNING - Batch index 281 is larger than freeze ratio history length 0. Filling with zeros.
[rank3]:2025-10-29 16:01:31,276 - WARNING - Batch index 281 is larger than freeze ratio history length 0. Filling with zeros.
[rank3]:2025-10-29 16:01:31,300 - WARNING - Batch index 281 is larger than freeze ratio history length 0. Filling with zeros.
[rank2]:2025-10-29 16:01:31,247 - WARNING - Batch index 281 is larger than freeze ratio history length 0. Filling with zeros.
[rank2]:2025-10-29 16:01:31,287 - WARNING - Batch index 281 is larger than freeze ratio history length 0. Filling with zeros.
[rank2]:2025-10-29 16:01:31,313 - WARNING - Batch index 281 is larger than freeze ratio history length 0. Filling with zeros.
[rank0]:2025-10-29 16:01:31,335 - WARNING - Batch index 281 is larger than freeze ratio history length 0. Filling with zeros.
[rank0]:2025-10-29 16:01:31,380 - WARNING - Batch index 281 is larger than freeze ratio history length 0. Filling with zeros.
[rank0]:2025-10-29 16:01:31,380 - WARNING - Batch index 281 is larger than freeze ratio history length 0. Filling with zeros.
[rank0]:2025-10-29 16:01:31,381 - WARNING - Batch index 281 is larger than freeze ratio history length 0. Filling with zeros.
[rank0]:2025-10-29 16:01:31,381 - WARNING - Batch index 281 is larger than freeze ratio history length 0. Filling with zeros.
[rank1]:2025-10-29 16:01:31,337 - WARNING - Batch index 281 is larger than freeze ratio history length 0. Filling with zeros.
[rank1]:2025-10-29 16:01:31,374 - WARNING - Batch index 281 is larger than freeze ratio history length 0. Filling with zeros.
[rank1]:2025-10-29 16:01:31,407 - WARNING - Batch index 281 is larger than freeze ratio history length 0. Filling with zeros.
[rank1]:2025-10-29 16:01:31,423 - WARNING - Batch index 281 is larger than freeze ratio history length 0. Filling with zeros.
[rank3]:2025-10-29 16:01:31,338 - WARNING - Batch index 281 is larger than freeze ratio history length 0. Filling with zeros.
[rank3]:2025-10-29 16:01:31,383 - WARNING - Batch index 281 is larger than freeze ratio history length 0. Filling with zeros.
[rank2]:2025-10-29 16:01:31,353 - WARNING - Batch index 281 is larger than freeze ratio history length 0. Filling with zeros.
[rank2]:2025-10-29 16:01:31,393 - WARNING - Batch index 281 is larger than freeze ratio history length 0. Filling with zeros.
[rank2]:2025-10-29 16:01:31,421 - WARNING - Batch index 281 is larger than freeze ratio history length 0. Filling with zeros.
[rank1]:2025-10-29 16:01:31,439 - WARNING - Batch index 281 is larger than freeze ratio history length 0. Filling with zeros.
[rank3]:2025-10-29 16:02:03,735 - INFO - [Step 90] ‚úîÔ∏è  Setting Lowerbound
[rank3]:2025-10-29 16:02:04,147 - INFO - Pipeline schedule is saved as: /data2/shcho/torchtitan/images/1028_1F1B_fullrand7_dm1/pipeline_schedule/251029_1602_max_batch_time.svg
[rank3]:> Batch Time: 521.57 ms, GPU Bubble Ratio: 51.45%, 49.20%, 60.58%, 18.29%
[rank3]:2025-10-29 16:02:04,329 - INFO - Pipeline schedule is saved as: /data2/shcho/torchtitan/images/1028_1F1B_fullrand7_dm1/pipeline_schedule/251029_1602_min_batch_time.svg
[rank3]:> Batch Time: 314.01 ms, GPU Bubble Ratio: 80.85%, 49.13%, 60.85%, 15.27%
[rank3]:2025-10-29 16:02:04,528 - INFO - Pipeline schedule is saved as: /data2/shcho/torchtitan/images/1028_1F1B_fullrand7_dm1/pipeline_schedule/251029_1602_frozen_pipeline_schedule.svg
[rank3]:> Batch Time: 328.95 ms, GPU Bubble Ratio: 34.42%, 23.48%, 40.62%, 14.58%
[rank3]:2025-10-29 16:02:04,528 - INFO - 	> Batch Time: 328.95 ms (Average Freeze Ratio: 0.34, Time Reduction Rate: 0.37)
[rank0]:2025-10-29 16:02:21,475 - INFO - [GC] Peforming periodical GC collection 0.00 seconds
[rank3]:2025-10-29 16:02:23,272 - INFO - Current/Expected Freeze Ratio per Block: [MB0] 0.33/1.00, [MB1] 0.07/0.20, [MB2] 0.33/1.00, [MB3] 0.33/1.00, [MB4] 0.33/1.00, [MB5] 0.33/1.00, [MB6] 0.33/1.00, [MB7] 0.33/1.00
[rank2]:2025-10-29 16:02:23,282 - INFO - Current/Expected Freeze Ratio per Block: [MB0] 0.00/0.00, [MB1] 0.00/0.00, [MB2] 0.00/0.00, [MB3] 0.00/0.00, [MB4] 0.00/0.00, [MB5] 0.00/0.00, [MB6] 0.00/0.00, [MB7] 0.33/1.00
[rank0]:2025-10-29 16:02:23,324 - INFO - Current/Expected Freeze Ratio per Block: [MB0] 0.00/0.00, [MB1] 0.00/0.00, [MB2] 0.00/0.00, [MB3] 0.00/0.00, [MB4] 0.00/0.00, [MB5] 0.00/0.00, [MB6] 0.19/0.56, [MB7] 0.33/1.00
[rank0]:2025-10-29 16:02:23,352 - INFO -  step: 100  loss: -4.0000  grad_norm:  6.5558  memory: 12.97GiB(27.31%)  tps: 8,080  tflops: 63.16  mfu: 20.24%
[rank1]:2025-10-29 16:02:23,304 - INFO - Current/Expected Freeze Ratio per Block: [MB0] 0.00/0.00, [MB1] 0.00/0.00, [MB2] 0.00/0.00, [MB3] 0.00/0.00, [MB4] 0.00/0.00, [MB5] 0.00/0.00, [MB6] 0.00/0.01, [MB7] 0.33/1.00
[rank1]:2025-10-29 16:02:23,342 - INFO -  step: 100  loss: -4.0000  grad_norm:  6.5558  memory:  9.36GiB(19.71%)  tps: 8,080  tflops: 63.16  mfu: 20.24%
[rank3]:2025-10-29 16:02:23,325 - INFO -  step: 100  loss:  9.8496  grad_norm:  0.0000  memory: 16.39GiB(34.50%)  tps: 8,082  tflops: 63.18  mfu: 20.25%
[rank2]:2025-10-29 16:02:23,337 - INFO -  step: 100  loss: -4.0000  grad_norm:  6.5558  memory:  6.51GiB(13.70%)  tps: 8,080  tflops: 63.16  mfu: 20.24%
[rank0]:2025-10-29 16:02:23,431 - INFO - Frozen Ratio History of Rank 0 (Stage 0)  is saved as: /data2/shcho/torchtitan/images/1028_1F1B_fullrand7_dm1/freeze_ratio_history/rank0/251029_1602_stage0_step100.svg
[rank1]:2025-10-29 16:02:23,431 - INFO - Frozen Ratio History of Rank 1 (Stage 1)  is saved as: /data2/shcho/torchtitan/images/1028_1F1B_fullrand7_dm1/freeze_ratio_history/rank1/251029_1602_stage1_step100.svg
[rank2]:2025-10-29 16:02:23,431 - INFO - Frozen Ratio History of Rank 2 (Stage 2)  is saved as: /data2/shcho/torchtitan/images/1028_1F1B_fullrand7_dm1/freeze_ratio_history/rank2/251029_1602_stage2_step100.svg
[rank3]:2025-10-29 16:02:23,537 - INFO - Pipeline schedule is saved as: /data2/shcho/torchtitan/images/1028_1F1B_fullrand7_dm1/pipeline_schedule/251029_1602_real_step100_rank3.svg
[rank3]:> Batch Time: 513.89 ms, GPU Bubble Ratio: 51.10%, 48.79%, 60.37%, 18.41%
[rank3]:2025-10-29 16:02:23,600 - INFO - Frozen Ratio History of Rank 3 (Stage 3)  is saved as: /data2/shcho/torchtitan/images/1028_1F1B_fullrand7_dm1/freeze_ratio_history/rank3/251029_1602_stage3_step100.svg
[rank0]:2025-10-29 16:02:23,860 - INFO - Avg. fwd time: 7.7562 / Avg. bwd time: 17.9321 / Avg. batch time: 546.7721 (ms) / GPU bubble ratio: 62.41%
[rank3]:2025-10-29 16:02:23,820 - INFO - Avg. fwd time: 12.5747 / Avg. bwd time: 34.6816 / Avg. batch time: 451.3788 (ms) / GPU bubble ratio: 16.25%
[rank2]:2025-10-29 16:02:23,882 - INFO - Avg. fwd time: 7.3232 / Avg. bwd time: 16.0885 / Avg. batch time: 480.7639 (ms) / GPU bubble ratio: 61.04%
[rank1]:2025-10-29 16:02:23,917 - INFO - Avg. fwd time: 9.5601 / Avg. bwd time: 20.5991 / Avg. batch time: 515.7481 (ms) / GPU bubble ratio: 53.22%
[rank0]:2025-10-29 16:04:06,748 - INFO - [GC] Peforming periodical GC collection 0.00 seconds
[rank3]:2025-10-29 16:04:08,473 - INFO - Current/Expected Freeze Ratio per Block: [MB0] 0.67/1.00, [MB1] 0.13/0.20, [MB2] 0.67/1.00, [MB3] 0.67/1.00, [MB4] 0.67/1.00, [MB5] 0.67/1.00, [MB6] 0.67/1.00, [MB7] 0.67/1.00
[rank0]:2025-10-29 16:04:08,706 - INFO - Current/Expected Freeze Ratio per Block: [MB0] 0.00/0.00, [MB1] 0.00/0.00, [MB2] 0.00/0.00, [MB3] 0.00/0.00, [MB4] 0.00/0.00, [MB5] 0.00/0.00, [MB6] 0.37/0.56, [MB7] 0.67/1.00
[rank3]:2025-10-29 16:04:08,717 - INFO -  step: 150  loss:  3.8727  grad_norm:  4.0929  memory: 16.88GiB(35.53%)  tps: 7,773  tflops: 60.77  mfu: 19.48%
[rank1]:2025-10-29 16:04:08,685 - INFO - Current/Expected Freeze Ratio per Block: [MB0] 0.00/0.00, [MB1] 0.00/0.00, [MB2] 0.00/0.00, [MB3] 0.00/0.00, [MB4] 0.00/0.00, [MB5] 0.00/0.00, [MB6] 0.01/0.01, [MB7] 0.67/1.00
[rank1]:2025-10-29 16:04:08,723 - INFO -  step: 150  loss: -4.0000  grad_norm:  4.0929  memory:  9.36GiB(19.71%)  tps: 7,774  tflops: 60.77  mfu: 19.48%
[rank2]:2025-10-29 16:04:08,661 - INFO - Current/Expected Freeze Ratio per Block: [MB0] 0.00/0.00, [MB1] 0.00/0.00, [MB2] 0.00/0.00, [MB3] 0.00/0.00, [MB4] 0.00/0.00, [MB5] 0.00/0.00, [MB6] 0.00/0.00, [MB7] 0.67/1.00
[rank2]:2025-10-29 16:04:08,719 - INFO -  step: 150  loss: -4.0000  grad_norm:  4.0929  memory:  6.51GiB(13.70%)  tps: 7,774  tflops: 60.77  mfu: 19.48%
[rank0]:2025-10-29 16:04:08,737 - INFO -  step: 150  loss: -4.0000  grad_norm:  4.0929  memory: 13.23GiB(27.85%)  tps: 7,773  tflops: 60.77  mfu: 19.48%
[rank3]:2025-10-29 16:04:09,149 - INFO - Avg. fwd time: 12.8368 / Avg. bwd time: 32.5207 / Avg. batch time: 436.1132 (ms) / GPU bubble ratio: 16.80%
[rank1]:2025-10-29 16:04:09,198 - INFO - Avg. fwd time: 9.5423 / Avg. bwd time: 20.8126 / Avg. batch time: 501.1322 (ms) / GPU bubble ratio: 51.54%
[rank2]:2025-10-29 16:04:09,172 - INFO - Avg. fwd time: 7.2771 / Avg. bwd time: 16.4820 / Avg. batch time: 465.6397 (ms) / GPU bubble ratio: 59.18%
[rank0]:2025-10-29 16:04:09,220 - INFO - Avg. fwd time: 7.7929 / Avg. bwd time: 17.8771 / Avg. batch time: 532.3370 (ms) / GPU bubble ratio: 61.42%
[rank0]:2025-10-29 16:05:44,595 - INFO - [GC] Peforming periodical GC collection 0.00 seconds
[rank3]:2025-10-29 16:05:46,273 - INFO - Current/Expected Freeze Ratio per Block: [MB0] 1.00/1.00, [MB1] 0.20/0.20, [MB2] 1.00/1.00, [MB3] 1.00/1.00, [MB4] 1.00/1.00, [MB5] 1.00/1.00, [MB6] 1.00/1.00, [MB7] 1.00/1.00
[rank2]:2025-10-29 16:05:46,465 - INFO - Current/Expected Freeze Ratio per Block: [MB0] 0.00/0.00, [MB1] 0.00/0.00, [MB2] 0.00/0.00, [MB3] 0.00/0.00, [MB4] 0.00/0.00, [MB5] 0.00/0.00, [MB6] 0.00/0.00, [MB7] 1.00/1.00
[rank0]:2025-10-29 16:05:46,508 - INFO - Current/Expected Freeze Ratio per Block: [MB0] 0.00/0.00, [MB1] 0.00/0.00, [MB2] 0.00/0.00, [MB3] 0.00/0.00, [MB4] 0.00/0.00, [MB5] 0.00/0.00, [MB6] 0.56/0.56, [MB7] 1.00/1.00
[rank1]:2025-10-29 16:05:46,488 - INFO - Current/Expected Freeze Ratio per Block: [MB0] 0.00/0.00, [MB1] 0.00/0.00, [MB2] 0.00/0.00, [MB3] 0.00/0.00, [MB4] 0.00/0.00, [MB5] 0.00/0.00, [MB6] 0.01/0.01, [MB7] 1.00/1.00
[rank1]:2025-10-29 16:05:46,526 - INFO -  step: 200  loss: -4.0000  grad_norm:  3.6492  memory:  9.36GiB(19.71%)  tps: 8,376  tflops: 65.48  mfu: 20.99%
[rank1]:2025-10-29 16:05:46,526 - INFO - üîé  Running validation at step 200
[rank3]:2025-10-29 16:05:46,527 - INFO -  step: 200  loss:  1.5712  grad_norm:  3.6492  memory: 16.88GiB(35.53%)  tps: 8,376  tflops: 65.48  mfu: 20.99%
[rank3]:2025-10-29 16:05:46,527 - INFO - üîé  Running validation at step 200
[rank2]:2025-10-29 16:05:46,522 - INFO -  step: 200  loss: -4.0000  grad_norm:  3.6492  memory:  6.51GiB(13.70%)  tps: 8,376  tflops: 65.48  mfu: 20.99%
[rank2]:2025-10-29 16:05:46,522 - INFO - üîé  Running validation at step 200
[rank0]:2025-10-29 16:05:46,537 - INFO -  step: 200  loss: -4.0000  grad_norm:  3.6492  memory: 13.23GiB(27.85%)  tps: 8,376  tflops: 65.48  mfu: 20.99%
[rank0]:2025-10-29 16:05:46,537 - INFO - üîé  Running validation at step 200
[rank0]:2025-10-29 16:06:08,909 - INFO - validate step: 200  loss: -1.0000  memory: 13.23GiB(27.85%)  tps: 18,309
[rank1]:2025-10-29 16:06:08,927 - INFO - validate step: 200  loss: -1.0000  memory:  9.36GiB(19.71%)  tps: 18,285
[rank3]:2025-10-29 16:06:08,956 - INFO - validate step: 200  loss:  0.5383  memory: 16.88GiB(35.53%)  tps: 18,263
[rank2]:2025-10-29 16:06:08,946 - INFO - validate step: 200  loss: -1.0000  memory:  6.51GiB(13.70%)  tps: 18,267
[rank0]:2025-10-29 16:06:09,031 - INFO - Frozen Ratio History of Rank 0 (Stage 0)  is saved as: /data2/shcho/torchtitan/images/1028_1F1B_fullrand7_dm1/freeze_ratio_history/rank0/251029_1606_stage0_step200.svg
[rank1]:2025-10-29 16:06:09,031 - INFO - Frozen Ratio History of Rank 1 (Stage 1)  is saved as: /data2/shcho/torchtitan/images/1028_1F1B_fullrand7_dm1/freeze_ratio_history/rank1/251029_1606_stage1_step200.svg
[rank2]:2025-10-29 16:06:09,036 - INFO - Frozen Ratio History of Rank 2 (Stage 2)  is saved as: /data2/shcho/torchtitan/images/1028_1F1B_fullrand7_dm1/freeze_ratio_history/rank2/251029_1606_stage2_step200.svg
[rank3]:2025-10-29 16:06:09,140 - INFO - Pipeline schedule is saved as: /data2/shcho/torchtitan/images/1028_1F1B_fullrand7_dm1/pipeline_schedule/251029_1606_real_step200_rank3.svg
[rank3]:> Batch Time: 420.90 ms, GPU Bubble Ratio: 50.00%, 41.85%, 53.78%, 20.68%
[rank3]:2025-10-29 16:06:09,207 - INFO - Frozen Ratio History of Rank 3 (Stage 3)  is saved as: /data2/shcho/torchtitan/images/1028_1F1B_fullrand7_dm1/freeze_ratio_history/rank3/251029_1606_stage3_step200.svg
[rank0]:2025-10-29 16:06:09,457 - INFO - Avg. fwd time: 7.8760 / Avg. bwd time: 17.0278 / Avg. batch time: 518.4420 (ms) / GPU bubble ratio: 61.57%
[rank3]:2025-10-29 16:06:09,401 - INFO - Avg. fwd time: 12.9739 / Avg. bwd time: 30.7033 / Avg. batch time: 422.6629 (ms) / GPU bubble ratio: 17.33%
[rank2]:2025-10-29 16:06:09,466 - INFO - Avg. fwd time: 7.2890 / Avg. bwd time: 16.4609 / Avg. batch time: 451.8997 (ms) / GPU bubble ratio: 57.96%
[rank1]:2025-10-29 16:06:09,502 - INFO - Avg. fwd time: 9.5809 / Avg. bwd time: 20.5884 / Avg. batch time: 487.4147 (ms) / GPU bubble ratio: 50.48%
[rank0]:2025-10-29 16:07:40,640 - INFO - [GC] Peforming periodical GC collection 0.01 seconds
[rank1]:2025-10-29 16:07:42,472 - INFO - Current/Expected Freeze Ratio per Block: [MB0] 0.00/0.00, [MB1] 0.00/0.00, [MB2] 0.00/0.00, [MB3] 0.00/0.00, [MB4] 0.00/0.00, [MB5] 0.00/0.00, [MB6] 0.01/0.01, [MB7] 1.00/1.00
[rank3]:2025-10-29 16:07:42,438 - INFO - Current/Expected Freeze Ratio per Block: [MB0] 1.00/1.00, [MB1] 0.20/0.20, [MB2] 1.00/1.00, [MB3] 1.00/1.00, [MB4] 1.00/1.00, [MB5] 1.00/1.00, [MB6] 1.00/1.00, [MB7] 1.00/1.00
[rank3]:2025-10-29 16:07:42,493 - INFO -  step: 250  loss:  1.2140  grad_norm:  0.0000  memory: 16.88GiB(35.53%)  tps: 8,758  tflops: 68.47  mfu: 21.94%
[rank2]:2025-10-29 16:07:42,449 - INFO - Current/Expected Freeze Ratio per Block: [MB0] 0.00/0.00, [MB1] 0.00/0.00, [MB2] 0.00/0.00, [MB3] 0.00/0.00, [MB4] 0.00/0.00, [MB5] 0.00/0.00, [MB6] 0.00/0.00, [MB7] 1.00/1.00
[rank2]:2025-10-29 16:07:42,505 - INFO -  step: 250  loss: -4.0000  grad_norm:  5.8952  memory:  6.51GiB(13.70%)  tps: 8,756  tflops: 68.45  mfu: 21.94%
[rank0]:2025-10-29 16:07:42,491 - INFO - Current/Expected Freeze Ratio per Block: [MB0] 0.00/0.00, [MB1] 0.00/0.00, [MB2] 0.00/0.00, [MB3] 0.00/0.00, [MB4] 0.00/0.00, [MB5] 0.00/0.00, [MB6] 0.56/0.56, [MB7] 1.00/1.00
[rank0]:2025-10-29 16:07:42,520 - INFO -  step: 250  loss: -4.0000  grad_norm:  5.8952  memory: 13.23GiB(27.85%)  tps: 8,751  tflops: 68.41  mfu: 21.93%
[rank1]:2025-10-29 16:07:42,509 - INFO -  step: 250  loss: -4.0000  grad_norm:  5.8952  memory:  9.36GiB(19.71%)  tps: 8,754  tflops: 68.43  mfu: 21.93%
[rank3]:2025-10-29 16:07:42,743 - INFO - Avg. fwd time: 13.0992 / Avg. bwd time: 28.8704 / Avg. batch time: 408.7482 (ms) / GPU bubble ratio: 17.86%
[rank2]:2025-10-29 16:07:42,807 - INFO - Avg. fwd time: 7.3138 / Avg. bwd time: 16.3009 / Avg. batch time: 437.7469 (ms) / GPU bubble ratio: 56.84%
[rank0]:2025-10-29 16:07:42,796 - INFO - Avg. fwd time: 7.9513 / Avg. bwd time: 15.6546 / Avg. batch time: 503.8879 (ms) / GPU bubble ratio: 62.52%
[rank1]:2025-10-29 16:07:42,843 - INFO - Avg. fwd time: 9.6443 / Avg. bwd time: 20.1781 / Avg. batch time: 473.1408 (ms) / GPU bubble ratio: 49.58%
[rank0]:2025-10-29 16:09:13,605 - INFO - [GC] Peforming periodical GC collection 0.00 seconds
[rank3]:2025-10-29 16:09:15,613 - INFO - Observed values (freeze ratio vs time) with Trend Line is saved as: /data2/shcho/torchtitan/images/1028_1F1B_fullrand7_dm1/pipeline_schedule_adjustment/251029_1609_rank3_trend_line.svg
[rank3]:2025-10-29 16:09:15,653 - INFO - Destroying the purge thread.
[rank2]:2025-10-29 16:09:15,645 - INFO - Observed values (freeze ratio vs time) with Trend Line is saved as: /data2/shcho/torchtitan/images/1028_1F1B_fullrand7_dm1/pipeline_schedule_adjustment/251029_1609_rank2_trend_line.svg
[rank2]:2025-10-29 16:09:15,654 - INFO - Destroying the purge thread.
[rank2]:[rank2]: Traceback (most recent call last):
[rank2]:[rank2]:   File "<frozen runpy>", line 198, in _run_module_as_main
[rank2]:[rank2]:   File "<frozen runpy>", line 88, in _run_code
[rank2]:[rank2]:   File "/home/shcho/torchtitan/timelyfreeze/train.py", line 725, in <module>
[rank2]:[rank2]:     trainer.train()
[rank2]:[rank2]:   File "/data2/shcho/miniforge3/envs/llm_eval/lib/python3.11/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 362, in wrapper
[rank2]:[rank2]:     return f(*args, **kwargs)
[rank2]:[rank2]:            ^^^^^^^^^^^^^^^^^^
[rank2]:[rank2]:   File "/home/shcho/torchtitan/timelyfreeze/train.py", line 584, in train
[rank2]:[rank2]:     self.train_step(data_iterator)
[rank2]:[rank2]:   File "/home/shcho/torchtitan/timelyfreeze/train.py", line 509, in train_step
[rank2]:[rank2]:     self.freezer.freeze_update(self.step) # this should be called after optimizer.step()
[rank2]:[rank2]:     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank2]:[rank2]:   File "/home/shcho/torchtitan/timelyfreeze/core/freezer.py", line 137, in freeze_update
[rank2]:[rank2]:     self.set_expected_freeze_ratio()
[rank2]:[rank2]:   File "/home/shcho/torchtitan/timelyfreeze/core/freezer.py", line 184, in set_expected_freeze_ratio
[rank2]:[rank2]:     self.pipeline_schedule = adjust_freeze_ratio(self.pipeline_schedule, monitored_values_dict, self.config)
[rank2]:[rank2]:                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank2]:[rank2]:   File "/home/shcho/torchtitan/timelyfreeze/core/schedule.py", line 428, in adjust_freeze_ratio
[rank2]:[rank2]:     pipeline_schedule = solve_dag_lp(pipeline_schedule) # solve the DAG LP problem to find the optimal schedule
[rank2]:[rank2]:                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank2]:[rank2]:   File "/home/shcho/torchtitan/timelyfreeze/core/schedule.py", line 171, in solve_dag_lp
[rank2]:[rank2]:     row[n + idx] = -1.0 / (w_max - w_min)
[rank2]:[rank2]:                    ~~~~~^~~~~~~~~~~~~~~~~
[rank2]:[rank2]: ZeroDivisionError: float division by zero
[rank1]:2025-10-29 16:09:15,633 - INFO - Observed values (freeze ratio vs time) with Trend Line is saved as: /data2/shcho/torchtitan/images/1028_1F1B_fullrand7_dm1/pipeline_schedule_adjustment/251029_1609_rank1_trend_line.svg
[rank1]:2025-10-29 16:09:15,653 - INFO - Destroying the purge thread.
[rank1]:[rank1]: Traceback (most recent call last):
[rank1]:[rank1]:   File "<frozen runpy>", line 198, in _run_module_as_main
[rank1]:[rank1]:   File "<frozen runpy>", line 88, in _run_code
[rank1]:[rank1]:   File "/home/shcho/torchtitan/timelyfreeze/train.py", line 725, in <module>
[rank1]:[rank1]:     trainer.train()
[rank1]:[rank1]:   File "/data2/shcho/miniforge3/envs/llm_eval/lib/python3.11/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 362, in wrapper
[rank1]:[rank1]:     return f(*args, **kwargs)
[rank1]:[rank1]:            ^^^^^^^^^^^^^^^^^^
[rank1]:[rank1]:   File "/home/shcho/torchtitan/timelyfreeze/train.py", line 584, in train
[rank1]:[rank1]:     self.train_step(data_iterator)
[rank1]:[rank1]:   File "/home/shcho/torchtitan/timelyfreeze/train.py", line 509, in train_step
[rank1]:[rank1]:     self.freezer.freeze_update(self.step) # this should be called after optimizer.step()
[rank1]:[rank1]:     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank1]:[rank1]:   File "/home/shcho/torchtitan/timelyfreeze/core/freezer.py", line 137, in freeze_update
[rank1]:[rank1]:     self.set_expected_freeze_ratio()
[rank1]:[rank1]:   File "/home/shcho/torchtitan/timelyfreeze/core/freezer.py", line 184, in set_expected_freeze_ratio
[rank1]:[rank1]:     self.pipeline_schedule = adjust_freeze_ratio(self.pipeline_schedule, monitored_values_dict, self.config)
[rank1]:[rank1]:                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank1]:[rank1]:   File "/home/shcho/torchtitan/timelyfreeze/core/schedule.py", line 428, in adjust_freeze_ratio
[rank1]:[rank1]:     pipeline_schedule = solve_dag_lp(pipeline_schedule) # solve the DAG LP problem to find the optimal schedule
[rank1]:[rank1]:                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank1]:[rank1]:   File "/home/shcho/torchtitan/timelyfreeze/core/schedule.py", line 171, in solve_dag_lp
[rank1]:[rank1]:     row[n + idx] = -1.0 / (w_max - w_min)
[rank1]:[rank1]:                    ~~~~~^~~~~~~~~~~~~~~~~
[rank1]:[rank1]: ZeroDivisionError: float division by zero
[rank0]:2025-10-29 16:09:15,650 - INFO - Observed values (freeze ratio vs time) with Trend Line is saved as: /data2/shcho/torchtitan/images/1028_1F1B_fullrand7_dm1/pipeline_schedule_adjustment/251029_1609_rank0_trend_line.svg
[rank0]:2025-10-29 16:09:15,654 - INFO - Destroying the purge thread.
[rank0]:[rank0]: Traceback (most recent call last):
[rank0]:[rank0]:   File "<frozen runpy>", line 198, in _run_module_as_main
[rank0]:[rank0]:   File "<frozen runpy>", line 88, in _run_code
[rank0]:[rank0]:   File "/home/shcho/torchtitan/timelyfreeze/train.py", line 725, in <module>
[rank0]:[rank0]:     trainer.train()
[rank0]:[rank0]:   File "/data2/shcho/miniforge3/envs/llm_eval/lib/python3.11/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 362, in wrapper
[rank0]:[rank0]:     return f(*args, **kwargs)
[rank0]:[rank0]:            ^^^^^^^^^^^^^^^^^^
[rank0]:[rank0]:   File "/home/shcho/torchtitan/timelyfreeze/train.py", line 584, in train
[rank0]:[rank0]:     self.train_step(data_iterator)
[rank0]:[rank0]:   File "/home/shcho/torchtitan/timelyfreeze/train.py", line 509, in train_step
[rank0]:[rank0]:     self.freezer.freeze_update(self.step) # this should be called after optimizer.step()
[rank0]:[rank0]:     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank0]:[rank0]:   File "/home/shcho/torchtitan/timelyfreeze/core/freezer.py", line 137, in freeze_update
[rank0]:[rank0]:     self.set_expected_freeze_ratio()
[rank0]:[rank0]:   File "/home/shcho/torchtitan/timelyfreeze/core/freezer.py", line 184, in set_expected_freeze_ratio
[rank0]:[rank0]:     self.pipeline_schedule = adjust_freeze_ratio(self.pipeline_schedule, monitored_values_dict, self.config)
[rank0]:[rank0]:                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank0]:[rank0]:   File "/home/shcho/torchtitan/timelyfreeze/core/schedule.py", line 428, in adjust_freeze_ratio
[rank0]:[rank0]:     pipeline_schedule = solve_dag_lp(pipeline_schedule) # solve the DAG LP problem to find the optimal schedule
[rank0]:[rank0]:                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank0]:[rank0]:   File "/home/shcho/torchtitan/timelyfreeze/core/schedule.py", line 171, in solve_dag_lp
[rank0]:[rank0]:     row[n + idx] = -1.0 / (w_max - w_min)
[rank0]:[rank0]:                    ~~~~~^~~~~~~~~~~~~~~~~
[rank0]:[rank0]: ZeroDivisionError: float division by zero
[rank3]:wandb: updating run metadata
[rank0]:[rank0]:[W1029 16:09:16.947751821 ProcessGroupNCCL.cpp:1552] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
[rank3]:wandb: uploading history steps 5-5, summary, console lines 232-233
[rank3]:wandb: 
[rank3]:wandb: Run history:
[rank3]:wandb:                    grad_norm ‚ñà‚ñÑ‚ñÅ‚ñÇ‚ñÅ‚ñÅ
[rank3]:wandb: loss_metrics/global_avg_loss ‚ñà‚ñà‚ñà‚ñÉ‚ñÅ‚ñÅ
[rank3]:wandb: loss_metrics/global_max_loss ‚ñà‚ñà‚ñà‚ñÉ‚ñÅ‚ñÅ
[rank3]:wandb:                           lr ‚ñÅ‚ñÑ‚ñà‚ñà‚ñà‚ñà
[rank3]:wandb:         memory/max_active(%) ‚ñÅ‚ñà‚ñà‚ñà‚ñà‚ñÖ
[rank3]:wandb:       memory/max_active(GiB) ‚ñÅ‚ñà‚ñà‚ñà‚ñà‚ñÖ
[rank3]:wandb:       memory/max_reserved(%) ‚ñÅ‚ñá‚ñá‚ñà‚ñà‚ñà
[rank3]:wandb:     memory/max_reserved(GiB) ‚ñÅ‚ñá‚ñá‚ñà‚ñà‚ñà
[rank3]:wandb:     memory/num_alloc_retries ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[rank3]:wandb:              memory/num_ooms ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[rank3]:wandb:                          +13 ...
[rank3]:wandb: 
[rank3]:wandb: Run summary:
[rank3]:wandb:                    grad_norm 0
[rank3]:wandb: loss_metrics/global_avg_loss 1.21396
[rank3]:wandb: loss_metrics/global_max_loss 1.21396
[rank3]:wandb:                           lr 1e-05
[rank3]:wandb:         memory/max_active(%) 29.79311
[rank3]:wandb:       memory/max_active(GiB) 14.1538
[rank3]:wandb:       memory/max_reserved(%) 35.52933
[rank3]:wandb:     memory/max_reserved(GiB) 16.87891
[rank3]:wandb:     memory/num_alloc_retries 0
[rank3]:wandb:              memory/num_ooms 0
[rank3]:wandb:                          +13 ...
[rank3]:wandb: 
[rank3]:wandb: üöÄ View run 1028_1F1B_fullrand7_dm1 at: https://wandb.ai/orangingq/torchtitan/runs/sy8qkvi8
[rank3]:wandb: ‚≠êÔ∏è View project at: https://wandb.ai/orangingq/torchtitan
[rank3]:wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
[rank3]:wandb: Find logs at: /data2/shcho/torchtitan/tb/1028_1F1B_fullrand7_dm1/20251029-1558/wandb/run-20251029_155826-sy8qkvi8/logs
[rank3]:Traceback (most recent call last):
[rank3]:  File "<frozen runpy>", line 198, in _run_module_as_main
[rank3]:  File "<frozen runpy>", line 88, in _run_code
[rank3]:  File "/home/shcho/torchtitan/timelyfreeze/train.py", line 725, in <module>
[rank3]:    trainer.train()
[rank3]:  File "/data2/shcho/miniforge3/envs/llm_eval/lib/python3.11/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 362, in wrapper
[rank3]:    return f(*args, **kwargs)
[rank3]:           ^^^^^^^^^^^^^^^^^^
[rank3]:  File "/home/shcho/torchtitan/timelyfreeze/train.py", line 584, in train
[rank3]:    self.train_step(data_iterator)
[rank3]:  File "/home/shcho/torchtitan/timelyfreeze/train.py", line 509, in train_step
[rank3]:    self.freezer.freeze_update(self.step) # this should be called after optimizer.step()
[rank3]:    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank3]:  File "/home/shcho/torchtitan/timelyfreeze/core/freezer.py", line 137, in freeze_update
[rank3]:    self.set_expected_freeze_ratio()
[rank3]:  File "/home/shcho/torchtitan/timelyfreeze/core/freezer.py", line 184, in set_expected_freeze_ratio
[rank3]:    self.pipeline_schedule = adjust_freeze_ratio(self.pipeline_schedule, monitored_values_dict, self.config)
[rank3]:                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank3]:  File "/home/shcho/torchtitan/timelyfreeze/core/schedule.py", line 428, in adjust_freeze_ratio
[rank3]:    pipeline_schedule = solve_dag_lp(pipeline_schedule) # solve the DAG LP problem to find the optimal schedule
[rank3]:                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank3]:  File "/home/shcho/torchtitan/timelyfreeze/core/schedule.py", line 171, in solve_dag_lp
[rank3]:    row[n + idx] = -1.0 / (w_max - w_min)
[rank3]:                   ~~~~~^~~~~~~~~~~~~~~~~
[rank3]:ZeroDivisionError: float division by zero
[rank3]:[rank3]: Traceback (most recent call last):
[rank3]:[rank3]:   File "<frozen runpy>", line 198, in _run_module_as_main
[rank3]:[rank3]:   File "<frozen runpy>", line 88, in _run_code
[rank3]:[rank3]:   File "/home/shcho/torchtitan/timelyfreeze/train.py", line 725, in <module>
[rank3]:[rank3]:     trainer.train()
[rank3]:[rank3]:   File "/data2/shcho/miniforge3/envs/llm_eval/lib/python3.11/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 362, in wrapper
[rank3]:[rank3]:     return f(*args, **kwargs)
[rank3]:[rank3]:            ^^^^^^^^^^^^^^^^^^
[rank3]:[rank3]:   File "/home/shcho/torchtitan/timelyfreeze/train.py", line 584, in train
[rank3]:[rank3]:     self.train_step(data_iterator)
[rank3]:[rank3]:   File "/home/shcho/torchtitan/timelyfreeze/train.py", line 509, in train_step
[rank3]:[rank3]:     self.freezer.freeze_update(self.step) # this should be called after optimizer.step()
[rank3]:[rank3]:     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank3]:[rank3]:   File "/home/shcho/torchtitan/timelyfreeze/core/freezer.py", line 137, in freeze_update
[rank3]:[rank3]:     self.set_expected_freeze_ratio()
[rank3]:[rank3]:   File "/home/shcho/torchtitan/timelyfreeze/core/freezer.py", line 184, in set_expected_freeze_ratio
[rank3]:[rank3]:     self.pipeline_schedule = adjust_freeze_ratio(self.pipeline_schedule, monitored_values_dict, self.config)
[rank3]:[rank3]:                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank3]:[rank3]:   File "/home/shcho/torchtitan/timelyfreeze/core/schedule.py", line 428, in adjust_freeze_ratio
[rank3]:[rank3]:     pipeline_schedule = solve_dag_lp(pipeline_schedule) # solve the DAG LP problem to find the optimal schedule
[rank3]:[rank3]:                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank3]:[rank3]:   File "/home/shcho/torchtitan/timelyfreeze/core/schedule.py", line 171, in solve_dag_lp
[rank3]:[rank3]:     row[n + idx] = -1.0 / (w_max - w_min)
[rank3]:[rank3]:                    ~~~~~^~~~~~~~~~~~~~~~~
[rank3]:[rank3]: ZeroDivisionError: float division by zero
W1029 16:09:18.138000 4144283 site-packages/torch/distributed/elastic/multiprocessing/api.py:940] Sending process 4144317 closing signal SIGTERM
W1029 16:09:18.139000 4144283 site-packages/torch/distributed/elastic/multiprocessing/api.py:940] Sending process 4144318 closing signal SIGTERM
W1029 16:09:18.139000 4144283 site-packages/torch/distributed/elastic/multiprocessing/api.py:940] Sending process 4144320 closing signal SIGTERM
E1029 16:09:18.521000 4144283 site-packages/torch/distributed/elastic/multiprocessing/api.py:914] failed (exitcode: 1) local_rank: 2 (pid: 4144319) of binary: /data2/shcho/miniforge3/envs/llm_eval/bin/python3.11
E1029 16:09:18.538000 4144283 site-packages/torch/distributed/elastic/multiprocessing/errors/error_handler.py:141] no error file defined for parent, to copy child error file (/tmp/torchelastic_7oqff67b/4d500067-e6a8-4d29-93e0-058b4b3e050d_pi5nffzx/attempt_0/2/error.json)
[rank1]:Stage 1: Modules to keep: {'layers.7', 'layers.4', 'layers.5', 'layers.8', 'layers.6'}
[rank2]:Stage 2: Modules to keep: {'layers.9', 'layers.12', 'layers.10', 'layers.11'}
[rank3]:Stage 3: Modules to keep: {'layers.13', 'layers.15', 'layers.14', 'norm', 'output'}
[rank3]:----- TimelyFreeze‚è∞ Configuration:
[rank3]:	- job:
[rank3]:		- config_file: /home/shcho/torchtitan/logs/dmserver1/1028_llama1b/config.toml
[rank3]:		- dump_folder: /data2/shcho/torchtitan
[rank3]:		- description: "Main Table Experiment, without streaming mode, sample-level with truncation, 2 epochs, with bf16 autocast"
[rank3]:		- use_for_integration_test: False
[rank3]:		- print_args: False
[rank3]:		- basename: 1028_1F1B_fullrand7_dm1
[rank3]:	- profiling:
[rank3]:		- enable_profiling: False
[rank3]:		- save_traces_folder: /data2/shcho/torchtitan/profile_trace/1028_1F1B_fullrand7_dm1
[rank3]:		- profile_freq: 100
[rank3]:		- enable_memory_snapshot: False
[rank3]:		- save_memory_snapshot_folder: /data2/shcho/torchtitan/memory_snapshot/1028_1F1B_fullrand7_dm1
[rank3]:	- metrics:
[rank3]:		- log_freq: 50
[rank3]:		- enable_tensorboard: False
[rank3]:		- disable_color_printing: True
[rank3]:		- save_tb_folder: /data2/shcho/torchtitan/tb/1028_1F1B_fullrand7_dm1
[rank3]:		- save_for_all_ranks: False
[rank3]:		- enable_wandb: True
[rank3]:		- image_folder: /data2/shcho/torchtitan/images/1028_1F1B_fullrand7_dm1
[rank3]:		- pplog_freq: 200
[rank3]:		- draw_freq: 100
[rank3]:		- wandb_name: 1028_1F1B_fullrand7_dm1
[rank3]:		- draw_graph: True
[rank3]:	- model:
[rank3]:		- name: llama3
[rank3]:		- flavor: 1B
[rank3]:		- tokenizer_path: ./assets/tokenizer/Llama-3.2-1B-Instruct
[rank3]:		- converters: []
[rank3]:		- print_after_conversion: False
[rank3]:	- optimizer:
[rank3]:		- name: AdamW
[rank3]:		- lr: 1e-05
[rank3]:		- beta1: 0.9
[rank3]:		- beta2: 0.95
[rank3]:		- eps: 1e-08
[rank3]:		- weight_decay: 0.1
[rank3]:		- implementation: fused
[rank3]:		- early_step_in_backward: False
[rank3]:	- lr_scheduler:
[rank3]:		- warmup_steps: 100
[rank3]:		- decay_ratio: 0.8
[rank3]:		- decay_type: cosine
[rank3]:		- min_lr_factor: 0.0
[rank3]:	- training:
[rank3]:		- dataset: alpaca
[rank3]:		- dataset_path: None
[rank3]:		- local_batch_size: 16
[rank3]:		- global_batch_size: 64
[rank3]:		- seq_len: 1024
[rank3]:		- max_norm: 1.0
[rank3]:		- steps: 1600
[rank3]:		- enable_cpu_offload: False
[rank3]:		- mixed_precision_param: bfloat16
[rank3]:		- mixed_precision_reduce: float32
[rank3]:		- compile: False
[rank3]:		- gc_freq: 50
[rank3]:		- gc_debug: False
[rank3]:		- seed: None
[rank3]:		- deterministic: False
[rank3]:	- parallelism:
[rank3]:		- data_parallel_replicate_degree: 1
[rank3]:		- enable_compiled_autograd: False
[rank3]:		- data_parallel_shard_degree: -1
[rank3]:		- fsdp_reshard_after_forward: default
[rank3]:		- tensor_parallel_degree: 1
[rank3]:		- disable_loss_parallel: False
[rank3]:		- enable_async_tensor_parallel: False
[rank3]:		- pipeline_parallel_degree: 4
[rank3]:		- pipeline_parallel_split_points: []
[rank3]:		- module_fqns_per_model_part: None
[rank3]:		- pipeline_parallel_first_stage_less_layers: 1
[rank3]:		- pipeline_parallel_last_stage_less_layers: 1
[rank3]:		- pipeline_parallel_layers_per_stage: None
[rank3]:		- pipeline_parallel_schedule: 1F1B
[rank3]:		- pipeline_parallel_schedule_csv: 
[rank3]:		- pipeline_parallel_microbatch_size: 2
[rank3]:		- context_parallel_degree: 1
[rank3]:		- context_parallel_rotate_method: allgather
[rank3]:		- expert_parallel_degree: 1
[rank3]:		- pp: 4
[rank3]:		- stages_per_rank: 1
[rank3]:		- stages_list: [3]
[rank3]:		- microbatches: 8
[rank3]:	- checkpoint:
[rank3]:		- enable_checkpoint: True
[rank3]:		- checkpoint_folder: /data2/shcho/torchtitan/checkpoint/1028_1F1B_fullrand7_dm1
[rank3]:		- interval: 800
[rank3]:		- initial_load_path: /data2/shcho/torchtitan/base_model/Llama-3.2-1B-Instruct/original_dcp
[rank3]:		- initial_load_model_only: True
[rank3]:		- initial_load_in_hf: False
[rank3]:		- last_save_model_only: True
[rank3]:		- last_save_in_hf: False
[rank3]:		- export_dtype: float16
[rank3]:		- async_mode: async
[rank3]:		- keep_latest_k: 2
[rank3]:		- load_step: -1
[rank3]:		- exclude_from_loading: ['dataloader', 'lr_scheduler', 'optimizer', 'train_state']
[rank3]:		- enable_first_step_checkpoint: False
[rank3]:		- create_seed_checkpoint: False
[rank3]:	- activation_checkpoint:
[rank3]:		- mode: none
[rank3]:		- selective_ac_option: op
[rank3]:		- per_op_sac_force_recompute_mm_shapes_by_fqns: ['moe.router.gate']
[rank3]:	- float8:
[rank3]:		- enable_fsdp_float8_all_gather: False
[rank3]:		- precompute_float8_dynamic_scale_for_fsdp: False
[rank3]:		- recipe_name: None
[rank3]:		- filter_fqns: ['output']
[rank3]:		- emulate: False
[rank3]:		- moe_fqns_prototype: []
[rank3]:	- mx:
[rank3]:		- mxfp8_dim1_cast_kernel_choice: triton
[rank3]:		- recipe_name: mxfp8
[rank3]:		- filter_fqns: ['output']
[rank3]:		- moe_fqns_prototype: []
[rank3]:	- comm:
[rank3]:		- init_timeout_seconds: 300
[rank3]:		- train_timeout_seconds: 300
[rank3]:		- trace_buf_size: 20000
[rank3]:		- save_traces_folder: /data2/shcho/torchtitan/comm_traces/1028_1F1B_fullrand7_dm1
[rank3]:		- world_size: 4
[rank3]:		- global_rank: 3
[rank3]:		- local_rank: 3
[rank3]:		- dp: 1
[rank3]:		- pp: 4
[rank3]:		- pp_rank: 3
[rank3]:		- dp_rank: 0
[rank3]:		- master_dp_rank: 0
[rank3]:	- memory_estimation:
[rank3]:		- enabled: False
[rank3]:		- disable_fake_mode: False
[rank3]:	- fault_tolerance:
[rank3]:		- enable: False
[rank3]:		- process_group: gloo
[rank3]:		- process_group_timeout_ms: 10000
[rank3]:		- replica_id: 0
[rank3]:		- group_size: 0
[rank3]:		- min_replica_size: 1
[rank3]:		- semi_sync_method: None
[rank3]:		- sync_steps: 5
[rank3]:		- should_quantize: False
[rank3]:		- fragment_sync_delay: 0
[rank3]:		- fragment_update_alpha: 0.0
[rank3]:	- experimental:
[rank3]:		- custom_import: 
[rank3]:		- custom_args_module: 
[rank3]:	- validation:
[rank3]:		- enabled: True
[rank3]:		- dataset: c4_validation
[rank3]:		- dataset_path: None
[rank3]:		- local_batch_size: 16
[rank3]:		- seq_len: 1024
[rank3]:		- freq: 200
[rank3]:		- steps: 100
[rank3]:	- freezing:
[rank3]:		- freeze: True
[rank3]:		- metric_type: fullrand7
[rank3]:		- phase_unit: 50
[rank3]:		- stability_check_freq: 10
[rank3]:		- aggressiveness: 0
[rank3]:
[rank0]:Stage 0: Modules to keep: {'layers.1', 'layers.3', 'tok_embeddings', 'layers.2', 'layers.0'}
[rank3]:[Gloo] Rank 3 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
[rank1]:[Gloo] Rank 1 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
[rank2]:[Gloo] Rank 2 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
[rank0]:[Gloo] Rank 0 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
Traceback (most recent call last):
  File "/data2/shcho/miniforge3/envs/llm_eval/bin/torchrun", line 7, in <module>
    sys.exit(main())
             ^^^^^^
  File "/data2/shcho/miniforge3/envs/llm_eval/lib/python3.11/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 362, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/data2/shcho/miniforge3/envs/llm_eval/lib/python3.11/site-packages/torch/distributed/run.py", line 946, in main
    run(args)
  File "/data2/shcho/miniforge3/envs/llm_eval/lib/python3.11/site-packages/torch/distributed/run.py", line 937, in run
    elastic_launch(
  File "/data2/shcho/miniforge3/envs/llm_eval/lib/python3.11/site-packages/torch/distributed/launcher/api.py", line 159, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data2/shcho/miniforge3/envs/llm_eval/lib/python3.11/site-packages/torch/distributed/launcher/api.py", line 300, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
timelyfreeze.train FAILED
------------------------------------------------------------
Failures:
[1]:
  time      : 2025-10-29_16:09:15
  host      : elga.kaist.ac.kr
  rank      : 0 (local_rank: 0)
  exitcode  : 1 (pid: 4144317)
  error_file: /tmp/torchelastic_7oqff67b/4d500067-e6a8-4d29-93e0-058b4b3e050d_pi5nffzx/attempt_0/0/error.json
  traceback : Traceback (most recent call last):
    File "/data2/shcho/miniforge3/envs/llm_eval/lib/python3.11/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 362, in wrapper
      return f(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^
    File "/home/shcho/torchtitan/timelyfreeze/train.py", line 584, in train
      self.train_step(data_iterator)
    File "/home/shcho/torchtitan/timelyfreeze/train.py", line 509, in train_step
      self.freezer.freeze_update(self.step) # this should be called after optimizer.step()
      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    File "/home/shcho/torchtitan/timelyfreeze/core/freezer.py", line 137, in freeze_update
      self.set_expected_freeze_ratio()
    File "/home/shcho/torchtitan/timelyfreeze/core/freezer.py", line 184, in set_expected_freeze_ratio
      self.pipeline_schedule = adjust_freeze_ratio(self.pipeline_schedule, monitored_values_dict, self.config)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    File "/home/shcho/torchtitan/timelyfreeze/core/schedule.py", line 428, in adjust_freeze_ratio
      pipeline_schedule = solve_dag_lp(pipeline_schedule) # solve the DAG LP problem to find the optimal schedule
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    File "/home/shcho/torchtitan/timelyfreeze/core/schedule.py", line 171, in solve_dag_lp
      row[n + idx] = -1.0 / (w_max - w_min)
                     ~~~~~^~~~~~~~~~~~~~~~~
  ZeroDivisionError: float division by zero
  
[2]:
  time      : 2025-10-29_16:09:15
  host      : elga.kaist.ac.kr
  rank      : 1 (local_rank: 1)
  exitcode  : 1 (pid: 4144318)
  error_file: /tmp/torchelastic_7oqff67b/4d500067-e6a8-4d29-93e0-058b4b3e050d_pi5nffzx/attempt_0/1/error.json
  traceback : Traceback (most recent call last):
    File "/data2/shcho/miniforge3/envs/llm_eval/lib/python3.11/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 362, in wrapper
      return f(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^
    File "/home/shcho/torchtitan/timelyfreeze/train.py", line 584, in train
      self.train_step(data_iterator)
    File "/home/shcho/torchtitan/timelyfreeze/train.py", line 509, in train_step
      self.freezer.freeze_update(self.step) # this should be called after optimizer.step()
      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    File "/home/shcho/torchtitan/timelyfreeze/core/freezer.py", line 137, in freeze_update
      self.set_expected_freeze_ratio()
    File "/home/shcho/torchtitan/timelyfreeze/core/freezer.py", line 184, in set_expected_freeze_ratio
      self.pipeline_schedule = adjust_freeze_ratio(self.pipeline_schedule, monitored_values_dict, self.config)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    File "/home/shcho/torchtitan/timelyfreeze/core/schedule.py", line 428, in adjust_freeze_ratio
      pipeline_schedule = solve_dag_lp(pipeline_schedule) # solve the DAG LP problem to find the optimal schedule
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    File "/home/shcho/torchtitan/timelyfreeze/core/schedule.py", line 171, in solve_dag_lp
      row[n + idx] = -1.0 / (w_max - w_min)
                     ~~~~~^~~~~~~~~~~~~~~~~
  ZeroDivisionError: float division by zero
  
[3]:
  time      : 2025-10-29_16:09:15
  host      : elga.kaist.ac.kr
  rank      : 3 (local_rank: 3)
  exitcode  : -15 (pid: 4144320)
  error_file: /tmp/torchelastic_7oqff67b/4d500067-e6a8-4d29-93e0-058b4b3e050d_pi5nffzx/attempt_0/3/error.json
  traceback : Traceback (most recent call last):
    File "/data2/shcho/miniforge3/envs/llm_eval/lib/python3.11/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 362, in wrapper
      return f(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^
    File "/home/shcho/torchtitan/timelyfreeze/train.py", line 584, in train
      self.train_step(data_iterator)
    File "/home/shcho/torchtitan/timelyfreeze/train.py", line 509, in train_step
      self.freezer.freeze_update(self.step) # this should be called after optimizer.step()
      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    File "/home/shcho/torchtitan/timelyfreeze/core/freezer.py", line 137, in freeze_update
      self.set_expected_freeze_ratio()
    File "/home/shcho/torchtitan/timelyfreeze/core/freezer.py", line 184, in set_expected_freeze_ratio
      self.pipeline_schedule = adjust_freeze_ratio(self.pipeline_schedule, monitored_values_dict, self.config)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    File "/home/shcho/torchtitan/timelyfreeze/core/schedule.py", line 428, in adjust_freeze_ratio
      pipeline_schedule = solve_dag_lp(pipeline_schedule) # solve the DAG LP problem to find the optimal schedule
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    File "/home/shcho/torchtitan/timelyfreeze/core/schedule.py", line 171, in solve_dag_lp
      row[n + idx] = -1.0 / (w_max - w_min)
                     ~~~~~^~~~~~~~~~~~~~~~~
  ZeroDivisionError: float division by zero
  
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2025-10-29_16:09:15
  host      : elga.kaist.ac.kr
  rank      : 2 (local_rank: 2)
  exitcode  : 1 (pid: 4144319)
  error_file: /tmp/torchelastic_7oqff67b/4d500067-e6a8-4d29-93e0-058b4b3e050d_pi5nffzx/attempt_0/2/error.json
  traceback : Traceback (most recent call last):
    File "/data2/shcho/miniforge3/envs/llm_eval/lib/python3.11/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 362, in wrapper
      return f(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^
    File "/home/shcho/torchtitan/timelyfreeze/train.py", line 584, in train
      self.train_step(data_iterator)
    File "/home/shcho/torchtitan/timelyfreeze/train.py", line 509, in train_step
      self.freezer.freeze_update(self.step) # this should be called after optimizer.step()
      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    File "/home/shcho/torchtitan/timelyfreeze/core/freezer.py", line 137, in freeze_update
      self.set_expected_freeze_ratio()
    File "/home/shcho/torchtitan/timelyfreeze/core/freezer.py", line 184, in set_expected_freeze_ratio
      self.pipeline_schedule = adjust_freeze_ratio(self.pipeline_schedule, monitored_values_dict, self.config)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    File "/home/shcho/torchtitan/timelyfreeze/core/schedule.py", line 428, in adjust_freeze_ratio
      pipeline_schedule = solve_dag_lp(pipeline_schedule) # solve the DAG LP problem to find the optimal schedule
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    File "/home/shcho/torchtitan/timelyfreeze/core/schedule.py", line 171, in solve_dag_lp
      row[n + idx] = -1.0 / (w_max - w_min)
                     ~~~~~^~~~~~~~~~~~~~~~~
  ZeroDivisionError: float division by zero
  
============================================================
