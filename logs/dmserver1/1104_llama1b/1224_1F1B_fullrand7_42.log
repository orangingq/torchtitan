
üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•
‚úîÔ∏èCurrent Timestamp: 2025. 12. 24. (Ïàò) 03:39:05 KST
‚úîÔ∏èSERVER: dmserver1 (143.248.135.95),  GPUs: 2,3,4,5
‚úîÔ∏èSCRIPT: /home/shcho/torchtitan/logs/dmserver1/1104_llama1b/run.sh
‚úîÔ∏èOUTPUT: /home/shcho/torchtitan/logs/dmserver1/1104_llama1b/1224_1F1B_fullrand7_42.log
‚úîÔ∏èMain Table Experiment, without streaming mode, sample-level with truncation, with bf16 autocast
1107: for timelyapf: clone().cpu() removed to fix freezing issue.!!! yay~~~
1108: steps 1200 (3 epochs) -> 800 (2 epochs) / alpaca dataset
    - learning rate : tried lr=3e-6 (->3e-9), 5e-6(->0), 1e-5(->0). BEST: lr=5e-6
1109: switch to alpaca_gpt4+alpaca_cleaned dataset
1224: everything same as 1109 but debugged requires_grad bug

‚úîÔ∏èRunning with fullrand7 x 1F1B ... 
‚òëÔ∏è> torchrun --standalone --nnodes=1 --nproc_per_node=4 --local_addr=127.0.0.1 --local-ranks-filter=0,1,2,3 --role=rank --tee=3 -m timelyfreeze.train --job.config_file=/home/shcho/torchtitan/logs/dmserver1/1104_llama1b/config_1224.toml --job.description="Main Table Experiment, without streaming mode, sample-level with truncation, with bf16 autocast
1107: for timelyapf: clone().cpu() removed to fix freezing issue.!!! yay~~~
1108: steps 1200 (3 epochs) -> 800 (2 epochs) / alpaca dataset
    - learning rate : tried lr=3e-6 (->3e-9), 5e-6(->0), 1e-5(->0). BEST: lr=5e-6
1109: switch to alpaca_gpt4+alpaca_cleaned dataset
1224: everything same as 1109 but debugged requires_grad bug
" --parallelism.pipeline_parallel_degree=4  --freezing.freeze --freezing.metric_type=fullrand7 --freezing.threshold=0.01 --freezing.percentile=80 --freezing.max_freeze_ratio=0.8
üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•
[rank2]:2025-12-24 03:39:12,205 - Starting job: "Main Table Experiment, without streaming mode, sample-level with truncation, with bf16 autocast
[rank2]:1107: for timelyapf: clone().cpu() removed to fix freezing issue.!!! yay~~~
[rank2]:1108: steps 1200 (3 epochs) -> 800 (2 epochs) / alpaca dataset
[rank2]:    - learning rate : tried lr=3e-6 (->3e-9), 5e-6(->0), 1e-5(->0). BEST: lr=5e-6
[rank2]:1109: switch to alpaca_gpt4+alpaca_cleaned dataset
[rank2]:1224: everything same as 1109 but debugged requires_grad bug
[rank2]:"
[rank0]:2025-12-24 03:39:12,240 - Starting job: "Main Table Experiment, without streaming mode, sample-level with truncation, with bf16 autocast
[rank0]:1107: for timelyapf: clone().cpu() removed to fix freezing issue.!!! yay~~~
[rank0]:1108: steps 1200 (3 epochs) -> 800 (2 epochs) / alpaca dataset
[rank0]:    - learning rate : tried lr=3e-6 (->3e-9), 5e-6(->0), 1e-5(->0). BEST: lr=5e-6
[rank0]:1109: switch to alpaca_gpt4+alpaca_cleaned dataset
[rank0]:1224: everything same as 1109 but debugged requires_grad bug
[rank0]:"
[rank0]:2025-12-24 03:39:12,588 - ENV[TORCH_NCCL_ASYNC_ERROR_HANDLING] = 1 will be overridden to 3 based on job config
[rank0]:2025-12-24 03:39:12,589 - Building 1-D device mesh with ['pp'], [4]
[rank0]:2025-12-24 03:39:12,592 - [GC] Initial GC collection 0.00 seconds
[rank0]:2025-12-24 03:39:12,593 - Loading tokenizer from tokenizer.json
[rank2]:2025-12-24 03:39:12,584 - ENV[TORCH_NCCL_ASYNC_ERROR_HANDLING] = 1 will be overridden to 3 based on job config
[rank2]:2025-12-24 03:39:12,586 - Building 1-D device mesh with ['pp'], [4]
[rank3]:2025-12-24 03:39:12,836 - Starting job: "Main Table Experiment, without streaming mode, sample-level with truncation, with bf16 autocast
[rank3]:1107: for timelyapf: clone().cpu() removed to fix freezing issue.!!! yay~~~
[rank3]:1108: steps 1200 (3 epochs) -> 800 (2 epochs) / alpaca dataset
[rank3]:    - learning rate : tried lr=3e-6 (->3e-9), 5e-6(->0), 1e-5(->0). BEST: lr=5e-6
[rank3]:1109: switch to alpaca_gpt4+alpaca_cleaned dataset
[rank3]:1224: everything same as 1109 but debugged requires_grad bug
[rank3]:"
[rank1]:2025-12-24 03:39:12,841 - Starting job: "Main Table Experiment, without streaming mode, sample-level with truncation, with bf16 autocast
[rank1]:1107: for timelyapf: clone().cpu() removed to fix freezing issue.!!! yay~~~
[rank1]:1108: steps 1200 (3 epochs) -> 800 (2 epochs) / alpaca dataset
[rank1]:    - learning rate : tried lr=3e-6 (->3e-9), 5e-6(->0), 1e-5(->0). BEST: lr=5e-6
[rank1]:1109: switch to alpaca_gpt4+alpaca_cleaned dataset
[rank1]:1224: everything same as 1109 but debugged requires_grad bug
[rank1]:"
[rank0]:2025-12-24 03:39:12,994 - Preparing alpaca_gpt4 dataset from vicgalle/alpaca-gpt4
[rank3]:2025-12-24 03:39:13,292 - ENV[TORCH_NCCL_ASYNC_ERROR_HANDLING] = 1 will be overridden to 3 based on job config
[rank3]:2025-12-24 03:39:13,295 - Building 1-D device mesh with ['pp'], [4]
[rank1]:2025-12-24 03:39:13,292 - ENV[TORCH_NCCL_ASYNC_ERROR_HANDLING] = 1 will be overridden to 3 based on job config
[rank1]:2025-12-24 03:39:13,294 - Building 1-D device mesh with ['pp'], [4]
[rank0]:2025-12-24 03:39:15,767 - Building llama3 1B with TransformerModelArgs(_enforced='This field is used to enforce all fields have defaults.', dim=2048, n_layers=16, n_heads=32, n_kv_heads=8, vocab_size=128256, multiple_of=256, ffn_dim_multiplier=1.5, norm_eps=1e-05, rope_theta=500000, max_seq_len=1024, depth_init=True, use_flex_attn=False, attn_mask_type='causal', eos_id=0)
[rank2]:2025-12-24 03:39:15,852 - CUDA capacity: NVIDIA RTX 6000 Ada Generation with 47.51GiB memory
[rank2]:2025-12-24 03:39:15,890 - Peak flops undefined for: NVIDIA RTX 6000 Ada Generation, fallback to A100
[rank2]:2025-12-24 03:39:15,916 - PP rank 2 is building stage_idx 2 with modules ['layers.9', 'layers.10', 'layers.11', 'layers.12']
[rank2]:2025-12-24 03:39:15,916 - Using pipeline schedule 1F1B with 8 microbatches and 4 stages.
[rank0]:2025-12-24 03:39:15,915 - CUDA capacity: NVIDIA RTX 6000 Ada Generation with 47.51GiB memory
[rank0]:2025-12-24 03:39:15,948 - Peak flops undefined for: NVIDIA RTX 6000 Ada Generation, fallback to A100
[rank0]:2025-12-24 03:39:15,949 - Model llama3 1B size: 1,498,482,688 total parameters
[rank0]:2025-12-24 03:39:15,971 - PP rank 0 is building stage_idx 0 with modules ['tok_embeddings', 'layers.0', 'layers.1', 'layers.2', 'layers.3']
[rank0]:2025-12-24 03:39:15,971 - Using pipeline schedule 1F1B with 8 microbatches and 4 stages.
[rank2]:2025-12-24 03:39:16,094 - Peak flops undefined for: NVIDIA RTX 6000 Ada Generation, fallback to A100
[rank2]:2025-12-24 03:39:16,094 - Peak FLOPS used for computing MFU: 3.120e+14
[rank2]:2025-12-24 03:39:16,094 - CUDA memory usage for model: 0.92GiB(1.94%)
[rank0]:2025-12-24 03:39:16,152 - Peak flops undefined for: NVIDIA RTX 6000 Ada Generation, fallback to A100
[rank0]:2025-12-24 03:39:16,152 - Peak FLOPS used for computing MFU: 3.120e+14
[rank0]:2025-12-24 03:39:16,153 - CUDA memory usage for model: 1.90GiB(3.99%)
[rank1]:2025-12-24 03:39:16,874 - CUDA capacity: NVIDIA RTX 6000 Ada Generation with 47.51GiB memory
[rank1]:2025-12-24 03:39:16,913 - Peak flops undefined for: NVIDIA RTX 6000 Ada Generation, fallback to A100
[rank1]:2025-12-24 03:39:16,940 - PP rank 1 is building stage_idx 1 with modules ['layers.4', 'layers.5', 'layers.6', 'layers.7', 'layers.8']
[rank1]:2025-12-24 03:39:16,940 - Using pipeline schedule 1F1B with 8 microbatches and 4 stages.
[rank1]:2025-12-24 03:39:17,140 - Peak flops undefined for: NVIDIA RTX 6000 Ada Generation, fallback to A100
[rank1]:2025-12-24 03:39:17,141 - Peak FLOPS used for computing MFU: 3.120e+14
[rank1]:2025-12-24 03:39:17,142 - CUDA memory usage for model: 1.13GiB(2.39%)
[rank3]:wandb: Currently logged in as: orangingq to https://api.wandb.ai. Use `wandb login --relogin` to force relogin
[rank3]:wandb: setting up run dozzgr3s
[rank3]:wandb: Tracking run with wandb version 0.22.2
[rank3]:wandb: Run data is saved locally in /data2/shcho/torchtitan/tb/1224_1F1B_fullrand7_42_dm1/20251224-0339/wandb/run-20251224_033917-dozzgr3s
[rank3]:wandb: Run `wandb offline` to turn off syncing.
[rank3]:wandb: Syncing run 1224_1F1B_fullrand7_42_dm1
[rank3]:wandb: ‚≠êÔ∏è View project at https://wandb.ai/orangingq/torchtitan
[rank3]:wandb: üöÄ View run at https://wandb.ai/orangingq/torchtitan/runs/dozzgr3s
[rank3]:2025-12-24 03:39:18,748 - WandB logging enabled
[rank3]:2025-12-24 03:39:18,748 - CUDA capacity: NVIDIA RTX 6000 Ada Generation with 47.51GiB memory
[rank3]:2025-12-24 03:39:18,787 - Peak flops undefined for: NVIDIA RTX 6000 Ada Generation, fallback to A100
[rank3]:2025-12-24 03:39:18,817 - PP rank 3 is building stage_idx 3 with modules ['layers.13', 'layers.14', 'layers.15', 'norm', 'output']
[rank3]:2025-12-24 03:39:18,817 - Using pipeline schedule 1F1B with 8 microbatches and 4 stages.
[rank3]:2025-12-24 03:39:19,001 - Peak flops undefined for: NVIDIA RTX 6000 Ada Generation, fallback to A100
[rank3]:2025-12-24 03:39:19,002 - Peak FLOPS used for computing MFU: 3.120e+14
[rank3]:2025-12-24 03:39:19,003 - CUDA memory usage for model: 1.66GiB(3.50%)
[rank3]:2025-12-24 03:39:19,017 - Mixed precision training with TP or PP is handled by autocast
[rank1]:2025-12-24 03:39:19,018 - Mixed precision training with TP or PP is handled by autocast
[rank0]:2025-12-24 03:39:19,017 - Checkpointing active. Checkpoints will be loaded from and saved to /data2/shcho/torchtitan/checkpoint/1224_1F1B_fullrand7_42_dm1
[rank0]:2025-12-24 03:39:19,017 - Mixed precision training with TP or PP is handled by autocast
[rank2]:2025-12-24 03:39:19,017 - Mixed precision training with TP or PP is handled by autocast
[rank0]:2025-12-24 03:39:19,017 - Trainer is initialized with local batch size 32, global batch size 128, gradient accumulation steps 4, sequence length 1024, total steps 800 (warmup 100)
[rank0]:2025-12-24 03:39:19,018 - Loading the checkpoint from /data2/shcho/torchtitan/base_model/Llama-3.2-1B/original_dcp.
[rank0]:2025-12-24 03:39:21,537 - [GC] GC collection for checkpoint loading. 0.00 seconds
[rank0]:2025-12-24 03:39:21,537 - Finished loading the checkpoint in 2.52 seconds.
[rank0]:2025-12-24 03:39:21,537 - Training starts at step 1
[rank2]:2025-12-24 03:39:26,846 -  step:  1  loss: -4.0000  grad_norm: 203.0656  memory:  6.84GiB(14.41%)  tps: 2,991  tflops: 23.38  mfu: 7.49%
[rank2]:2025-12-24 03:39:26,846 - Synchronizing and adjusting timeout for all ProcessGroups to 0:05:00
[rank3]:2025-12-24 03:39:26,857 -  step:  1  loss: 10.6092  grad_norm: 203.0656  memory: 21.88GiB(46.05%)  tps: 4,062  tflops: 31.76  mfu: 10.18%
[rank3]:2025-12-24 03:39:26,857 - Synchronizing and adjusting timeout for all ProcessGroups to 0:05:00
[rank0]:2025-12-24 03:39:26,885 -  step:  1  loss: -4.0000  grad_norm: 203.0656  memory: 13.10GiB(27.57%)  tps: 2,996  tflops: 23.42  mfu: 7.51%
[rank0]:2025-12-24 03:39:26,885 - Synchronizing and adjusting timeout for all ProcessGroups to 0:05:00
[rank1]:2025-12-24 03:39:26,852 -  step:  1  loss: -4.0000  grad_norm: 203.0656  memory: 10.58GiB(22.26%)  tps: 3,297  tflops: 25.78  mfu: 8.26%
[rank1]:2025-12-24 03:39:26,852 - Synchronizing and adjusting timeout for all ProcessGroups to 0:05:00
