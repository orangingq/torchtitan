
ðŸ”¥ðŸ”¥ðŸ”¥ðŸ”¥ðŸ”¥ðŸ”¥ðŸ”¥ðŸ”¥ðŸ”¥ðŸ”¥ðŸ”¥ðŸ”¥ðŸ”¥ðŸ”¥ðŸ”¥ðŸ”¥ðŸ”¥ðŸ”¥ðŸ”¥ðŸ”¥ðŸ”¥ðŸ”¥ðŸ”¥ðŸ”¥ðŸ”¥ðŸ”¥ðŸ”¥ðŸ”¥
âœ”ï¸Current Timestamp: 2025. 11. 07. (ê¸ˆ) 16:31:24 KST
âœ”ï¸SERVER: dmserver1 (143.248.135.95),  GPUs: 0,1,2,3
âœ”ï¸SCRIPT: /home/shcho/torchtitan/logs/dmserver1/1104_llama1b/run.sh
âœ”ï¸OUTPUT: /home/shcho/torchtitan/logs/dmserver1/1104_llama1b/1108_Interleaved1F1B_nofreeze.log
âœ”ï¸Main Table Experiment, without streaming mode, sample-level with truncation, with bf16 autocast
1107: for timelyapf: clone().cpu() removed to fix freezing issue.!!! yay~~~
1108: steps 1200 (3 epochs) -> 800 (2 epochs) / alpaca dataset

âœ”ï¸Running with nofreeze x Interleaved1F1B ... 
â˜‘ï¸> torchrun --standalone --nnodes=1 --nproc_per_node=4 --local_addr=127.0.0.1 --local-ranks-filter=0,1,2,3 --role=rank --tee=3 -m timelyfreeze.train --job.config_file=/home/shcho/torchtitan/logs/dmserver1/1104_llama1b/config_1108.toml --job.description="Main Table Experiment, without streaming mode, sample-level with truncation, with bf16 autocast
1107: for timelyapf: clone().cpu() removed to fix freezing issue.!!! yay~~~
1108: steps 1200 (3 epochs) -> 800 (2 epochs) / alpaca dataset
" --parallelism.pipeline_parallel_degree=4  --freezing.no-freeze
ðŸ”¥ðŸ”¥ðŸ”¥ðŸ”¥ðŸ”¥ðŸ”¥ðŸ”¥ðŸ”¥ðŸ”¥ðŸ”¥ðŸ”¥ðŸ”¥ðŸ”¥ðŸ”¥ðŸ”¥ðŸ”¥ðŸ”¥ðŸ”¥ðŸ”¥ðŸ”¥ðŸ”¥ðŸ”¥ðŸ”¥ðŸ”¥ðŸ”¥ðŸ”¥ðŸ”¥ðŸ”¥
[rank1]:2025-11-07 16:31:30,141 - INFO - Starting job: "Main Table Experiment, without streaming mode, sample-level with truncation, with bf16 autocast
[rank1]:1107: for timelyapf: clone().cpu() removed to fix freezing issue.!!! yay~~~
[rank1]:1108: steps 1200 (3 epochs) -> 800 (2 epochs) / alpaca dataset
[rank1]:"
[rank0]:2025-11-07 16:31:30,220 - INFO - Starting job: "Main Table Experiment, without streaming mode, sample-level with truncation, with bf16 autocast
[rank0]:1107: for timelyapf: clone().cpu() removed to fix freezing issue.!!! yay~~~
[rank0]:1108: steps 1200 (3 epochs) -> 800 (2 epochs) / alpaca dataset
[rank0]:"
[rank2]:2025-11-07 16:31:30,335 - INFO - Starting job: "Main Table Experiment, without streaming mode, sample-level with truncation, with bf16 autocast
[rank2]:1107: for timelyapf: clone().cpu() removed to fix freezing issue.!!! yay~~~
[rank2]:1108: steps 1200 (3 epochs) -> 800 (2 epochs) / alpaca dataset
[rank2]:"
[rank1]:2025-11-07 16:31:30,323 - WARNING - ENV[TORCH_NCCL_ASYNC_ERROR_HANDLING] = 1 will be overridden to 3 based on job config
[rank1]:2025-11-07 16:31:30,325 - INFO - Building 1-D device mesh with ['pp'], [4]
[rank0]:2025-11-07 16:31:30,409 - WARNING - ENV[TORCH_NCCL_ASYNC_ERROR_HANDLING] = 1 will be overridden to 3 based on job config
[rank0]:2025-11-07 16:31:30,411 - INFO - Building 1-D device mesh with ['pp'], [4]
[rank0]:2025-11-07 16:31:30,416 - INFO - [GC] Initial GC collection 0.00 seconds
[rank2]:2025-11-07 16:31:30,517 - WARNING - ENV[TORCH_NCCL_ASYNC_ERROR_HANDLING] = 1 will be overridden to 3 based on job config
[rank2]:2025-11-07 16:31:30,520 - INFO - Building 1-D device mesh with ['pp'], [4]
[rank3]:2025-11-07 16:31:30,573 - INFO - Starting job: "Main Table Experiment, without streaming mode, sample-level with truncation, with bf16 autocast
[rank3]:1107: for timelyapf: clone().cpu() removed to fix freezing issue.!!! yay~~~
[rank3]:1108: steps 1200 (3 epochs) -> 800 (2 epochs) / alpaca dataset
[rank3]:"
[rank3]:2025-11-07 16:31:30,749 - WARNING - ENV[TORCH_NCCL_ASYNC_ERROR_HANDLING] = 1 will be overridden to 3 based on job config
[rank3]:2025-11-07 16:31:30,752 - INFO - Building 1-D device mesh with ['pp'], [4]
[rank0]:2025-11-07 16:31:31,049 - INFO - Loading tokenizer from tokenizer.json
[rank0]:2025-11-07 16:31:31,473 - INFO - Preparing alpaca_cleaned dataset from yahma/alpaca-cleaned
[rank0]:2025-11-07 16:31:35,159 - INFO - Building llama3 1B with TransformerModelArgs(_enforced='This field is used to enforce all fields have defaults.', dim=2048, n_layers=16, n_heads=32, n_kv_heads=8, vocab_size=128256, multiple_of=256, ffn_dim_multiplier=1.5, norm_eps=1e-05, rope_theta=500000, max_seq_len=512, depth_init=True, use_flex_attn=False, attn_mask_type='causal', eos_id=0)
[rank0]:2025-11-07 16:31:35,309 - INFO - CUDA capacity: NVIDIA RTX 6000 Ada Generation with 47.51GiB memory
[rank0]:2025-11-07 16:31:35,348 - WARNING - Peak flops undefined for: NVIDIA RTX 6000 Ada Generation, fallback to A100
[rank0]:2025-11-07 16:31:35,349 - INFO - Model llama3 1B size: 1,498,482,688 total parameters
[rank0]:2025-11-07 16:31:35,374 - INFO - PP rank 0 is building stage_idx 0 with modules ['tok_embeddings', 'layers.0', 'layers.1']
[rank0]:2025-11-07 16:31:35,386 - INFO - PP rank 0 is building stage_idx 4 with modules ['layers.9', 'layers.10']
[rank0]:2025-11-07 16:31:35,387 - INFO - Using pipeline schedule Interleaved1F1B with 8 microbatches and 8 stages.
[rank0]:2025-11-07 16:31:35,559 - WARNING - Peak flops undefined for: NVIDIA RTX 6000 Ada Generation, fallback to A100
[rank0]:2025-11-07 16:31:35,559 - INFO - Peak FLOPS used for computing MFU: 3.120e+14
[rank0]:2025-11-07 16:31:35,559 - INFO - CUDA memory usage for model: 1.90GiB(3.99%)
[rank1]:2025-11-07 16:31:35,894 - INFO - CUDA capacity: NVIDIA RTX 6000 Ada Generation with 47.51GiB memory
[rank1]:2025-11-07 16:31:35,931 - WARNING - Peak flops undefined for: NVIDIA RTX 6000 Ada Generation, fallback to A100
[rank2]:2025-11-07 16:31:35,966 - INFO - CUDA capacity: NVIDIA RTX 6000 Ada Generation with 47.51GiB memory
[rank1]:2025-11-07 16:31:35,957 - INFO - PP rank 1 is building stage_idx 1 with modules ['layers.2', 'layers.3', 'layers.4']
[rank2]:2025-11-07 16:31:36,006 - WARNING - Peak flops undefined for: NVIDIA RTX 6000 Ada Generation, fallback to A100
[rank1]:2025-11-07 16:31:35,970 - INFO - PP rank 1 is building stage_idx 5 with modules ['layers.11', 'layers.12']
[rank2]:2025-11-07 16:31:36,035 - INFO - PP rank 2 is building stage_idx 2 with modules ['layers.5', 'layers.6']
[rank1]:2025-11-07 16:31:35,971 - INFO - Using pipeline schedule Interleaved1F1B with 8 microbatches and 8 stages.
[rank2]:2025-11-07 16:31:36,048 - INFO - PP rank 2 is building stage_idx 6 with modules ['layers.13', 'layers.14']
[rank2]:2025-11-07 16:31:36,049 - INFO - Using pipeline schedule Interleaved1F1B with 8 microbatches and 8 stages.
[rank1]:2025-11-07 16:31:36,153 - WARNING - Peak flops undefined for: NVIDIA RTX 6000 Ada Generation, fallback to A100
[rank1]:2025-11-07 16:31:36,154 - INFO - Peak FLOPS used for computing MFU: 3.120e+14
[rank2]:2025-11-07 16:31:36,228 - WARNING - Peak flops undefined for: NVIDIA RTX 6000 Ada Generation, fallback to A100
[rank2]:2025-11-07 16:31:36,228 - INFO - Peak FLOPS used for computing MFU: 3.120e+14
[rank1]:2025-11-07 16:31:36,154 - INFO - CUDA memory usage for model: 1.13GiB(2.39%)
[rank2]:2025-11-07 16:31:36,229 - INFO - CUDA memory usage for model: 0.92GiB(1.94%)
[rank3]:wandb: Currently logged in as: orangingq to https://api.wandb.ai. Use `wandb login --relogin` to force relogin
[rank3]:wandb: setting up run krryjqqb
[rank3]:wandb: Tracking run with wandb version 0.22.2
[rank3]:wandb: Run data is saved locally in /data2/shcho/torchtitan/tb/1108_Interleaved1F1B_nofreeze_dm1/20251107-1631/wandb/run-20251107_163138-krryjqqb
[rank3]:wandb: Run `wandb offline` to turn off syncing.
[rank3]:wandb: Syncing run 1108_Interleaved1F1B_nofreeze_dm1
[rank3]:wandb: â­ï¸ View project at https://wandb.ai/orangingq/torchtitan
[rank3]:wandb: ðŸš€ View run at https://wandb.ai/orangingq/torchtitan/runs/krryjqqb
[rank3]:2025-11-07 16:31:39,281 - INFO - WandB logging enabled
[rank3]:2025-11-07 16:31:39,282 - INFO - CUDA capacity: NVIDIA RTX 6000 Ada Generation with 47.51GiB memory
[rank3]:2025-11-07 16:31:39,320 - WARNING - Peak flops undefined for: NVIDIA RTX 6000 Ada Generation, fallback to A100
[rank3]:2025-11-07 16:31:39,349 - INFO - PP rank 3 is building stage_idx 3 with modules ['layers.7', 'layers.8']
[rank3]:2025-11-07 16:31:39,363 - INFO - PP rank 3 is building stage_idx 7 with modules ['layers.15', 'norm', 'output']
[rank3]:2025-11-07 16:31:39,364 - INFO - Using pipeline schedule Interleaved1F1B with 8 microbatches and 8 stages.
[rank0]:2025-11-07 16:31:39,597 - INFO - Checkpointing active. Checkpoints will be loaded from and saved to /data2/shcho/torchtitan/checkpoint/1108_Interleaved1F1B_nofreeze_dm1
[rank0]:2025-11-07 16:31:39,597 - INFO - Mixed precision training with TP or PP is handled by autocast
[rank0]:2025-11-07 16:31:39,597 - INFO - Trainer is initialized with local batch size 32, global batch size 128, gradient accumulation steps 4, sequence length 512, total steps 800 (warmup 100)
[rank0]:2025-11-07 16:31:39,597 - WARNING - checkpoint.initial_load_path is provided but the checkpoint.folder exists. Checkpointer will use the checkpoints from the checkpoint.folder /data2/shcho/torchtitan/checkpoint/1108_Interleaved1F1B_nofreeze_dm1.
[rank0]:2025-11-07 16:31:39,598 - INFO - Loading the checkpoint from /data2/shcho/torchtitan/checkpoint/1108_Interleaved1F1B_nofreeze_dm1/step-1200.
[rank3]:2025-11-07 16:31:39,573 - WARNING - Peak flops undefined for: NVIDIA RTX 6000 Ada Generation, fallback to A100
[rank3]:2025-11-07 16:31:39,574 - INFO - Peak FLOPS used for computing MFU: 3.120e+14
[rank3]:2025-11-07 16:31:39,574 - INFO - CUDA memory usage for model: 1.66GiB(3.50%)
[rank3]:2025-11-07 16:31:39,591 - INFO - Mixed precision training with TP or PP is handled by autocast
[rank3]:2025-11-07 16:31:39,592 - WARNING - checkpoint.initial_load_path is provided but the checkpoint.folder exists. Checkpointer will use the checkpoints from the checkpoint.folder /data2/shcho/torchtitan/checkpoint/1108_Interleaved1F1B_nofreeze_dm1.
[rank1]:2025-11-07 16:31:39,591 - INFO - Mixed precision training with TP or PP is handled by autocast
[rank1]:2025-11-07 16:31:39,591 - WARNING - checkpoint.initial_load_path is provided but the checkpoint.folder exists. Checkpointer will use the checkpoints from the checkpoint.folder /data2/shcho/torchtitan/checkpoint/1108_Interleaved1F1B_nofreeze_dm1.
[rank2]:2025-11-07 16:31:39,591 - INFO - Mixed precision training with TP or PP is handled by autocast
[rank2]:2025-11-07 16:31:39,592 - WARNING - checkpoint.initial_load_path is provided but the checkpoint.folder exists. Checkpointer will use the checkpoints from the checkpoint.folder /data2/shcho/torchtitan/checkpoint/1108_Interleaved1F1B_nofreeze_dm1.
[rank0]:2025-11-07 16:31:41,785 - INFO - [GC] GC collection for checkpoint loading. 0.00 seconds
[rank0]:2025-11-07 16:31:41,785 - INFO - Finished loading the checkpoint in 2.19 seconds.
[rank0]:2025-11-07 16:31:41,785 - INFO - Training starts at step 1
[rank3]:2025-11-07 16:31:45,129 - INFO -  step:  1  loss:  0.5425  grad_norm:  1.6616  memory: 15.04GiB(31.66%)  tps: 2,822  tflops: 21.49  mfu: 6.89%
[rank3]:2025-11-07 16:31:45,130 - INFO - Synchronizing and adjusting timeout for all ProcessGroups to 0:05:00
[rank0]:2025-11-07 16:31:45,152 - INFO -  step:  1  loss: -4.0000  grad_norm:  1.6616  memory: 10.96GiB(23.08%)  tps: 1,671  tflops: 12.73  mfu: 4.08%
[rank2]:2025-11-07 16:31:45,117 - INFO -  step:  1  loss: -4.0000  grad_norm:  1.6616  memory:  6.31GiB(13.29%)  tps: 1,798  tflops: 13.70  mfu: 4.39%
[rank2]:2025-11-07 16:31:45,117 - INFO - Synchronizing and adjusting timeout for all ProcessGroups to 0:05:00
[rank0]:2025-11-07 16:31:45,153 - INFO - Synchronizing and adjusting timeout for all ProcessGroups to 0:05:00
[rank1]:2025-11-07 16:31:45,133 - INFO -  step:  1  loss: -4.0000  grad_norm:  1.6616  memory:  9.58GiB(20.17%)  tps: 1,781  tflops: 13.56  mfu: 4.35%
[rank1]:2025-11-07 16:31:45,133 - INFO - Synchronizing and adjusting timeout for all ProcessGroups to 0:05:00
[rank0]:2025-11-07 16:33:56,405 - INFO - [GC] Peforming periodical GC collection 0.00 seconds
[rank3]:2025-11-07 16:33:58,816 - INFO - Avg. fwd time: 6.8632 / Avg. bwd time: 22.0698 / Avg. batch time: 571.5902 (ms) / GPU bubble ratio: 19.01%
[rank2]:2025-11-07 16:33:58,874 - INFO - Avg. fwd time: 3.9837 / Avg. bwd time: 10.0926 / Avg. batch time: 603.9507 (ms) / GPU bubble ratio: 62.71%
[rank0]:2025-11-07 16:33:58,895 - INFO - Avg. fwd time: 4.1234 / Avg. bwd time: 12.0284 / Avg. batch time: 656.3332 (ms) / GPU bubble ratio: 60.63%
[rank1]:2025-11-07 16:33:58,978 - INFO - Avg. fwd time: 4.8869 / Avg. bwd time: 12.3071 / Avg. batch time: 633.4840 (ms) / GPU bubble ratio: 56.57%
[rank2]:2025-11-07 16:33:59,145 - INFO -  step: 50  loss: -4.0000  grad_norm:  0.3558  memory:  8.13GiB(17.12%)  tps: 5,990  tflops: 45.62  mfu: 14.62%
[rank1]:2025-11-07 16:33:59,149 - INFO -  step: 50  loss: -4.0000  grad_norm:  0.3558  memory: 11.85GiB(24.93%)  tps: 5,990  tflops: 45.62  mfu: 14.62%
[rank3]:2025-11-07 16:33:59,157 - INFO -  step: 50  loss:  0.4353  grad_norm:  0.3558  memory: 18.46GiB(38.86%)  tps: 5,990  tflops: 45.62  mfu: 14.62%
[rank0]:2025-11-07 16:33:59,159 - INFO -  step: 50  loss: -4.0000  grad_norm:  0.3558  memory: 14.71GiB(30.97%)  tps: 5,991  tflops: 45.63  mfu: 14.62%
[rank0]:2025-11-07 16:36:13,764 - INFO - [GC] Peforming periodical GC collection 0.00 seconds
[rank3]:2025-11-07 16:36:16,220 - INFO - Avg. fwd time: 6.9030 / Avg. bwd time: 22.1829 / Avg. batch time: 573.8918 (ms) / GPU bubble ratio: 18.91%
[rank2]:2025-11-07 16:36:16,280 - INFO - Avg. fwd time: 3.9857 / Avg. bwd time: 10.1076 / Avg. batch time: 605.9913 (ms) / GPU bubble ratio: 62.79%
[rank0]:2025-11-07 16:36:16,299 - INFO - Avg. fwd time: 4.1205 / Avg. bwd time: 12.0330 / Avg. batch time: 658.3918 (ms) / GPU bubble ratio: 60.74%
[rank1]:2025-11-07 16:36:16,381 - INFO - Avg. fwd time: 4.8783 / Avg. bwd time: 12.3263 / Avg. batch time: 635.5426 (ms) / GPU bubble ratio: 56.69%
[rank2]:2025-11-07 16:36:16,548 - INFO -  step: 100  loss: -4.0000  grad_norm:  0.3439  memory:  8.13GiB(17.12%)  tps: 5,962  tflops: 45.41  mfu: 14.55%
[rank0]:2025-11-07 16:36:16,563 - INFO -  step: 100  loss: -4.0000  grad_norm:  0.3439  memory: 14.71GiB(30.97%)  tps: 5,962  tflops: 45.41  mfu: 14.55%
[rank1]:2025-11-07 16:36:16,552 - INFO -  step: 100  loss: -4.0000  grad_norm:  0.3439  memory: 11.85GiB(24.93%)  tps: 5,962  tflops: 45.41  mfu: 14.55%
[rank3]:2025-11-07 16:36:16,560 - INFO -  step: 100  loss:  0.4738  grad_norm:  0.3439  memory: 18.46GiB(38.86%)  tps: 5,962  tflops: 45.41  mfu: 14.55%
[rank3]:2025-11-07 16:36:16,841 - INFO - Pipeline schedule is saved as: /data2/shcho/torchtitan/images/1108_Interleaved1F1B_nofreeze_dm1/pipeline_schedule/251107_1636_real_step100_rank3.svg
[rank3]:> Batch Time: 660.85 ms, GPU Bubble Ratio: 60.64%, 58.21%, 65.76%, 29.27%
[rank0]:2025-11-07 16:38:31,747 - INFO - [GC] Peforming periodical GC collection 0.00 seconds
[rank3]:2025-11-07 16:38:34,423 - INFO - Avg. fwd time: 6.9249 / Avg. bwd time: 22.2432 / Avg. batch time: 575.1737 (ms) / GPU bubble ratio: 18.86%
[rank2]:2025-11-07 16:38:34,450 - INFO - Avg. fwd time: 3.9872 / Avg. bwd time: 10.1133 / Avg. batch time: 607.5608 (ms) / GPU bubble ratio: 62.87%
[rank1]:2025-11-07 16:38:34,474 - INFO - Avg. fwd time: 4.8773 / Avg. bwd time: 12.3398 / Avg. batch time: 637.1517 (ms) / GPU bubble ratio: 56.76%
[rank0]:2025-11-07 16:38:34,498 - INFO - Avg. fwd time: 4.1178 / Avg. bwd time: 12.0360 / Avg. batch time: 660.0133 (ms) / GPU bubble ratio: 60.84%
[rank3]:2025-11-07 16:38:34,532 - INFO -  step: 150  loss:  0.4307  grad_norm:  0.3641  memory: 18.46GiB(38.86%)  tps: 5,938  tflops: 45.22  mfu: 14.49%
[rank2]:2025-11-07 16:38:34,520 - INFO -  step: 150  loss: -4.0000  grad_norm:  0.3641  memory:  8.13GiB(17.12%)  tps: 5,937  tflops: 45.22  mfu: 14.49%
[rank1]:2025-11-07 16:38:34,523 - INFO -  step: 150  loss: -4.0000  grad_norm:  0.3641  memory: 11.85GiB(24.93%)  tps: 5,937  tflops: 45.22  mfu: 14.49%
[rank0]:2025-11-07 16:38:34,534 - INFO -  step: 150  loss: -4.0000  grad_norm:  0.3641  memory: 14.71GiB(30.97%)  tps: 5,937  tflops: 45.22  mfu: 14.49%
[rank0]:2025-11-07 16:40:49,813 - INFO - [GC] Peforming periodical GC collection 0.00 seconds
[rank3]:2025-11-07 16:40:52,268 - INFO - Avg. fwd time: 6.9424 / Avg. bwd time: 22.2867 / Avg. batch time: 576.1410 (ms) / GPU bubble ratio: 18.83%
[rank2]:2025-11-07 16:40:52,327 - INFO - Avg. fwd time: 3.9896 / Avg. bwd time: 10.1180 / Avg. batch time: 608.3639 (ms) / GPU bubble ratio: 62.90%
[rank0]:2025-11-07 16:40:52,348 - INFO - Avg. fwd time: 4.1177 / Avg. bwd time: 12.0387 / Avg. batch time: 660.8436 (ms) / GPU bubble ratio: 60.88%
[rank1]:2025-11-07 16:40:52,432 - INFO - Avg. fwd time: 4.8781 / Avg. bwd time: 12.3502 / Avg. batch time: 637.9764 (ms) / GPU bubble ratio: 56.79%
[rank3]:2025-11-07 16:40:52,609 - INFO -  step: 200  loss:  0.4953  grad_norm:  0.3367  memory: 18.46GiB(38.86%)  tps: 5,933  tflops: 45.19  mfu: 14.48%
[rank1]:2025-11-07 16:40:52,600 - INFO -  step: 200  loss: -4.0000  grad_norm:  0.3367  memory: 11.85GiB(24.93%)  tps: 5,933  tflops: 45.19  mfu: 14.48%
[rank2]:2025-11-07 16:40:52,597 - INFO -  step: 200  loss: -4.0000  grad_norm:  0.3367  memory:  8.13GiB(17.12%)  tps: 5,933  tflops: 45.19  mfu: 14.48%
[rank0]:2025-11-07 16:40:52,611 - INFO -  step: 200  loss: -4.0000  grad_norm:  0.3367  memory: 14.71GiB(30.97%)  tps: 5,933  tflops: 45.19  mfu: 14.48%
[rank3]:2025-11-07 16:40:52,860 - INFO - Pipeline schedule is saved as: /data2/shcho/torchtitan/images/1108_Interleaved1F1B_nofreeze_dm1/pipeline_schedule/251107_1640_real_step200_rank3.svg
[rank3]:> Batch Time: 663.38 ms, GPU Bubble Ratio: 60.77%, 58.27%, 65.82%, 29.18%
[rank0]:2025-11-07 16:43:07,831 - INFO - [GC] Peforming periodical GC collection 0.00 seconds
[rank3]:2025-11-07 16:43:10,264 - INFO - Avg. fwd time: 6.9497 / Avg. bwd time: 22.3015 / Avg. batch time: 576.4858 (ms) / GPU bubble ratio: 18.82%
[rank2]:2025-11-07 16:43:10,326 - INFO - Avg. fwd time: 3.9906 / Avg. bwd time: 10.1204 / Avg. batch time: 608.8584 (ms) / GPU bubble ratio: 62.92%
[rank0]:2025-11-07 16:43:10,347 - INFO - Avg. fwd time: 4.1175 / Avg. bwd time: 12.0389 / Avg. batch time: 661.3449 (ms) / GPU bubble ratio: 60.91%
[rank1]:2025-11-07 16:43:10,430 - INFO - Avg. fwd time: 4.8781 / Avg. bwd time: 12.3545 / Avg. batch time: 638.4808 (ms) / GPU bubble ratio: 56.82%
[rank3]:2025-11-07 16:43:10,604 - INFO -  step: 250  loss:  0.5098  grad_norm:  0.4029  memory: 18.46GiB(38.86%)  tps: 5,937  tflops: 45.21  mfu: 14.49%
[rank1]:2025-11-07 16:43:10,596 - INFO -  step: 250  loss: -4.0000  grad_norm:  0.4029  memory: 11.85GiB(24.93%)  tps: 5,936  tflops: 45.21  mfu: 14.49%
[rank2]:2025-11-07 16:43:10,592 - INFO -  step: 250  loss: -4.0000  grad_norm:  0.4029  memory:  8.13GiB(17.12%)  tps: 5,936  tflops: 45.21  mfu: 14.49%
[rank0]:2025-11-07 16:43:10,606 - INFO -  step: 250  loss: -4.0000  grad_norm:  0.4029  memory: 14.71GiB(30.97%)  tps: 5,936  tflops: 45.21  mfu: 14.49%
[rank0]:2025-11-07 16:45:25,444 - INFO - [GC] Peforming periodical GC collection 0.00 seconds
[rank3]:2025-11-07 16:45:28,163 - INFO - Avg. fwd time: 6.9481 / Avg. bwd time: 22.3026 / Avg. batch time: 576.4673 (ms) / GPU bubble ratio: 18.81%
[rank2]:2025-11-07 16:45:28,190 - INFO - Avg. fwd time: 3.9905 / Avg. bwd time: 10.1214 / Avg. batch time: 608.7364 (ms) / GPU bubble ratio: 62.91%
[rank1]:2025-11-07 16:45:28,216 - INFO - Avg. fwd time: 4.8779 / Avg. bwd time: 12.3566 / Avg. batch time: 638.3644 (ms) / GPU bubble ratio: 56.80%
[rank0]:2025-11-07 16:45:28,243 - INFO - Avg. fwd time: 4.1172 / Avg. bwd time: 12.0391 / Avg. batch time: 661.2367 (ms) / GPU bubble ratio: 60.91%
[rank3]:2025-11-07 16:45:28,277 - INFO -  step: 300  loss:  0.4982  grad_norm:  0.3595  memory: 18.46GiB(38.86%)  tps: 5,950  tflops: 45.32  mfu: 14.53%
[rank2]:2025-11-07 16:45:28,265 - INFO -  step: 300  loss: -4.0000  grad_norm:  0.3595  memory:  8.13GiB(17.12%)  tps: 5,950  tflops: 45.32  mfu: 14.53%
[rank1]:2025-11-07 16:45:28,269 - INFO -  step: 300  loss: -4.0000  grad_norm:  0.3595  memory: 11.85GiB(24.93%)  tps: 5,950  tflops: 45.32  mfu: 14.53%
[rank0]:2025-11-07 16:45:28,279 - INFO -  step: 300  loss: -4.0000  grad_norm:  0.3595  memory: 14.71GiB(30.97%)  tps: 5,950  tflops: 45.32  mfu: 14.53%
[rank3]:2025-11-07 16:45:28,523 - INFO - Pipeline schedule is saved as: /data2/shcho/torchtitan/images/1108_Interleaved1F1B_nofreeze_dm1/pipeline_schedule/251107_1645_real_step300_rank3.svg
[rank3]:> Batch Time: 661.36 ms, GPU Bubble Ratio: 60.69%, 58.16%, 65.73%, 29.14%
[rank0]:2025-11-07 16:47:43,887 - INFO - [GC] Peforming periodical GC collection 0.00 seconds
[rank2]:2025-11-07 16:47:46,384 - INFO - Avg. fwd time: 3.9910 / Avg. bwd time: 10.1226 / Avg. batch time: 609.0906 (ms) / GPU bubble ratio: 62.93%
[rank3]:2025-11-07 16:47:46,325 - INFO - Avg. fwd time: 6.9532 / Avg. bwd time: 22.3133 / Avg. batch time: 576.7264 (ms) / GPU bubble ratio: 18.81%
[rank0]:2025-11-07 16:47:46,408 - INFO - Avg. fwd time: 4.1173 / Avg. bwd time: 12.0394 / Avg. batch time: 661.6077 (ms) / GPU bubble ratio: 60.93%
[rank1]:2025-11-07 16:47:46,489 - INFO - Avg. fwd time: 4.8780 / Avg. bwd time: 12.3591 / Avg. batch time: 638.7280 (ms) / GPU bubble ratio: 56.82%
[rank2]:2025-11-07 16:47:46,650 - INFO -  step: 350  loss: -4.0000  grad_norm:  0.3637  memory:  8.13GiB(17.12%)  tps: 5,920  tflops: 45.09  mfu: 14.45%
[rank1]:2025-11-07 16:47:46,654 - INFO -  step: 350  loss: -4.0000  grad_norm:  0.3637  memory: 11.85GiB(24.93%)  tps: 5,920  tflops: 45.09  mfu: 14.45%
[rank3]:2025-11-07 16:47:46,662 - INFO -  step: 350  loss:  0.4750  grad_norm:  0.3637  memory: 18.46GiB(38.86%)  tps: 5,920  tflops: 45.09  mfu: 14.45%
[rank0]:2025-11-07 16:47:46,664 - INFO -  step: 350  loss: -4.0000  grad_norm:  0.3637  memory: 14.71GiB(30.97%)  tps: 5,920  tflops: 45.09  mfu: 14.45%
[rank0]:2025-11-07 16:50:02,064 - INFO - [GC] Peforming periodical GC collection 0.00 seconds
[rank3]:2025-11-07 16:50:04,529 - INFO - Avg. fwd time: 6.9608 / Avg. bwd time: 22.3298 / Avg. batch time: 577.1120 (ms) / GPU bubble ratio: 18.79%
[rank2]:2025-11-07 16:50:04,587 - INFO - Avg. fwd time: 3.9920 / Avg. bwd time: 10.1239 / Avg. batch time: 609.3968 (ms) / GPU bubble ratio: 62.94%
[rank0]:2025-11-07 16:50:04,608 - INFO - Avg. fwd time: 4.1168 / Avg. bwd time: 12.0395 / Avg. batch time: 661.9231 (ms) / GPU bubble ratio: 60.95%
[rank1]:2025-11-07 16:50:04,694 - INFO - Avg. fwd time: 4.8780 / Avg. bwd time: 12.3618 / Avg. batch time: 639.0467 (ms) / GPU bubble ratio: 56.84%
[rank2]:2025-11-07 16:50:04,856 - INFO -  step: 400  loss: -4.0000  grad_norm:  0.3549  memory:  8.13GiB(17.12%)  tps: 5,927  tflops: 45.14  mfu: 14.47%
[rank1]:2025-11-07 16:50:04,860 - INFO -  step: 400  loss: -4.0000  grad_norm:  0.3549  memory: 11.85GiB(24.93%)  tps: 5,927  tflops: 45.14  mfu: 14.47%
[rank3]:2025-11-07 16:50:04,868 - INFO -  step: 400  loss:  0.4651  grad_norm:  0.3549  memory: 18.46GiB(38.86%)  tps: 5,927  tflops: 45.14  mfu: 14.47%
[rank0]:2025-11-07 16:50:04,871 - INFO -  step: 400  loss: -4.0000  grad_norm:  0.3549  memory: 14.71GiB(30.97%)  tps: 5,927  tflops: 45.14  mfu: 14.47%
[rank3]:2025-11-07 16:50:05,140 - INFO - Pipeline schedule is saved as: /data2/shcho/torchtitan/images/1108_Interleaved1F1B_nofreeze_dm1/pipeline_schedule/251107_1650_real_step400_rank3.svg
[rank3]:> Batch Time: 664.36 ms, GPU Bubble Ratio: 60.86%, 58.29%, 65.88%, 29.04%
[rank3]:2025-11-07 16:50:14,476 - WARNING - Dataset alpaca_cleaned is being re-looped
[rank2]:2025-11-07 16:50:14,749 - WARNING - Dataset alpaca_cleaned is being re-looped
[rank1]:2025-11-07 16:50:14,766 - WARNING - Dataset alpaca_cleaned is being re-looped
[rank0]:2025-11-07 16:50:14,782 - WARNING - Dataset alpaca_cleaned is being re-looped
[rank0]:2025-11-07 16:52:20,525 - INFO - [GC] Peforming periodical GC collection 0.00 seconds
[rank3]:2025-11-07 16:52:23,219 - INFO - Avg. fwd time: 6.9673 / Avg. bwd time: 22.3430 / Avg. batch time: 577.4448 (ms) / GPU bubble ratio: 18.79%
[rank2]:2025-11-07 16:52:23,245 - INFO - Avg. fwd time: 3.9925 / Avg. bwd time: 10.1250 / Avg. batch time: 609.8211 (ms) / GPU bubble ratio: 62.96%
[rank2]:2025-11-07 16:52:23,321 - INFO -  step: 450  loss: -4.0000  grad_norm:  0.3628  memory:  8.13GiB(17.12%)  tps: 5,916  tflops: 45.06  mfu: 14.44%
[rank1]:2025-11-07 16:52:23,273 - INFO - Avg. fwd time: 4.8773 / Avg. bwd time: 12.3633 / Avg. batch time: 639.4868 (ms) / GPU bubble ratio: 56.86%
[rank1]:2025-11-07 16:52:23,324 - INFO -  step: 450  loss: -4.0000  grad_norm:  0.3628  memory: 11.85GiB(24.93%)  tps: 5,916  tflops: 45.06  mfu: 14.44%
[rank3]:2025-11-07 16:52:23,333 - INFO -  step: 450  loss:  0.5079  grad_norm:  0.3628  memory: 18.46GiB(38.86%)  tps: 5,916  tflops: 45.06  mfu: 14.44%
[rank0]:2025-11-07 16:52:23,299 - INFO - Avg. fwd time: 4.1167 / Avg. bwd time: 12.0400 / Avg. batch time: 662.3697 (ms) / GPU bubble ratio: 60.97%
[rank0]:2025-11-07 16:52:23,335 - INFO -  step: 450  loss: -4.0000  grad_norm:  0.3628  memory: 14.71GiB(30.97%)  tps: 5,916  tflops: 45.06  mfu: 14.44%
[rank0]:2025-11-07 16:54:38,621 - INFO - [GC] Peforming periodical GC collection 0.00 seconds
[rank2]:2025-11-07 16:54:41,124 - INFO - Avg. fwd time: 3.9928 / Avg. bwd time: 10.1254 / Avg. batch time: 609.8993 (ms) / GPU bubble ratio: 62.96%
[rank3]:2025-11-07 16:54:41,067 - INFO - Avg. fwd time: 6.9698 / Avg. bwd time: 22.3482 / Avg. batch time: 577.5654 (ms) / GPU bubble ratio: 18.78%
[rank0]:2025-11-07 16:54:41,144 - INFO - Avg. fwd time: 4.1168 / Avg. bwd time: 12.0400 / Avg. batch time: 662.4490 (ms) / GPU bubble ratio: 60.98%
[rank1]:2025-11-07 16:54:41,228 - INFO - Avg. fwd time: 4.8768 / Avg. bwd time: 12.3635 / Avg. batch time: 639.5701 (ms) / GPU bubble ratio: 56.87%
[rank2]:2025-11-07 16:54:41,388 - INFO -  step: 500  loss: -4.0000  grad_norm:  0.2784  memory:  8.13GiB(17.12%)  tps: 5,933  tflops: 45.19  mfu: 14.48%
[rank1]:2025-11-07 16:54:41,392 - INFO -  step: 500  loss: -4.0000  grad_norm:  0.2784  memory: 11.85GiB(24.93%)  tps: 5,933  tflops: 45.19  mfu: 14.48%
[rank3]:2025-11-07 16:54:41,400 - INFO -  step: 500  loss:  0.3717  grad_norm:  0.2784  memory: 18.46GiB(38.86%)  tps: 5,933  tflops: 45.19  mfu: 14.48%
[rank0]:2025-11-07 16:54:41,402 - INFO -  step: 500  loss: -4.0000  grad_norm:  0.2784  memory: 14.71GiB(30.97%)  tps: 5,933  tflops: 45.19  mfu: 14.48%
[rank3]:2025-11-07 16:54:41,683 - INFO - Pipeline schedule is saved as: /data2/shcho/torchtitan/images/1108_Interleaved1F1B_nofreeze_dm1/pipeline_schedule/251107_1654_real_step500_rank3.svg
[rank3]:> Batch Time: 661.35 ms, GPU Bubble Ratio: 60.71%, 58.19%, 65.72%, 29.11%
[rank0]:2025-11-07 16:56:56,615 - INFO - [GC] Peforming periodical GC collection 0.00 seconds
[rank3]:2025-11-07 16:56:59,049 - INFO - Avg. fwd time: 6.9706 / Avg. bwd time: 22.3485 / Avg. batch time: 577.5794 (ms) / GPU bubble ratio: 18.78%
[rank2]:2025-11-07 16:56:59,107 - INFO - Avg. fwd time: 3.9931 / Avg. bwd time: 10.1255 / Avg. batch time: 609.9867 (ms) / GPU bubble ratio: 62.97%
[rank0]:2025-11-07 16:56:59,127 - INFO - Avg. fwd time: 4.1162 / Avg. bwd time: 12.0395 / Avg. batch time: 662.5323 (ms) / GPU bubble ratio: 60.98%
[rank1]:2025-11-07 16:56:59,209 - INFO - Avg. fwd time: 4.8765 / Avg. bwd time: 12.3625 / Avg. batch time: 639.6574 (ms) / GPU bubble ratio: 56.88%
[rank2]:2025-11-07 16:56:59,364 - INFO -  step: 550  loss: -4.0000  grad_norm:  0.3507  memory:  8.13GiB(17.12%)  tps: 5,937  tflops: 45.22  mfu: 14.49%
[rank1]:2025-11-07 16:56:59,368 - INFO -  step: 550  loss: -4.0000  grad_norm:  0.3507  memory: 11.85GiB(24.93%)  tps: 5,937  tflops: 45.22  mfu: 14.49%
[rank3]:2025-11-07 16:56:59,376 - INFO -  step: 550  loss:  0.4189  grad_norm:  0.3507  memory: 18.46GiB(38.86%)  tps: 5,937  tflops: 45.22  mfu: 14.49%
[rank0]:2025-11-07 16:56:59,379 - INFO -  step: 550  loss: -4.0000  grad_norm:  0.3507  memory: 14.71GiB(30.97%)  tps: 5,937  tflops: 45.22  mfu: 14.49%
[rank0]:2025-11-07 16:59:14,332 - INFO - [GC] Peforming periodical GC collection 0.00 seconds
[rank3]:2025-11-07 16:59:17,041 - INFO - Avg. fwd time: 6.9703 / Avg. bwd time: 22.3481 / Avg. batch time: 577.5681 (ms) / GPU bubble ratio: 18.78%
[rank2]:2025-11-07 16:59:17,066 - INFO - Avg. fwd time: 3.9930 / Avg. bwd time: 10.1256 / Avg. batch time: 609.9249 (ms) / GPU bubble ratio: 62.96%
[rank2]:2025-11-07 16:59:17,145 - INFO -  step: 600  loss: -4.0000  grad_norm:  0.3391  memory:  8.13GiB(17.12%)  tps: 5,946  tflops: 45.28  mfu: 14.51%
[rank1]:2025-11-07 16:59:17,095 - INFO - Avg. fwd time: 4.8759 / Avg. bwd time: 12.3610 / Avg. batch time: 639.5943 (ms) / GPU bubble ratio: 56.88%
[rank0]:2025-11-07 16:59:17,123 - INFO - Avg. fwd time: 4.1164 / Avg. bwd time: 12.0397 / Avg. batch time: 662.4734 (ms) / GPU bubble ratio: 60.98%
[rank0]:2025-11-07 16:59:17,159 - INFO -  step: 600  loss: -4.0000  grad_norm:  0.3391  memory: 14.71GiB(30.97%)  tps: 5,946  tflops: 45.28  mfu: 14.51%
[rank3]:2025-11-07 16:59:17,158 - INFO -  step: 600  loss:  0.4194  grad_norm:  0.3391  memory: 18.46GiB(38.86%)  tps: 5,946  tflops: 45.28  mfu: 14.51%
[rank1]:2025-11-07 16:59:17,148 - INFO -  step: 600  loss: -4.0000  grad_norm:  0.3391  memory: 11.85GiB(24.93%)  tps: 5,946  tflops: 45.28  mfu: 14.51%
[rank3]:2025-11-07 16:59:17,457 - INFO - Pipeline schedule is saved as: /data2/shcho/torchtitan/images/1108_Interleaved1F1B_nofreeze_dm1/pipeline_schedule/251107_1659_real_step600_rank3.svg
[rank3]:> Batch Time: 662.37 ms, GPU Bubble Ratio: 60.75%, 58.29%, 65.78%, 29.11%
[rank0]:2025-11-07 17:01:32,752 - INFO - [GC] Peforming periodical GC collection 0.00 seconds
[rank3]:2025-11-07 17:01:35,181 - INFO - Avg. fwd time: 6.9726 / Avg. bwd time: 22.3526 / Avg. batch time: 577.6777 (ms) / GPU bubble ratio: 18.78%
[rank2]:2025-11-07 17:01:35,239 - INFO - Avg. fwd time: 3.9936 / Avg. bwd time: 10.1259 / Avg. batch time: 610.0993 (ms) / GPU bubble ratio: 62.97%
[rank0]:2025-11-07 17:01:35,259 - INFO - Avg. fwd time: 4.1166 / Avg. bwd time: 12.0400 / Avg. batch time: 662.6492 (ms) / GPU bubble ratio: 60.99%
[rank1]:2025-11-07 17:01:35,342 - INFO - Avg. fwd time: 4.8760 / Avg. bwd time: 12.3612 / Avg. batch time: 639.7699 (ms) / GPU bubble ratio: 56.89%
[rank0]:2025-11-07 17:01:35,513 - INFO -  step: 650  loss: -4.0000  grad_norm:  0.3380  memory: 14.71GiB(30.97%)  tps: 5,921  tflops: 45.10  mfu: 14.45%
[rank2]:2025-11-07 17:01:35,498 - INFO -  step: 650  loss: -4.0000  grad_norm:  0.3380  memory:  8.13GiB(17.12%)  tps: 5,921  tflops: 45.10  mfu: 14.45%
[rank1]:2025-11-07 17:01:35,502 - INFO -  step: 650  loss: -4.0000  grad_norm:  0.3380  memory: 11.85GiB(24.93%)  tps: 5,921  tflops: 45.10  mfu: 14.45%
[rank3]:2025-11-07 17:01:35,511 - INFO -  step: 650  loss:  0.3608  grad_norm:  0.3380  memory: 18.46GiB(38.86%)  tps: 5,921  tflops: 45.10  mfu: 14.45%
[rank0]:2025-11-07 17:03:51,032 - INFO - [GC] Peforming periodical GC collection 0.00 seconds
[rank3]:2025-11-07 17:03:53,500 - INFO - Avg. fwd time: 6.9758 / Avg. bwd time: 22.3588 / Avg. batch time: 577.8307 (ms) / GPU bubble ratio: 18.77%
[rank2]:2025-11-07 17:03:53,557 - INFO - Avg. fwd time: 3.9941 / Avg. bwd time: 10.1264 / Avg. batch time: 610.2053 (ms) / GPU bubble ratio: 62.98%
[rank0]:2025-11-07 17:03:53,577 - INFO - Avg. fwd time: 4.1172 / Avg. bwd time: 12.0399 / Avg. batch time: 662.7625 (ms) / GPU bubble ratio: 60.99%
[rank1]:2025-11-07 17:03:53,663 - INFO - Avg. fwd time: 4.8760 / Avg. bwd time: 12.3617 / Avg. batch time: 639.8793 (ms) / GPU bubble ratio: 56.90%
[rank1]:2025-11-07 17:03:53,823 - INFO -  step: 700  loss: -4.0000  grad_norm:  0.3854  memory: 11.85GiB(24.93%)  tps: 5,922  tflops: 45.11  mfu: 14.46%
[rank2]:2025-11-07 17:03:53,820 - INFO -  step: 700  loss: -4.0000  grad_norm:  0.3854  memory:  8.13GiB(17.12%)  tps: 5,922  tflops: 45.11  mfu: 14.46%
[rank3]:2025-11-07 17:03:53,832 - INFO -  step: 700  loss:  0.4271  grad_norm:  0.3854  memory: 18.46GiB(38.86%)  tps: 5,923  tflops: 45.11  mfu: 14.46%
[rank0]:2025-11-07 17:03:53,834 - INFO -  step: 700  loss: -4.0000  grad_norm:  0.3854  memory: 14.71GiB(30.97%)  tps: 5,922  tflops: 45.11  mfu: 14.46%
[rank3]:2025-11-07 17:03:54,155 - INFO - Pipeline schedule is saved as: /data2/shcho/torchtitan/images/1108_Interleaved1F1B_nofreeze_dm1/pipeline_schedule/251107_1703_real_step700_rank3.svg
[rank3]:> Batch Time: 663.37 ms, GPU Bubble Ratio: 60.82%, 58.34%, 65.81%, 29.09%
[rank0]:2025-11-07 17:06:09,173 - INFO - [GC] Peforming periodical GC collection 0.00 seconds
[rank2]:2025-11-07 17:06:11,880 - INFO - Avg. fwd time: 3.9941 / Avg. bwd time: 10.1264 / Avg. batch time: 610.2713 (ms) / GPU bubble ratio: 62.98%
[rank3]:2025-11-07 17:06:11,854 - INFO - Avg. fwd time: 6.9760 / Avg. bwd time: 22.3596 / Avg. batch time: 577.8430 (ms) / GPU bubble ratio: 18.77%
[rank1]:2025-11-07 17:06:11,909 - INFO - Avg. fwd time: 4.8757 / Avg. bwd time: 12.3610 / Avg. batch time: 639.9458 (ms) / GPU bubble ratio: 56.90%
[rank2]:2025-11-07 17:06:11,960 - INFO -  step: 750  loss: -4.0000  grad_norm:  0.4196  memory:  8.13GiB(17.12%)  tps: 5,930  tflops: 45.17  mfu: 14.48%
[rank3]:2025-11-07 17:06:11,973 - INFO -  step: 750  loss:  0.4064  grad_norm:  0.4196  memory: 18.46GiB(38.86%)  tps: 5,930  tflops: 45.17  mfu: 14.48%
[rank1]:2025-11-07 17:06:11,964 - INFO -  step: 750  loss: -4.0000  grad_norm:  0.4196  memory: 11.85GiB(24.93%)  tps: 5,930  tflops: 45.17  mfu: 14.48%
[rank0]:2025-11-07 17:06:11,939 - INFO - Avg. fwd time: 4.1168 / Avg. bwd time: 12.0399 / Avg. batch time: 662.8303 (ms) / GPU bubble ratio: 61.00%
[rank0]:2025-11-07 17:06:11,974 - INFO -  step: 750  loss: -4.0000  grad_norm:  0.4196  memory: 14.71GiB(30.97%)  tps: 5,930  tflops: 45.17  mfu: 14.48%
[rank0]:2025-11-07 17:08:26,846 - INFO - [GC] Peforming periodical GC collection 0.00 seconds
[rank3]:2025-11-07 17:08:29,299 - INFO - Avg. fwd time: 6.9754 / Avg. bwd time: 22.3594 / Avg. batch time: 577.8305 (ms) / GPU bubble ratio: 18.77%
[rank2]:2025-11-07 17:08:29,359 - INFO - Avg. fwd time: 3.9942 / Avg. bwd time: 10.1262 / Avg. batch time: 610.2152 (ms) / GPU bubble ratio: 62.98%
[rank0]:2025-11-07 17:08:29,379 - INFO - Avg. fwd time: 4.1165 / Avg. bwd time: 12.0396 / Avg. batch time: 662.7694 (ms) / GPU bubble ratio: 61.00%
[rank1]:2025-11-07 17:08:29,462 - INFO - Avg. fwd time: 4.8755 / Avg. bwd time: 12.3599 / Avg. batch time: 639.8873 (ms) / GPU bubble ratio: 56.90%
[rank2]:2025-11-07 17:08:29,618 - INFO -  step: 800  loss: -4.0000  grad_norm:  0.3663  memory:  8.13GiB(17.12%)  tps: 5,951  tflops: 45.32  mfu: 14.53%
[rank2]:2025-11-07 17:08:29,618 - INFO -  final step: 800  loss: -4.0000  grad_norm:  0.3663  tps: 6,291  tflops: 47.92  mfu: 13.90%
[rank2]:2025-11-07 17:08:29,618 - INFO - Saving the checkpoint (or staging if async is enabled).
[rank2]:2025-11-07 17:08:29,619 - INFO - Saving a model only checkpoint in torch.float16 at last step, step 800.
[rank1]:2025-11-07 17:08:29,622 - INFO -  step: 800  loss: -4.0000  grad_norm:  0.3663  memory: 11.85GiB(24.93%)  tps: 5,951  tflops: 45.32  mfu: 14.53%
[rank1]:2025-11-07 17:08:29,622 - INFO -  final step: 800  loss: -4.0000  grad_norm:  0.3663  tps: 6,291  tflops: 47.91  mfu: 13.90%
[rank1]:2025-11-07 17:08:29,622 - INFO - Saving the checkpoint (or staging if async is enabled).
[rank1]:2025-11-07 17:08:29,623 - INFO - Saving a model only checkpoint in torch.float16 at last step, step 800.
[rank0]:2025-11-07 17:08:29,632 - INFO -  step: 800  loss: -4.0000  grad_norm:  0.3663  memory: 14.71GiB(30.97%)  tps: 5,951  tflops: 45.32  mfu: 14.53%
[rank0]:2025-11-07 17:08:29,633 - INFO -  final step: 800  loss: -4.0000  grad_norm:  0.3663  tps: 6,289  tflops: 47.90  mfu: 13.88%
[rank0]:2025-11-07 17:08:29,633 - INFO - Saving the checkpoint (or staging if async is enabled).
[rank0]:2025-11-07 17:08:29,633 - INFO - Saving a model only checkpoint in torch.float16 at last step, step 800.
[rank3]:2025-11-07 17:08:29,630 - INFO -  step: 800  loss:  0.4153  grad_norm:  0.3663  memory: 18.46GiB(38.86%)  tps: 5,951  tflops: 45.32  mfu: 14.53%
[rank3]:2025-11-07 17:08:29,631 - INFO -  final step: 800  loss:  0.4153  grad_norm:  0.3663  tps: 6,301  tflops: 47.99  mfu: 14.05%
[rank3]:2025-11-07 17:08:29,631 - INFO - Saving the checkpoint (or staging if async is enabled).
[rank3]:2025-11-07 17:08:29,632 - INFO - Saving a model only checkpoint in torch.float16 at last step, step 800.
[rank2]:2025-11-07 17:08:31,708 - INFO - Destroying the purge thread.
[rank1]:2025-11-07 17:08:31,707 - INFO - Destroying the purge thread.
[rank0]:2025-11-07 17:08:31,684 - INFO - [GC] GC collection invoked by checkpointer. 0.00 seconds
[rank0]:2025-11-07 17:08:31,707 - INFO - Sleeping 2 seconds for other ranks to complete
[rank2]:2025-11-07 17:08:31,887 - INFO - Process group destroyed
[rank1]:2025-11-07 17:08:31,909 - INFO - Process group destroyed
[rank3]:2025-11-07 17:08:31,976 - INFO - Pipeline schedule is saved as: /data2/shcho/torchtitan/images/1108_Interleaved1F1B_nofreeze_dm1/pipeline_schedule/251107_1708_real_final800_rank3.svg
[rank3]:> Batch Time: 662.36 ms, GPU Bubble Ratio: 60.75%, 58.26%, 65.78%, 29.15%
[rank3]:2025-11-07 17:08:32,244 - INFO - Pipeline schedule is saved as: /data2/shcho/torchtitan/images/1108_Interleaved1F1B_nofreeze_dm1/pipeline_schedule/251107_1708_thry_final800_rank3.svg
[rank3]:> Batch Time: 283.58 ms, GPU Bubble Ratio: 15.79%, 15.79%, 15.79%, 15.79%
[rank3]:2025-11-07 17:08:32,245 - INFO - Destroying the purge thread.
[rank3]:wandb: updating run metadata
[rank3]:wandb: uploading history steps 15-16, summary, console lines 229-238
[rank3]:wandb: 
[rank3]:wandb: Run history:
[rank3]:wandb:      final/avg_end_to_end(s) â–
[rank3]:wandb:               final/avg_loss â–
[rank3]:wandb:             final/avg_mfu(%) â–
[rank3]:wandb:             final/avg_tflops â–
[rank3]:wandb:    final/avg_throughput(tps) â–
[rank3]:wandb:              final/grad_norm â–
[rank3]:wandb:               final/max_loss â–
[rank3]:wandb:                    grad_norm â–ˆâ–â–â–â–â–‚â–â–â–â–â–â–â–â–â–‚â–‚â–
[rank3]:wandb: loss_metrics/global_avg_loss â–ˆâ–„â–…â–„â–†â–‡â–†â–…â–…â–‡â–â–ƒâ–ƒâ–â–„â–ƒâ–ƒ
[rank3]:wandb: loss_metrics/global_max_loss â–ˆâ–„â–…â–„â–†â–‡â–†â–…â–…â–‡â–â–ƒâ–ƒâ–â–„â–ƒâ–ƒ
[rank3]:wandb:                          +14 ...
[rank3]:wandb: 
[rank3]:wandb: Run summary:
[rank3]:wandb:      final/avg_end_to_end(s) 2.60032
[rank3]:wandb:               final/avg_loss 0.41528
[rank3]:wandb:             final/avg_mfu(%) 14.04873
[rank3]:wandb:             final/avg_tflops 47.98787
[rank3]:wandb:    final/avg_throughput(tps) 6300.75171
[rank3]:wandb:              final/grad_norm 0.3663
[rank3]:wandb:               final/max_loss 0.41528
[rank3]:wandb:                    grad_norm 0.3663
[rank3]:wandb: loss_metrics/global_avg_loss 0.41528
[rank3]:wandb: loss_metrics/global_max_loss 0.41528
[rank3]:wandb:                          +14 ...
[rank3]:wandb: 
[rank3]:wandb: ðŸš€ View run 1108_Interleaved1F1B_nofreeze_dm1 at: https://wandb.ai/orangingq/torchtitan/runs/krryjqqb
[rank3]:wandb: â­ï¸ View project at: https://wandb.ai/orangingq/torchtitan
[rank3]:wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
[rank3]:wandb: Find logs at: /data2/shcho/torchtitan/tb/1108_Interleaved1F1B_nofreeze_dm1/20251107-1631/wandb/run-20251107_163138-krryjqqb/logs
[rank3]:2025-11-07 17:08:33,394 - INFO - Process group destroyed
[rank0]:2025-11-07 17:08:33,708 - INFO - Training completed
[rank0]:2025-11-07 17:08:33,708 - INFO - Destroying the purge thread.
[rank0]:2025-11-07 17:08:33,912 - INFO - Process group destroyed
[rank0]:Stage 0: Modules to keep: {'tok_embeddings', 'layers.0', 'layers.1'}
[rank0]:Stage 4: Modules to keep: {'layers.10', 'layers.9'}
[rank1]:Stage 1: Modules to keep: {'layers.3', 'layers.4', 'layers.2'}
[rank1]:Stage 5: Modules to keep: {'layers.12', 'layers.11'}
[rank2]:Stage 2: Modules to keep: {'layers.5', 'layers.6'}
[rank2]:Stage 6: Modules to keep: {'layers.14', 'layers.13'}
[rank3]:Stage 3: Modules to keep: {'layers.8', 'layers.7'}
[rank3]:Stage 7: Modules to keep: {'output', 'norm', 'layers.15'}
[rank3]:----- TimelyFreezeâ° Configuration:
[rank3]:	- job:
[rank3]:		- config_file: /home/shcho/torchtitan/logs/dmserver1/1104_llama1b/config_1108.toml
[rank3]:		- dump_folder: /data2/shcho/torchtitan
[rank3]:		- description: "Main Table Experiment, without streaming mode, sample-level with truncation, with bf16 autocast
[rank3]:1107: for timelyapf: clone().cpu() removed to fix freezing issue.!!! yay~~~
[rank3]:1108: steps 1200 (3 epochs) -> 800 (2 epochs) / alpaca dataset
[rank3]:"
[rank3]:		- use_for_integration_test: False
[rank3]:		- print_args: False
[rank3]:		- basename: 1108_Interleaved1F1B_nofreeze_dm1
[rank3]:	- profiling:
[rank3]:		- enable_profiling: False
[rank3]:		- save_traces_folder: /data2/shcho/torchtitan/profile_trace/1108_Interleaved1F1B_nofreeze_dm1
[rank3]:		- profile_freq: 100
[rank3]:		- enable_memory_snapshot: False
[rank3]:		- save_memory_snapshot_folder: /data2/shcho/torchtitan/memory_snapshot/1108_Interleaved1F1B_nofreeze_dm1
[rank3]:	- metrics:
[rank3]:		- log_freq: 50
[rank3]:		- enable_tensorboard: False
[rank3]:		- disable_color_printing: True
[rank3]:		- save_tb_folder: /data2/shcho/torchtitan/tb/1108_Interleaved1F1B_nofreeze_dm1
[rank3]:		- save_for_all_ranks: False
[rank3]:		- enable_wandb: True
[rank3]:		- image_folder: /data2/shcho/torchtitan/images/1108_Interleaved1F1B_nofreeze_dm1
[rank3]:		- pplog_freq: 200
[rank3]:		- draw_freq: 100
[rank3]:		- wandb_name: 1108_Interleaved1F1B_nofreeze_dm1
[rank3]:		- draw_graph: True
[rank3]:	- model:
[rank3]:		- name: llama3
[rank3]:		- flavor: 1B
[rank3]:		- tokenizer_path: ./assets/tokenizer/Llama-3.2-1B
[rank3]:		- converters: []
[rank3]:		- print_after_conversion: False
[rank3]:	- optimizer:
[rank3]:		- name: AdamW
[rank3]:		- lr: 1e-05
[rank3]:		- beta1: 0.9
[rank3]:		- beta2: 0.95
[rank3]:		- eps: 1e-08
[rank3]:		- weight_decay: 0.1
[rank3]:		- implementation: fused
[rank3]:		- early_step_in_backward: False
[rank3]:	- lr_scheduler:
[rank3]:		- warmup_steps: 100
[rank3]:		- decay_ratio: 0.8
[rank3]:		- decay_type: cosine
[rank3]:		- min_lr_factor: 0.0
[rank3]:	- training:
[rank3]:		- dataset: alpaca_cleaned
[rank3]:		- dataset_path: None
[rank3]:		- local_batch_size: 32
[rank3]:		- global_batch_size: 128
[rank3]:		- seq_len: 512
[rank3]:		- max_norm: 1.0
[rank3]:		- steps: 800
[rank3]:		- enable_cpu_offload: False
[rank3]:		- mixed_precision_param: bfloat16
[rank3]:		- mixed_precision_reduce: float32
[rank3]:		- compile: False
[rank3]:		- gc_freq: 50
[rank3]:		- gc_debug: False
[rank3]:		- seed: None
[rank3]:		- deterministic: False
[rank3]:	- parallelism:
[rank3]:		- data_parallel_replicate_degree: 1
[rank3]:		- enable_compiled_autograd: False
[rank3]:		- data_parallel_shard_degree: -1
[rank3]:		- fsdp_reshard_after_forward: default
[rank3]:		- tensor_parallel_degree: 1
[rank3]:		- disable_loss_parallel: False
[rank3]:		- enable_async_tensor_parallel: False
[rank3]:		- pipeline_parallel_degree: 4
[rank3]:		- pipeline_parallel_split_points: []
[rank3]:		- module_fqns_per_model_part: None
[rank3]:		- pipeline_parallel_first_stage_less_layers: 1
[rank3]:		- pipeline_parallel_last_stage_less_layers: 1
[rank3]:		- pipeline_parallel_layers_per_stage: None
[rank3]:		- pipeline_parallel_schedule: Interleaved1F1B
[rank3]:		- pipeline_parallel_schedule_csv: 
[rank3]:		- pipeline_parallel_microbatch_size: 4
[rank3]:		- context_parallel_degree: 1
[rank3]:		- context_parallel_rotate_method: allgather
[rank3]:		- expert_parallel_degree: 1
[rank3]:		- pp: 4
[rank3]:		- stages_per_rank: 2
[rank3]:		- stages_list: [3, 7]
[rank3]:		- microbatches: 8
[rank3]:	- checkpoint:
[rank3]:		- enable_checkpoint: True
[rank3]:		- checkpoint_folder: /data2/shcho/torchtitan/checkpoint/1108_Interleaved1F1B_nofreeze_dm1
[rank3]:		- interval: 1200
[rank3]:		- initial_load_path: /data2/shcho/torchtitan/base_model/Llama-3.2-1B/original_dcp
[rank3]:		- initial_load_model_only: True
[rank3]:		- initial_load_in_hf: False
[rank3]:		- last_save_model_only: True
[rank3]:		- last_save_in_hf: False
[rank3]:		- export_dtype: float16
[rank3]:		- async_mode: async
[rank3]:		- keep_latest_k: 2
[rank3]:		- load_step: -1
[rank3]:		- exclude_from_loading: ['dataloader', 'lr_scheduler', 'optimizer', 'train_state']
[rank3]:		- enable_first_step_checkpoint: False
[rank3]:		- create_seed_checkpoint: False
[rank3]:	- activation_checkpoint:
[rank3]:		- mode: none
[rank3]:		- selective_ac_option: op
[rank3]:		- per_op_sac_force_recompute_mm_shapes_by_fqns: ['moe.router.gate']
[rank3]:	- float8:
[rank3]:		- enable_fsdp_float8_all_gather: False
[rank3]:		- precompute_float8_dynamic_scale_for_fsdp: False
[rank3]:		- recipe_name: None
[rank3]:		- filter_fqns: ['output']
[rank3]:		- emulate: False
[rank3]:		- moe_fqns_prototype: []
[rank3]:	- mx:
[rank3]:		- mxfp8_dim1_cast_kernel_choice: triton
[rank3]:		- recipe_name: mxfp8
[rank3]:		- filter_fqns: ['output']
[rank3]:		- moe_fqns_prototype: []
[rank3]:	- comm:
[rank3]:		- init_timeout_seconds: 300
[rank3]:		- train_timeout_seconds: 300
[rank3]:		- trace_buf_size: 20000
[rank3]:		- save_traces_folder: /data2/shcho/torchtitan/comm_traces/1108_Interleaved1F1B_nofreeze_dm1
[rank3]:		- world_size: 4
[rank3]:		- global_rank: 3
[rank3]:		- local_rank: 3
[rank3]:		- dp: 1
[rank3]:		- pp: 4
[rank3]:		- pp_rank: 3
[rank3]:		- dp_rank: 0
[rank3]:		- master_dp_rank: 0
[rank3]:	- memory_estimation:
[rank3]:		- enabled: False
[rank3]:		- disable_fake_mode: False
[rank3]:	- fault_tolerance:
[rank3]:		- enable: False
[rank3]:		- process_group: gloo
[rank3]:		- process_group_timeout_ms: 10000
[rank3]:		- replica_id: 0
[rank3]:		- group_size: 0
[rank3]:		- min_replica_size: 1
[rank3]:		- semi_sync_method: None
[rank3]:		- sync_steps: 5
[rank3]:		- should_quantize: False
[rank3]:		- fragment_sync_delay: 0
[rank3]:		- fragment_update_alpha: 0.0
[rank3]:	- experimental:
[rank3]:		- custom_import: 
[rank3]:		- custom_args_module: 
[rank3]:	- validation:
[rank3]:		- enabled: False
[rank3]:		- dataset: c4_validation
[rank3]:		- dataset_path: None
[rank3]:		- local_batch_size: 32
[rank3]:		- seq_len: 512
[rank3]:		- freq: 200
[rank3]:		- steps: 100
[rank3]:	- freezing:
[rank3]:		- freeze: False
[rank3]:		- metric_type: apf
[rank3]:		- phase_unit: 50
[rank3]:		- stability_check_freq: 10
[rank3]:		- max_freeze_ratio: 0.7
[rank3]:		- adjustment: False
[rank3]:		- threshold: 0.05
[rank3]:		- percentile: 70
[rank3]:
[rank1]:[Gloo] Rank 1 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
[rank0]:[Gloo] Rank 0 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
[rank2]:[Gloo] Rank 2 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
[rank3]:[Gloo] Rank 3 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
