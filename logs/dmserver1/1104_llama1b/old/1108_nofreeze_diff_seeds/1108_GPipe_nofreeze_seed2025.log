
ðŸ”¥ðŸ”¥ðŸ”¥ðŸ”¥ðŸ”¥ðŸ”¥ðŸ”¥ðŸ”¥ðŸ”¥ðŸ”¥ðŸ”¥ðŸ”¥ðŸ”¥ðŸ”¥ðŸ”¥ðŸ”¥ðŸ”¥ðŸ”¥ðŸ”¥ðŸ”¥ðŸ”¥ðŸ”¥ðŸ”¥ðŸ”¥ðŸ”¥ðŸ”¥ðŸ”¥ðŸ”¥
âœ”ï¸Current Timestamp: 2025. 11. 07. (ê¸ˆ) 17:15:57 KST
âœ”ï¸SERVER: dmserver1 (143.248.135.95),  GPUs: 0,1,2,3
âœ”ï¸SCRIPT: /home/shcho/torchtitan/logs/dmserver1/1104_llama1b/run.sh
âœ”ï¸OUTPUT: /home/shcho/torchtitan/logs/dmserver1/1104_llama1b/1108_GPipe_nofreeze_seed2025.log
âœ”ï¸Main Table Experiment, without streaming mode, sample-level with truncation, with bf16 autocast
1107: for timelyapf: clone().cpu() removed to fix freezing issue.!!! yay~~~
1108: steps 1200 (3 epochs) -> 800 (2 epochs) / alpaca dataset

âœ”ï¸Running with nofreeze x GPipe ... 
â˜‘ï¸> torchrun --standalone --nnodes=1 --nproc_per_node=4 --local_addr=127.0.0.1 --local-ranks-filter=0,1,2,3 --role=rank --tee=3 -m timelyfreeze.train --job.config_file=/home/shcho/torchtitan/logs/dmserver1/1104_llama1b/config_1108.toml --job.description="Main Table Experiment, without streaming mode, sample-level with truncation, with bf16 autocast
1107: for timelyapf: clone().cpu() removed to fix freezing issue.!!! yay~~~
1108: steps 1200 (3 epochs) -> 800 (2 epochs) / alpaca dataset
" --parallelism.pipeline_parallel_degree=4 --training.seed=2025  --freezing.no-freeze
ðŸ”¥ðŸ”¥ðŸ”¥ðŸ”¥ðŸ”¥ðŸ”¥ðŸ”¥ðŸ”¥ðŸ”¥ðŸ”¥ðŸ”¥ðŸ”¥ðŸ”¥ðŸ”¥ðŸ”¥ðŸ”¥ðŸ”¥ðŸ”¥ðŸ”¥ðŸ”¥ðŸ”¥ðŸ”¥ðŸ”¥ðŸ”¥ðŸ”¥ðŸ”¥ðŸ”¥ðŸ”¥
[rank3]:2025-11-07 17:16:03,792 - INFO - Starting job: "Main Table Experiment, without streaming mode, sample-level with truncation, with bf16 autocast
[rank3]:1107: for timelyapf: clone().cpu() removed to fix freezing issue.!!! yay~~~
[rank3]:1108: steps 1200 (3 epochs) -> 800 (2 epochs) / alpaca dataset
[rank3]:"
[rank0]:2025-11-07 17:16:03,802 - INFO - Starting job: "Main Table Experiment, without streaming mode, sample-level with truncation, with bf16 autocast
[rank2]:2025-11-07 17:16:03,792 - INFO - Starting job: "Main Table Experiment, without streaming mode, sample-level with truncation, with bf16 autocast
[rank2]:1107: for timelyapf: clone().cpu() removed to fix freezing issue.!!! yay~~~
[rank2]:1108: steps 1200 (3 epochs) -> 800 (2 epochs) / alpaca dataset
[rank2]:"
[rank0]:1107: for timelyapf: clone().cpu() removed to fix freezing issue.!!! yay~~~
[rank0]:1108: steps 1200 (3 epochs) -> 800 (2 epochs) / alpaca dataset
[rank0]:"
[rank1]:2025-11-07 17:16:03,772 - INFO - Starting job: "Main Table Experiment, without streaming mode, sample-level with truncation, with bf16 autocast
[rank1]:1107: for timelyapf: clone().cpu() removed to fix freezing issue.!!! yay~~~
[rank1]:1108: steps 1200 (3 epochs) -> 800 (2 epochs) / alpaca dataset
[rank1]:"
[rank3]:2025-11-07 17:16:04,176 - WARNING - ENV[TORCH_NCCL_ASYNC_ERROR_HANDLING] = 1 will be overridden to 3 based on job config
[rank3]:2025-11-07 17:16:04,185 - INFO - Building 1-D device mesh with ['pp'], [4]
[rank2]:2025-11-07 17:16:04,171 - WARNING - ENV[TORCH_NCCL_ASYNC_ERROR_HANDLING] = 1 will be overridden to 3 based on job config
[rank2]:2025-11-07 17:16:04,185 - INFO - Building 1-D device mesh with ['pp'], [4]
[rank0]:2025-11-07 17:16:04,209 - WARNING - ENV[TORCH_NCCL_ASYNC_ERROR_HANDLING] = 1 will be overridden to 3 based on job config
[rank0]:2025-11-07 17:16:04,211 - INFO - Building 1-D device mesh with ['pp'], [4]
[rank0]:2025-11-07 17:16:04,215 - INFO - [GC] Initial GC collection 0.00 seconds
[rank0]:2025-11-07 17:16:04,216 - INFO - Loading tokenizer from tokenizer.json
[rank1]:2025-11-07 17:16:04,181 - WARNING - ENV[TORCH_NCCL_ASYNC_ERROR_HANDLING] = 1 will be overridden to 3 based on job config
[rank1]:2025-11-07 17:16:04,185 - INFO - Building 1-D device mesh with ['pp'], [4]
[rank0]:2025-11-07 17:16:04,595 - INFO - Preparing alpaca_cleaned dataset from yahma/alpaca-cleaned
[rank2]:2025-11-07 17:16:07,679 - INFO - CUDA capacity: NVIDIA RTX 6000 Ada Generation with 47.51GiB memory
[rank2]:2025-11-07 17:16:07,720 - WARNING - Peak flops undefined for: NVIDIA RTX 6000 Ada Generation, fallback to A100
[rank2]:2025-11-07 17:16:07,746 - INFO - PP rank 2 is building stage_idx 2 with modules ['layers.9', 'layers.10', 'layers.11', 'layers.12']
[rank2]:2025-11-07 17:16:07,746 - INFO - Using pipeline schedule GPipe with 8 microbatches and 4 stages.
[rank2]:2025-11-07 17:16:07,930 - WARNING - Peak flops undefined for: NVIDIA RTX 6000 Ada Generation, fallback to A100
[rank2]:2025-11-07 17:16:07,930 - INFO - Peak FLOPS used for computing MFU: 3.120e+14
[rank2]:2025-11-07 17:16:07,930 - INFO - CUDA memory usage for model: 0.92GiB(1.94%)
[rank1]:2025-11-07 17:16:08,306 - INFO - CUDA capacity: NVIDIA RTX 6000 Ada Generation with 47.51GiB memory
[rank1]:2025-11-07 17:16:08,344 - WARNING - Peak flops undefined for: NVIDIA RTX 6000 Ada Generation, fallback to A100
[rank1]:2025-11-07 17:16:08,372 - INFO - PP rank 1 is building stage_idx 1 with modules ['layers.4', 'layers.5', 'layers.6', 'layers.7', 'layers.8']
[rank1]:2025-11-07 17:16:08,373 - INFO - Using pipeline schedule GPipe with 8 microbatches and 4 stages.
[rank1]:2025-11-07 17:16:08,558 - WARNING - Peak flops undefined for: NVIDIA RTX 6000 Ada Generation, fallback to A100
[rank1]:2025-11-07 17:16:08,558 - INFO - Peak FLOPS used for computing MFU: 3.120e+14
[rank1]:2025-11-07 17:16:08,559 - INFO - CUDA memory usage for model: 1.13GiB(2.39%)
[rank0]:2025-11-07 17:16:17,550 - INFO - Building llama3 1B with TransformerModelArgs(_enforced='This field is used to enforce all fields have defaults.', dim=2048, n_layers=16, n_heads=32, n_kv_heads=8, vocab_size=128256, multiple_of=256, ffn_dim_multiplier=1.5, norm_eps=1e-05, rope_theta=500000, max_seq_len=512, depth_init=True, use_flex_attn=False, attn_mask_type='causal', eos_id=0)
[rank0]:2025-11-07 17:16:17,702 - INFO - CUDA capacity: NVIDIA RTX 6000 Ada Generation with 47.51GiB memory
[rank0]:2025-11-07 17:16:17,742 - WARNING - Peak flops undefined for: NVIDIA RTX 6000 Ada Generation, fallback to A100
[rank0]:2025-11-07 17:16:17,743 - INFO - Model llama3 1B size: 1,498,482,688 total parameters
[rank0]:2025-11-07 17:16:17,767 - INFO - PP rank 0 is building stage_idx 0 with modules ['tok_embeddings', 'layers.0', 'layers.1', 'layers.2', 'layers.3']
[rank0]:2025-11-07 17:16:17,767 - INFO - Using pipeline schedule GPipe with 8 microbatches and 4 stages.
[rank0]:2025-11-07 17:16:17,948 - WARNING - Peak flops undefined for: NVIDIA RTX 6000 Ada Generation, fallback to A100
[rank0]:2025-11-07 17:16:17,948 - INFO - Peak FLOPS used for computing MFU: 3.120e+14
[rank0]:2025-11-07 17:16:17,948 - INFO - CUDA memory usage for model: 1.90GiB(3.99%)
[rank3]:wandb: Currently logged in as: orangingq to https://api.wandb.ai. Use `wandb login --relogin` to force relogin
[rank3]:wandb: setting up run j6npx48m
[rank3]:wandb: Tracking run with wandb version 0.22.2
[rank3]:wandb: Run data is saved locally in /data2/shcho/torchtitan/tb/1108_GPipe_nofreeze_seed2025_dm1/20251107-1716/wandb/run-20251107_171618-j6npx48m
[rank3]:wandb: Run `wandb offline` to turn off syncing.
[rank3]:wandb: Syncing run 1108_GPipe_nofreeze_seed2025_dm1
[rank3]:wandb: â­ï¸ View project at https://wandb.ai/orangingq/torchtitan
[rank3]:wandb: ðŸš€ View run at https://wandb.ai/orangingq/torchtitan/runs/j6npx48m
[rank3]:2025-11-07 17:16:19,845 - INFO - WandB logging enabled
[rank3]:2025-11-07 17:16:19,846 - INFO - CUDA capacity: NVIDIA RTX 6000 Ada Generation with 47.51GiB memory
[rank3]:2025-11-07 17:16:19,886 - WARNING - Peak flops undefined for: NVIDIA RTX 6000 Ada Generation, fallback to A100
[rank3]:2025-11-07 17:16:19,916 - INFO - PP rank 3 is building stage_idx 3 with modules ['layers.13', 'layers.14', 'layers.15', 'norm', 'output']
[rank3]:2025-11-07 17:16:19,916 - INFO - Using pipeline schedule GPipe with 8 microbatches and 4 stages.
[rank1]:2025-11-07 17:16:20,118 - INFO - Mixed precision training with TP or PP is handled by autocast
[rank2]:2025-11-07 17:16:20,118 - INFO - Mixed precision training with TP or PP is handled by autocast
[rank0]:2025-11-07 17:16:20,118 - INFO - Checkpointing active. Checkpoints will be loaded from and saved to /data2/shcho/torchtitan/checkpoint/1108_GPipe_nofreeze_seed2025_dm1
[rank0]:2025-11-07 17:16:20,118 - INFO - Mixed precision training with TP or PP is handled by autocast
[rank0]:2025-11-07 17:16:20,119 - INFO - Trainer is initialized with local batch size 32, global batch size 128, gradient accumulation steps 4, sequence length 512, total steps 800 (warmup 100)
[rank0]:2025-11-07 17:16:20,119 - INFO - Loading the checkpoint from /data2/shcho/torchtitan/base_model/Llama-3.2-1B/original_dcp.
[rank3]:2025-11-07 17:16:20,102 - WARNING - Peak flops undefined for: NVIDIA RTX 6000 Ada Generation, fallback to A100
[rank3]:2025-11-07 17:16:20,102 - INFO - Peak FLOPS used for computing MFU: 3.120e+14
[rank3]:2025-11-07 17:16:20,103 - INFO - CUDA memory usage for model: 1.66GiB(3.50%)
[rank3]:2025-11-07 17:16:20,117 - INFO - Mixed precision training with TP or PP is handled by autocast
[rank0]:2025-11-07 17:16:22,649 - INFO - [GC] GC collection for checkpoint loading. 0.00 seconds
[rank0]:2025-11-07 17:16:22,649 - INFO - Finished loading the checkpoint in 2.53 seconds.
[rank0]:2025-11-07 17:16:22,649 - INFO - Training starts at step 1
[rank1]:2025-11-07 17:16:25,722 - INFO -  step:  1  loss: -4.0000  grad_norm: 132.8876  memory: 12.38GiB(26.05%)  tps: 943  tflops: 7.18  mfu: 2.30%
[rank1]:2025-11-07 17:16:25,722 - INFO - Synchronizing and adjusting timeout for all ProcessGroups to 0:05:00
[rank3]:2025-11-07 17:16:25,728 - INFO -  step:  1  loss:  8.4951  grad_norm: 132.8876  memory: 24.19GiB(50.91%)  tps: 2,806  tflops: 21.37  mfu: 6.85%
[rank3]:2025-11-07 17:16:25,729 - INFO - Synchronizing and adjusting timeout for all ProcessGroups to 0:05:00
[rank2]:2025-11-07 17:16:25,717 - INFO -  step:  1  loss: -4.0000  grad_norm: 132.8876  memory:  9.99GiB(21.03%)  tps: 910  tflops: 6.93  mfu: 2.22%
[rank0]:2025-11-07 17:16:25,759 - INFO -  step:  1  loss: -4.0000  grad_norm: 132.8876  memory: 12.80GiB(26.95%)  tps: 2,044  tflops: 15.57  mfu: 4.99%
[rank0]:2025-11-07 17:16:25,759 - INFO - Synchronizing and adjusting timeout for all ProcessGroups to 0:05:00
[rank2]:2025-11-07 17:16:25,718 - INFO - Synchronizing and adjusting timeout for all ProcessGroups to 0:05:00
[rank0]:2025-11-07 17:18:28,223 - INFO - [GC] Peforming periodical GC collection 0.00 seconds
[rank3]:2025-11-07 17:18:30,514 - INFO - Avg. fwd time: 11.3049 / Avg. bwd time: 44.1204 / Avg. batch time: 503.6218 (ms) / GPU bubble ratio: 11.96%
[rank1]:2025-11-07 17:18:30,625 - INFO - Avg. fwd time: 9.0604 / Avg. bwd time: 23.7787 / Avg. batch time: 574.7517 (ms) / GPU bubble ratio: 54.29%
[rank2]:2025-11-07 17:18:30,586 - INFO - Avg. fwd time: 7.1564 / Avg. bwd time: 18.7496 / Avg. batch time: 535.5435 (ms) / GPU bubble ratio: 61.30%
[rank0]:2025-11-07 17:18:30,633 - INFO - Avg. fwd time: 7.9117 / Avg. bwd time: 23.3500 / Avg. batch time: 611.9811 (ms) / GPU bubble ratio: 59.13%
[rank1]:2025-11-07 17:18:30,813 - INFO -  step: 50  loss: -4.0000  grad_norm: 11.9242  memory: 14.64GiB(30.82%)  tps: 6,418  tflops: 48.88  mfu: 15.67%
[rank3]:2025-11-07 17:18:30,822 - INFO -  step: 50  loss:  7.2403  grad_norm: 11.9242  memory: 26.98GiB(56.79%)  tps: 6,418  tflops: 48.88  mfu: 15.67%
[rank0]:2025-11-07 17:18:30,823 - INFO -  step: 50  loss: -4.0000  grad_norm: 11.9242  memory: 16.57GiB(34.88%)  tps: 6,419  tflops: 48.89  mfu: 15.67%
[rank2]:2025-11-07 17:18:30,809 - INFO -  step: 50  loss: -4.0000  grad_norm: 11.9242  memory: 11.81GiB(24.85%)  tps: 6,418  tflops: 48.88  mfu: 15.67%
[rank0]:2025-11-07 17:20:38,367 - INFO - [GC] Peforming periodical GC collection 0.00 seconds
[rank3]:2025-11-07 17:20:40,697 - INFO - Avg. fwd time: 11.4401 / Avg. bwd time: 44.9759 / Avg. batch time: 511.3048 (ms) / GPU bubble ratio: 11.73%
[rank2]:2025-11-07 17:20:40,772 - INFO - Avg. fwd time: 7.1672 / Avg. bwd time: 18.8552 / Avg. batch time: 542.8540 (ms) / GPU bubble ratio: 61.65%
[rank1]:2025-11-07 17:20:40,812 - INFO - Avg. fwd time: 9.1109 / Avg. bwd time: 23.9675 / Avg. batch time: 581.8846 (ms) / GPU bubble ratio: 54.52%
[rank0]:2025-11-07 17:20:40,820 - INFO - Avg. fwd time: 7.9113 / Avg. bwd time: 23.4335 / Avg. batch time: 618.6365 (ms) / GPU bubble ratio: 59.47%
[rank2]:2025-11-07 17:20:40,998 - INFO -  step: 100  loss: -4.0000  grad_norm: 17.0290  memory: 11.81GiB(24.85%)  tps: 6,292  tflops: 47.92  mfu: 15.36%
[rank1]:2025-11-07 17:20:41,002 - INFO -  step: 100  loss: -4.0000  grad_norm: 17.0290  memory: 14.64GiB(30.82%)  tps: 6,292  tflops: 47.92  mfu: 15.36%
[rank3]:2025-11-07 17:20:41,014 - INFO -  step: 100  loss:  2.6772  grad_norm: 17.0290  memory: 26.98GiB(56.79%)  tps: 6,292  tflops: 47.92  mfu: 15.36%
[rank0]:2025-11-07 17:20:41,013 - INFO -  step: 100  loss: -4.0000  grad_norm: 17.0290  memory: 16.57GiB(34.88%)  tps: 6,292  tflops: 47.92  mfu: 15.36%
[rank3]:2025-11-07 17:20:41,215 - INFO - Pipeline schedule is saved as: /data2/shcho/torchtitan/images/1108_GPipe_nofreeze_seed2025_dm1/pipeline_schedule/251107_1720_real_step100_rank3.svg
[rank3]:> Batch Time: 625.08 ms, GPU Bubble Ratio: 59.52%, 57.29%, 66.46%, 26.56%
[rank0]:2025-11-07 17:22:48,900 - INFO - [GC] Peforming periodical GC collection 0.00 seconds
[rank2]:2025-11-07 17:22:51,437 - INFO - Avg. fwd time: 7.1688 / Avg. bwd time: 18.8970 / Avg. batch time: 545.7278 (ms) / GPU bubble ratio: 61.79%
[rank3]:2025-11-07 17:22:51,411 - INFO - Avg. fwd time: 11.4904 / Avg. bwd time: 45.2751 / Avg. batch time: 514.0227 (ms) / GPU bubble ratio: 11.65%
[rank1]:2025-11-07 17:22:51,467 - INFO - Avg. fwd time: 9.1230 / Avg. bwd time: 24.0534 / Avg. batch time: 584.7484 (ms) / GPU bubble ratio: 54.61%
[rank0]:2025-11-07 17:22:51,497 - INFO - Avg. fwd time: 7.9082 / Avg. bwd time: 23.4653 / Avg. batch time: 621.3519 (ms) / GPU bubble ratio: 59.61%
[rank0]:2025-11-07 17:22:51,533 - INFO -  step: 150  loss: -4.0000  grad_norm: 23.1937  memory: 16.57GiB(34.88%)  tps: 6,276  tflops: 47.80  mfu: 15.32%
[rank2]:2025-11-07 17:22:51,518 - INFO -  step: 150  loss: -4.0000  grad_norm: 23.1937  memory: 11.81GiB(24.85%)  tps: 6,276  tflops: 47.80  mfu: 15.32%
[rank3]:2025-11-07 17:22:51,531 - INFO -  step: 150  loss:  0.6892  grad_norm: 23.1937  memory: 26.98GiB(56.79%)  tps: 6,277  tflops: 47.80  mfu: 15.32%
[rank1]:2025-11-07 17:22:51,522 - INFO -  step: 150  loss: -4.0000  grad_norm: 23.1937  memory: 14.64GiB(30.82%)  tps: 6,276  tflops: 47.80  mfu: 15.32%
[rank0]:2025-11-07 17:24:59,122 - INFO - [GC] Peforming periodical GC collection 0.00 seconds
[rank3]:2025-11-07 17:25:01,460 - INFO - Avg. fwd time: 11.5018 / Avg. bwd time: 45.3787 / Avg. batch time: 514.9008 (ms) / GPU bubble ratio: 11.62%
[rank2]:2025-11-07 17:25:01,535 - INFO - Avg. fwd time: 7.1685 / Avg. bwd time: 18.9238 / Avg. batch time: 546.5101 (ms) / GPU bubble ratio: 61.81%
[rank0]:2025-11-07 17:25:01,583 - INFO - Avg. fwd time: 7.9093 / Avg. bwd time: 23.4810 / Avg. batch time: 622.0820 (ms) / GPU bubble ratio: 59.63%
[rank1]:2025-11-07 17:25:01,575 - INFO - Avg. fwd time: 9.1285 / Avg. bwd time: 24.1010 / Avg. batch time: 585.5334 (ms) / GPU bubble ratio: 54.60%
[rank0]:2025-11-07 17:25:01,776 - INFO -  step: 200  loss: -4.0000  grad_norm:  3.6182  memory: 16.57GiB(34.88%)  tps: 6,290  tflops: 47.90  mfu: 15.35%
[rank3]:2025-11-07 17:25:01,774 - INFO -  step: 200  loss:  0.5571  grad_norm:  3.6182  memory: 26.98GiB(56.79%)  tps: 6,290  tflops: 47.91  mfu: 15.35%
[rank1]:2025-11-07 17:25:01,765 - INFO -  step: 200  loss: -4.0000  grad_norm:  3.6182  memory: 14.64GiB(30.82%)  tps: 6,290  tflops: 47.90  mfu: 15.35%
[rank2]:2025-11-07 17:25:01,761 - INFO -  step: 200  loss: -4.0000  grad_norm:  3.6182  memory: 11.81GiB(24.85%)  tps: 6,290  tflops: 47.90  mfu: 15.35%
[rank3]:2025-11-07 17:25:01,941 - INFO - Pipeline schedule is saved as: /data2/shcho/torchtitan/images/1108_GPipe_nofreeze_seed2025_dm1/pipeline_schedule/251107_1725_real_step200_rank3.svg
[rank3]:> Batch Time: 623.12 ms, GPU Bubble Ratio: 59.32%, 57.01%, 66.28%, 26.62%
[rank0]:2025-11-07 17:27:09,860 - INFO - [GC] Peforming periodical GC collection 0.00 seconds
[rank3]:2025-11-07 17:27:12,176 - INFO - Avg. fwd time: 11.5073 / Avg. bwd time: 45.4564 / Avg. batch time: 515.5360 (ms) / GPU bubble ratio: 11.60%
[rank1]:2025-11-07 17:27:12,289 - INFO - Avg. fwd time: 9.1314 / Avg. bwd time: 24.1343 / Avg. batch time: 586.2482 (ms) / GPU bubble ratio: 54.61%
[rank2]:2025-11-07 17:27:12,249 - INFO - Avg. fwd time: 7.1692 / Avg. bwd time: 18.9406 / Avg. batch time: 547.2139 (ms) / GPU bubble ratio: 61.83%
[rank0]:2025-11-07 17:27:12,297 - INFO - Avg. fwd time: 7.9159 / Avg. bwd time: 23.4920 / Avg. batch time: 622.7847 (ms) / GPU bubble ratio: 59.65%
[rank3]:2025-11-07 17:27:12,485 - INFO -  step: 250  loss:  0.5286  grad_norm:  0.4277  memory: 26.98GiB(56.79%)  tps: 6,267  tflops: 47.73  mfu: 15.30%
[rank1]:2025-11-07 17:27:12,476 - INFO -  step: 250  loss: -4.0000  grad_norm:  0.4277  memory: 14.64GiB(30.82%)  tps: 6,267  tflops: 47.73  mfu: 15.30%
[rank2]:2025-11-07 17:27:12,472 - INFO -  step: 250  loss: -4.0000  grad_norm:  0.4277  memory: 11.81GiB(24.85%)  tps: 6,267  tflops: 47.73  mfu: 15.30%
[rank0]:2025-11-07 17:27:12,487 - INFO -  step: 250  loss: -4.0000  grad_norm:  0.4277  memory: 16.57GiB(34.88%)  tps: 6,267  tflops: 47.73  mfu: 15.30%
[rank0]:2025-11-07 17:29:19,946 - INFO - [GC] Peforming periodical GC collection 0.00 seconds
[rank3]:2025-11-07 17:29:22,487 - INFO - Avg. fwd time: 11.5066 / Avg. bwd time: 45.4776 / Avg. batch time: 515.6841 (ms) / GPU bubble ratio: 11.60%
[rank2]:2025-11-07 17:29:22,513 - INFO - Avg. fwd time: 7.1677 / Avg. bwd time: 18.9463 / Avg. batch time: 547.2838 (ms) / GPU bubble ratio: 61.83%
[rank1]:2025-11-07 17:29:22,544 - INFO - Avg. fwd time: 9.1301 / Avg. bwd time: 24.1515 / Avg. batch time: 586.3239 (ms) / GPU bubble ratio: 54.59%
[rank0]:2025-11-07 17:29:22,574 - INFO - Avg. fwd time: 7.9129 / Avg. bwd time: 23.4948 / Avg. batch time: 622.8333 (ms) / GPU bubble ratio: 59.66%
[rank0]:2025-11-07 17:29:22,611 - INFO -  step: 300  loss: -4.0000  grad_norm:  0.3632  memory: 16.57GiB(34.88%)  tps: 6,296  tflops: 47.95  mfu: 15.37%
[rank3]:2025-11-07 17:29:22,610 - INFO -  step: 300  loss:  0.5083  grad_norm:  0.3632  memory: 26.98GiB(56.79%)  tps: 6,296  tflops: 47.95  mfu: 15.37%
[rank2]:2025-11-07 17:29:22,596 - INFO -  step: 300  loss: -4.0000  grad_norm:  0.3632  memory: 11.81GiB(24.85%)  tps: 6,296  tflops: 47.95  mfu: 15.37%
[rank1]:2025-11-07 17:29:22,600 - INFO -  step: 300  loss: -4.0000  grad_norm:  0.3632  memory: 14.64GiB(30.82%)  tps: 6,296  tflops: 47.95  mfu: 15.37%
[rank3]:2025-11-07 17:29:22,763 - INFO - Pipeline schedule is saved as: /data2/shcho/torchtitan/images/1108_GPipe_nofreeze_seed2025_dm1/pipeline_schedule/251107_1729_real_step300_rank3.svg
[rank3]:> Batch Time: 622.09 ms, GPU Bubble Ratio: 59.35%, 57.00%, 66.28%, 26.56%
[rank0]:2025-11-07 17:31:30,446 - INFO - [GC] Peforming periodical GC collection 0.00 seconds
[rank3]:2025-11-07 17:31:32,743 - INFO - Avg. fwd time: 11.5098 / Avg. bwd time: 45.5080 / Avg. batch time: 515.9443 (ms) / GPU bubble ratio: 11.59%
[rank2]:2025-11-07 17:31:32,818 - INFO - Avg. fwd time: 7.1678 / Avg. bwd time: 18.9515 / Avg. batch time: 547.5873 (ms) / GPU bubble ratio: 61.84%
[rank1]:2025-11-07 17:31:32,858 - INFO - Avg. fwd time: 9.1300 / Avg. bwd time: 24.1637 / Avg. batch time: 586.6274 (ms) / GPU bubble ratio: 54.60%
[rank0]:2025-11-07 17:31:32,865 - INFO - Avg. fwd time: 7.9119 / Avg. bwd time: 23.4974 / Avg. batch time: 623.1246 (ms) / GPU bubble ratio: 59.68%
[rank1]:2025-11-07 17:31:33,045 - INFO -  step: 350  loss: -4.0000  grad_norm:  0.3723  memory: 14.64GiB(30.82%)  tps: 6,280  tflops: 47.83  mfu: 15.33%
[rank3]:2025-11-07 17:31:33,054 - INFO -  step: 350  loss:  0.4837  grad_norm:  0.3723  memory: 26.98GiB(56.79%)  tps: 6,280  tflops: 47.83  mfu: 15.33%
[rank0]:2025-11-07 17:31:33,056 - INFO -  step: 350  loss: -4.0000  grad_norm:  0.3723  memory: 16.57GiB(34.88%)  tps: 6,280  tflops: 47.83  mfu: 15.33%
[rank2]:2025-11-07 17:31:33,041 - INFO -  step: 350  loss: -4.0000  grad_norm:  0.3723  memory: 11.81GiB(24.85%)  tps: 6,280  tflops: 47.83  mfu: 15.33%
[rank0]:2025-11-07 17:33:40,522 - INFO - [GC] Peforming periodical GC collection 0.00 seconds
[rank3]:2025-11-07 17:33:42,855 - INFO - Avg. fwd time: 11.5088 / Avg. bwd time: 45.5181 / Avg. batch time: 516.0086 (ms) / GPU bubble ratio: 11.59%
[rank2]:2025-11-07 17:33:42,929 - INFO - Avg. fwd time: 7.1681 / Avg. bwd time: 18.9564 / Avg. batch time: 547.6005 (ms) / GPU bubble ratio: 61.83%
[rank1]:2025-11-07 17:33:42,969 - INFO - Avg. fwd time: 9.1296 / Avg. bwd time: 24.1758 / Avg. batch time: 586.6362 (ms) / GPU bubble ratio: 54.58%
[rank0]:2025-11-07 17:33:42,977 - INFO - Avg. fwd time: 7.9114 / Avg. bwd time: 23.5008 / Avg. batch time: 623.1210 (ms) / GPU bubble ratio: 59.67%
[rank1]:2025-11-07 17:33:43,155 - INFO -  step: 400  loss: -4.0000  grad_norm:  0.3604  memory: 14.64GiB(30.82%)  tps: 6,296  tflops: 47.95  mfu: 15.37%
[rank2]:2025-11-07 17:33:43,152 - INFO -  step: 400  loss: -4.0000  grad_norm:  0.3604  memory: 11.81GiB(24.85%)  tps: 6,296  tflops: 47.95  mfu: 15.37%
[rank3]:2025-11-07 17:33:43,164 - INFO -  step: 400  loss:  0.4721  grad_norm:  0.3604  memory: 26.98GiB(56.79%)  tps: 6,296  tflops: 47.95  mfu: 15.37%
[rank0]:2025-11-07 17:33:43,166 - INFO -  step: 400  loss: -4.0000  grad_norm:  0.3604  memory: 16.57GiB(34.88%)  tps: 6,296  tflops: 47.95  mfu: 15.37%
[rank3]:2025-11-07 17:33:43,321 - INFO - Pipeline schedule is saved as: /data2/shcho/torchtitan/images/1108_GPipe_nofreeze_seed2025_dm1/pipeline_schedule/251107_1733_real_step400_rank3.svg
[rank3]:> Batch Time: 624.14 ms, GPU Bubble Ratio: 59.45%, 57.14%, 66.37%, 26.63%
[rank3]:2025-11-07 17:33:52,135 - WARNING - Dataset alpaca_cleaned is being re-looped
[rank2]:2025-11-07 17:33:52,358 - WARNING - Dataset alpaca_cleaned is being re-looped
[rank0]:2025-11-07 17:33:52,407 - WARNING - Dataset alpaca_cleaned is being re-looped
[rank1]:2025-11-07 17:33:52,384 - WARNING - Dataset alpaca_cleaned is being re-looped
[rank0]:2025-11-07 17:35:50,659 - INFO - [GC] Peforming periodical GC collection 0.00 seconds
[rank3]:2025-11-07 17:35:53,198 - INFO - Avg. fwd time: 11.5070 / Avg. bwd time: 45.5292 / Avg. batch time: 516.0758 (ms) / GPU bubble ratio: 11.58%
[rank2]:2025-11-07 17:35:53,229 - INFO - Avg. fwd time: 7.1677 / Avg. bwd time: 18.9605 / Avg. batch time: 547.7020 (ms) / GPU bubble ratio: 61.84%
[rank1]:2025-11-07 17:35:53,260 - INFO - Avg. fwd time: 9.1277 / Avg. bwd time: 24.1826 / Avg. batch time: 586.7247 (ms) / GPU bubble ratio: 54.58%
[rank0]:2025-11-07 17:35:53,291 - INFO - Avg. fwd time: 7.9114 / Avg. bwd time: 23.5039 / Avg. batch time: 623.2075 (ms) / GPU bubble ratio: 59.67%
[rank2]:2025-11-07 17:35:53,313 - INFO -  step: 450  loss: -4.0000  grad_norm:  0.3737  memory: 11.81GiB(24.85%)  tps: 6,294  tflops: 47.93  mfu: 15.36%
[rank3]:2025-11-07 17:35:53,326 - INFO -  step: 450  loss:  0.5253  grad_norm:  0.3737  memory: 26.98GiB(56.79%)  tps: 6,294  tflops: 47.94  mfu: 15.36%
[rank1]:2025-11-07 17:35:53,316 - INFO -  step: 450  loss: -4.0000  grad_norm:  0.3737  memory: 14.64GiB(30.82%)  tps: 6,294  tflops: 47.93  mfu: 15.36%
[rank0]:2025-11-07 17:35:53,327 - INFO -  step: 450  loss: -4.0000  grad_norm:  0.3737  memory: 16.57GiB(34.88%)  tps: 6,294  tflops: 47.93  mfu: 15.36%
[rank0]:2025-11-07 17:38:00,841 - INFO - [GC] Peforming periodical GC collection 0.00 seconds
[rank3]:2025-11-07 17:38:03,182 - INFO - Avg. fwd time: 11.5064 / Avg. bwd time: 45.5375 / Avg. batch time: 516.1334 (ms) / GPU bubble ratio: 11.58%
[rank2]:2025-11-07 17:38:03,255 - INFO - Avg. fwd time: 7.1676 / Avg. bwd time: 18.9635 / Avg. batch time: 547.7295 (ms) / GPU bubble ratio: 61.83%
[rank1]:2025-11-07 17:38:03,295 - INFO - Avg. fwd time: 9.1276 / Avg. bwd time: 24.1882 / Avg. batch time: 586.7397 (ms) / GPU bubble ratio: 54.57%
[rank0]:2025-11-07 17:38:03,299 - INFO - Avg. fwd time: 7.9113 / Avg. bwd time: 23.5068 / Avg. batch time: 623.2185 (ms) / GPU bubble ratio: 59.67%
[rank2]:2025-11-07 17:38:03,474 - INFO -  step: 500  loss: -4.0000  grad_norm:  0.2925  memory: 11.81GiB(24.85%)  tps: 6,294  tflops: 47.93  mfu: 15.36%
[rank1]:2025-11-07 17:38:03,477 - INFO -  step: 500  loss: -4.0000  grad_norm:  0.2925  memory: 14.64GiB(30.82%)  tps: 6,294  tflops: 47.93  mfu: 15.36%
[rank3]:2025-11-07 17:38:03,486 - INFO -  step: 500  loss:  0.3916  grad_norm:  0.2925  memory: 26.98GiB(56.79%)  tps: 6,294  tflops: 47.94  mfu: 15.36%
[rank0]:2025-11-07 17:38:03,489 - INFO -  step: 500  loss: -4.0000  grad_norm:  0.2925  memory: 16.57GiB(34.88%)  tps: 6,294  tflops: 47.93  mfu: 15.36%
[rank3]:2025-11-07 17:38:03,640 - INFO - Pipeline schedule is saved as: /data2/shcho/torchtitan/images/1108_GPipe_nofreeze_seed2025_dm1/pipeline_schedule/251107_1738_real_step500_rank3.svg
[rank3]:> Batch Time: 623.66 ms, GPU Bubble Ratio: 59.38%, 57.09%, 66.34%, 26.58%
[rank0]:2025-11-07 17:40:11,018 - INFO - [GC] Peforming periodical GC collection 0.00 seconds
[rank3]:2025-11-07 17:40:13,330 - INFO - Avg. fwd time: 11.5067 / Avg. bwd time: 45.5456 / Avg. batch time: 516.1958 (ms) / GPU bubble ratio: 11.58%
[rank2]:2025-11-07 17:40:13,408 - INFO - Avg. fwd time: 7.1676 / Avg. bwd time: 18.9644 / Avg. batch time: 547.8138 (ms) / GPU bubble ratio: 61.84%
[rank0]:2025-11-07 17:40:13,455 - INFO - Avg. fwd time: 7.9105 / Avg. bwd time: 23.5075 / Avg. batch time: 623.2815 (ms) / GPU bubble ratio: 59.67%
[rank1]:2025-11-07 17:40:13,449 - INFO - Avg. fwd time: 9.1271 / Avg. bwd time: 24.1897 / Avg. batch time: 586.8069 (ms) / GPU bubble ratio: 54.58%
[rank1]:2025-11-07 17:40:13,630 - INFO -  step: 550  loss: -4.0000  grad_norm:  0.3697  memory: 14.64GiB(30.82%)  tps: 6,294  tflops: 47.94  mfu: 15.36%
[rank2]:2025-11-07 17:40:13,626 - INFO -  step: 550  loss: -4.0000  grad_norm:  0.3697  memory: 11.81GiB(24.85%)  tps: 6,294  tflops: 47.94  mfu: 15.36%
[rank0]:2025-11-07 17:40:13,641 - INFO -  step: 550  loss: -4.0000  grad_norm:  0.3697  memory: 16.57GiB(34.88%)  tps: 6,294  tflops: 47.94  mfu: 15.36%
[rank3]:2025-11-07 17:40:13,639 - INFO -  step: 550  loss:  0.4329  grad_norm:  0.3697  memory: 26.98GiB(56.79%)  tps: 6,294  tflops: 47.94  mfu: 15.36%
[rank0]:2025-11-07 17:42:21,249 - INFO - [GC] Peforming periodical GC collection 0.00 seconds
[rank3]:2025-11-07 17:42:23,776 - INFO - Avg. fwd time: 11.5081 / Avg. bwd time: 45.5558 / Avg. batch time: 516.2866 (ms) / GPU bubble ratio: 11.58%
[rank2]:2025-11-07 17:42:23,804 - INFO - Avg. fwd time: 7.1672 / Avg. bwd time: 18.9653 / Avg. batch time: 547.8748 (ms) / GPU bubble ratio: 61.84%
[rank0]:2025-11-07 17:42:23,867 - INFO - Avg. fwd time: 7.9095 / Avg. bwd time: 23.5085 / Avg. batch time: 623.3217 (ms) / GPU bubble ratio: 59.68%
[rank1]:2025-11-07 17:42:23,836 - INFO - Avg. fwd time: 9.1261 / Avg. bwd time: 24.1893 / Avg. batch time: 586.8497 (ms) / GPU bubble ratio: 54.58%
[rank2]:2025-11-07 17:42:23,889 - INFO -  step: 600  loss: -4.0000  grad_norm:  0.3579  memory: 11.81GiB(24.85%)  tps: 6,289  tflops: 47.90  mfu: 15.35%
[rank0]:2025-11-07 17:42:23,903 - INFO -  step: 600  loss: -4.0000  grad_norm:  0.3579  memory: 16.57GiB(34.88%)  tps: 6,289  tflops: 47.90  mfu: 15.35%
[rank3]:2025-11-07 17:42:23,902 - INFO -  step: 600  loss:  0.4240  grad_norm:  0.3579  memory: 26.98GiB(56.79%)  tps: 6,289  tflops: 47.90  mfu: 15.35%
[rank1]:2025-11-07 17:42:23,892 - INFO -  step: 600  loss: -4.0000  grad_norm:  0.3579  memory: 14.64GiB(30.82%)  tps: 6,289  tflops: 47.90  mfu: 15.35%
[rank3]:2025-11-07 17:42:24,055 - INFO - Pipeline schedule is saved as: /data2/shcho/torchtitan/images/1108_GPipe_nofreeze_seed2025_dm1/pipeline_schedule/251107_1742_real_step600_rank3.svg
[rank3]:> Batch Time: 624.16 ms, GPU Bubble Ratio: 59.45%, 57.20%, 66.40%, 26.66%
[rank0]:2025-11-07 17:44:31,838 - INFO - [GC] Peforming periodical GC collection 0.00 seconds
[rank3]:2025-11-07 17:44:34,141 - INFO - Avg. fwd time: 11.5110 / Avg. bwd time: 45.5685 / Avg. batch time: 516.4120 (ms) / GPU bubble ratio: 11.58%
[rank2]:2025-11-07 17:44:34,218 - INFO - Avg. fwd time: 7.1675 / Avg. bwd time: 18.9666 / Avg. batch time: 548.0251 (ms) / GPU bubble ratio: 61.85%
[rank0]:2025-11-07 17:44:34,266 - INFO - Avg. fwd time: 7.9104 / Avg. bwd time: 23.5099 / Avg. batch time: 623.4547 (ms) / GPU bubble ratio: 59.68%
[rank1]:2025-11-07 17:44:34,259 - INFO - Avg. fwd time: 9.1262 / Avg. bwd time: 24.1891 / Avg. batch time: 586.9826 (ms) / GPU bubble ratio: 54.59%
[rank2]:2025-11-07 17:44:34,437 - INFO -  step: 650  loss: -4.0000  grad_norm:  0.3503  memory: 11.81GiB(24.85%)  tps: 6,275  tflops: 47.79  mfu: 15.32%
[rank1]:2025-11-07 17:44:34,440 - INFO -  step: 650  loss: -4.0000  grad_norm:  0.3503  memory: 14.64GiB(30.82%)  tps: 6,275  tflops: 47.79  mfu: 15.32%
[rank3]:2025-11-07 17:44:34,449 - INFO -  step: 650  loss:  0.3701  grad_norm:  0.3503  memory: 26.98GiB(56.79%)  tps: 6,275  tflops: 47.79  mfu: 15.32%
[rank0]:2025-11-07 17:44:34,451 - INFO -  step: 650  loss: -4.0000  grad_norm:  0.3503  memory: 16.57GiB(34.88%)  tps: 6,275  tflops: 47.79  mfu: 15.32%
[rank0]:2025-11-07 17:46:41,940 - INFO - [GC] Peforming periodical GC collection 0.00 seconds
[rank3]:2025-11-07 17:46:44,263 - INFO - Avg. fwd time: 11.5103 / Avg. bwd time: 45.5760 / Avg. batch time: 516.4617 (ms) / GPU bubble ratio: 11.57%
[rank0]:2025-11-07 17:46:44,387 - INFO - Avg. fwd time: 7.9107 / Avg. bwd time: 23.5112 / Avg. batch time: 623.4639 (ms) / GPU bubble ratio: 59.68%
[rank2]:2025-11-07 17:46:44,344 - INFO - Avg. fwd time: 7.1677 / Avg. bwd time: 18.9681 / Avg. batch time: 548.0512 (ms) / GPU bubble ratio: 61.85%
[rank1]:2025-11-07 17:46:44,384 - INFO - Avg. fwd time: 9.1263 / Avg. bwd time: 24.1889 / Avg. batch time: 586.9931 (ms) / GPU bubble ratio: 54.60%
[rank3]:2025-11-07 17:46:44,576 - INFO -  step: 700  loss:  0.4352  grad_norm:  0.3950  memory: 26.98GiB(56.79%)  tps: 6,295  tflops: 47.95  mfu: 15.37%
[rank0]:2025-11-07 17:46:44,578 - INFO -  step: 700  loss: -4.0000  grad_norm:  0.3950  memory: 16.57GiB(34.88%)  tps: 6,295  tflops: 47.95  mfu: 15.37%
[rank2]:2025-11-07 17:46:44,564 - INFO -  step: 700  loss: -4.0000  grad_norm:  0.3950  memory: 11.81GiB(24.85%)  tps: 6,295  tflops: 47.95  mfu: 15.37%
[rank1]:2025-11-07 17:46:44,568 - INFO -  step: 700  loss: -4.0000  grad_norm:  0.3950  memory: 14.64GiB(30.82%)  tps: 6,295  tflops: 47.95  mfu: 15.37%
[rank3]:2025-11-07 17:46:44,728 - INFO - Pipeline schedule is saved as: /data2/shcho/torchtitan/images/1108_GPipe_nofreeze_seed2025_dm1/pipeline_schedule/251107_1746_real_step700_rank3.svg
[rank3]:> Batch Time: 623.19 ms, GPU Bubble Ratio: 59.35%, 57.11%, 66.31%, 26.85%
[rank0]:2025-11-07 17:48:52,428 - INFO - [GC] Peforming periodical GC collection 0.00 seconds
[rank3]:2025-11-07 17:48:54,947 - INFO - Avg. fwd time: 11.5118 / Avg. bwd time: 45.5857 / Avg. batch time: 516.5486 (ms) / GPU bubble ratio: 11.57%
[rank2]:2025-11-07 17:48:54,976 - INFO - Avg. fwd time: 7.1680 / Avg. bwd time: 18.9698 / Avg. batch time: 548.1602 (ms) / GPU bubble ratio: 61.85%
[rank1]:2025-11-07 17:48:55,013 - INFO - Avg. fwd time: 9.1268 / Avg. bwd time: 24.1884 / Avg. batch time: 587.0880 (ms) / GPU bubble ratio: 54.60%
[rank3]:2025-11-07 17:48:55,081 - INFO -  step: 750  loss:  0.4137  grad_norm:  0.4228  memory: 26.98GiB(56.79%)  tps: 6,277  tflops: 47.81  mfu: 15.32%
[rank2]:2025-11-07 17:48:55,068 - INFO -  step: 750  loss: -4.0000  grad_norm:  0.4228  memory: 11.81GiB(24.85%)  tps: 6,277  tflops: 47.81  mfu: 15.32%
[rank0]:2025-11-07 17:48:55,046 - INFO - Avg. fwd time: 7.9106 / Avg. bwd time: 23.5129 / Avg. batch time: 623.5634 (ms) / GPU bubble ratio: 59.69%
[rank0]:2025-11-07 17:48:55,082 - INFO -  step: 750  loss: -4.0000  grad_norm:  0.4228  memory: 16.57GiB(34.88%)  tps: 6,277  tflops: 47.81  mfu: 15.32%
[rank1]:2025-11-07 17:48:55,071 - INFO -  step: 750  loss: -4.0000  grad_norm:  0.4228  memory: 14.64GiB(30.82%)  tps: 6,277  tflops: 47.81  mfu: 15.32%
[rank0]:2025-11-07 17:51:02,752 - INFO - [GC] Peforming periodical GC collection 0.00 seconds
[rank3]:2025-11-07 17:51:05,065 - INFO - Avg. fwd time: 11.5122 / Avg. bwd time: 45.5915 / Avg. batch time: 516.5954 (ms) / GPU bubble ratio: 11.57%
[rank0]:2025-11-07 17:51:05,190 - INFO - Avg. fwd time: 7.9115 / Avg. bwd time: 23.5146 / Avg. batch time: 623.5846 (ms) / GPU bubble ratio: 59.68%
[rank2]:2025-11-07 17:51:05,138 - INFO - Avg. fwd time: 7.1683 / Avg. bwd time: 18.9710 / Avg. batch time: 548.1922 (ms) / GPU bubble ratio: 61.85%
[rank1]:2025-11-07 17:51:05,183 - INFO - Avg. fwd time: 9.1275 / Avg. bwd time: 24.1873 / Avg. batch time: 587.1076 (ms) / GPU bubble ratio: 54.60%
[rank3]:2025-11-07 17:51:05,373 - INFO -  step: 800  loss:  0.4198  grad_norm:  0.3748  memory: 26.98GiB(56.79%)  tps: 6,288  tflops: 47.89  mfu: 15.35%
[rank3]:2025-11-07 17:51:05,374 - INFO -  final step: 800  loss:  0.4198  grad_norm:  0.3748  tps: 6,678  tflops: 50.86  mfu: 14.87%
[rank3]:2025-11-07 17:51:05,375 - INFO - Saving the checkpoint (or staging if async is enabled).
[rank3]:2025-11-07 17:51:05,376 - INFO - Saving a model only checkpoint in torch.float16 at last step, step 800.
[rank0]:2025-11-07 17:51:05,375 - INFO -  step: 800  loss: -4.0000  grad_norm:  0.3748  memory: 16.57GiB(34.88%)  tps: 6,287  tflops: 47.89  mfu: 15.35%
[rank0]:2025-11-07 17:51:05,376 - INFO -  final step: 800  loss: -4.0000  grad_norm:  0.3748  tps: 6,671  tflops: 50.81  mfu: 14.76%
[rank0]:2025-11-07 17:51:05,376 - INFO - Saving the checkpoint (or staging if async is enabled).
[rank0]:2025-11-07 17:51:05,376 - INFO - Saving a model only checkpoint in torch.float16 at last step, step 800.
[rank2]:2025-11-07 17:51:05,361 - INFO -  step: 800  loss: -4.0000  grad_norm:  0.3748  memory: 11.81GiB(24.85%)  tps: 6,287  tflops: 47.89  mfu: 15.35%
[rank2]:2025-11-07 17:51:05,361 - INFO -  final step: 800  loss: -4.0000  grad_norm:  0.3748  tps: 6,639  tflops: 50.56  mfu: 14.59%
[rank2]:2025-11-07 17:51:05,361 - INFO - Saving the checkpoint (or staging if async is enabled).
[rank2]:2025-11-07 17:51:05,361 - INFO - Saving a model only checkpoint in torch.float16 at last step, step 800.
[rank1]:2025-11-07 17:51:05,364 - INFO -  step: 800  loss: -4.0000  grad_norm:  0.3748  memory: 14.64GiB(30.82%)  tps: 6,287  tflops: 47.89  mfu: 15.35%
[rank1]:2025-11-07 17:51:05,364 - INFO -  final step: 800  loss: -4.0000  grad_norm:  0.3748  tps: 6,641  tflops: 50.58  mfu: 14.60%
[rank1]:2025-11-07 17:51:05,364 - INFO - Saving the checkpoint (or staging if async is enabled).
[rank1]:2025-11-07 17:51:05,365 - INFO - Saving a model only checkpoint in torch.float16 at last step, step 800.
[rank0]:2025-11-07 17:51:07,459 - INFO - [GC] GC collection invoked by checkpointer. 0.00 seconds
[rank0]:2025-11-07 17:51:07,475 - INFO - Sleeping 2 seconds for other ranks to complete
[rank2]:2025-11-07 17:51:07,475 - INFO - Destroying the purge thread.
[rank1]:2025-11-07 17:51:07,475 - INFO - Destroying the purge thread.
[rank2]:2025-11-07 17:51:07,610 - INFO - Process group destroyed
[rank1]:2025-11-07 17:51:07,623 - INFO - Process group destroyed
[rank3]:2025-11-07 17:51:07,622 - INFO - Pipeline schedule is saved as: /data2/shcho/torchtitan/images/1108_GPipe_nofreeze_seed2025_dm1/pipeline_schedule/251107_1751_real_final800_rank3.svg
[rank3]:> Batch Time: 623.62 ms, GPU Bubble Ratio: 59.41%, 57.15%, 66.35%, 26.64%
[rank3]:2025-11-07 17:51:07,767 - INFO - Pipeline schedule is saved as: /data2/shcho/torchtitan/images/1108_GPipe_nofreeze_seed2025_dm1/pipeline_schedule/251107_1751_thry_final800_rank3.svg
[rank3]:> Batch Time: 294.82 ms, GPU Bubble Ratio: 27.27%, 27.27%, 27.27%, 27.27%
[rank3]:2025-11-07 17:51:07,768 - INFO - Destroying the purge thread.
[rank3]:wandb: updating run metadata
[rank3]:wandb: uploading history steps 15-16, summary, console lines 226-235
[rank3]:wandb: 
[rank3]:wandb: Run history:
[rank3]:wandb:      final/avg_end_to_end(s) â–
[rank3]:wandb:               final/avg_loss â–
[rank3]:wandb:             final/avg_mfu(%) â–
[rank3]:wandb:             final/avg_tflops â–
[rank3]:wandb:    final/avg_throughput(tps) â–
[rank3]:wandb:              final/grad_norm â–
[rank3]:wandb:               final/max_loss â–
[rank3]:wandb:                    grad_norm â–ˆâ–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–
[rank3]:wandb: loss_metrics/global_avg_loss â–ˆâ–‡â–ƒâ–â–â–â–â–â–â–â–â–â–â–â–â–â–
[rank3]:wandb: loss_metrics/global_max_loss â–ˆâ–‡â–ƒâ–â–â–â–â–â–â–â–â–â–â–â–â–â–
[rank3]:wandb:                          +14 ...
[rank3]:wandb: 
[rank3]:wandb: Run summary:
[rank3]:wandb:      final/avg_end_to_end(s) 2.45346
[rank3]:wandb:               final/avg_loss 0.41977
[rank3]:wandb:             final/avg_mfu(%) 14.86605
[rank3]:wandb:             final/avg_tflops 50.86042
[rank3]:wandb:    final/avg_throughput(tps) 6677.91416
[rank3]:wandb:              final/grad_norm 0.37482
[rank3]:wandb:               final/max_loss 0.41977
[rank3]:wandb:                    grad_norm 0.37482
[rank3]:wandb: loss_metrics/global_avg_loss 0.41977
[rank3]:wandb: loss_metrics/global_max_loss 0.41977
[rank3]:wandb:                          +14 ...
[rank3]:wandb: 
[rank3]:wandb: ðŸš€ View run 1108_GPipe_nofreeze_seed2025_dm1 at: https://wandb.ai/orangingq/torchtitan/runs/j6npx48m
[rank3]:wandb: â­ï¸ View project at: https://wandb.ai/orangingq/torchtitan
[rank3]:wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
[rank3]:wandb: Find logs at: /data2/shcho/torchtitan/tb/1108_GPipe_nofreeze_seed2025_dm1/20251107-1716/wandb/run-20251107_171618-j6npx48m/logs
[rank3]:2025-11-07 17:51:09,137 - INFO - Process group destroyed
[rank0]:2025-11-07 17:51:09,476 - INFO - Training completed
[rank0]:2025-11-07 17:51:09,476 - INFO - Destroying the purge thread.
[rank0]:2025-11-07 17:51:09,612 - INFO - Process group destroyed
[rank2]:Stage 2: Modules to keep: {'layers.11', 'layers.12', 'layers.9', 'layers.10'}
[rank1]:Stage 1: Modules to keep: {'layers.4', 'layers.7', 'layers.8', 'layers.6', 'layers.5'}
[rank0]:Stage 0: Modules to keep: {'layers.1', 'layers.3', 'tok_embeddings', 'layers.2', 'layers.0'}
[rank3]:Stage 3: Modules to keep: {'output', 'layers.14', 'layers.13', 'layers.15', 'norm'}
[rank3]:----- TimelyFreezeâ° Configuration:
[rank3]:	- job:
[rank3]:		- config_file: /home/shcho/torchtitan/logs/dmserver1/1104_llama1b/config_1108.toml
[rank3]:		- dump_folder: /data2/shcho/torchtitan
[rank3]:		- description: "Main Table Experiment, without streaming mode, sample-level with truncation, with bf16 autocast
[rank3]:1107: for timelyapf: clone().cpu() removed to fix freezing issue.!!! yay~~~
[rank3]:1108: steps 1200 (3 epochs) -> 800 (2 epochs) / alpaca dataset
[rank3]:"
[rank3]:		- use_for_integration_test: False
[rank3]:		- print_args: False
[rank3]:		- basename: 1108_GPipe_nofreeze_seed2025_dm1
[rank3]:	- profiling:
[rank3]:		- enable_profiling: False
[rank3]:		- save_traces_folder: /data2/shcho/torchtitan/profile_trace/1108_GPipe_nofreeze_seed2025_dm1
[rank3]:		- profile_freq: 100
[rank3]:		- enable_memory_snapshot: False
[rank3]:		- save_memory_snapshot_folder: /data2/shcho/torchtitan/memory_snapshot/1108_GPipe_nofreeze_seed2025_dm1
[rank3]:	- metrics:
[rank3]:		- log_freq: 50
[rank3]:		- enable_tensorboard: False
[rank3]:		- disable_color_printing: True
[rank3]:		- save_tb_folder: /data2/shcho/torchtitan/tb/1108_GPipe_nofreeze_seed2025_dm1
[rank3]:		- save_for_all_ranks: False
[rank3]:		- enable_wandb: True
[rank3]:		- image_folder: /data2/shcho/torchtitan/images/1108_GPipe_nofreeze_seed2025_dm1
[rank3]:		- pplog_freq: 200
[rank3]:		- draw_freq: 100
[rank3]:		- wandb_name: 1108_GPipe_nofreeze_seed2025_dm1
[rank3]:		- draw_graph: True
[rank3]:	- model:
[rank3]:		- name: llama3
[rank3]:		- flavor: 1B
[rank3]:		- tokenizer_path: ./assets/tokenizer/Llama-3.2-1B
[rank3]:		- converters: []
[rank3]:		- print_after_conversion: False
[rank3]:	- optimizer:
[rank3]:		- name: AdamW
[rank3]:		- lr: 1e-05
[rank3]:		- beta1: 0.9
[rank3]:		- beta2: 0.95
[rank3]:		- eps: 1e-08
[rank3]:		- weight_decay: 0.1
[rank3]:		- implementation: fused
[rank3]:		- early_step_in_backward: False
[rank3]:	- lr_scheduler:
[rank3]:		- warmup_steps: 100
[rank3]:		- decay_ratio: 0.8
[rank3]:		- decay_type: cosine
[rank3]:		- min_lr_factor: 0.0
[rank3]:	- training:
[rank3]:		- dataset: alpaca_cleaned
[rank3]:		- dataset_path: None
[rank3]:		- local_batch_size: 32
[rank3]:		- global_batch_size: 128
[rank3]:		- seq_len: 512
[rank3]:		- max_norm: 1.0
[rank3]:		- steps: 800
[rank3]:		- enable_cpu_offload: False
[rank3]:		- mixed_precision_param: bfloat16
[rank3]:		- mixed_precision_reduce: float32
[rank3]:		- compile: False
[rank3]:		- gc_freq: 50
[rank3]:		- gc_debug: False
[rank3]:		- seed: 2025
[rank3]:		- deterministic: False
[rank3]:	- parallelism:
[rank3]:		- data_parallel_replicate_degree: 1
[rank3]:		- enable_compiled_autograd: False
[rank3]:		- data_parallel_shard_degree: -1
[rank3]:		- fsdp_reshard_after_forward: default
[rank3]:		- tensor_parallel_degree: 1
[rank3]:		- disable_loss_parallel: False
[rank3]:		- enable_async_tensor_parallel: False
[rank3]:		- pipeline_parallel_degree: 4
[rank3]:		- pipeline_parallel_split_points: []
[rank3]:		- module_fqns_per_model_part: None
[rank3]:		- pipeline_parallel_first_stage_less_layers: 1
[rank3]:		- pipeline_parallel_last_stage_less_layers: 1
[rank3]:		- pipeline_parallel_layers_per_stage: None
[rank3]:		- pipeline_parallel_schedule: GPipe
[rank3]:		- pipeline_parallel_schedule_csv: 
[rank3]:		- pipeline_parallel_microbatch_size: 4
[rank3]:		- context_parallel_degree: 1
[rank3]:		- context_parallel_rotate_method: allgather
[rank3]:		- expert_parallel_degree: 1
[rank3]:		- pp: 4
[rank3]:		- stages_per_rank: 1
[rank3]:		- stages_list: [3]
[rank3]:		- microbatches: 8
[rank3]:	- checkpoint:
[rank3]:		- enable_checkpoint: True
[rank3]:		- checkpoint_folder: /data2/shcho/torchtitan/checkpoint/1108_GPipe_nofreeze_seed2025_dm1
[rank3]:		- interval: 1200
[rank3]:		- initial_load_path: /data2/shcho/torchtitan/base_model/Llama-3.2-1B/original_dcp
[rank3]:		- initial_load_model_only: True
[rank3]:		- initial_load_in_hf: False
[rank3]:		- last_save_model_only: True
[rank3]:		- last_save_in_hf: False
[rank3]:		- export_dtype: float16
[rank3]:		- async_mode: async
[rank3]:		- keep_latest_k: 2
[rank3]:		- load_step: -1
[rank3]:		- exclude_from_loading: ['dataloader', 'lr_scheduler', 'optimizer', 'train_state']
[rank3]:		- enable_first_step_checkpoint: False
[rank3]:		- create_seed_checkpoint: False
[rank3]:	- activation_checkpoint:
[rank3]:		- mode: none
[rank3]:		- selective_ac_option: op
[rank3]:		- per_op_sac_force_recompute_mm_shapes_by_fqns: ['moe.router.gate']
[rank3]:	- float8:
[rank3]:		- enable_fsdp_float8_all_gather: False
[rank3]:		- precompute_float8_dynamic_scale_for_fsdp: False
[rank3]:		- recipe_name: None
[rank3]:		- filter_fqns: ['output']
[rank3]:		- emulate: False
[rank3]:		- moe_fqns_prototype: []
[rank3]:	- mx:
[rank3]:		- mxfp8_dim1_cast_kernel_choice: triton
[rank3]:		- recipe_name: mxfp8
[rank3]:		- filter_fqns: ['output']
[rank3]:		- moe_fqns_prototype: []
[rank3]:	- comm:
[rank3]:		- init_timeout_seconds: 300
[rank3]:		- train_timeout_seconds: 300
[rank3]:		- trace_buf_size: 20000
[rank3]:		- save_traces_folder: /data2/shcho/torchtitan/comm_traces/1108_GPipe_nofreeze_seed2025_dm1
[rank3]:		- world_size: 4
[rank3]:		- global_rank: 3
[rank3]:		- local_rank: 3
[rank3]:		- dp: 1
[rank3]:		- pp: 4
[rank3]:		- pp_rank: 3
[rank3]:		- dp_rank: 0
[rank3]:		- master_dp_rank: 0
[rank3]:	- memory_estimation:
[rank3]:		- enabled: False
[rank3]:		- disable_fake_mode: False
[rank3]:	- fault_tolerance:
[rank3]:		- enable: False
[rank3]:		- process_group: gloo
[rank3]:		- process_group_timeout_ms: 10000
[rank3]:		- replica_id: 0
[rank3]:		- group_size: 0
[rank3]:		- min_replica_size: 1
[rank3]:		- semi_sync_method: None
[rank3]:		- sync_steps: 5
[rank3]:		- should_quantize: False
[rank3]:		- fragment_sync_delay: 0
[rank3]:		- fragment_update_alpha: 0.0
[rank3]:	- experimental:
[rank3]:		- custom_import: 
[rank3]:		- custom_args_module: 
[rank3]:	- validation:
[rank3]:		- enabled: False
[rank3]:		- dataset: c4_validation
[rank3]:		- dataset_path: None
[rank3]:		- local_batch_size: 32
[rank3]:		- seq_len: 512
[rank3]:		- freq: 200
[rank3]:		- steps: 100
[rank3]:	- freezing:
[rank3]:		- freeze: False
[rank3]:		- metric_type: apf
[rank3]:		- phase_unit: 50
[rank3]:		- stability_check_freq: 10
[rank3]:		- max_freeze_ratio: 0.7
[rank3]:		- adjustment: False
[rank3]:		- threshold: 0.05
[rank3]:		- percentile: 70
[rank3]:
[rank2]:[Gloo] Rank 2 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
[rank1]:[Gloo] Rank 1 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
[rank0]:[Gloo] Rank 0 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
[rank3]:[Gloo] Rank 3 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
