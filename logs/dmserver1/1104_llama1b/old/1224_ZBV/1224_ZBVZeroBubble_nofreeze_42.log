
üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•
‚úîÔ∏èCurrent Timestamp: 2025. 12. 26. (Í∏à) 14:33:24 KST
‚úîÔ∏èSERVER: dmserver1 (143.248.135.95),  GPUs: 1,2,3,4
‚úîÔ∏èSCRIPT: /home/shcho/torchtitan/logs/dmserver1/1104_llama1b/run.sh
‚úîÔ∏èOUTPUT: /home/shcho/torchtitan/logs/dmserver1/1104_llama1b/1224_ZBVZeroBubble_nofreeze_42.log
‚úîÔ∏èMain Table Experiment, without streaming mode, sample-level with truncation, with bf16 autocast
1107: for timelyapf: clone().cpu() removed to fix freezing issue.!!! yay~~~
1108: steps 1200 (3 epochs) -> 800 (2 epochs) / alpaca dataset
    - learning rate : tried lr=3e-6 (->3e-9), 5e-6(->0), 1e-5(->0). BEST: lr=5e-6
1109: switch to alpaca_gpt4+alpaca_cleaned dataset
1224: everything same as 1109 (dataset: alpaca_gpt4) but debugged requires_grad bug

‚úîÔ∏èRunning with nofreeze x ZBVZeroBubble ... 
‚òëÔ∏è> torchrun --standalone --nnodes=1 --nproc_per_node=4 --local_addr=127.0.0.1 --local-ranks-filter=0,1,2,3 --role=rank --tee=3 -m timelyfreeze.train --job.config_file=/home/shcho/torchtitan/logs/dmserver1/1104_llama1b/config_1224.toml --job.description="Main Table Experiment, without streaming mode, sample-level with truncation, with bf16 autocast
1107: for timelyapf: clone().cpu() removed to fix freezing issue.!!! yay~~~
1108: steps 1200 (3 epochs) -> 800 (2 epochs) / alpaca dataset
    - learning rate : tried lr=3e-6 (->3e-9), 5e-6(->0), 1e-5(->0). BEST: lr=5e-6
1109: switch to alpaca_gpt4+alpaca_cleaned dataset
1224: everything same as 1109 (dataset: alpaca_gpt4) but debugged requires_grad bug
" --parallelism.pipeline_parallel_degree=4  --freezing.no-freeze
üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•
[rank0]:2025-12-26 14:33:30,385 - Starting job: "Main Table Experiment, without streaming mode, sample-level with truncation, with bf16 autocast
[rank0]:1107: for timelyapf: clone().cpu() removed to fix freezing issue.!!! yay~~~
[rank0]:1108: steps 1200 (3 epochs) -> 800 (2 epochs) / alpaca dataset
[rank0]:    - learning rate : tried lr=3e-6 (->3e-9), 5e-6(->0), 1e-5(->0). BEST: lr=5e-6
[rank0]:1109: switch to alpaca_gpt4+alpaca_cleaned dataset
[rank0]:1224: everything same as 1109 (dataset: alpaca_gpt4) but debugged requires_grad bug
[rank0]:"
[rank1]:2025-12-26 14:33:30,360 - Starting job: "Main Table Experiment, without streaming mode, sample-level with truncation, with bf16 autocast
[rank1]:1107: for timelyapf: clone().cpu() removed to fix freezing issue.!!! yay~~~
[rank1]:1108: steps 1200 (3 epochs) -> 800 (2 epochs) / alpaca dataset
[rank1]:    - learning rate : tried lr=3e-6 (->3e-9), 5e-6(->0), 1e-5(->0). BEST: lr=5e-6
[rank1]:1109: switch to alpaca_gpt4+alpaca_cleaned dataset
[rank1]:1224: everything same as 1109 (dataset: alpaca_gpt4) but debugged requires_grad bug
[rank1]:"
[rank2]:2025-12-26 14:33:30,344 - Starting job: "Main Table Experiment, without streaming mode, sample-level with truncation, with bf16 autocast
[rank2]:1107: for timelyapf: clone().cpu() removed to fix freezing issue.!!! yay~~~
[rank2]:1108: steps 1200 (3 epochs) -> 800 (2 epochs) / alpaca dataset
[rank2]:    - learning rate : tried lr=3e-6 (->3e-9), 5e-6(->0), 1e-5(->0). BEST: lr=5e-6
[rank2]:1109: switch to alpaca_gpt4+alpaca_cleaned dataset
[rank2]:1224: everything same as 1109 (dataset: alpaca_gpt4) but debugged requires_grad bug
[rank2]:"
[rank3]:2025-12-26 14:33:30,351 - Starting job: "Main Table Experiment, without streaming mode, sample-level with truncation, with bf16 autocast
[rank3]:1107: for timelyapf: clone().cpu() removed to fix freezing issue.!!! yay~~~
[rank3]:1108: steps 1200 (3 epochs) -> 800 (2 epochs) / alpaca dataset
[rank3]:    - learning rate : tried lr=3e-6 (->3e-9), 5e-6(->0), 1e-5(->0). BEST: lr=5e-6
[rank3]:1109: switch to alpaca_gpt4+alpaca_cleaned dataset
[rank3]:1224: everything same as 1109 (dataset: alpaca_gpt4) but debugged requires_grad bug
[rank3]:"
[rank1]:2025-12-26 14:33:30,875 - ENV[TORCH_NCCL_ASYNC_ERROR_HANDLING] = 1 will be overridden to 3 based on job config
[rank1]:2025-12-26 14:33:30,877 - Building 1-D device mesh with ['pp'], [4]
[rank2]:2025-12-26 14:33:30,892 - ENV[TORCH_NCCL_ASYNC_ERROR_HANDLING] = 1 will be overridden to 3 based on job config
[rank2]:2025-12-26 14:33:30,895 - Building 1-D device mesh with ['pp'], [4]
[rank3]:2025-12-26 14:33:30,914 - ENV[TORCH_NCCL_ASYNC_ERROR_HANDLING] = 1 will be overridden to 3 based on job config
[rank3]:2025-12-26 14:33:30,916 - Building 1-D device mesh with ['pp'], [4]
[rank0]:2025-12-26 14:33:30,946 - ENV[TORCH_NCCL_ASYNC_ERROR_HANDLING] = 1 will be overridden to 3 based on job config
[rank0]:2025-12-26 14:33:30,950 - Building 1-D device mesh with ['pp'], [4]
[rank0]:2025-12-26 14:33:30,955 - [GC] Initial GC collection 0.00 seconds
[rank0]:2025-12-26 14:33:30,956 - Loading tokenizer from tokenizer.json
[rank0]:2025-12-26 14:33:31,342 - Preparing alpaca_gpt4 dataset from vicgalle/alpaca-gpt4
[rank1]:2025-12-26 14:33:34,893 - CUDA capacity: NVIDIA RTX 6000 Ada Generation with 47.51GiB memory
[rank2]:2025-12-26 14:33:34,841 - CUDA capacity: NVIDIA RTX 6000 Ada Generation with 47.51GiB memory
[rank2]:2025-12-26 14:33:34,881 - Peak flops undefined for: NVIDIA RTX 6000 Ada Generation, fallback to A100
[rank2]:2025-12-26 14:33:34,908 - PP rank 2 is building stage_idx 2 with modules ['layers.5', 'layers.6']
[rank2]:2025-12-26 14:33:34,920 - PP rank 2 is building stage_idx 5 with modules ['layers.11', 'layers.12']
[rank3]:2025-12-26 14:33:34,909 - CUDA capacity: NVIDIA RTX 6000 Ada Generation with 47.51GiB memory
[rank1]:2025-12-26 14:33:34,936 - Peak flops undefined for: NVIDIA RTX 6000 Ada Generation, fallback to A100
[rank1]:2025-12-26 14:33:34,964 - PP rank 1 is building stage_idx 1 with modules ['layers.2', 'layers.3', 'layers.4']
[rank1]:2025-12-26 14:33:34,977 - PP rank 1 is building stage_idx 6 with modules ['layers.13', 'layers.14']
[rank1]:2025-12-26 14:33:34,980 - Using pipeline schedule ZBVZeroBubble with 8 microbatches and 8 stages.
[rank2]:2025-12-26 14:33:34,922 - Using pipeline schedule ZBVZeroBubble with 8 microbatches and 8 stages.
[rank3]:2025-12-26 14:33:34,947 - Peak flops undefined for: NVIDIA RTX 6000 Ada Generation, fallback to A100
[rank3]:2025-12-26 14:33:34,974 - PP rank 3 is building stage_idx 3 with modules ['layers.7', 'layers.8']
[rank3]:2025-12-26 14:33:34,987 - PP rank 3 is building stage_idx 4 with modules ['layers.9', 'layers.10']
[rank3]:2025-12-26 14:33:34,989 - Using pipeline schedule ZBVZeroBubble with 8 microbatches and 8 stages.
[rank1]:2025-12-26 14:33:35,170 - Peak flops undefined for: NVIDIA RTX 6000 Ada Generation, fallback to A100
[rank1]:2025-12-26 14:33:35,170 - Peak FLOPS used for computing MFU: 3.120e+14
[rank1]:2025-12-26 14:33:35,170 - CUDA memory usage for model: 1.13GiB(2.39%)
[rank2]:2025-12-26 14:33:35,129 - Peak flops undefined for: NVIDIA RTX 6000 Ada Generation, fallback to A100
[rank2]:2025-12-26 14:33:35,129 - Peak FLOPS used for computing MFU: 3.120e+14
[rank2]:2025-12-26 14:33:35,130 - CUDA memory usage for model: 0.92GiB(1.94%)
[rank3]:2025-12-26 14:33:35,189 - Peak flops undefined for: NVIDIA RTX 6000 Ada Generation, fallback to A100
[rank3]:2025-12-26 14:33:35,189 - Peak FLOPS used for computing MFU: 3.120e+14
[rank3]:2025-12-26 14:33:35,190 - CUDA memory usage for model: 0.92GiB(1.94%)
[rank0]:2025-12-26 14:33:35,288 - Building llama3 1B with TransformerModelArgs(_enforced='This field is used to enforce all fields have defaults.', dim=2048, n_layers=16, n_heads=32, n_kv_heads=8, vocab_size=128256, multiple_of=256, ffn_dim_multiplier=1.5, norm_eps=1e-05, rope_theta=500000, max_seq_len=1024, depth_init=True, use_flex_attn=False, attn_mask_type='causal', eos_id=0)
[rank0]:wandb: Currently logged in as: orangingq to https://api.wandb.ai. Use `wandb login --relogin` to force relogin
[rank0]:wandb: setting up run fwv979at
[rank0]:wandb: Tracking run with wandb version 0.22.2
[rank0]:wandb: Run data is saved locally in /data2/shcho/torchtitan/tb/1224_ZBVZeroBubble_nofreeze_42_dm1/20251226-1433/wandb/run-20251226_143336-fwv979at
[rank0]:wandb: Run `wandb offline` to turn off syncing.
[rank0]:wandb: Syncing run 1224_ZBVZeroBubble_nofreeze_42_dm1
[rank0]:wandb: ‚≠êÔ∏è View project at https://wandb.ai/orangingq/torchtitan
[rank0]:wandb: üöÄ View run at https://wandb.ai/orangingq/torchtitan/runs/fwv979at
[rank0]:2025-12-26 14:33:37,778 - WandB logging enabled
[rank0]:2025-12-26 14:33:37,779 - CUDA capacity: NVIDIA RTX 6000 Ada Generation with 47.51GiB memory
[rank0]:2025-12-26 14:33:37,818 - Peak flops undefined for: NVIDIA RTX 6000 Ada Generation, fallback to A100
[rank0]:2025-12-26 14:33:37,819 - Model llama3 1B size: 1,498,482,688 total parameters
[rank0]:2025-12-26 14:33:37,845 - PP rank 0 is building stage_idx 0 with modules ['tok_embeddings', 'layers.0', 'layers.1']
[rank0]:2025-12-26 14:33:37,858 - PP rank 0 is building stage_idx 7 with modules ['layers.15', 'norm', 'output']
[rank0]:2025-12-26 14:33:37,860 - Using pipeline schedule ZBVZeroBubble with 8 microbatches and 8 stages.
[rank2]:2025-12-26 14:33:38,077 - Mixed precision training with TP or PP is handled by autocast
[rank0]:2025-12-26 14:33:38,059 - Peak flops undefined for: NVIDIA RTX 6000 Ada Generation, fallback to A100
[rank0]:2025-12-26 14:33:38,059 - Peak FLOPS used for computing MFU: 3.120e+14
[rank0]:2025-12-26 14:33:38,060 - CUDA memory usage for model: 2.64GiB(5.55%)
[rank0]:2025-12-26 14:33:38,076 - Checkpointing active. Checkpoints will be loaded from and saved to /data2/shcho/torchtitan/checkpoint/1224_ZBVZeroBubble_nofreeze_42_dm1
[rank0]:2025-12-26 14:33:38,076 - Mixed precision training with TP or PP is handled by autocast
[rank0]:2025-12-26 14:33:38,077 - Trainer is initialized with local batch size 32, global batch size 128, gradient accumulation steps 4, sequence length 1024, total steps 800 (warmup 100)
[rank0]:2025-12-26 14:33:38,077 - Loading the checkpoint from /data2/shcho/torchtitan/base_model/Llama-3.2-1B/original_dcp.
[rank1]:2025-12-26 14:33:38,077 - Mixed precision training with TP or PP is handled by autocast
[rank3]:2025-12-26 14:33:38,077 - Mixed precision training with TP or PP is handled by autocast
[rank0]:2025-12-26 14:33:41,509 - [GC] GC collection for checkpoint loading. 0.03 seconds
[rank0]:2025-12-26 14:33:41,510 - Finished loading the checkpoint in 3.43 seconds.
[rank0]:2025-12-26 14:33:41,510 - Training starts at step 1
[rank3]:2025-12-26 14:33:46,630 -  step:  1  loss: -4.0000  grad_norm: 203.0661  memory: 13.45GiB(28.31%)  tps: 2,805  tflops: 21.93  mfu: 7.03%
[rank3]:2025-12-26 14:33:46,630 - Synchronizing and adjusting timeout for all ProcessGroups to 0:05:00
[rank2]:2025-12-26 14:33:46,627 -  step:  1  loss: -4.0000  grad_norm: 203.0661  memory: 11.98GiB(25.23%)  tps: 2,790  tflops: 21.81  mfu: 6.99%
[rank2]:2025-12-26 14:33:46,627 - Synchronizing and adjusting timeout for all ProcessGroups to 0:05:00
[rank1]:2025-12-26 14:33:46,648 -  step:  1  loss: -4.0000  grad_norm: 203.0661  memory: 15.58GiB(32.80%)  tps: 2,798  tflops: 21.87  mfu: 7.01%
[rank1]:2025-12-26 14:33:46,648 - Synchronizing and adjusting timeout for all ProcessGroups to 0:05:00
[rank0]:2025-12-26 14:33:46,680 -  step:  1  loss: 10.6092  grad_norm: 203.0661  memory: 30.01GiB(63.17%)  tps: 3,699  tflops: 28.91  mfu: 9.27%
[rank0]:2025-12-26 14:33:46,680 - Synchronizing and adjusting timeout for all ProcessGroups to 0:05:00
