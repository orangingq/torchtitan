
üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•
‚úîÔ∏èCurrent Timestamp: 2025. 10. 20. (Ïõî) 00:45:22 KST
‚úîÔ∏èSERVER: dmserver1 (143.248.135.95),  GPUs: 3,4,5,6
‚úîÔ∏èSCRIPT: 
‚úîÔ∏èOUTPUT: /home/shcho/torchtitan/logs/dmserver1/1020_main/1020_gpipe_fullrand7.log
‚úîÔ∏èMain Table Experiment
‚úîÔ∏èRunning with fullrand7 x gpipe ... 
‚òëÔ∏è> torchrun --standalone --nnodes=1 --nproc_per_node=4 --local_addr=127.0.0.1 --local-ranks-filter=0,3 --role=rank --tee=3 -m timelyfreeze.train --job.config_file=/home/shcho/torchtitan/logs/dmserver1/1020_main/config.toml --job.description="Main Table Experiment" --training.global_batch_size=128 --training.local_batch_size=8 --parallelism.pipeline_parallel_microbatch_size=1 --training.seq_len=1024 --training.steps=500 --parallelism.pipeline_parallel_degree=4  --freezing.freeze --freezing.metric_type=fullrand7 --freezing.stability_check_freq=50 --freezing.aggressiveness=0.05
üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•
2025-10-20 00:45:29,814 - Starting job: "Main Table Experiment"
2025-10-20 00:45:29,815 - Starting job: "Main Table Experiment"
2025-10-20 00:45:29,900 - Starting job: "Main Table Experiment"
[rank0]:[titan] 2025-10-20 00:45:29,900 - root - INFO - Starting job: "Main Table Experiment"
2025-10-20 00:45:30,167 - Starting job: "Main Table Experiment"
[rank3]:[titan] 2025-10-20 00:45:30,167 - root - INFO - Starting job: "Main Table Experiment"
2025-10-20 00:45:30,589 - ENV[TORCH_NCCL_ASYNC_ERROR_HANDLING] = 1 will be overridden to 3 based on job config
2025-10-20 00:45:30,592 - Building 1-D device mesh with ['pp'], [4]
2025-10-20 00:45:30,596 - ENV[TORCH_NCCL_ASYNC_ERROR_HANDLING] = 1 will be overridden to 3 based on job config
2025-10-20 00:45:30,596 - [GC] Initial GC collection 0.00 seconds
2025-10-20 00:45:30,598 - Building 1-D device mesh with ['pp'], [4]
2025-10-20 00:45:30,610 - ENV[TORCH_NCCL_ASYNC_ERROR_HANDLING] = 1 will be overridden to 3 based on job config
2025-10-20 00:45:30,615 - Building 1-D device mesh with ['pp'], [4]
[rank0]:[titan] 2025-10-20 00:45:30,589 - root - WARNING - ENV[TORCH_NCCL_ASYNC_ERROR_HANDLING] = 1 will be overridden to 3 based on job config
[rank0]:[titan] 2025-10-20 00:45:30,592 - root - INFO - Building 1-D device mesh with ['pp'], [4]
[rank0]:[titan] 2025-10-20 00:45:30,596 - root - INFO - [GC] Initial GC collection 0.00 seconds
2025-10-20 00:45:30,621 - ENV[TORCH_NCCL_ASYNC_ERROR_HANDLING] = 1 will be overridden to 3 based on job config
2025-10-20 00:45:30,625 - Building 1-D device mesh with ['pp'], [4]
[rank3]:[titan] 2025-10-20 00:45:30,621 - root - WARNING - ENV[TORCH_NCCL_ASYNC_ERROR_HANDLING] = 1 will be overridden to 3 based on job config
[rank3]:[titan] 2025-10-20 00:45:30,625 - root - INFO - Building 1-D device mesh with ['pp'], [4]
2025-10-20 00:45:31,107 - Loading tokenizer from tokenizer.json
[rank0]:[titan] 2025-10-20 00:45:31,107 - root - INFO - Loading tokenizer from tokenizer.json
2025-10-20 00:45:31,564 - Preparing slimorca dataset from Open-Orca/SlimOrca
[rank0]:[titan] 2025-10-20 00:45:31,564 - root - INFO - Preparing slimorca dataset from Open-Orca/SlimOrca
2025-10-20 00:45:34,365 - Building llama3 1B with TransformerModelArgs(_enforced='This field is used to enforce all fields have defaults.', dim=2048, n_layers=16, n_heads=32, n_kv_heads=8, vocab_size=128256, multiple_of=1024, ffn_dim_multiplier=1.3, norm_eps=1e-05, rope_theta=500000, max_seq_len=1024, depth_init=True, use_flex_attn=False, attn_mask_type='causal', eos_id=0)
2025-10-20 00:45:34,418 - CUDA capacity: NVIDIA RTX 6000 Ada Generation with 47.51GiB memory
[rank0]:[titan] 2025-10-20 00:45:34,365 - root - INFO - Building llama3 1B with TransformerModelArgs(_enforced='This field is used to enforce all fields have defaults.', dim=2048, n_layers=16, n_heads=32, n_kv_heads=8, vocab_size=128256, multiple_of=1024, ffn_dim_multiplier=1.3, norm_eps=1e-05, rope_theta=500000, max_seq_len=1024, depth_init=True, use_flex_attn=False, attn_mask_type='causal', eos_id=0)
2025-10-20 00:45:34,459 - Peak flops undefined for: NVIDIA RTX 6000 Ada Generation, fallback to A100
2025-10-20 00:45:34,486 - PP rank 2 is building stage_idx 2 with modules ['layers.9', 'layers.10', 'layers.11', 'layers.12']
2025-10-20 00:45:34,486 - Using pipeline schedule gpipe with 8 microbatches and 4 stages.
2025-10-20 00:45:34,528 - CUDA capacity: NVIDIA RTX 6000 Ada Generation with 47.51GiB memory
2025-10-20 00:45:34,567 - Peak flops undefined for: NVIDIA RTX 6000 Ada Generation, fallback to A100
2025-10-20 00:45:34,569 - [34mModel llama3 1B [31msize: 1,397,819,392 total parameters[39m
2025-10-20 00:45:34,595 - PP rank 0 is building stage_idx 0 with modules ['tok_embeddings', 'layers.0', 'layers.1', 'layers.2', 'layers.3']
2025-10-20 00:45:34,595 - Using pipeline schedule gpipe with 8 microbatches and 4 stages.
[rank0]:[titan] 2025-10-20 00:45:34,528 - root - INFO - CUDA capacity: NVIDIA RTX 6000 Ada Generation with 47.51GiB memory
[rank0]:[titan] 2025-10-20 00:45:34,567 - root - WARNING - Peak flops undefined for: NVIDIA RTX 6000 Ada Generation, fallback to A100
[rank0]:[titan] 2025-10-20 00:45:34,569 - root - INFO - [34mModel llama3 1B [31msize: 1,397,819,392 total parameters[39m
[rank0]:[titan] 2025-10-20 00:45:34,595 - root - INFO - PP rank 0 is building stage_idx 0 with modules ['tok_embeddings', 'layers.0', 'layers.1', 'layers.2', 'layers.3']
[rank0]:[titan] 2025-10-20 00:45:34,595 - root - INFO - Using pipeline schedule gpipe with 8 microbatches and 4 stages.
2025-10-20 00:45:34,673 - Peak flops undefined for: NVIDIA RTX 6000 Ada Generation, fallback to A100
2025-10-20 00:45:34,674 - Peak FLOPS used for computing MFU: 3.120e+14
2025-10-20 00:45:34,674 - CUDA memory usage for model: 0.82GiB(1.73%)
2025-10-20 00:45:34,675 - Warmup (200) + decay (400) steps exceed total training steps (500). Adjusting decay steps to 300.
2025-10-20 00:45:34,805 - Peak flops undefined for: NVIDIA RTX 6000 Ada Generation, fallback to A100
2025-10-20 00:45:34,805 - Peak FLOPS used for computing MFU: 3.120e+14
2025-10-20 00:45:34,805 - CUDA memory usage for model: 1.80GiB(3.79%)
2025-10-20 00:45:34,806 - Warmup (200) + decay (400) steps exceed total training steps (500). Adjusting decay steps to 300.
[rank3]:/data2/shcho/miniforge3/envs/llm/lib/python3.11/site-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
[rank3]:  warnings.warn(
[rank3]:/data2/shcho/miniforge3/envs/llm/lib/python3.11/site-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
[rank3]:  warnings.warn(
[rank0]:[titan] 2025-10-20 00:45:34,805 - root - WARNING - Peak flops undefined for: NVIDIA RTX 6000 Ada Generation, fallback to A100
[rank0]:[titan] 2025-10-20 00:45:34,805 - root - INFO - Peak FLOPS used for computing MFU: 3.120e+14
[rank0]:[titan] 2025-10-20 00:45:34,805 - root - INFO - CUDA memory usage for model: 1.80GiB(3.79%)
[rank0]:[titan] 2025-10-20 00:45:34,806 - root - WARNING - Warmup (200) + decay (400) steps exceed total training steps (500). Adjusting decay steps to 300.
2025-10-20 00:45:34,925 - CUDA capacity: NVIDIA RTX 6000 Ada Generation with 47.51GiB memory
2025-10-20 00:45:34,965 - Peak flops undefined for: NVIDIA RTX 6000 Ada Generation, fallback to A100
2025-10-20 00:45:34,993 - PP rank 1 is building stage_idx 1 with modules ['layers.4', 'layers.5', 'layers.6', 'layers.7', 'layers.8']
2025-10-20 00:45:34,994 - Using pipeline schedule gpipe with 8 microbatches and 4 stages.
2025-10-20 00:45:35,188 - Peak flops undefined for: NVIDIA RTX 6000 Ada Generation, fallback to A100
2025-10-20 00:45:35,189 - Peak FLOPS used for computing MFU: 3.120e+14
2025-10-20 00:45:35,189 - CUDA memory usage for model: 1.02GiB(2.14%)
2025-10-20 00:45:35,191 - Warmup (200) + decay (400) steps exceed total training steps (500). Adjusting decay steps to 300.
[rank3]:wandb: Currently logged in as: orangingq to https://api.wandb.ai. Use `wandb login --relogin` to force relogin
[rank3]:wandb: setting up run 6obzb682
[rank3]:wandb: Tracking run with wandb version 0.22.2
[rank3]:wandb: Run data is saved locally in /data2/shcho/torchtitan/tb/1020_gpipe_fullrand7_dm4/20251020-0045/wandb/run-20251020_004535-6obzb682
[rank3]:wandb: Run `wandb offline` to turn off syncing.
[rank3]:wandb: Syncing run 1020_gpipe_fullrand7_dm4
[rank3]:wandb: ‚≠êÔ∏è View project at https://wandb.ai/orangingq/torchtitan
[rank3]:wandb: üöÄ View run at https://wandb.ai/orangingq/torchtitan/runs/6obzb682
2025-10-20 00:45:36,489 - WandB logging enabled
2025-10-20 00:45:36,490 - CUDA capacity: NVIDIA RTX 6000 Ada Generation with 47.51GiB memory
[rank3]:[titan] 2025-10-20 00:45:36,489 - root - INFO - WandB logging enabled
[rank3]:[titan] 2025-10-20 00:45:36,490 - root - INFO - CUDA capacity: NVIDIA RTX 6000 Ada Generation with 47.51GiB memory
2025-10-20 00:45:36,528 - Peak flops undefined for: NVIDIA RTX 6000 Ada Generation, fallback to A100
2025-10-20 00:45:36,557 - PP rank 3 is building stage_idx 3 with modules ['layers.13', 'layers.14', 'layers.15', 'norm', 'output']
2025-10-20 00:45:36,557 - Using pipeline schedule gpipe with 8 microbatches and 4 stages.
[rank3]:[titan] 2025-10-20 00:45:36,528 - root - WARNING - Peak flops undefined for: NVIDIA RTX 6000 Ada Generation, fallback to A100
[rank3]:[titan] 2025-10-20 00:45:36,557 - root - INFO - PP rank 3 is building stage_idx 3 with modules ['layers.13', 'layers.14', 'layers.15', 'norm', 'output']
[rank3]:[titan] 2025-10-20 00:45:36,557 - root - INFO - Using pipeline schedule gpipe with 8 microbatches and 4 stages.
2025-10-20 00:45:36,737 - Peak flops undefined for: NVIDIA RTX 6000 Ada Generation, fallback to A100
2025-10-20 00:45:36,738 - Peak FLOPS used for computing MFU: 3.120e+14
2025-10-20 00:45:36,739 - CUDA memory usage for model: 1.60GiB(3.38%)
2025-10-20 00:45:36,740 - Warmup (200) + decay (400) steps exceed total training steps (500). Adjusting decay steps to 300.
2025-10-20 00:45:36,756 - Mixed precision training with TP or PP is only supported when FSDP/HSDP/CP is enabled.
2025-10-20 00:45:36,757 - Mixed precision training with TP or PP is only supported when FSDP/HSDP/CP is enabled.
2025-10-20 00:45:36,757 - Mixed precision training is disabled
2025-10-20 00:45:36,757 - Mixed precision training with TP or PP is only supported when FSDP/HSDP/CP is enabled.
2025-10-20 00:45:36,757 - Mixed precision training is disabled
2025-10-20 00:45:36,757 - Checkpointing active. Checkpoints will be loaded from and saved to /data2/shcho/torchtitan/checkpoint/1020_gpipe_fullrand7_dm4
2025-10-20 00:45:36,757 - Mixed precision training is disabled
2025-10-20 00:45:36,757 - Mixed precision training with TP or PP is only supported when FSDP/HSDP/CP is enabled.
2025-10-20 00:45:36,757 - Mixed precision training is disabled
2025-10-20 00:45:36,759 - Trainer is initialized with local batch size 8, global batch size 128, gradient accumulation steps 16, sequence length 1024, total steps 500 (warmup 200)
2025-10-20 00:45:36,759 - Training starts at step 1
[rank3]:[titan] 2025-10-20 00:45:36,737 - root - WARNING - Peak flops undefined for: NVIDIA RTX 6000 Ada Generation, fallback to A100
[rank3]:[titan] 2025-10-20 00:45:36,738 - root - INFO - Peak FLOPS used for computing MFU: 3.120e+14
[rank3]:[titan] 2025-10-20 00:45:36,739 - root - INFO - CUDA memory usage for model: 1.60GiB(3.38%)
[rank3]:[titan] 2025-10-20 00:45:36,740 - root - WARNING - Warmup (200) + decay (400) steps exceed total training steps (500). Adjusting decay steps to 300.
[rank3]:[titan] 2025-10-20 00:45:36,756 - root - WARNING - Mixed precision training with TP or PP is only supported when FSDP/HSDP/CP is enabled.
[rank3]:[titan] 2025-10-20 00:45:36,757 - root - INFO - Mixed precision training is disabled
[rank0]:[titan] 2025-10-20 00:45:36,757 - root - INFO - Checkpointing active. Checkpoints will be loaded from and saved to /data2/shcho/torchtitan/checkpoint/1020_gpipe_fullrand7_dm4
[rank0]:[titan] 2025-10-20 00:45:36,757 - root - WARNING - Mixed precision training with TP or PP is only supported when FSDP/HSDP/CP is enabled.
[rank0]:[titan] 2025-10-20 00:45:36,757 - root - INFO - Mixed precision training is disabled
[rank0]:[titan] 2025-10-20 00:45:36,759 - root - INFO - Trainer is initialized with local batch size 8, global batch size 128, gradient accumulation steps 16, sequence length 1024, total steps 500 (warmup 200)
[rank0]:[titan] 2025-10-20 00:45:36,759 - root - INFO - Training starts at step 1
[rank0]:/data2/shcho/miniforge3/envs/llm/lib/python3.11/site-packages/torch/autograd/graph.py:849: UserWarning: Attempting to run cuBLAS, but there was no current CUDA context! Attempting to set the primary context... (Triggered internally at /pytorch/aten/src/ATen/cuda/CublasHandlePool.cpp:270.)
[rank0]:  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
2025-10-20 00:45:54,839 - [31m step:  1 [32m loss: -16.0000 [38;2;180;60;0m grad_norm:  0.1623 [38;2;54;234;195m memory:  7.43GiB(15.64%) [34m tps: 1,608 [36m tflops: 11.60 [35m mfu: 3.72%[39m
2025-10-20 00:45:54,840 - Synchronizing and adjusting timeout for all ProcessGroups to 0:05:00
2025-10-20 00:45:54,843 - [31m step:  1 [32m loss: -16.0000 [38;2;180;60;0m grad_norm:  0.1623 [38;2;54;234;195m memory:  9.23GiB(19.42%) [34m tps: 1,649 [36m tflops: 11.89 [35m mfu: 3.81%[39m
2025-10-20 00:45:54,844 - Synchronizing and adjusting timeout for all ProcessGroups to 0:05:00
2025-10-20 00:45:54,851 - [31m step:  1 [32m loss: 12.2718 [38;2;180;60;0m grad_norm:  0.1623 [38;2;54;234;195m memory: 19.60GiB(41.25%) [34m tps: 1,789 [36m tflops: 12.90 [35m mfu: 4.14%[39m
2025-10-20 00:45:54,852 - Synchronizing and adjusting timeout for all ProcessGroups to 0:05:00
2025-10-20 00:45:54,876 - [31m step:  1 [32m loss: -16.0000 [38;2;180;60;0m grad_norm:  0.1623 [38;2;54;234;195m memory: 10.28GiB(21.64%) [34m tps: 1,614 [36m tflops: 11.64 [35m mfu: 3.73%[39m
2025-10-20 00:45:54,876 - Synchronizing and adjusting timeout for all ProcessGroups to 0:05:00
[rank3]:[titan] 2025-10-20 00:45:54,851 - root - INFO - [31m step:  1 [32m loss: 12.2718 [38;2;180;60;0m grad_norm:  0.1623 [38;2;54;234;195m memory: 19.60GiB(41.25%) [34m tps: 1,789 [36m tflops: 12.90 [35m mfu: 4.14%[39m
[rank3]:[titan] 2025-10-20 00:45:54,852 - root - INFO - Synchronizing and adjusting timeout for all ProcessGroups to 0:05:00
[rank0]:[titan] 2025-10-20 00:45:54,876 - root - INFO - [31m step:  1 [32m loss: -16.0000 [38;2;180;60;0m grad_norm:  0.1623 [38;2;54;234;195m memory: 10.28GiB(21.64%) [34m tps: 1,614 [36m tflops: 11.64 [35m mfu: 3.73%[39m
[rank0]:[titan] 2025-10-20 00:45:54,876 - root - INFO - Synchronizing and adjusting timeout for all ProcessGroups to 0:05:00

üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•
‚úîÔ∏èCurrent Timestamp: 2025. 10. 20. (Ïõî) 00:47:29 KST
‚úîÔ∏èSERVER: dmserver1 (143.248.135.95),  GPUs: 3,4,5,6
‚úîÔ∏èSCRIPT: 
‚úîÔ∏èOUTPUT: /home/shcho/torchtitan/logs/dmserver1/1020_main/1020_gpipe_fullrand7.log
‚úîÔ∏èMain Table Experiment
‚úîÔ∏èRunning with fullrand7 x gpipe ... 
‚òëÔ∏è> torchrun --standalone --nnodes=1 --nproc_per_node=4 --local_addr=127.0.0.1 --local-ranks-filter=0,3 --role=rank --tee=3 -m timelyfreeze.train --job.config_file=/home/shcho/torchtitan/logs/dmserver1/1020_main/config.toml --job.description="Main Table Experiment" --training.global_batch_size=512 --training.local_batch_size=16 --parallelism.pipeline_parallel_microbatch_size=1 --training.seq_len=1024 --training.steps=500 --parallelism.pipeline_parallel_degree=4  --freezing.freeze --freezing.metric_type=fullrand7 --freezing.stability_check_freq=50 --freezing.aggressiveness=0.0
üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•
2025-10-20 00:47:35,640 - Starting job: "Main Table Experiment"
2025-10-20 00:47:35,646 - Starting job: "Main Table Experiment"
[rank3]:[titan] 2025-10-20 00:47:35,646 - root - INFO - Starting job: "Main Table Experiment"
2025-10-20 00:47:35,846 - Starting job: "Main Table Experiment"
2025-10-20 00:47:35,871 - Starting job: "Main Table Experiment"
2025-10-20 00:47:35,878 - ENV[TORCH_NCCL_ASYNC_ERROR_HANDLING] = 1 will be overridden to 3 based on job config
2025-10-20 00:47:35,880 - Building 1-D device mesh with ['pp'], [4]
2025-10-20 00:47:35,907 - ENV[TORCH_NCCL_ASYNC_ERROR_HANDLING] = 1 will be overridden to 3 based on job config
2025-10-20 00:47:35,909 - Building 1-D device mesh with ['pp'], [4]
[rank0]:[titan] 2025-10-20 00:47:35,846 - root - INFO - Starting job: "Main Table Experiment"
[rank3]:[titan] 2025-10-20 00:47:35,878 - root - WARNING - ENV[TORCH_NCCL_ASYNC_ERROR_HANDLING] = 1 will be overridden to 3 based on job config
[rank3]:[titan] 2025-10-20 00:47:35,880 - root - INFO - Building 1-D device mesh with ['pp'], [4]
2025-10-20 00:47:36,072 - ENV[TORCH_NCCL_ASYNC_ERROR_HANDLING] = 1 will be overridden to 3 based on job config
2025-10-20 00:47:36,075 - Building 1-D device mesh with ['pp'], [4]
2025-10-20 00:47:36,080 - [GC] Initial GC collection 0.00 seconds
2025-10-20 00:47:36,096 - ENV[TORCH_NCCL_ASYNC_ERROR_HANDLING] = 1 will be overridden to 3 based on job config
2025-10-20 00:47:36,099 - Building 1-D device mesh with ['pp'], [4]
[rank0]:[titan] 2025-10-20 00:47:36,072 - root - WARNING - ENV[TORCH_NCCL_ASYNC_ERROR_HANDLING] = 1 will be overridden to 3 based on job config
[rank0]:[titan] 2025-10-20 00:47:36,075 - root - INFO - Building 1-D device mesh with ['pp'], [4]
[rank0]:[titan] 2025-10-20 00:47:36,080 - root - INFO - [GC] Initial GC collection 0.00 seconds
2025-10-20 00:47:37,180 - Loading tokenizer from tokenizer.json
[rank0]:[titan] 2025-10-20 00:47:37,180 - root - INFO - Loading tokenizer from tokenizer.json
2025-10-20 00:47:37,648 - Preparing slimorca dataset from Open-Orca/SlimOrca
[rank0]:[titan] 2025-10-20 00:47:37,648 - root - INFO - Preparing slimorca dataset from Open-Orca/SlimOrca
2025-10-20 00:47:40,660 - CUDA capacity: NVIDIA RTX 6000 Ada Generation with 47.51GiB memory
2025-10-20 00:47:40,677 - CUDA capacity: NVIDIA RTX 6000 Ada Generation with 47.51GiB memory
2025-10-20 00:47:40,700 - Peak flops undefined for: NVIDIA RTX 6000 Ada Generation, fallback to A100
2025-10-20 00:47:40,716 - Peak flops undefined for: NVIDIA RTX 6000 Ada Generation, fallback to A100
2025-10-20 00:47:40,725 - PP rank 1 is building stage_idx 1 with modules ['layers.4', 'layers.5', 'layers.6', 'layers.7', 'layers.8']
2025-10-20 00:47:40,725 - Using pipeline schedule gpipe with 16 microbatches and 4 stages.
2025-10-20 00:47:40,743 - PP rank 2 is building stage_idx 2 with modules ['layers.9', 'layers.10', 'layers.11', 'layers.12']
2025-10-20 00:47:40,743 - Using pipeline schedule gpipe with 16 microbatches and 4 stages.
2025-10-20 00:47:40,751 - Building llama3 1B with TransformerModelArgs(_enforced='This field is used to enforce all fields have defaults.', dim=2048, n_layers=16, n_heads=32, n_kv_heads=8, vocab_size=128256, multiple_of=1024, ffn_dim_multiplier=1.3, norm_eps=1e-05, rope_theta=500000, max_seq_len=1024, depth_init=True, use_flex_attn=False, attn_mask_type='causal', eos_id=0)
[rank0]:[titan] 2025-10-20 00:47:40,751 - root - INFO - Building llama3 1B with TransformerModelArgs(_enforced='This field is used to enforce all fields have defaults.', dim=2048, n_layers=16, n_heads=32, n_kv_heads=8, vocab_size=128256, multiple_of=1024, ffn_dim_multiplier=1.3, norm_eps=1e-05, rope_theta=500000, max_seq_len=1024, depth_init=True, use_flex_attn=False, attn_mask_type='causal', eos_id=0)
2025-10-20 00:47:40,903 - CUDA capacity: NVIDIA RTX 6000 Ada Generation with 47.51GiB memory
2025-10-20 00:47:40,906 - Peak flops undefined for: NVIDIA RTX 6000 Ada Generation, fallback to A100
2025-10-20 00:47:40,906 - Peak FLOPS used for computing MFU: 3.120e+14
2025-10-20 00:47:40,907 - CUDA memory usage for model: 1.02GiB(2.14%)
2025-10-20 00:47:40,908 - Warmup (200) + decay (400) steps exceed total training steps (500). Adjusting decay steps to 300.
2025-10-20 00:47:40,943 - Peak flops undefined for: NVIDIA RTX 6000 Ada Generation, fallback to A100
2025-10-20 00:47:40,943 - Peak FLOPS used for computing MFU: 3.120e+14
2025-10-20 00:47:40,943 - CUDA memory usage for model: 0.82GiB(1.73%)
[rank3]:/data2/shcho/miniforge3/envs/llm/lib/python3.11/site-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
[rank0]:[titan] 2025-10-20 00:47:40,903 - root - INFO - CUDA capacity: NVIDIA RTX 6000 Ada Generation with 47.51GiB memory
[rank3]:  warnings.warn(
[rank3]:/data2/shcho/miniforge3/envs/llm/lib/python3.11/site-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
[rank3]:  warnings.warn(
2025-10-20 00:47:40,944 - Warmup (200) + decay (400) steps exceed total training steps (500). Adjusting decay steps to 300.
2025-10-20 00:47:40,946 - Peak flops undefined for: NVIDIA RTX 6000 Ada Generation, fallback to A100
2025-10-20 00:47:40,947 - [34mModel llama3 1B [31msize: 1,397,819,392 total parameters[39m
2025-10-20 00:47:40,974 - PP rank 0 is building stage_idx 0 with modules ['tok_embeddings', 'layers.0', 'layers.1', 'layers.2', 'layers.3']
2025-10-20 00:47:40,974 - Using pipeline schedule gpipe with 16 microbatches and 4 stages.
[rank0]:[titan] 2025-10-20 00:47:40,946 - root - WARNING - Peak flops undefined for: NVIDIA RTX 6000 Ada Generation, fallback to A100
[rank0]:[titan] 2025-10-20 00:47:40,947 - root - INFO - [34mModel llama3 1B [31msize: 1,397,819,392 total parameters[39m
[rank0]:[titan] 2025-10-20 00:47:40,974 - root - INFO - PP rank 0 is building stage_idx 0 with modules ['tok_embeddings', 'layers.0', 'layers.1', 'layers.2', 'layers.3']
[rank0]:[titan] 2025-10-20 00:47:40,974 - root - INFO - Using pipeline schedule gpipe with 16 microbatches and 4 stages.
2025-10-20 00:47:41,152 - Peak flops undefined for: NVIDIA RTX 6000 Ada Generation, fallback to A100
2025-10-20 00:47:41,152 - Peak FLOPS used for computing MFU: 3.120e+14
2025-10-20 00:47:41,153 - CUDA memory usage for model: 1.80GiB(3.79%)
2025-10-20 00:47:41,153 - Warmup (200) + decay (400) steps exceed total training steps (500). Adjusting decay steps to 300.
[rank0]:[titan] 2025-10-20 00:47:41,152 - root - WARNING - Peak flops undefined for: NVIDIA RTX 6000 Ada Generation, fallback to A100
[rank0]:[titan] 2025-10-20 00:47:41,152 - root - INFO - Peak FLOPS used for computing MFU: 3.120e+14
[rank0]:[titan] 2025-10-20 00:47:41,153 - root - INFO - CUDA memory usage for model: 1.80GiB(3.79%)
[rank0]:[titan] 2025-10-20 00:47:41,153 - root - WARNING - Warmup (200) + decay (400) steps exceed total training steps (500). Adjusting decay steps to 300.
[rank3]:wandb: Currently logged in as: orangingq to https://api.wandb.ai. Use `wandb login --relogin` to force relogin
[rank3]:wandb: setting up run 6a8gq84r
[rank3]:wandb: Tracking run with wandb version 0.22.2
[rank3]:wandb: Run data is saved locally in /data2/shcho/torchtitan/tb/1020_gpipe_fullrand7_dm4/20251020-0047/wandb/run-20251020_004741-6a8gq84r
[rank3]:wandb: Run `wandb offline` to turn off syncing.
[rank3]:wandb: Syncing run 1020_gpipe_fullrand7_dm4
[rank3]:wandb: ‚≠êÔ∏è View project at https://wandb.ai/orangingq/torchtitan
[rank3]:wandb: üöÄ View run at https://wandb.ai/orangingq/torchtitan/runs/6a8gq84r
2025-10-20 00:47:43,200 - WandB logging enabled
2025-10-20 00:47:43,201 - CUDA capacity: NVIDIA RTX 6000 Ada Generation with 47.51GiB memory
2025-10-20 00:47:43,240 - Peak flops undefined for: NVIDIA RTX 6000 Ada Generation, fallback to A100
[rank3]:[titan] 2025-10-20 00:47:43,200 - root - INFO - WandB logging enabled
[rank3]:[titan] 2025-10-20 00:47:43,201 - root - INFO - CUDA capacity: NVIDIA RTX 6000 Ada Generation with 47.51GiB memory
[rank3]:[titan] 2025-10-20 00:47:43,240 - root - WARNING - Peak flops undefined for: NVIDIA RTX 6000 Ada Generation, fallback to A100
2025-10-20 00:47:43,269 - PP rank 3 is building stage_idx 3 with modules ['layers.13', 'layers.14', 'layers.15', 'norm', 'output']
2025-10-20 00:47:43,269 - Using pipeline schedule gpipe with 16 microbatches and 4 stages.
[rank3]:[titan] 2025-10-20 00:47:43,269 - root - INFO - PP rank 3 is building stage_idx 3 with modules ['layers.13', 'layers.14', 'layers.15', 'norm', 'output']
[rank3]:[titan] 2025-10-20 00:47:43,269 - root - INFO - Using pipeline schedule gpipe with 16 microbatches and 4 stages.
2025-10-20 00:47:43,474 - Peak flops undefined for: NVIDIA RTX 6000 Ada Generation, fallback to A100
2025-10-20 00:47:43,475 - Peak FLOPS used for computing MFU: 3.120e+14
2025-10-20 00:47:43,476 - CUDA memory usage for model: 1.60GiB(3.38%)
2025-10-20 00:47:43,477 - Warmup (200) + decay (400) steps exceed total training steps (500). Adjusting decay steps to 300.
2025-10-20 00:47:43,491 - Mixed precision training with TP or PP is only supported when FSDP/HSDP/CP is enabled.
2025-10-20 00:47:43,491 - Mixed precision training with TP or PP is only supported when FSDP/HSDP/CP is enabled.
2025-10-20 00:47:43,491 - Mixed precision training is disabled
2025-10-20 00:47:43,491 - Checkpointing active. Checkpoints will be loaded from and saved to /data2/shcho/torchtitan/checkpoint/1020_gpipe_fullrand7_dm4
2025-10-20 00:47:43,492 - Mixed precision training with TP or PP is only supported when FSDP/HSDP/CP is enabled.
2025-10-20 00:47:43,492 - Mixed precision training with TP or PP is only supported when FSDP/HSDP/CP is enabled.
2025-10-20 00:47:43,492 - Mixed precision training is disabled
2025-10-20 00:47:43,492 - Mixed precision training is disabled
2025-10-20 00:47:43,492 - Mixed precision training is disabled
2025-10-20 00:47:43,493 - Trainer is initialized with local batch size 16, global batch size 512, gradient accumulation steps 32, sequence length 1024, total steps 500 (warmup 200)
2025-10-20 00:47:43,494 - Training starts at step 1
[rank0]:[titan] 2025-10-20 00:47:43,491 - root - INFO - Checkpointing active. Checkpoints will be loaded from and saved to /data2/shcho/torchtitan/checkpoint/1020_gpipe_fullrand7_dm4
[rank0]:[titan] 2025-10-20 00:47:43,492 - root - WARNING - Mixed precision training with TP or PP is only supported when FSDP/HSDP/CP is enabled.
[rank0]:[titan] 2025-10-20 00:47:43,492 - root - INFO - Mixed precision training is disabled
[rank0]:[titan] 2025-10-20 00:47:43,493 - root - INFO - Trainer is initialized with local batch size 16, global batch size 512, gradient accumulation steps 32, sequence length 1024, total steps 500 (warmup 200)
[rank0]:[titan] 2025-10-20 00:47:43,494 - root - INFO - Training starts at step 1
[rank3]:[titan] 2025-10-20 00:47:43,474 - root - WARNING - Peak flops undefined for: NVIDIA RTX 6000 Ada Generation, fallback to A100
[rank3]:[titan] 2025-10-20 00:47:43,475 - root - INFO - Peak FLOPS used for computing MFU: 3.120e+14
[rank3]:[titan] 2025-10-20 00:47:43,476 - root - INFO - CUDA memory usage for model: 1.60GiB(3.38%)
[rank3]:[titan] 2025-10-20 00:47:43,477 - root - WARNING - Warmup (200) + decay (400) steps exceed total training steps (500). Adjusting decay steps to 300.
[rank3]:[titan] 2025-10-20 00:47:43,491 - root - WARNING - Mixed precision training with TP or PP is only supported when FSDP/HSDP/CP is enabled.
[rank3]:[titan] 2025-10-20 00:47:43,492 - root - INFO - Mixed precision training is disabled
[rank0]:/data2/shcho/miniforge3/envs/llm/lib/python3.11/site-packages/torch/autograd/graph.py:849: UserWarning: Attempting to run cuBLAS, but there was no current CUDA context! Attempting to set the primary context... (Triggered internally at /pytorch/aten/src/ATen/cuda/CublasHandlePool.cpp:270.)
[rank0]:  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
2025-10-20 00:48:48,467 - [31m step:  1 [32m loss: -32.0000 [38;2;180;60;0m grad_norm:  0.0867 [38;2;54;234;195m memory: 13.06GiB(27.48%) [34m tps: 1,935 [36m tflops: 13.96 [35m mfu: 4.47%[39m
2025-10-20 00:48:48,467 - Synchronizing and adjusting timeout for all ProcessGroups to 0:05:00
2025-10-20 00:48:48,469 - [31m step:  1 [32m loss: -32.0000 [38;2;180;60;0m grad_norm:  0.0867 [38;2;54;234;195m memory: 16.22GiB(34.15%) [34m tps: 1,934 [36m tflops: 13.95 [35m mfu: 4.47%[39m
2025-10-20 00:48:48,469 - Synchronizing and adjusting timeout for all ProcessGroups to 0:05:00
2025-10-20 00:48:48,474 - [31m step:  1 [32m loss: 12.2568 [38;2;180;60;0m grad_norm:  0.0867 [38;2;54;234;195m memory: 35.57GiB(74.88%) [34m tps: 2,009 [36m tflops: 14.49 [35m mfu: 4.65%[39m
2025-10-20 00:48:48,475 - Synchronizing and adjusting timeout for all ProcessGroups to 0:05:00
2025-10-20 00:48:48,518 - [31m step:  1 [32m loss: -32.0000 [38;2;180;60;0m grad_norm:  0.0867 [38;2;54;234;195m memory: 15.91GiB(33.49%) [34m tps: 1,940 [36m tflops: 13.99 [35m mfu: 4.48%[39m
2025-10-20 00:48:48,519 - Synchronizing and adjusting timeout for all ProcessGroups to 0:05:00
[rank0]:[titan] 2025-10-20 00:48:48,518 - root - INFO - [31m step:  1 [32m loss: -32.0000 [38;2;180;60;0m grad_norm:  0.0867 [38;2;54;234;195m memory: 15.91GiB(33.49%) [34m tps: 1,940 [36m tflops: 13.99 [35m mfu: 4.48%[39m
[rank0]:[titan] 2025-10-20 00:48:48,519 - root - INFO - Synchronizing and adjusting timeout for all ProcessGroups to 0:05:00
[rank3]:[titan] 2025-10-20 00:48:48,474 - root - INFO - [31m step:  1 [32m loss: 12.2568 [38;2;180;60;0m grad_norm:  0.0867 [38;2;54;234;195m memory: 35.57GiB(74.88%) [34m tps: 2,009 [36m tflops: 14.49 [35m mfu: 4.65%[39m
[rank3]:[titan] 2025-10-20 00:48:48,475 - root - INFO - Synchronizing and adjusting timeout for all ProcessGroups to 0:05:00
2025-10-20 01:39:07,662 - [GC] Peforming periodical GC collection 0.02 seconds
[rank0]:[titan] 2025-10-20 01:39:07,662 - root - INFO - [GC] Peforming periodical GC collection 0.02 seconds
2025-10-20 02:31:25,629 - [GC] Peforming periodical GC collection 0.01 seconds
[rank0]:[titan] 2025-10-20 02:31:25,629 - root - INFO - [GC] Peforming periodical GC collection 0.01 seconds
2025-10-20 02:32:28,407 - [31m step: 100 [32m loss: -32.0000 [38;2;180;60;0m grad_norm:  0.0487 [38;2;54;234;195m memory: 14.70GiB(30.94%) [34m tps: 2,086 [36m tflops: 15.05 [35m mfu: 4.82%[39m
2025-10-20 02:32:28,410 - [31m step: 100 [32m loss: -32.0000 [38;2;180;60;0m grad_norm:  0.0487 [38;2;54;234;195m memory: 18.25GiB(38.42%) [34m tps: 2,086 [36m tflops: 15.05 [35m mfu: 4.82%[39m
2025-10-20 02:32:28,421 - [31m step: 100 [32m loss:  6.0547 [38;2;180;60;0m grad_norm:  0.0487 [38;2;54;234;195m memory: 38.80GiB(81.67%) [34m tps: 2,086 [36m tflops: 15.05 [35m mfu: 4.82%[39m
2025-10-20 02:32:28,423 - [31m step: 100 [32m loss: -32.0000 [38;2;180;60;0m grad_norm:  0.0487 [38;2;54;234;195m memory: 19.50GiB(41.05%) [34m tps: 2,086 [36m tflops: 15.05 [35m mfu: 4.82%[39m
[rank3]:[titan] 2025-10-20 02:32:28,421 - root - INFO - [31m step: 100 [32m loss:  6.0547 [38;2;180;60;0m grad_norm:  0.0487 [38;2;54;234;195m memory: 38.80GiB(81.67%) [34m tps: 2,086 [36m tflops: 15.05 [35m mfu: 4.82%[39m
[rank0]:[titan] 2025-10-20 02:32:28,423 - root - INFO - [31m step: 100 [32m loss: -32.0000 [38;2;180;60;0m grad_norm:  0.0487 [38;2;54;234;195m memory: 19.50GiB(41.05%) [34m tps: 2,086 [36m tflops: 15.05 [35m mfu: 4.82%[39m
2025-10-20 03:24:06,626 - [GC] Peforming periodical GC collection 0.01 seconds
[rank0]:[titan] 2025-10-20 03:24:06,626 - root - INFO - [GC] Peforming periodical GC collection 0.01 seconds
2025-10-20 04:16:51,166 - [GC] Peforming periodical GC collection 0.01 seconds
[rank0]:[titan] 2025-10-20 04:16:51,166 - root - INFO - [GC] Peforming periodical GC collection 0.01 seconds
2025-10-20 04:17:54,599 - [31m step: 200 [32m loss: -32.0000 [38;2;180;60;0m grad_norm:  0.0343 [38;2;54;234;195m memory: 14.70GiB(30.94%) [34m tps: 2,072 [36m tflops: 14.95 [35m mfu: 4.79%[39m
2025-10-20 04:17:54,602 - [31m step: 200 [32m loss: -32.0000 [38;2;180;60;0m grad_norm:  0.0343 [38;2;54;234;195m memory: 18.25GiB(38.42%) [34m tps: 2,072 [36m tflops: 14.95 [35m mfu: 4.79%[39m
2025-10-20 04:17:54,616 - [31m step: 200 [32m loss: -32.0000 [38;2;180;60;0m grad_norm:  0.0343 [38;2;54;234;195m memory: 19.50GiB(41.05%) [34m tps: 2,072 [36m tflops: 14.95 [35m mfu: 4.79%[39m
2025-10-20 04:17:54,621 - [31m step: 200 [32m loss:  5.2501 [38;2;180;60;0m grad_norm:  0.0343 [38;2;54;234;195m memory: 38.80GiB(81.67%) [34m tps: 2,072 [36m tflops: 14.95 [35m mfu: 4.79%[39m
[rank0]:[titan] 2025-10-20 04:17:54,616 - root - INFO - [31m step: 200 [32m loss: -32.0000 [38;2;180;60;0m grad_norm:  0.0343 [38;2;54;234;195m memory: 19.50GiB(41.05%) [34m tps: 2,072 [36m tflops: 14.95 [35m mfu: 4.79%[39m
[rank3]:[titan] 2025-10-20 04:17:54,621 - root - INFO - [31m step: 200 [32m loss:  5.2501 [38;2;180;60;0m grad_norm:  0.0343 [38;2;54;234;195m memory: 38.80GiB(81.67%) [34m tps: 2,072 [36m tflops: 14.95 [35m mfu: 4.79%[39m
2025-10-20 05:09:35,705 - [GC] Peforming periodical GC collection 0.01 seconds
[rank0]:[titan] 2025-10-20 05:09:35,705 - root - INFO - [GC] Peforming periodical GC collection 0.01 seconds
2025-10-20 06:02:26,024 - [GC] Peforming periodical GC collection 0.01 seconds
[rank0]:[titan] 2025-10-20 06:02:26,024 - root - INFO - [GC] Peforming periodical GC collection 0.01 seconds
2025-10-20 06:03:29,555 - [31m step: 300 [32m loss: -32.0000 [38;2;180;60;0m grad_norm:  0.0245 [38;2;54;234;195m memory: 14.70GiB(30.94%) [34m tps: 2,069 [36m tflops: 14.93 [35m mfu: 4.78%[39m
2025-10-20 06:03:29,558 - [31m step: 300 [32m loss: -32.0000 [38;2;180;60;0m grad_norm:  0.0245 [38;2;54;234;195m memory: 18.25GiB(38.42%) [34m tps: 2,069 [36m tflops: 14.93 [35m mfu: 4.78%[39m
2025-10-20 06:03:29,569 - [31m step: 300 [32m loss:  4.8303 [38;2;180;60;0m grad_norm:  0.0245 [38;2;54;234;195m memory: 38.80GiB(81.67%) [34m tps: 2,069 [36m tflops: 14.93 [35m mfu: 4.78%[39m
2025-10-20 06:03:29,570 - [31m step: 300 [32m loss: -32.0000 [38;2;180;60;0m grad_norm:  0.0245 [38;2;54;234;195m memory: 19.50GiB(41.05%) [34m tps: 2,069 [36m tflops: 14.93 [35m mfu: 4.78%[39m
[rank0]:[titan] 2025-10-20 06:03:29,570 - root - INFO - [31m step: 300 [32m loss: -32.0000 [38;2;180;60;0m grad_norm:  0.0245 [38;2;54;234;195m memory: 19.50GiB(41.05%) [34m tps: 2,069 [36m tflops: 14.93 [35m mfu: 4.78%[39m
[rank3]:[titan] 2025-10-20 06:03:29,569 - root - INFO - [31m step: 300 [32m loss:  4.8303 [38;2;180;60;0m grad_norm:  0.0245 [38;2;54;234;195m memory: 38.80GiB(81.67%) [34m tps: 2,069 [36m tflops: 14.93 [35m mfu: 4.78%[39m
2025-10-20 06:55:15,924 - [GC] Peforming periodical GC collection 0.01 seconds
[rank0]:[titan] 2025-10-20 06:55:15,924 - root - INFO - [GC] Peforming periodical GC collection 0.01 seconds
2025-10-20 07:38:08,513 - Dataset slimorca is being re-looped
[rank3]:[titan] 2025-10-20 07:38:08,513 - root - WARNING - Dataset slimorca is being re-looped
2025-10-20 07:38:08,915 - Dataset slimorca is being re-looped
2025-10-20 07:38:08,953 - Dataset slimorca is being re-looped
2025-10-20 07:38:08,988 - Dataset slimorca is being re-looped
[rank0]:[titan] 2025-10-20 07:38:08,988 - root - WARNING - Dataset slimorca is being re-looped
2025-10-20 07:48:07,724 - [GC] Peforming periodical GC collection 0.01 seconds
[rank0]:[titan] 2025-10-20 07:48:07,724 - root - INFO - [GC] Peforming periodical GC collection 0.01 seconds
2025-10-20 07:49:11,205 - [31m step: 400 [32m loss: -32.0000 [38;2;180;60;0m grad_norm:  0.0243 [38;2;54;234;195m memory: 14.70GiB(30.94%) [34m tps: 2,067 [36m tflops: 14.91 [35m mfu: 4.78%[39m
2025-10-20 07:49:11,208 - [31m step: 400 [32m loss: -32.0000 [38;2;180;60;0m grad_norm:  0.0243 [38;2;54;234;195m memory: 18.25GiB(38.42%) [34m tps: 2,067 [36m tflops: 14.91 [35m mfu: 4.78%[39m
2025-10-20 07:49:11,220 - [31m step: 400 [32m loss:  4.9314 [38;2;180;60;0m grad_norm:  0.0243 [38;2;54;234;195m memory: 38.80GiB(81.67%) [34m tps: 2,067 [36m tflops: 14.91 [35m mfu: 4.78%[39m
2025-10-20 07:49:11,222 - [31m step: 400 [32m loss: -32.0000 [38;2;180;60;0m grad_norm:  0.0243 [38;2;54;234;195m memory: 19.50GiB(41.05%) [34m tps: 2,067 [36m tflops: 14.91 [35m mfu: 4.78%[39m
[rank3]:[titan] 2025-10-20 07:49:11,220 - root - INFO - [31m step: 400 [32m loss:  4.9314 [38;2;180;60;0m grad_norm:  0.0243 [38;2;54;234;195m memory: 38.80GiB(81.67%) [34m tps: 2,067 [36m tflops: 14.91 [35m mfu: 4.78%[39m
[rank0]:[titan] 2025-10-20 07:49:11,222 - root - INFO - [31m step: 400 [32m loss: -32.0000 [38;2;180;60;0m grad_norm:  0.0243 [38;2;54;234;195m memory: 19.50GiB(41.05%) [34m tps: 2,067 [36m tflops: 14.91 [35m mfu: 4.78%[39m
2025-10-20 08:41:01,973 - [GC] Peforming periodical GC collection 0.01 seconds
[rank0]:[titan] 2025-10-20 08:41:01,973 - root - INFO - [GC] Peforming periodical GC collection 0.01 seconds
2025-10-20 09:33:49,510 - [GC] Peforming periodical GC collection 0.01 seconds
[rank0]:[titan] 2025-10-20 09:33:49,510 - root - INFO - [GC] Peforming periodical GC collection 0.01 seconds
2025-10-20 09:34:52,788 - [31m step: 500 [32m loss: -32.0000 [38;2;180;60;0m grad_norm:  0.0183 [38;2;54;234;195m memory: 14.70GiB(30.94%) [34m tps: 2,067 [36m tflops: 14.91 [35m mfu: 4.78%[39m
2025-10-20 09:34:52,788 - Saving the checkpoint (or staging if async is enabled).
2025-10-20 09:34:52,789 - Saving a model only checkpoint in torch.float16 at last step, step 500.
2025-10-20 09:34:52,792 - [31m step: 500 [32m loss: -32.0000 [38;2;180;60;0m grad_norm:  0.0183 [38;2;54;234;195m memory: 18.25GiB(38.42%) [34m tps: 2,067 [36m tflops: 14.91 [35m mfu: 4.78%[39m
2025-10-20 09:34:52,793 - Saving the checkpoint (or staging if async is enabled).
2025-10-20 09:34:52,793 - Saving a model only checkpoint in torch.float16 at last step, step 500.
2025-10-20 09:34:52,802 - [31m step: 500 [32m loss:  4.5626 [38;2;180;60;0m grad_norm:  0.0183 [38;2;54;234;195m memory: 38.80GiB(81.67%) [34m tps: 2,067 [36m tflops: 14.91 [35m mfu: 4.78%[39m
2025-10-20 09:34:52,803 - Saving the checkpoint (or staging if async is enabled).
2025-10-20 09:34:52,804 - Saving a model only checkpoint in torch.float16 at last step, step 500.
2025-10-20 09:34:52,805 - [31m step: 500 [32m loss: -32.0000 [38;2;180;60;0m grad_norm:  0.0183 [38;2;54;234;195m memory: 19.50GiB(41.05%) [34m tps: 2,067 [36m tflops: 14.91 [35m mfu: 4.78%[39m
2025-10-20 09:34:52,805 - Saving the checkpoint (or staging if async is enabled).
2025-10-20 09:34:52,806 - Saving a model only checkpoint in torch.float16 at last step, step 500.
[rank3]:[titan] 2025-10-20 09:34:52,802 - root - INFO - [31m step: 500 [32m loss:  4.5626 [38;2;180;60;0m grad_norm:  0.0183 [38;2;54;234;195m memory: 38.80GiB(81.67%) [34m tps: 2,067 [36m tflops: 14.91 [35m mfu: 4.78%[39m
[rank3]:[titan] 2025-10-20 09:34:52,803 - root - INFO - Saving the checkpoint (or staging if async is enabled).
[rank3]:[titan] 2025-10-20 09:34:52,804 - root - INFO - Saving a model only checkpoint in torch.float16 at last step, step 500.
[rank0]:[titan] 2025-10-20 09:34:52,805 - root - INFO - [31m step: 500 [32m loss: -32.0000 [38;2;180;60;0m grad_norm:  0.0183 [38;2;54;234;195m memory: 19.50GiB(41.05%) [34m tps: 2,067 [36m tflops: 14.91 [35m mfu: 4.78%[39m
[rank0]:[titan] 2025-10-20 09:34:52,805 - root - INFO - Saving the checkpoint (or staging if async is enabled).
[rank0]:[titan] 2025-10-20 09:34:52,806 - root - INFO - Saving a model only checkpoint in torch.float16 at last step, step 500.
[rank3]:Traceback (most recent call last):
[rank3]:  File "<frozen runpy>", line 198, in _run_module_as_main
[rank3]:  File "<frozen runpy>", line 88, in _run_code
[rank3]:  File "/home/shcho/torchtitan/timelyfreeze/train.py", line 726, in <module>
[rank3]:    trainer.train()
[rank3]:  File "/data2/shcho/miniforge3/envs/llm/lib/python3.11/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 362, in wrapper
[rank3]:    return f(*args, **kwargs)
[rank3]:           ^^^^^^^^^^^^^^^^^^
[rank3]:  File "/home/shcho/torchtitan/timelyfreeze/train.py", line 586, in train
[rank3]:    self.checkpointer.save(
[rank3]:  File "/data2/shcho/miniforge3/envs/llm/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 122, in decorate_context
[rank3]:    return func(*args, **kwargs)
[rank3]:           ^^^^^^^^^^^^^^^^^^^^^
[rank3]:  File "/home/shcho/torchtitan/torchtitan/components/checkpoint.py", line 479, in save
[rank3]:    self._save_last_step(curr_step)
[rank3]:  File "/home/shcho/torchtitan/torchtitan/components/checkpoint.py", line 733, in _save_last_step
[rank3]:    self.dcp_save(
[rank3]:  File "/data2/shcho/miniforge3/envs/llm/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 122, in decorate_context
[rank3]:    return func(*args, **kwargs)
[rank3]:           ^^^^^^^^^^^^^^^^^^^^^
[rank3]:  File "/home/shcho/torchtitan/torchtitan/components/checkpoint.py", line 401, in dcp_save
[rank3]:    ret = dcp.save(
[rank3]:          ^^^^^^^^^
[rank3]:  File "/data2/shcho/miniforge3/envs/llm/lib/python3.11/site-packages/torch/distributed/checkpoint/logger.py", line 91, in wrapper
[rank3]:    result = func(*args, **kwargs)
[rank3]:             ^^^^^^^^^^^^^^^^^^^^^
[rank3]:  File "/data2/shcho/miniforge3/envs/llm/lib/python3.11/site-packages/torch/distributed/checkpoint/utils.py", line 482, in inner_func
[rank3]:    return func(*args, **kwargs)
[rank3]:           ^^^^^^^^^^^^^^^^^^^^^
[rank3]:  File "/data2/shcho/miniforge3/envs/llm/lib/python3.11/site-packages/torch/distributed/checkpoint/state_dict_saver.py", line 193, in save
[rank3]:    return _save_state_dict(
[rank3]:           ^^^^^^^^^^^^^^^^^
[rank3]:  File "/data2/shcho/miniforge3/envs/llm/lib/python3.11/site-packages/torch/distributed/checkpoint/state_dict_saver.py", line 481, in _save_state_dict
[rank3]:    metadata = distW.all_reduce("write", write_data, finish_checkpoint)
[rank3]:               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank3]:  File "/data2/shcho/miniforge3/envs/llm/lib/python3.11/site-packages/torch/distributed/checkpoint/utils.py", line 263, in all_reduce
[rank3]:    raise final_result
[rank3]:torch.distributed.checkpoint.api.CheckpointException: CheckpointException ranks:dict_keys([1, 2, 3])
[rank3]:Traceback (most recent call last): (RANK 1)
[rank3]:  File "/data2/shcho/miniforge3/envs/llm/lib/python3.11/site-packages/torch/distributed/checkpoint/utils.py", line 241, in all_reduce
[rank3]:    local_data = map_fun()
[rank3]:                 ^^^^^^^^^
[rank3]:  File "/data2/shcho/miniforge3/envs/llm/lib/python3.11/site-packages/torch/distributed/checkpoint/logger.py", line 91, in wrapper
[rank3]:    result = func(*args, **kwargs)
[rank3]:             ^^^^^^^^^^^^^^^^^^^^^
[rank3]:  File "/data2/shcho/miniforge3/envs/llm/lib/python3.11/site-packages/torch/distributed/checkpoint/state_dict_saver.py", line 468, in write_data
[rank3]:    all_writes = storage_writer.write_data(final_local_plan, planner)
[rank3]:                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank3]:  File "/data2/shcho/miniforge3/envs/llm/lib/python3.11/site-packages/torch/distributed/checkpoint/hf_storage.py", line 127, in write_data
[rank3]:    buckets = self._split_by_storage_plan(storage_plan, plan.items)
[rank3]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank3]:  File "/data2/shcho/miniforge3/envs/llm/lib/python3.11/site-packages/torch/distributed/checkpoint/hf_storage.py", line 189, in _split_by_storage_plan
[rank3]:    idx = storage_plan[key]
[rank3]:          ~~~~~~~~~~~~^^^^^
[rank3]:KeyError: 'model.layers.4.self_attn.q_proj.weight'
[rank3]:Traceback (most recent call last): (RANK 2)
[rank3]:  File "/data2/shcho/miniforge3/envs/llm/lib/python3.11/site-packages/torch/distributed/checkpoint/utils.py", line 241, in all_reduce
[rank3]:    local_data = map_fun()
[rank3]:                 ^^^^^^^^^
[rank3]:  File "/data2/shcho/miniforge3/envs/llm/lib/python3.11/site-packages/torch/distributed/checkpoint/logger.py", line 91, in wrapper
[rank3]:    result = func(*args, **kwargs)
[rank3]:             ^^^^^^^^^^^^^^^^^^^^^
[rank3]:  File "/data2/shcho/miniforge3/envs/llm/lib/python3.11/site-packages/torch/distributed/checkpoint/state_dict_saver.py", line 468, in write_data
[rank3]:    all_writes = storage_writer.write_data(final_local_plan, planner)
[rank3]:                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank3]:  File "/data2/shcho/miniforge3/envs/llm/lib/python3.11/site-packages/torch/distributed/checkpoint/hf_storage.py", line 127, in write_data
[rank3]:    buckets = self._split_by_storage_plan(storage_plan, plan.items)
[rank3]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank3]:  File "/data2/shcho/miniforge3/envs/llm/lib/python3.11/site-packages/torch/distributed/checkpoint/hf_storage.py", line 189, in _split_by_storage_plan
[rank3]:    idx = storage_plan[key]
[rank3]:          ~~~~~~~~~~~~^^^^^
[rank3]:KeyError: 'model.layers.9.self_attn.q_proj.weight'
[rank3]:Traceback (most recent call last): (RANK 3)
[rank3]:  File "/data2/shcho/miniforge3/envs/llm/lib/python3.11/site-packages/torch/distributed/checkpoint/utils.py", line 241, in all_reduce
[rank3]:    local_data = map_fun()
[rank3]:                 ^^^^^^^^^
[rank3]:  File "/data2/shcho/miniforge3/envs/llm/lib/python3.11/site-packages/torch/distributed/checkpoint/logger.py", line 91, in wrapper
[rank3]:    result = func(*args, **kwargs)
[rank3]:             ^^^^^^^^^^^^^^^^^^^^^
[rank3]:  File "/data2/shcho/miniforge3/envs/llm/lib/python3.11/site-packages/torch/distributed/checkpoint/state_dict_saver.py", line 468, in write_data
[rank3]:    all_writes = storage_writer.write_data(final_local_plan, planner)
[rank3]:                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank3]:  File "/data2/shcho/miniforge3/envs/llm/lib/python3.11/site-packages/torch/distributed/checkpoint/hf_storage.py", line 127, in write_data
[rank3]:    buckets = self._split_by_storage_plan(storage_plan, plan.items)
[rank3]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank3]:  File "/data2/shcho/miniforge3/envs/llm/lib/python3.11/site-packages/torch/distributed/checkpoint/hf_storage.py", line 189, in _split_by_storage_plan
[rank3]:    idx = storage_plan[key]
[rank3]:          ~~~~~~~~~~~~^^^^^
[rank3]:KeyError: 'model.layers.13.self_attn.q_proj.weight'
[rank3]:
[rank3]:[rank3]: Traceback (most recent call last):
[rank3]:[rank3]:   File "<frozen runpy>", line 198, in _run_module_as_main
[rank3]:[rank3]:   File "<frozen runpy>", line 88, in _run_code
[rank3]:[rank3]:   File "/home/shcho/torchtitan/timelyfreeze/train.py", line 726, in <module>
[rank3]:[rank3]:     trainer.train()
[rank3]:[rank3]:   File "/data2/shcho/miniforge3/envs/llm/lib/python3.11/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 362, in wrapper
[rank3]:[rank3]:     return f(*args, **kwargs)
[rank3]:[rank3]:            ^^^^^^^^^^^^^^^^^^
[rank3]:[rank3]:   File "/home/shcho/torchtitan/timelyfreeze/train.py", line 586, in train
[rank3]:[rank3]:     self.checkpointer.save(
[rank3]:[rank3]:   File "/data2/shcho/miniforge3/envs/llm/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 122, in decorate_context
[rank3]:[rank3]:     return func(*args, **kwargs)
[rank3]:[rank3]:            ^^^^^^^^^^^^^^^^^^^^^
[rank3]:[rank3]:   File "/home/shcho/torchtitan/torchtitan/components/checkpoint.py", line 479, in save
[rank3]:[rank3]:     self._save_last_step(curr_step)
[rank3]:[rank3]:   File "/home/shcho/torchtitan/torchtitan/components/checkpoint.py", line 733, in _save_last_step
[rank3]:[rank3]:     self.dcp_save(
[rank3]:[rank3]:   File "/data2/shcho/miniforge3/envs/llm/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 122, in decorate_context
[rank3]:[rank3]:     return func(*args, **kwargs)
[rank3]:[rank3]:            ^^^^^^^^^^^^^^^^^^^^^
[rank3]:[rank3]:   File "/home/shcho/torchtitan/torchtitan/components/checkpoint.py", line 401, in dcp_save
[rank3]:[rank3]:     ret = dcp.save(
[rank3]:[rank3]:           ^^^^^^^^^
[rank3]:[rank3]:   File "/data2/shcho/miniforge3/envs/llm/lib/python3.11/site-packages/torch/distributed/checkpoint/logger.py", line 91, in wrapper
[rank3]:[rank3]:     result = func(*args, **kwargs)
[rank3]:[rank3]:              ^^^^^^^^^^^^^^^^^^^^^
[rank3]:[rank3]:   File "/data2/shcho/miniforge3/envs/llm/lib/python3.11/site-packages/torch/distributed/checkpoint/utils.py", line 482, in inner_func
[rank3]:[rank3]:     return func(*args, **kwargs)
[rank3]:[rank3]:            ^^^^^^^^^^^^^^^^^^^^^
[rank3]:[rank3]:   File "/data2/shcho/miniforge3/envs/llm/lib/python3.11/site-packages/torch/distributed/checkpoint/state_dict_saver.py", line 193, in save
[rank3]:[rank3]:     return _save_state_dict(
[rank3]:[rank3]:            ^^^^^^^^^^^^^^^^^
[rank3]:[rank3]:   File "/data2/shcho/miniforge3/envs/llm/lib/python3.11/site-packages/torch/distributed/checkpoint/state_dict_saver.py", line 481, in _save_state_dict
[rank3]:[rank3]:     metadata = distW.all_reduce("write", write_data, finish_checkpoint)
[rank3]:[rank3]:                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank3]:[rank3]:   File "/data2/shcho/miniforge3/envs/llm/lib/python3.11/site-packages/torch/distributed/checkpoint/utils.py", line 263, in all_reduce
[rank3]:[rank3]:     raise final_result
[rank3]:[rank3]: torch.distributed.checkpoint.api.CheckpointException: CheckpointException ranks:dict_keys([1, 2, 3])
[rank3]:[rank3]: Traceback (most recent call last): (RANK 1)
[rank3]:[rank3]:   File "/data2/shcho/miniforge3/envs/llm/lib/python3.11/site-packages/torch/distributed/checkpoint/utils.py", line 241, in all_reduce
[rank3]:[rank3]:     local_data = map_fun()
[rank3]:[rank3]:                  ^^^^^^^^^
[rank3]:[rank3]:   File "/data2/shcho/miniforge3/envs/llm/lib/python3.11/site-packages/torch/distributed/checkpoint/logger.py", line 91, in wrapper
[rank3]:[rank3]:     result = func(*args, **kwargs)
[rank3]:[rank3]:              ^^^^^^^^^^^^^^^^^^^^^
[rank3]:[rank3]:   File "/data2/shcho/miniforge3/envs/llm/lib/python3.11/site-packages/torch/distributed/checkpoint/state_dict_saver.py", line 468, in write_data
[rank3]:[rank3]:     all_writes = storage_writer.write_data(final_local_plan, planner)
[rank3]:[rank3]:                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank3]:[rank3]:   File "/data2/shcho/miniforge3/envs/llm/lib/python3.11/site-packages/torch/distributed/checkpoint/hf_storage.py", line 127, in write_data
[rank3]:[rank3]:     buckets = self._split_by_storage_plan(storage_plan, plan.items)
[rank3]:[rank3]:               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank3]:[rank3]:   File "/data2/shcho/miniforge3/envs/llm/lib/python3.11/site-packages/torch/distributed/checkpoint/hf_storage.py", line 189, in _split_by_storage_plan
[rank3]:[rank3]:     idx = storage_plan[key]
[rank3]:[rank3]:           ~~~~~~~~~~~~^^^^^
[rank3]:[rank3]: KeyError: 'model.layers.4.self_attn.q_proj.weight'
[rank3]:[rank3]: Traceback (most recent call last): (RANK 2)
[rank3]:[rank3]:   File "/data2/shcho/miniforge3/envs/llm/lib/python3.11/site-packages/torch/distributed/checkpoint/utils.py", line 241, in all_reduce
[rank3]:[rank3]:     local_data = map_fun()
[rank3]:[rank3]:                  ^^^^^^^^^
[rank3]:[rank3]:   File "/data2/shcho/miniforge3/envs/llm/lib/python3.11/site-packages/torch/distributed/checkpoint/logger.py", line 91, in wrapper
[rank3]:[rank3]:     result = func(*args, **kwargs)
[rank3]:[rank3]:              ^^^^^^^^^^^^^^^^^^^^^
[rank3]:[rank3]:   File "/data2/shcho/miniforge3/envs/llm/lib/python3.11/site-packages/torch/distributed/checkpoint/state_dict_saver.py", line 468, in write_data
[rank3]:[rank3]:     all_writes = storage_writer.write_data(final_local_plan, planner)
[rank3]:[rank3]:                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank3]:[rank3]:   File "/data2/shcho/miniforge3/envs/llm/lib/python3.11/site-packages/torch/distributed/checkpoint/hf_storage.py", line 127, in write_data
[rank3]:[rank3]:     buckets = self._split_by_storage_plan(storage_plan, plan.items)
[rank3]:[rank3]:               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank3]:[rank3]:   File "/data2/shcho/miniforge3/envs/llm/lib/python3.11/site-packages/torch/distributed/checkpoint/hf_storage.py", line 189, in _split_by_storage_plan
[rank3]:[rank3]:     idx = storage_plan[key]
[rank3]:[rank3]:           ~~~~~~~~~~~~^^^^^
[rank3]:[rank3]: KeyError: 'model.layers.9.self_attn.q_proj.weight'
[rank3]:[rank3]: Traceback (most recent call last): (RANK 3)
[rank3]:[rank3]:   File "/data2/shcho/miniforge3/envs/llm/lib/python3.11/site-packages/torch/distributed/checkpoint/utils.py", line 241, in all_reduce
[rank3]:[rank3]:     local_data = map_fun()
[rank3]:[rank3]:                  ^^^^^^^^^
[rank3]:[rank3]:   File "/data2/shcho/miniforge3/envs/llm/lib/python3.11/site-packages/torch/distributed/checkpoint/logger.py", line 91, in wrapper
[rank3]:[rank3]:     result = func(*args, **kwargs)
[rank3]:[rank3]:              ^^^^^^^^^^^^^^^^^^^^^
[rank3]:[rank3]:   File "/data2/shcho/miniforge3/envs/llm/lib/python3.11/site-packages/torch/distributed/checkpoint/state_dict_saver.py", line 468, in write_data
[rank3]:[rank3]:     all_writes = storage_writer.write_data(final_local_plan, planner)
[rank3]:[rank3]:                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank3]:[rank3]:   File "/data2/shcho/miniforge3/envs/llm/lib/python3.11/site-packages/torch/distributed/checkpoint/hf_storage.py", line 127, in write_data
[rank3]:[rank3]:     buckets = self._split_by_storage_plan(storage_plan, plan.items)
[rank3]:[rank3]:               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank3]:[rank3]:   File "/data2/shcho/miniforge3/envs/llm/lib/python3.11/site-packages/torch/distributed/checkpoint/hf_storage.py", line 189, in _split_by_storage_plan
[rank3]:[rank3]:     idx = storage_plan[key]
[rank3]:[rank3]:           ~~~~~~~~~~~~^^^^^
[rank3]:[rank3]: KeyError: 'model.layers.13.self_attn.q_proj.weight'
[rank3]:
[rank0]:[rank0]: Traceback (most recent call last):
[rank0]:[rank0]:   File "<frozen runpy>", line 198, in _run_module_as_main
[rank0]:[rank0]:   File "<frozen runpy>", line 88, in _run_code
[rank0]:[rank0]:   File "/home/shcho/torchtitan/timelyfreeze/train.py", line 726, in <module>
[rank0]:[rank0]:     trainer.train()
[rank0]:[rank0]:   File "/data2/shcho/miniforge3/envs/llm/lib/python3.11/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 362, in wrapper
[rank0]:[rank0]:     return f(*args, **kwargs)
[rank0]:[rank0]:            ^^^^^^^^^^^^^^^^^^
[rank0]:[rank0]:   File "/home/shcho/torchtitan/timelyfreeze/train.py", line 586, in train
[rank0]:[rank0]:     self.checkpointer.save(
[rank0]:[rank0]:   File "/data2/shcho/miniforge3/envs/llm/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 122, in decorate_context
[rank0]:[rank0]:     return func(*args, **kwargs)
[rank0]:[rank0]:            ^^^^^^^^^^^^^^^^^^^^^
[rank0]:[rank0]:   File "/home/shcho/torchtitan/torchtitan/components/checkpoint.py", line 479, in save
[rank0]:[rank0]:     self._save_last_step(curr_step)
[rank0]:[rank0]:   File "/home/shcho/torchtitan/torchtitan/components/checkpoint.py", line 733, in _save_last_step
[rank0]:[rank0]:     self.dcp_save(
[rank0]:[rank0]:   File "/data2/shcho/miniforge3/envs/llm/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 122, in decorate_context
[rank0]:[rank0]:     return func(*args, **kwargs)
[rank0]:[rank0]:            ^^^^^^^^^^^^^^^^^^^^^
[rank0]:[rank0]:   File "/home/shcho/torchtitan/torchtitan/components/checkpoint.py", line 401, in dcp_save
[rank0]:[rank0]:     ret = dcp.save(
[rank0]:[rank0]:           ^^^^^^^^^
[rank0]:[rank0]:   File "/data2/shcho/miniforge3/envs/llm/lib/python3.11/site-packages/torch/distributed/checkpoint/logger.py", line 91, in wrapper
[rank0]:[rank0]:     result = func(*args, **kwargs)
[rank0]:[rank0]:              ^^^^^^^^^^^^^^^^^^^^^
[rank0]:[rank0]:   File "/data2/shcho/miniforge3/envs/llm/lib/python3.11/site-packages/torch/distributed/checkpoint/utils.py", line 482, in inner_func
[rank0]:[rank0]:     return func(*args, **kwargs)
[rank0]:[rank0]:            ^^^^^^^^^^^^^^^^^^^^^
[rank0]:[rank0]:   File "/data2/shcho/miniforge3/envs/llm/lib/python3.11/site-packages/torch/distributed/checkpoint/state_dict_saver.py", line 193, in save
[rank0]:[rank0]:     return _save_state_dict(
[rank0]:[rank0]:            ^^^^^^^^^^^^^^^^^
[rank0]:[rank0]:   File "/data2/shcho/miniforge3/envs/llm/lib/python3.11/site-packages/torch/distributed/checkpoint/state_dict_saver.py", line 481, in _save_state_dict
[rank0]:[rank0]:     metadata = distW.all_reduce("write", write_data, finish_checkpoint)
[rank0]:[rank0]:                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank0]:[rank0]:   File "/data2/shcho/miniforge3/envs/llm/lib/python3.11/site-packages/torch/distributed/checkpoint/utils.py", line 263, in all_reduce
[rank0]:[rank0]:     raise final_result
[rank0]:[rank0]: torch.distributed.checkpoint.api.CheckpointException: CheckpointException ranks:dict_keys([1, 2, 3])
[rank0]:[rank0]: Traceback (most recent call last): (RANK 1)
[rank0]:[rank0]:   File "/data2/shcho/miniforge3/envs/llm/lib/python3.11/site-packages/torch/distributed/checkpoint/utils.py", line 241, in all_reduce
[rank0]:[rank0]:     local_data = map_fun()
[rank0]:[rank0]:                  ^^^^^^^^^
[rank0]:[rank0]:   File "/data2/shcho/miniforge3/envs/llm/lib/python3.11/site-packages/torch/distributed/checkpoint/logger.py", line 91, in wrapper
[rank0]:[rank0]:     result = func(*args, **kwargs)
[rank0]:[rank0]:              ^^^^^^^^^^^^^^^^^^^^^
[rank0]:[rank0]:   File "/data2/shcho/miniforge3/envs/llm/lib/python3.11/site-packages/torch/distributed/checkpoint/state_dict_saver.py", line 468, in write_data
[rank0]:[rank0]:     all_writes = storage_writer.write_data(final_local_plan, planner)
[rank0]:[rank0]:                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank0]:[rank0]:   File "/data2/shcho/miniforge3/envs/llm/lib/python3.11/site-packages/torch/distributed/checkpoint/hf_storage.py", line 127, in write_data
[rank0]:[rank0]:     buckets = self._split_by_storage_plan(storage_plan, plan.items)
[rank0]:[rank0]:               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank0]:[rank0]:   File "/data2/shcho/miniforge3/envs/llm/lib/python3.11/site-packages/torch/distributed/checkpoint/hf_storage.py", line 189, in _split_by_storage_plan
[rank0]:[rank0]:     idx = storage_plan[key]
[rank0]:[rank0]:           ~~~~~~~~~~~~^^^^^
[rank0]:[rank0]: KeyError: 'model.layers.4.self_attn.q_proj.weight'
[rank0]:[rank0]: Traceback (most recent call last): (RANK 2)
[rank0]:[rank0]:   File "/data2/shcho/miniforge3/envs/llm/lib/python3.11/site-packages/torch/distributed/checkpoint/utils.py", line 241, in all_reduce
[rank0]:[rank0]:     local_data = map_fun()
[rank0]:[rank0]:                  ^^^^^^^^^
[rank0]:[rank0]:   File "/data2/shcho/miniforge3/envs/llm/lib/python3.11/site-packages/torch/distributed/checkpoint/logger.py", line 91, in wrapper
[rank0]:[rank0]:     result = func(*args, **kwargs)
[rank0]:[rank0]:              ^^^^^^^^^^^^^^^^^^^^^
[rank0]:[rank0]:   File "/data2/shcho/miniforge3/envs/llm/lib/python3.11/site-packages/torch/distributed/checkpoint/state_dict_saver.py", line 468, in write_data
[rank0]:[rank0]:     all_writes = storage_writer.write_data(final_local_plan, planner)
[rank0]:[rank0]:                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank0]:[rank0]:   File "/data2/shcho/miniforge3/envs/llm/lib/python3.11/site-packages/torch/distributed/checkpoint/hf_storage.py", line 127, in write_data
[rank0]:[rank0]:     buckets = self._split_by_storage_plan(storage_plan, plan.items)
[rank0]:[rank0]:               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank0]:[rank0]:   File "/data2/shcho/miniforge3/envs/llm/lib/python3.11/site-packages/torch/distributed/checkpoint/hf_storage.py", line 189, in _split_by_storage_plan
[rank0]:[rank0]:     idx = storage_plan[key]
[rank0]:[rank0]:           ~~~~~~~~~~~~^^^^^
[rank0]:[rank0]: KeyError: 'model.layers.9.self_attn.q_proj.weight'
[rank0]:[rank0]: Traceback (most recent call last): (RANK 3)
[rank0]:[rank0]:   File "/data2/shcho/miniforge3/envs/llm/lib/python3.11/site-packages/torch/distributed/checkpoint/utils.py", line 241, in all_reduce
[rank0]:[rank0]:     local_data = map_fun()
[rank0]:[rank0]:                  ^^^^^^^^^
[rank0]:[rank0]:   File "/data2/shcho/miniforge3/envs/llm/lib/python3.11/site-packages/torch/distributed/checkpoint/logger.py", line 91, in wrapper
[rank0]:[rank0]:     result = func(*args, **kwargs)
[rank0]:[rank0]:              ^^^^^^^^^^^^^^^^^^^^^
[rank0]:[rank0]:   File "/data2/shcho/miniforge3/envs/llm/lib/python3.11/site-packages/torch/distributed/checkpoint/state_dict_saver.py", line 468, in write_data
[rank0]:[rank0]:     all_writes = storage_writer.write_data(final_local_plan, planner)
[rank0]:[rank0]:                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank0]:[rank0]:   File "/data2/shcho/miniforge3/envs/llm/lib/python3.11/site-packages/torch/distributed/checkpoint/hf_storage.py", line 127, in write_data
[rank0]:[rank0]:     buckets = self._split_by_storage_plan(storage_plan, plan.items)
[rank0]:[rank0]:               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank0]:[rank0]:   File "/data2/shcho/miniforge3/envs/llm/lib/python3.11/site-packages/torch/distributed/checkpoint/hf_storage.py", line 189, in _split_by_storage_plan
[rank0]:[rank0]:     idx = storage_plan[key]
[rank0]:[rank0]:           ~~~~~~~~~~~~^^^^^
[rank0]:[rank0]: KeyError: 'model.layers.13.self_attn.q_proj.weight'
[rank0]:
[rank0]:[rank0]:[W1020 09:34:59.527521813 ProcessGroupNCCL.cpp:1552] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
W1020 09:35:00.374000 204317 site-packages/torch/distributed/elastic/multiprocessing/api.py:940] Sending process 204369 closing signal SIGTERM
W1020 09:35:00.376000 204317 site-packages/torch/distributed/elastic/multiprocessing/api.py:940] Sending process 204371 closing signal SIGTERM
W1020 09:35:00.376000 204317 site-packages/torch/distributed/elastic/multiprocessing/api.py:940] Sending process 204372 closing signal SIGTERM
E1020 09:35:00.927000 204317 site-packages/torch/distributed/elastic/multiprocessing/api.py:914] failed (exitcode: 1) local_rank: 1 (pid: 204370) of binary: /data2/shcho/miniforge3/envs/llm/bin/python3.11
[rank0]:Stage 0: Modules to keep: {'layers.1', 'layers.2', 'tok_embeddings', 'layers.3', 'layers.0'}
[rank3]:Stage 3: Modules to keep: {'layers.14', 'norm', 'output', 'layers.13', 'layers.15'}
[rank0]:[Gloo] Rank 0 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
[rank3]:[Gloo] Rank 3 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
[rank3]:----- TimelyFreeze‚è∞ Configuration:
[rank3]:	- job:
[rank3]:		- config_file: /home/shcho/torchtitan/logs/dmserver1/1020_main/config.toml
[rank3]:		- dump_folder: /data2/shcho/torchtitan
[rank3]:		- description: "Main Table Experiment"
[rank3]:		- use_for_integration_test: False
[rank3]:		- print_args: False
[rank3]:		- basename: 1020_gpipe_fullrand7_dm4
[rank3]:	- profiling:
[rank3]:		- enable_profiling: False
[rank3]:		- save_traces_folder: profile_trace/1020_gpipe_fullrand7_dm4/1020_gpipe_fullrand7_dm4
[rank3]:		- profile_freq: 100
[rank3]:		- enable_memory_snapshot: False
[rank3]:		- save_memory_snapshot_folder: memory_snapshot/1020_gpipe_fullrand7_dm4/1020_gpipe_fullrand7_dm4
[rank3]:	- metrics:
[rank3]:		- log_freq: 100
[rank3]:		- enable_tensorboard: False
[rank3]:		- disable_color_printing: False
[rank3]:		- save_tb_folder: tb/1020_gpipe_fullrand7_dm4/1020_gpipe_fullrand7_dm4
[rank3]:		- save_for_all_ranks: False
[rank3]:		- enable_wandb: True
[rank3]:		- log_file: /home/shcho/torchtitan/logs/dmserver1/1020_main/1020_gpipe_fullrand7.log
[rank3]:		- wandb_name: 1020_gpipe_fullrand7_dm4
[rank3]:		- draw_graph: False
[rank3]:	- model:
[rank3]:		- name: llama3
[rank3]:		- flavor: 1B
[rank3]:		- tokenizer_path: ./assets/tokenizer/Llama-3.2-1B
[rank3]:		- converters: []
[rank3]:		- print_after_conversion: False
[rank3]:	- optimizer:
[rank3]:		- name: AdamW
[rank3]:		- lr: 0.0003
[rank3]:		- beta1: 0.9
[rank3]:		- beta2: 0.95
[rank3]:		- eps: 1e-08
[rank3]:		- weight_decay: 0.1
[rank3]:		- implementation: fused
[rank3]:		- early_step_in_backward: False
[rank3]:	- lr_scheduler:
[rank3]:		- warmup_steps: 200
[rank3]:		- decay_ratio: 0.8
[rank3]:		- decay_type: cosine
[rank3]:		- min_lr_factor: 0.0
[rank3]:	- training:
[rank3]:		- dataset: slimorca
[rank3]:		- dataset_path: None
[rank3]:		- local_batch_size: 16
[rank3]:		- global_batch_size: 512
[rank3]:		- seq_len: 1024
[rank3]:		- max_norm: 1.0
[rank3]:		- steps: 500
[rank3]:		- enable_cpu_offload: False
[rank3]:		- mixed_precision_param: bfloat16
[rank3]:		- mixed_precision_reduce: float32
[rank3]:		- compile: False
[rank3]:		- gc_freq: 50
[rank3]:		- gc_debug: False
[rank3]:		- seed: None
[rank3]:		- deterministic: False
[rank3]:	- parallelism:
[rank3]:		- data_parallel_replicate_degree: 1
[rank3]:		- enable_compiled_autograd: False
[rank3]:		- data_parallel_shard_degree: -1
[rank3]:		- fsdp_reshard_after_forward: default
[rank3]:		- tensor_parallel_degree: 1
[rank3]:		- disable_loss_parallel: False
[rank3]:		- enable_async_tensor_parallel: False
[rank3]:		- pipeline_parallel_degree: 4
[rank3]:		- pipeline_parallel_split_points: []
[rank3]:		- module_fqns_per_model_part: None
[rank3]:		- pipeline_parallel_first_stage_less_layers: 1
[rank3]:		- pipeline_parallel_last_stage_less_layers: 1
[rank3]:		- pipeline_parallel_layers_per_stage: None
[rank3]:		- pipeline_parallel_schedule: gpipe
[rank3]:		- pipeline_parallel_schedule_csv: 
[rank3]:		- pipeline_parallel_microbatch_size: 1
[rank3]:		- context_parallel_degree: 1
[rank3]:		- context_parallel_rotate_method: allgather
[rank3]:		- expert_parallel_degree: 1
[rank3]:		- pp: 1
[rank3]:		- pp_scheduler: None
[rank3]:		- stages_per_rank: 1
[rank3]:		- stages_list: [3]
[rank3]:		- microbatches: 16
[rank3]:	- checkpoint:
[rank3]:		- enable_checkpoint: True
[rank3]:		- folder: checkpoint/1020_gpipe_fullrand7_dm4/1020_gpipe_fullrand7_dm4
[rank3]:		- interval: 500
[rank3]:		- initial_load_path: None
[rank3]:		- initial_load_model_only: True
[rank3]:		- initial_load_in_hf: False
[rank3]:		- last_save_model_only: True
[rank3]:		- last_save_in_hf: True
[rank3]:		- export_dtype: float16
[rank3]:		- async_mode: async
[rank3]:		- keep_latest_k: 2
[rank3]:		- load_step: -1
[rank3]:		- exclude_from_loading: ['dataloader', 'lr_scheduler', 'optimizer', 'train_state']
[rank3]:		- enable_first_step_checkpoint: False
[rank3]:		- create_seed_checkpoint: False
[rank3]:	- activation_checkpoint:
[rank3]:		- mode: none
[rank3]:		- selective_ac_option: op
[rank3]:		- per_op_sac_force_recompute_mm_shapes_by_fqns: ['moe.router.gate']
[rank3]:	- float8:
[rank3]:		- enable_fsdp_float8_all_gather: False
[rank3]:		- precompute_float8_dynamic_scale_for_fsdp: False
[rank3]:		- recipe_name: None
[rank3]:		- filter_fqns: ['output']
[rank3]:		- emulate: False
[rank3]:		- moe_fqns_prototype: []
[rank3]:	- mx:
[rank3]:		- mxfp8_dim1_cast_kernel_choice: triton
[rank3]:		- recipe_name: mxfp8
[rank3]:		- filter_fqns: ['output']
[rank3]:		- moe_fqns_prototype: []
[rank3]:	- comm:
[rank3]:		- init_timeout_seconds: 300
[rank3]:		- train_timeout_seconds: 300
[rank3]:		- trace_buf_size: 20000
[rank3]:		- save_traces_folder: comm_traces/1020_gpipe_fullrand7_dm4/1020_gpipe_fullrand7_dm4
[rank3]:		- world_size: 4
[rank3]:		- global_rank: 3
[rank3]:		- local_rank: 3
[rank3]:		- dp: 1
[rank3]:		- pp: 4
[rank3]:		- pp_rank: 3
[rank3]:		- dp_rank: 0
[rank3]:		- master_dp_rank: 0
[rank3]:	- memory_estimation:
[rank3]:		- enabled: False
[rank3]:		- disable_fake_mode: False
[rank3]:	- fault_tolerance:
[rank3]:		- enable: False
[rank3]:		- process_group: gloo
[rank3]:		- process_group_timeout_ms: 10000
[rank3]:		- replica_id: 0
[rank3]:		- group_size: 0
[rank3]:		- min_replica_size: 1
[rank3]:		- semi_sync_method: None
[rank3]:		- sync_steps: 5
[rank3]:		- should_quantize: False
[rank3]:		- fragment_sync_delay: 0
[rank3]:		- fragment_update_alpha: 0.0
[rank3]:	- experimental:
[rank3]:		- custom_import: 
[rank3]:		- custom_args_module: 
[rank3]:	- validation:
[rank3]:		- enabled: False
[rank3]:		- dataset: c4_validation
[rank3]:		- dataset_path: None
[rank3]:		- local_batch_size: 8
[rank3]:		- seq_len: 2048
[rank3]:		- freq: 10
[rank3]:		- steps: -1
[rank3]:	- freezing:
[rank3]:		- freeze: True
[rank3]:		- metric_type: fullrand7
[rank3]:		- phase_unit: 100
[rank3]:		- stability_check_freq: 50
[rank3]:		- aggressiveness: 0.0
[rank3]:
[rank3]:[1;34mwandb[0m: 
[rank3]:[1;34mwandb[0m: üöÄ View run [33m1020_gpipe_fullrand7_dm4[0m at: [34m[0m
[rank3]:[1;34mwandb[0m: Find logs at: [1;35m../../../data2/shcho/torchtitan/tb/1020_gpipe_fullrand7_dm4/20251020-0047/wandb/run-20251020_004741-6a8gq84r/logs[0m
Traceback (most recent call last):
  File "/data2/shcho/miniforge3/envs/llm/bin/torchrun", line 7, in <module>
    sys.exit(main())
             ^^^^^^
  File "/data2/shcho/miniforge3/envs/llm/lib/python3.11/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 362, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/data2/shcho/miniforge3/envs/llm/lib/python3.11/site-packages/torch/distributed/run.py", line 946, in main
    run(args)
  File "/data2/shcho/miniforge3/envs/llm/lib/python3.11/site-packages/torch/distributed/run.py", line 937, in run
    elastic_launch(
  File "/data2/shcho/miniforge3/envs/llm/lib/python3.11/site-packages/torch/distributed/launcher/api.py", line 159, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data2/shcho/miniforge3/envs/llm/lib/python3.11/site-packages/torch/distributed/launcher/api.py", line 300, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
timelyfreeze.train FAILED
------------------------------------------------------------
Failures:
[1]:
  time      : 2025-10-20_09:35:00
  host      : elga.kaist.ac.kr
  rank      : 0 (local_rank: 0)
  exitcode  : 1 (pid: 204369)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
[2]:
  time      : 2025-10-20_09:35:00
  host      : elga.kaist.ac.kr
  rank      : 2 (local_rank: 2)
  exitcode  : 1 (pid: 204371)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
[3]:
  time      : 2025-10-20_09:35:00
  host      : elga.kaist.ac.kr
  rank      : 3 (local_rank: 3)
  exitcode  : 1 (pid: 204372)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2025-10-20_09:35:00
  host      : elga.kaist.ac.kr
  rank      : 1 (local_rank: 1)
  exitcode  : 1 (pid: 204370)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================

üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•
‚úîÔ∏èCurrent Timestamp: 2025. 10. 21. (Ìôî) 03:12:35 KST
‚úîÔ∏èSERVER: dmserver1 (143.248.135.95),  GPUs: 3,4,5,6
‚úîÔ∏èSCRIPT: /home/shcho/torchtitan/logs/dmserver1/1020_main/run.sh
‚úîÔ∏èOUTPUT: /home/shcho/torchtitan/logs/dmserver1/1020_main/1020_gpipe_fullrand7.log
‚úîÔ∏èMain Table Experiment
‚úîÔ∏èRunning with fullrand7 x gpipe ... 
‚òëÔ∏è> torchrun --standalone --nnodes=1 --nproc_per_node=4 --local_addr=127.0.0.1 --local-ranks-filter=0,3 --role=rank --tee=3 -m timelyfreeze.train --job.config_file=/home/shcho/torchtitan/logs/dmserver1/1020_main/config.toml --job.description="Main Table Experiment" --training.global_batch_size=128 --training.local_batch_size=8 --parallelism.pipeline_parallel_microbatch_size=1 --training.seq_len=1024 --training.steps=500 --metrics.log_freq=50 --parallelism.pipeline_parallel_degree=4  --freezing.freeze --freezing.metric_type=fullrand7 --freezing.stability_check_freq=50 --freezing.aggressiveness=0.0
üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•
Traceback (most recent call last):
  File "/data2/shcho/miniforge3/envs/llm/bin/torchrun", line 7, in <module>
    from torch.distributed.run import main
  File "/data2/shcho/miniforge3/envs/llm/lib/python3.11/site-packages/torch/__init__.py", line 405, in <module>
    from torch._C import *  # noqa: F403
    ^^^^^^^^^^^^^^^^^^^^^^
ImportError: /data2/shcho/miniforge3/envs/llm/lib/python3.11/site-packages/torch/../../../././libcusparse.so.12: undefined symbol: __nvJitLinkGetErrorLogSize_12_9, version libnvJitLink.so.12

üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•
‚úîÔ∏èCurrent Timestamp: 2025. 10. 21. (Ìôî) 03:13:04 KST
‚úîÔ∏èSERVER: dmserver1 (143.248.135.95),  GPUs: 3,4,5,6
‚úîÔ∏èSCRIPT: /home/shcho/torchtitan/logs/dmserver1/1020_main/run.sh
‚úîÔ∏èOUTPUT: /home/shcho/torchtitan/logs/dmserver1/1020_main/1020_gpipe_fullrand7.log
‚úîÔ∏èMain Table Experiment
‚úîÔ∏èRunning with fullrand7 x gpipe ... 
‚òëÔ∏è> torchrun --standalone --nnodes=1 --nproc_per_node=4 --local_addr=127.0.0.1 --local-ranks-filter=0,3 --role=rank --tee=3 -m timelyfreeze.train --job.config_file=/home/shcho/torchtitan/logs/dmserver1/1020_main/config.toml --job.description="Main Table Experiment" --training.global_batch_size=128 --training.local_batch_size=8 --parallelism.pipeline_parallel_microbatch_size=1 --training.seq_len=1024 --training.steps=500 --metrics.log_freq=50 --parallelism.pipeline_parallel_degree=4  --freezing.freeze --freezing.metric_type=fullrand7 --freezing.stability_check_freq=50 --freezing.aggressiveness=0.0
üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•
[rank3]:Traceback (most recent call last):
[rank3]:  File "<frozen runpy>", line 198, in _run_module_as_main
[rank3]:  File "<frozen runpy>", line 88, in _run_code
[rank3]:  File "/home/shcho/torchtitan/timelyfreeze/train.py", line 37, in <module>
[rank3]:    from timelyfreeze.core.freezer import _Freezer, get_freezer
[rank3]:  File "/home/shcho/torchtitan/timelyfreeze/core/freezer.py", line 8, in <module>
[rank3]:    from . import logger as pplog
[rank3]:  File "/home/shcho/torchtitan/timelyfreeze/core/logger.py", line 8, in <module>
[rank3]:    from .config import TimelyFreezeConfig
[rank3]:  File "/home/shcho/torchtitan/timelyfreeze/core/config.py", line 10, in <module>
[rank3]:    from setproctitle import setproctitle
[rank3]:ModuleNotFoundError: No module named 'setproctitle'
[rank0]:Traceback (most recent call last):
[rank0]:  File "<frozen runpy>", line 198, in _run_module_as_main
[rank0]:  File "<frozen runpy>", line 88, in _run_code
[rank0]:  File "/home/shcho/torchtitan/timelyfreeze/train.py", line 37, in <module>
[rank0]:    from timelyfreeze.core.freezer import _Freezer, get_freezer
[rank0]:  File "/home/shcho/torchtitan/timelyfreeze/core/freezer.py", line 8, in <module>
[rank0]:    from . import logger as pplog
[rank0]:  File "/home/shcho/torchtitan/timelyfreeze/core/logger.py", line 8, in <module>
[rank0]:    from .config import TimelyFreezeConfig
[rank0]:  File "/home/shcho/torchtitan/timelyfreeze/core/config.py", line 10, in <module>
[rank0]:    from setproctitle import setproctitle
[rank0]:ModuleNotFoundError: No module named 'setproctitle'
W1021 03:13:11.575000 2552911 site-packages/torch/distributed/elastic/multiprocessing/api.py:940] Sending process 2552953 closing signal SIGTERM
W1021 03:13:11.576000 2552911 site-packages/torch/distributed/elastic/multiprocessing/api.py:940] Sending process 2552954 closing signal SIGTERM
E1021 03:13:11.766000 2552911 site-packages/torch/distributed/elastic/multiprocessing/api.py:914] failed (exitcode: 1) local_rank: 2 (pid: 2552955) of binary: /data2/shcho/miniforge3/envs/llm_eval/bin/python3.11
Traceback (most recent call last):
  File "/data2/shcho/miniforge3/envs/llm_eval/bin/torchrun", line 7, in <module>
    sys.exit(main())
             ^^^^^^
  File "/data2/shcho/miniforge3/envs/llm_eval/lib/python3.11/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 362, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/data2/shcho/miniforge3/envs/llm_eval/lib/python3.11/site-packages/torch/distributed/run.py", line 946, in main
    run(args)
  File "/data2/shcho/miniforge3/envs/llm_eval/lib/python3.11/site-packages/torch/distributed/run.py", line 937, in run
    elastic_launch(
  File "/data2/shcho/miniforge3/envs/llm_eval/lib/python3.11/site-packages/torch/distributed/launcher/api.py", line 159, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data2/shcho/miniforge3/envs/llm_eval/lib/python3.11/site-packages/torch/distributed/launcher/api.py", line 300, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
timelyfreeze.train FAILED
------------------------------------------------------------
Failures:
[1]:
  time      : 2025-10-21_03:13:11
  host      : elga.kaist.ac.kr
  rank      : 3 (local_rank: 3)
  exitcode  : 1 (pid: 2552956)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
[2]:
  time      : 2025-10-21_03:13:11
  host      : elga.kaist.ac.kr
  rank      : 0 (local_rank: 0)
  exitcode  : -15 (pid: 2552953)
  error_file: <N/A>
  traceback : Signal 15 (SIGTERM) received by PID 2552953
[3]:
  time      : 2025-10-21_03:13:11
  host      : elga.kaist.ac.kr
  rank      : 1 (local_rank: 1)
  exitcode  : -15 (pid: 2552954)
  error_file: <N/A>
  traceback : Signal 15 (SIGTERM) received by PID 2552954
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2025-10-21_03:13:11
  host      : elga.kaist.ac.kr
  rank      : 2 (local_rank: 2)
  exitcode  : 1 (pid: 2552955)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================

üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•
‚úîÔ∏èCurrent Timestamp: 2025. 10. 21. (Ìôî) 03:14:09 KST
‚úîÔ∏èSERVER: dmserver1 (143.248.135.95),  GPUs: 3,4,5,6
‚úîÔ∏èSCRIPT: /home/shcho/torchtitan/logs/dmserver1/1020_main/run.sh
‚úîÔ∏èOUTPUT: /home/shcho/torchtitan/logs/dmserver1/1020_main/1020_gpipe_fullrand7.log
‚úîÔ∏èMain Table Experiment
‚úîÔ∏èRunning with fullrand7 x gpipe ... 
‚òëÔ∏è> torchrun --standalone --nnodes=1 --nproc_per_node=4 --local_addr=127.0.0.1 --local-ranks-filter=0,3 --role=rank --tee=3 -m timelyfreeze.train --job.config_file=/home/shcho/torchtitan/logs/dmserver1/1020_main/config.toml --job.description="Main Table Experiment" --training.global_batch_size=128 --training.local_batch_size=8 --parallelism.pipeline_parallel_microbatch_size=1 --training.seq_len=1024 --training.steps=500 --metrics.log_freq=50 --parallelism.pipeline_parallel_degree=4  --freezing.freeze --freezing.metric_type=fullrand7 --freezing.stability_check_freq=50 --freezing.aggressiveness=0.0
üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•
2025-10-21 03:14:16,599 - Starting job: "Main Table Experiment"
2025-10-21 03:14:16,600 - Starting job: "Main Table Experiment"
2025-10-21 03:14:16,624 - Starting job: "Main Table Experiment"
[rank0]:[titan] 2025-10-21 03:14:16,600 - root - INFO - Starting job: "Main Table Experiment"
[rank3]:[titan] 2025-10-21 03:14:16,624 - root - INFO - Starting job: "Main Table Experiment"
2025-10-21 03:14:16,820 - Starting job: "Main Table Experiment"
2025-10-21 03:14:17,458 - ENV[TORCH_NCCL_ASYNC_ERROR_HANDLING] = 1 will be overridden to 3 based on job config
2025-10-21 03:14:17,462 - Building 1-D device mesh with ['pp'], [4]
2025-10-21 03:14:17,466 - [GC] Initial GC collection 0.00 seconds
2025-10-21 03:14:17,468 - ENV[TORCH_NCCL_ASYNC_ERROR_HANDLING] = 1 will be overridden to 3 based on job config
2025-10-21 03:14:17,471 - Building 1-D device mesh with ['pp'], [4]
2025-10-21 03:14:17,472 - ENV[TORCH_NCCL_ASYNC_ERROR_HANDLING] = 1 will be overridden to 3 based on job config
2025-10-21 03:14:17,475 - Building 1-D device mesh with ['pp'], [4]
2025-10-21 03:14:17,486 - ENV[TORCH_NCCL_ASYNC_ERROR_HANDLING] = 1 will be overridden to 3 based on job config
2025-10-21 03:14:17,490 - Building 1-D device mesh with ['pp'], [4]
[rank0]:[titan] 2025-10-21 03:14:17,458 - root - WARNING - ENV[TORCH_NCCL_ASYNC_ERROR_HANDLING] = 1 will be overridden to 3 based on job config
[rank0]:[titan] 2025-10-21 03:14:17,462 - root - INFO - Building 1-D device mesh with ['pp'], [4]
[rank0]:[titan] 2025-10-21 03:14:17,466 - root - INFO - [GC] Initial GC collection 0.00 seconds
[rank3]:[titan] 2025-10-21 03:14:17,468 - root - WARNING - ENV[TORCH_NCCL_ASYNC_ERROR_HANDLING] = 1 will be overridden to 3 based on job config
[rank3]:[titan] 2025-10-21 03:14:17,471 - root - INFO - Building 1-D device mesh with ['pp'], [4]
2025-10-21 03:14:17,834 - Loading tokenizer from tokenizer.json
[rank0]:[titan] 2025-10-21 03:14:17,834 - root - INFO - Loading tokenizer from tokenizer.json
2025-10-21 03:14:18,237 - Preparing slimorca dataset from Open-Orca/SlimOrca
[rank0]:[titan] 2025-10-21 03:14:18,237 - root - INFO - Preparing slimorca dataset from Open-Orca/SlimOrca
2025-10-21 03:14:21,178 - Building llama3 1B with TransformerModelArgs(_enforced='This field is used to enforce all fields have defaults.', dim=2048, n_layers=16, n_heads=32, n_kv_heads=8, vocab_size=128256, multiple_of=1024, ffn_dim_multiplier=1.3, norm_eps=1e-05, rope_theta=500000, max_seq_len=1024, depth_init=True, use_flex_attn=False, attn_mask_type='causal', eos_id=0)
[rank0]:[titan] 2025-10-21 03:14:21,178 - root - INFO - Building llama3 1B with TransformerModelArgs(_enforced='This field is used to enforce all fields have defaults.', dim=2048, n_layers=16, n_heads=32, n_kv_heads=8, vocab_size=128256, multiple_of=1024, ffn_dim_multiplier=1.3, norm_eps=1e-05, rope_theta=500000, max_seq_len=1024, depth_init=True, use_flex_attn=False, attn_mask_type='causal', eos_id=0)
2025-10-21 03:14:21,339 - CUDA capacity: NVIDIA RTX 6000 Ada Generation with 47.51GiB memory
2025-10-21 03:14:21,353 - CUDA capacity: NVIDIA RTX 6000 Ada Generation with 47.51GiB memory
[rank0]:[titan] 2025-10-21 03:14:21,353 - root - INFO - CUDA capacity: NVIDIA RTX 6000 Ada Generation with 47.51GiB memory
2025-10-21 03:14:21,383 - Peak flops undefined for: NVIDIA RTX 6000 Ada Generation, fallback to A100
2025-10-21 03:14:21,393 - Peak flops undefined for: NVIDIA RTX 6000 Ada Generation, fallback to A100
2025-10-21 03:14:21,394 - [34mModel llama3 1B [31msize: 1,397,819,392 total parameters[39m
2025-10-21 03:14:21,411 - PP rank 1 is building stage_idx 1 with modules ['layers.4', 'layers.5', 'layers.6', 'layers.7', 'layers.8']
2025-10-21 03:14:21,411 - Using pipeline schedule gpipe with 8 microbatches and 4 stages.
2025-10-21 03:14:21,419 - PP rank 0 is building stage_idx 0 with modules ['tok_embeddings', 'layers.0', 'layers.1', 'layers.2', 'layers.3']
2025-10-21 03:14:21,419 - Using pipeline schedule gpipe with 8 microbatches and 4 stages.
[rank0]:[titan] 2025-10-21 03:14:21,393 - root - WARNING - Peak flops undefined for: NVIDIA RTX 6000 Ada Generation, fallback to A100
[rank0]:[titan] 2025-10-21 03:14:21,394 - root - INFO - [34mModel llama3 1B [31msize: 1,397,819,392 total parameters[39m
[rank0]:[titan] 2025-10-21 03:14:21,419 - root - INFO - PP rank 0 is building stage_idx 0 with modules ['tok_embeddings', 'layers.0', 'layers.1', 'layers.2', 'layers.3']
[rank0]:[titan] 2025-10-21 03:14:21,419 - root - INFO - Using pipeline schedule gpipe with 8 microbatches and 4 stages.
2025-10-21 03:14:21,586 - Peak flops undefined for: NVIDIA RTX 6000 Ada Generation, fallback to A100
2025-10-21 03:14:21,587 - Peak FLOPS used for computing MFU: 3.120e+14
2025-10-21 03:14:21,587 - CUDA memory usage for model: 1.02GiB(2.14%)
2025-10-21 03:14:21,588 - Warmup (200) + decay (400) steps exceed total training steps (500). Adjusting decay steps to 300.
2025-10-21 03:14:21,598 - Peak flops undefined for: NVIDIA RTX 6000 Ada Generation, fallback to A100
2025-10-21 03:14:21,598 - Peak FLOPS used for computing MFU: 3.120e+14
2025-10-21 03:14:21,606 - CUDA memory usage for model: 1.80GiB(3.79%)
2025-10-21 03:14:21,608 - Warmup (200) + decay (400) steps exceed total training steps (500). Adjusting decay steps to 300.
[rank3]:/data2/shcho/miniforge3/envs/llm_eval/lib/python3.11/site-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
[rank3]:  warnings.warn(
[rank3]:/data2/shcho/miniforge3/envs/llm_eval/lib/python3.11/site-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
[rank3]:  warnings.warn(
[rank0]:[titan] 2025-10-21 03:14:21,598 - root - WARNING - Peak flops undefined for: NVIDIA RTX 6000 Ada Generation, fallback to A100
[rank0]:[titan] 2025-10-21 03:14:21,598 - root - INFO - Peak FLOPS used for computing MFU: 3.120e+14
[rank0]:[titan] 2025-10-21 03:14:21,606 - root - INFO - CUDA memory usage for model: 1.80GiB(3.79%)
[rank0]:[titan] 2025-10-21 03:14:21,608 - root - WARNING - Warmup (200) + decay (400) steps exceed total training steps (500). Adjusting decay steps to 300.
2025-10-21 03:14:21,789 - CUDA capacity: NVIDIA RTX 6000 Ada Generation with 47.51GiB memory
2025-10-21 03:14:21,827 - Peak flops undefined for: NVIDIA RTX 6000 Ada Generation, fallback to A100
2025-10-21 03:14:21,854 - PP rank 2 is building stage_idx 2 with modules ['layers.9', 'layers.10', 'layers.11', 'layers.12']
2025-10-21 03:14:21,854 - Using pipeline schedule gpipe with 8 microbatches and 4 stages.
2025-10-21 03:14:22,028 - Peak flops undefined for: NVIDIA RTX 6000 Ada Generation, fallback to A100
2025-10-21 03:14:22,028 - Peak FLOPS used for computing MFU: 3.120e+14
2025-10-21 03:14:22,029 - CUDA memory usage for model: 0.82GiB(1.73%)
2025-10-21 03:14:22,030 - Warmup (200) + decay (400) steps exceed total training steps (500). Adjusting decay steps to 300.
[rank3]:wandb: Currently logged in as: orangingq to https://api.wandb.ai. Use `wandb login --relogin` to force relogin
[rank3]:wandb: setting up run fz0aagum
[rank3]:wandb: Tracking run with wandb version 0.22.2
[rank3]:wandb: Run data is saved locally in /data2/shcho/torchtitan/tb/1020_gpipe_fullrand7_dm1/20251021-0314/wandb/run-20251021_031422-fz0aagum
[rank3]:wandb: Run `wandb offline` to turn off syncing.
[rank3]:wandb: Syncing run 1020_gpipe_fullrand7_dm1
[rank3]:wandb: ‚≠êÔ∏è View project at https://wandb.ai/orangingq/torchtitan
[rank3]:wandb: üöÄ View run at https://wandb.ai/orangingq/torchtitan/runs/fz0aagum
2025-10-21 03:14:23,613 - WandB logging enabled
2025-10-21 03:14:23,614 - CUDA capacity: NVIDIA RTX 6000 Ada Generation with 47.51GiB memory
2025-10-21 03:14:23,654 - Peak flops undefined for: NVIDIA RTX 6000 Ada Generation, fallback to A100
[rank3]:[titan] 2025-10-21 03:14:23,613 - root - INFO - WandB logging enabled
[rank3]:[titan] 2025-10-21 03:14:23,614 - root - INFO - CUDA capacity: NVIDIA RTX 6000 Ada Generation with 47.51GiB memory
[rank3]:[titan] 2025-10-21 03:14:23,654 - root - WARNING - Peak flops undefined for: NVIDIA RTX 6000 Ada Generation, fallback to A100
2025-10-21 03:14:23,683 - PP rank 3 is building stage_idx 3 with modules ['layers.13', 'layers.14', 'layers.15', 'norm', 'output']
2025-10-21 03:14:23,684 - Using pipeline schedule gpipe with 8 microbatches and 4 stages.
[rank3]:[titan] 2025-10-21 03:14:23,683 - root - INFO - PP rank 3 is building stage_idx 3 with modules ['layers.13', 'layers.14', 'layers.15', 'norm', 'output']
[rank3]:[titan] 2025-10-21 03:14:23,684 - root - INFO - Using pipeline schedule gpipe with 8 microbatches and 4 stages.
2025-10-21 03:14:23,857 - Peak flops undefined for: NVIDIA RTX 6000 Ada Generation, fallback to A100
2025-10-21 03:14:23,858 - Peak FLOPS used for computing MFU: 3.120e+14
2025-10-21 03:14:23,859 - CUDA memory usage for model: 1.60GiB(3.38%)
[rank3]:[titan] 2025-10-21 03:14:23,857 - root - WARNING - Peak flops undefined for: NVIDIA RTX 6000 Ada Generation, fallback to A100
[rank3]:[titan] 2025-10-21 03:14:23,858 - root - INFO - Peak FLOPS used for computing MFU: 3.120e+14
[rank3]:[titan] 2025-10-21 03:14:23,859 - root - INFO - CUDA memory usage for model: 1.60GiB(3.38%)
2025-10-21 03:14:23,860 - Warmup (200) + decay (400) steps exceed total training steps (500). Adjusting decay steps to 300.
2025-10-21 03:14:23,874 - Mixed precision training with TP or PP is only supported when FSDP/HSDP/CP is enabled.
2025-10-21 03:14:23,874 - Mixed precision training with TP or PP is only supported when FSDP/HSDP/CP is enabled.
2025-10-21 03:14:23,874 - Mixed precision training is disabled
2025-10-21 03:14:23,874 - Mixed precision training with TP or PP is only supported when FSDP/HSDP/CP is enabled.
2025-10-21 03:14:23,874 - Mixed precision training is disabled
2025-10-21 03:14:23,874 - Checkpointing active. Checkpoints will be loaded from and saved to /data2/shcho/torchtitan/checkpoint/1020_gpipe_fullrand7_dm1
2025-10-21 03:14:23,874 - Mixed precision training is disabled
2025-10-21 03:14:23,875 - Mixed precision training with TP or PP is only supported when FSDP/HSDP/CP is enabled.
2025-10-21 03:14:23,875 - Mixed precision training is disabled
2025-10-21 03:14:23,876 - Trainer is initialized with local batch size 8, global batch size 128, gradient accumulation steps 16, sequence length 1024, total steps 500 (warmup 200)
2025-10-21 03:14:23,877 - Training starts at step 1
[rank0]:[titan] 2025-10-21 03:14:23,874 - root - INFO - Checkpointing active. Checkpoints will be loaded from and saved to /data2/shcho/torchtitan/checkpoint/1020_gpipe_fullrand7_dm1
[rank0]:[titan] 2025-10-21 03:14:23,875 - root - WARNING - Mixed precision training with TP or PP is only supported when FSDP/HSDP/CP is enabled.
[rank0]:[titan] 2025-10-21 03:14:23,875 - root - INFO - Mixed precision training is disabled
[rank0]:[titan] 2025-10-21 03:14:23,876 - root - INFO - Trainer is initialized with local batch size 8, global batch size 128, gradient accumulation steps 16, sequence length 1024, total steps 500 (warmup 200)
[rank0]:[titan] 2025-10-21 03:14:23,877 - root - INFO - Training starts at step 1
[rank3]:[titan] 2025-10-21 03:14:23,860 - root - WARNING - Warmup (200) + decay (400) steps exceed total training steps (500). Adjusting decay steps to 300.
[rank3]:[titan] 2025-10-21 03:14:23,874 - root - WARNING - Mixed precision training with TP or PP is only supported when FSDP/HSDP/CP is enabled.
[rank3]:[titan] 2025-10-21 03:14:23,874 - root - INFO - Mixed precision training is disabled
[rank0]:/data2/shcho/miniforge3/envs/llm_eval/lib/python3.11/site-packages/torch/autograd/graph.py:849: UserWarning: Attempting to run cuBLAS, but there was no current CUDA context! Attempting to set the primary context... (Triggered internally at /pytorch/aten/src/ATen/cuda/CublasHandlePool.cpp:270.)
[rank0]:  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
2025-10-21 03:14:41,767 - [31m step:  1 [32m loss: -16.0000 [38;2;180;60;0m grad_norm:  0.1630 [38;2;54;234;195m memory:  7.43GiB(15.64%) [34m tps: 1,643 [36m tflops: 11.85 [35m mfu: 3.80%[39m
2025-10-21 03:14:41,768 - Synchronizing and adjusting timeout for all ProcessGroups to 0:05:00
2025-10-21 03:14:41,771 - [31m step:  1 [32m loss: -16.0000 [38;2;180;60;0m grad_norm:  0.1630 [38;2;54;234;195m memory:  9.23GiB(19.42%) [34m tps: 1,607 [36m tflops: 11.59 [35m mfu: 3.72%[39m
2025-10-21 03:14:41,771 - Synchronizing and adjusting timeout for all ProcessGroups to 0:05:00
2025-10-21 03:14:41,777 - [31m step:  1 [32m loss: 12.2455 [38;2;180;60;0m grad_norm:  0.1630 [38;2;54;234;195m memory: 19.60GiB(41.25%) [34m tps: 1,808 [36m tflops: 13.04 [35m mfu: 4.18%[39m
2025-10-21 03:14:41,777 - Synchronizing and adjusting timeout for all ProcessGroups to 0:05:00
[rank3]:[titan] 2025-10-21 03:14:41,777 - root - INFO - [31m step:  1 [32m loss: 12.2455 [38;2;180;60;0m grad_norm:  0.1630 [38;2;54;234;195m memory: 19.60GiB(41.25%) [34m tps: 1,808 [36m tflops: 13.04 [35m mfu: 4.18%[39m
[rank3]:[titan] 2025-10-21 03:14:41,777 - root - INFO - Synchronizing and adjusting timeout for all ProcessGroups to 0:05:00
2025-10-21 03:14:41,813 - [31m step:  1 [32m loss: -16.0000 [38;2;180;60;0m grad_norm:  0.1630 [38;2;54;234;195m memory: 10.28GiB(21.64%) [34m tps: 1,605 [36m tflops: 11.58 [35m mfu: 3.71%[39m
2025-10-21 03:14:41,813 - Synchronizing and adjusting timeout for all ProcessGroups to 0:05:00
[rank0]:[titan] 2025-10-21 03:14:41,813 - root - INFO - [31m step:  1 [32m loss: -16.0000 [38;2;180;60;0m grad_norm:  0.1630 [38;2;54;234;195m memory: 10.28GiB(21.64%) [34m tps: 1,605 [36m tflops: 11.58 [35m mfu: 3.71%[39m
[rank0]:[titan] 2025-10-21 03:14:41,813 - root - INFO - Synchronizing and adjusting timeout for all ProcessGroups to 0:05:00
2025-10-21 03:28:03,374 - [GC] Peforming periodical GC collection 0.01 seconds
[rank0]:[titan] 2025-10-21 03:28:03,374 - root - INFO - [GC] Peforming periodical GC collection 0.01 seconds
2025-10-21 03:28:19,767 - [31m step: 50 [32m loss: -16.0000 [38;2;180;60;0m grad_norm:  0.0946 [38;2;54;234;195m memory:  9.07GiB(19.09%) [34m tps: 1,963 [36m tflops: 14.16 [35m mfu: 4.54%[39m
2025-10-21 03:28:19,770 - [31m step: 50 [32m loss: -16.0000 [38;2;180;60;0m grad_norm:  0.0946 [38;2;54;234;195m memory: 11.26GiB(23.70%) [34m tps: 1,963 [36m tflops: 14.16 [35m mfu: 4.54%[39m
2025-10-21 03:28:19,780 - [31m step: 50 [32m loss:  7.0126 [38;2;180;60;0m grad_norm:  0.0946 [38;2;54;234;195m memory: 22.80GiB(47.99%) [34m tps: 1,963 [36m tflops: 14.16 [35m mfu: 4.54%[39m
2025-10-21 03:28:19,783 - [31m step: 50 [32m loss: -16.0000 [38;2;180;60;0m grad_norm:  0.0946 [38;2;54;234;195m memory: 13.87GiB(29.20%) [34m tps: 1,963 [36m tflops: 14.16 [35m mfu: 4.54%[39m
[rank3]:[titan] 2025-10-21 03:28:19,780 - root - INFO - [31m step: 50 [32m loss:  7.0126 [38;2;180;60;0m grad_norm:  0.0946 [38;2;54;234;195m memory: 22.80GiB(47.99%) [34m tps: 1,963 [36m tflops: 14.16 [35m mfu: 4.54%[39m
[rank0]:[titan] 2025-10-21 03:28:19,783 - root - INFO - [31m step: 50 [32m loss: -16.0000 [38;2;180;60;0m grad_norm:  0.0946 [38;2;54;234;195m memory: 13.87GiB(29.20%) [34m tps: 1,963 [36m tflops: 14.16 [35m mfu: 4.54%[39m
2025-10-21 03:41:55,376 - [GC] Peforming periodical GC collection 0.01 seconds
[rank0]:[titan] 2025-10-21 03:41:55,376 - root - INFO - [GC] Peforming periodical GC collection 0.01 seconds
2025-10-21 03:42:12,125 - [31m step: 100 [32m loss: -16.0000 [38;2;180;60;0m grad_norm:  0.1212 [38;2;54;234;195m memory:  9.07GiB(19.09%) [34m tps: 1,968 [36m tflops: 14.20 [35m mfu: 4.55%[39m
2025-10-21 03:42:12,128 - [31m step: 100 [32m loss: -16.0000 [38;2;180;60;0m grad_norm:  0.1212 [38;2;54;234;195m memory: 11.26GiB(23.70%) [34m tps: 1,968 [36m tflops: 14.20 [35m mfu: 4.55%[39m
2025-10-21 03:42:12,138 - [31m step: 100 [32m loss:  6.1133 [38;2;180;60;0m grad_norm:  0.1212 [38;2;54;234;195m memory: 22.80GiB(47.99%) [34m tps: 1,968 [36m tflops: 14.20 [35m mfu: 4.55%[39m
2025-10-21 03:42:12,140 - [31m step: 100 [32m loss: -16.0000 [38;2;180;60;0m grad_norm:  0.1212 [38;2;54;234;195m memory: 13.87GiB(29.20%) [34m tps: 1,968 [36m tflops: 14.20 [35m mfu: 4.55%[39m
[rank0]:[titan] 2025-10-21 03:42:12,140 - root - INFO - [31m step: 100 [32m loss: -16.0000 [38;2;180;60;0m grad_norm:  0.1212 [38;2;54;234;195m memory: 13.87GiB(29.20%) [34m tps: 1,968 [36m tflops: 14.20 [35m mfu: 4.55%[39m
[rank3]:[titan] 2025-10-21 03:42:12,138 - root - INFO - [31m step: 100 [32m loss:  6.1133 [38;2;180;60;0m grad_norm:  0.1212 [38;2;54;234;195m memory: 22.80GiB(47.99%) [34m tps: 1,968 [36m tflops: 14.20 [35m mfu: 4.55%[39m
2025-10-21 03:55:53,313 - [GC] Peforming periodical GC collection 0.01 seconds
[rank0]:[titan] 2025-10-21 03:55:53,313 - root - INFO - [GC] Peforming periodical GC collection 0.01 seconds
2025-10-21 03:56:10,055 - [31m step: 150 [32m loss: -16.0000 [38;2;180;60;0m grad_norm:  0.0709 [38;2;54;234;195m memory:  9.07GiB(19.09%) [34m tps: 1,955 [36m tflops: 14.10 [35m mfu: 4.52%[39m
2025-10-21 03:56:10,059 - [31m step: 150 [32m loss: -16.0000 [38;2;180;60;0m grad_norm:  0.0709 [38;2;54;234;195m memory: 11.26GiB(23.70%) [34m tps: 1,955 [36m tflops: 14.10 [35m mfu: 4.52%[39m
2025-10-21 03:56:10,069 - [31m step: 150 [32m loss:  5.7088 [38;2;180;60;0m grad_norm:  0.0709 [38;2;54;234;195m memory: 22.80GiB(47.99%) [34m tps: 1,955 [36m tflops: 14.10 [35m mfu: 4.52%[39m
[rank3]:[titan] 2025-10-21 03:56:10,069 - root - INFO - [31m step: 150 [32m loss:  5.7088 [38;2;180;60;0m grad_norm:  0.0709 [38;2;54;234;195m memory: 22.80GiB(47.99%) [34m tps: 1,955 [36m tflops: 14.10 [35m mfu: 4.52%[39m
2025-10-21 03:56:10,072 - [31m step: 150 [32m loss: -16.0000 [38;2;180;60;0m grad_norm:  0.0709 [38;2;54;234;195m memory: 13.87GiB(29.20%) [34m tps: 1,955 [36m tflops: 14.10 [35m mfu: 4.52%[39m
[rank0]:[titan] 2025-10-21 03:56:10,072 - root - INFO - [31m step: 150 [32m loss: -16.0000 [38;2;180;60;0m grad_norm:  0.0709 [38;2;54;234;195m memory: 13.87GiB(29.20%) [34m tps: 1,955 [36m tflops: 14.10 [35m mfu: 4.52%[39m
2025-10-21 04:09:51,234 - [GC] Peforming periodical GC collection 0.01 seconds
[rank0]:[titan] 2025-10-21 04:09:51,234 - root - INFO - [GC] Peforming periodical GC collection 0.01 seconds
2025-10-21 04:10:08,114 - [31m step: 200 [32m loss: -16.0000 [38;2;180;60;0m grad_norm:  0.0897 [38;2;54;234;195m memory:  9.07GiB(19.09%) [34m tps: 1,955 [36m tflops: 14.10 [35m mfu: 4.52%[39m
2025-10-21 04:10:08,118 - [31m step: 200 [32m loss: -16.0000 [38;2;180;60;0m grad_norm:  0.0897 [38;2;54;234;195m memory: 11.26GiB(23.70%) [34m tps: 1,955 [36m tflops: 14.10 [35m mfu: 4.52%[39m
2025-10-21 04:10:08,127 - [31m step: 200 [32m loss:  5.3708 [38;2;180;60;0m grad_norm:  0.0897 [38;2;54;234;195m memory: 22.80GiB(47.99%) [34m tps: 1,955 [36m tflops: 14.10 [35m mfu: 4.52%[39m
2025-10-21 04:10:08,131 - [31m step: 200 [32m loss: -16.0000 [38;2;180;60;0m grad_norm:  0.0897 [38;2;54;234;195m memory: 13.87GiB(29.20%) [34m tps: 1,955 [36m tflops: 14.10 [35m mfu: 4.52%[39m
[rank0]:[titan] 2025-10-21 04:10:08,131 - root - INFO - [31m step: 200 [32m loss: -16.0000 [38;2;180;60;0m grad_norm:  0.0897 [38;2;54;234;195m memory: 13.87GiB(29.20%) [34m tps: 1,955 [36m tflops: 14.10 [35m mfu: 4.52%[39m
[rank3]:[titan] 2025-10-21 04:10:08,127 - root - INFO - [31m step: 200 [32m loss:  5.3708 [38;2;180;60;0m grad_norm:  0.0897 [38;2;54;234;195m memory: 22.80GiB(47.99%) [34m tps: 1,955 [36m tflops: 14.10 [35m mfu: 4.52%[39m
2025-10-21 04:23:50,413 - [GC] Peforming periodical GC collection 0.01 seconds
[rank0]:[titan] 2025-10-21 04:23:50,413 - root - INFO - [GC] Peforming periodical GC collection 0.01 seconds
2025-10-21 04:24:07,249 - [31m step: 250 [32m loss: -16.0000 [38;2;180;60;0m grad_norm:  0.0703 [38;2;54;234;195m memory:  9.07GiB(19.09%) [34m tps: 1,952 [36m tflops: 14.08 [35m mfu: 4.51%[39m
2025-10-21 04:24:07,253 - [31m step: 250 [32m loss: -16.0000 [38;2;180;60;0m grad_norm:  0.0703 [38;2;54;234;195m memory: 11.26GiB(23.70%) [34m tps: 1,952 [36m tflops: 14.08 [35m mfu: 4.51%[39m
2025-10-21 04:24:07,262 - [31m step: 250 [32m loss:  5.2966 [38;2;180;60;0m grad_norm:  0.0703 [38;2;54;234;195m memory: 22.80GiB(47.99%) [34m tps: 1,952 [36m tflops: 14.08 [35m mfu: 4.51%[39m
2025-10-21 04:24:07,264 - [31m step: 250 [32m loss: -16.0000 [38;2;180;60;0m grad_norm:  0.0703 [38;2;54;234;195m memory: 13.87GiB(29.20%) [34m tps: 1,952 [36m tflops: 14.08 [35m mfu: 4.51%[39m
[rank3]:[titan] 2025-10-21 04:24:07,262 - root - INFO - [31m step: 250 [32m loss:  5.2966 [38;2;180;60;0m grad_norm:  0.0703 [38;2;54;234;195m memory: 22.80GiB(47.99%) [34m tps: 1,952 [36m tflops: 14.08 [35m mfu: 4.51%[39m
[rank0]:[titan] 2025-10-21 04:24:07,264 - root - INFO - [31m step: 250 [32m loss: -16.0000 [38;2;180;60;0m grad_norm:  0.0703 [38;2;54;234;195m memory: 13.87GiB(29.20%) [34m tps: 1,952 [36m tflops: 14.08 [35m mfu: 4.51%[39m
2025-10-21 04:37:50,179 - [GC] Peforming periodical GC collection 0.01 seconds
[rank0]:[titan] 2025-10-21 04:37:50,179 - root - INFO - [GC] Peforming periodical GC collection 0.01 seconds
2025-10-21 04:38:06,929 - [31m step: 300 [32m loss: -16.0000 [38;2;180;60;0m grad_norm:  0.0642 [38;2;54;234;195m memory:  9.07GiB(19.09%) [34m tps: 1,951 [36m tflops: 14.08 [35m mfu: 4.51%[39m
2025-10-21 04:38:06,933 - [31m step: 300 [32m loss: -16.0000 [38;2;180;60;0m grad_norm:  0.0642 [38;2;54;234;195m memory: 11.26GiB(23.70%) [34m tps: 1,951 [36m tflops: 14.08 [35m mfu: 4.51%[39m
2025-10-21 04:38:06,942 - [31m step: 300 [32m loss:  5.0546 [38;2;180;60;0m grad_norm:  0.0642 [38;2;54;234;195m memory: 22.80GiB(47.99%) [34m tps: 1,951 [36m tflops: 14.08 [35m mfu: 4.51%[39m
2025-10-21 04:38:06,947 - [31m step: 300 [32m loss: -16.0000 [38;2;180;60;0m grad_norm:  0.0642 [38;2;54;234;195m memory: 13.87GiB(29.20%) [34m tps: 1,951 [36m tflops: 14.08 [35m mfu: 4.51%[39m
[rank3]:[titan] 2025-10-21 04:38:06,942 - root - INFO - [31m step: 300 [32m loss:  5.0546 [38;2;180;60;0m grad_norm:  0.0642 [38;2;54;234;195m memory: 22.80GiB(47.99%) [34m tps: 1,951 [36m tflops: 14.08 [35m mfu: 4.51%[39m
[rank0]:[titan] 2025-10-21 04:38:06,947 - root - INFO - [31m step: 300 [32m loss: -16.0000 [38;2;180;60;0m grad_norm:  0.0642 [38;2;54;234;195m memory: 13.87GiB(29.20%) [34m tps: 1,951 [36m tflops: 14.08 [35m mfu: 4.51%[39m
2025-10-21 04:51:49,868 - [GC] Peforming periodical GC collection 0.01 seconds
[rank0]:[titan] 2025-10-21 04:51:49,868 - root - INFO - [GC] Peforming periodical GC collection 0.01 seconds
2025-10-21 04:52:06,722 - [31m step: 350 [32m loss: -16.0000 [38;2;180;60;0m grad_norm:  0.0566 [38;2;54;234;195m memory:  9.07GiB(19.09%) [34m tps: 1,951 [36m tflops: 14.07 [35m mfu: 4.51%[39m
2025-10-21 04:52:06,725 - [31m step: 350 [32m loss: -16.0000 [38;2;180;60;0m grad_norm:  0.0566 [38;2;54;234;195m memory: 11.26GiB(23.70%) [34m tps: 1,951 [36m tflops: 14.07 [35m mfu: 4.51%[39m
2025-10-21 04:52:06,735 - [31m step: 350 [32m loss:  4.9178 [38;2;180;60;0m grad_norm:  0.0566 [38;2;54;234;195m memory: 22.80GiB(47.99%) [34m tps: 1,951 [36m tflops: 14.07 [35m mfu: 4.51%[39m
2025-10-21 04:52:06,739 - [31m step: 350 [32m loss: -16.0000 [38;2;180;60;0m grad_norm:  0.0566 [38;2;54;234;195m memory: 13.87GiB(29.20%) [34m tps: 1,951 [36m tflops: 14.07 [35m mfu: 4.51%[39m
[rank3]:[titan] 2025-10-21 04:52:06,735 - root - INFO - [31m step: 350 [32m loss:  4.9178 [38;2;180;60;0m grad_norm:  0.0566 [38;2;54;234;195m memory: 22.80GiB(47.99%) [34m tps: 1,951 [36m tflops: 14.07 [35m mfu: 4.51%[39m
[rank0]:[titan] 2025-10-21 04:52:06,739 - root - INFO - [31m step: 350 [32m loss: -16.0000 [38;2;180;60;0m grad_norm:  0.0566 [38;2;54;234;195m memory: 13.87GiB(29.20%) [34m tps: 1,951 [36m tflops: 14.07 [35m mfu: 4.51%[39m
2025-10-21 05:05:51,794 - [GC] Peforming periodical GC collection 0.01 seconds
[rank0]:[titan] 2025-10-21 05:05:51,794 - root - INFO - [GC] Peforming periodical GC collection 0.01 seconds
2025-10-21 05:06:08,679 - [31m step: 400 [32m loss: -16.0000 [38;2;180;60;0m grad_norm:  0.0535 [38;2;54;234;195m memory:  9.07GiB(19.09%) [34m tps: 1,946 [36m tflops: 14.04 [35m mfu: 4.50%[39m
2025-10-21 05:06:08,683 - [31m step: 400 [32m loss: -16.0000 [38;2;180;60;0m grad_norm:  0.0535 [38;2;54;234;195m memory: 11.26GiB(23.70%) [34m tps: 1,946 [36m tflops: 14.04 [35m mfu: 4.50%[39m
2025-10-21 05:06:08,692 - [31m step: 400 [32m loss:  4.7663 [38;2;180;60;0m grad_norm:  0.0535 [38;2;54;234;195m memory: 22.80GiB(47.99%) [34m tps: 1,946 [36m tflops: 14.04 [35m mfu: 4.50%[39m
2025-10-21 05:06:08,697 - [31m step: 400 [32m loss: -16.0000 [38;2;180;60;0m grad_norm:  0.0535 [38;2;54;234;195m memory: 13.87GiB(29.20%) [34m tps: 1,946 [36m tflops: 14.04 [35m mfu: 4.50%[39m
[rank0]:[titan] 2025-10-21 05:06:08,697 - root - INFO - [31m step: 400 [32m loss: -16.0000 [38;2;180;60;0m grad_norm:  0.0535 [38;2;54;234;195m memory: 13.87GiB(29.20%) [34m tps: 1,946 [36m tflops: 14.04 [35m mfu: 4.50%[39m
[rank3]:[titan] 2025-10-21 05:06:08,692 - root - INFO - [31m step: 400 [32m loss:  4.7663 [38;2;180;60;0m grad_norm:  0.0535 [38;2;54;234;195m memory: 22.80GiB(47.99%) [34m tps: 1,946 [36m tflops: 14.04 [35m mfu: 4.50%[39m
2025-10-21 05:19:55,228 - [GC] Peforming periodical GC collection 0.01 seconds
[rank0]:[titan] 2025-10-21 05:19:55,228 - root - INFO - [GC] Peforming periodical GC collection 0.01 seconds
2025-10-21 05:20:12,055 - [31m step: 450 [32m loss: -16.0000 [38;2;180;60;0m grad_norm:  0.0486 [38;2;54;234;195m memory:  9.07GiB(19.09%) [34m tps: 1,943 [36m tflops: 14.01 [35m mfu: 4.49%[39m
2025-10-21 05:20:12,059 - [31m step: 450 [32m loss: -16.0000 [38;2;180;60;0m grad_norm:  0.0486 [38;2;54;234;195m memory: 11.26GiB(23.70%) [34m tps: 1,943 [36m tflops: 14.01 [35m mfu: 4.49%[39m
2025-10-21 05:20:12,069 - [31m step: 450 [32m loss:  4.6901 [38;2;180;60;0m grad_norm:  0.0486 [38;2;54;234;195m memory: 22.80GiB(47.99%) [34m tps: 1,943 [36m tflops: 14.01 [35m mfu: 4.49%[39m
2025-10-21 05:20:12,073 - [31m step: 450 [32m loss: -16.0000 [38;2;180;60;0m grad_norm:  0.0486 [38;2;54;234;195m memory: 13.87GiB(29.20%) [34m tps: 1,943 [36m tflops: 14.01 [35m mfu: 4.49%[39m
[rank0]:[titan] 2025-10-21 05:20:12,073 - root - INFO - [31m step: 450 [32m loss: -16.0000 [38;2;180;60;0m grad_norm:  0.0486 [38;2;54;234;195m memory: 13.87GiB(29.20%) [34m tps: 1,943 [36m tflops: 14.01 [35m mfu: 4.49%[39m
[rank3]:[titan] 2025-10-21 05:20:12,069 - root - INFO - [31m step: 450 [32m loss:  4.6901 [38;2;180;60;0m grad_norm:  0.0486 [38;2;54;234;195m memory: 22.80GiB(47.99%) [34m tps: 1,943 [36m tflops: 14.01 [35m mfu: 4.49%[39m
2025-10-21 05:33:56,913 - [GC] Peforming periodical GC collection 0.01 seconds
[rank0]:[titan] 2025-10-21 05:33:56,913 - root - INFO - [GC] Peforming periodical GC collection 0.01 seconds
2025-10-21 05:34:13,784 - [31m step: 500 [32m loss: -16.0000 [38;2;180;60;0m grad_norm:  0.0477 [38;2;54;234;195m memory:  9.07GiB(19.09%) [34m tps: 1,946 [36m tflops: 14.04 [35m mfu: 4.50%[39m
2025-10-21 05:34:13,784 - Saving the checkpoint (or staging if async is enabled).
2025-10-21 05:34:13,787 - [31m step: 500 [32m loss: -16.0000 [38;2;180;60;0m grad_norm:  0.0477 [38;2;54;234;195m memory: 11.26GiB(23.70%) [34m tps: 1,946 [36m tflops: 14.04 [35m mfu: 4.50%[39m
2025-10-21 05:34:13,788 - Saving the checkpoint (or staging if async is enabled).
2025-10-21 05:34:13,794 - Saving a model only checkpoint in torch.float16 at last step, step 500.
2025-10-21 05:34:13,794 - Saving a model only checkpoint in torch.float16 at last step, step 500.
2025-10-21 05:34:13,797 - [31m step: 500 [32m loss:  4.6239 [38;2;180;60;0m grad_norm:  0.0477 [38;2;54;234;195m memory: 22.80GiB(47.99%) [34m tps: 1,946 [36m tflops: 14.04 [35m mfu: 4.50%[39m
[rank3]:[titan] 2025-10-21 05:34:13,797 - root - INFO - [31m step: 500 [32m loss:  4.6239 [38;2;180;60;0m grad_norm:  0.0477 [38;2;54;234;195m memory: 22.80GiB(47.99%) [34m tps: 1,946 [36m tflops: 14.04 [35m mfu: 4.50%[39m
2025-10-21 05:34:13,797 - Saving the checkpoint (or staging if async is enabled).
2025-10-21 05:34:13,798 - Saving a model only checkpoint in torch.float16 at last step, step 500.
2025-10-21 05:34:13,801 - [31m step: 500 [32m loss: -16.0000 [38;2;180;60;0m grad_norm:  0.0477 [38;2;54;234;195m memory: 13.87GiB(29.20%) [34m tps: 1,946 [36m tflops: 14.04 [35m mfu: 4.50%[39m
2025-10-21 05:34:13,802 - Saving the checkpoint (or staging if async is enabled).
2025-10-21 05:34:13,802 - Saving a model only checkpoint in torch.float16 at last step, step 500.
[rank3]:[titan] 2025-10-21 05:34:13,797 - root - INFO - Saving the checkpoint (or staging if async is enabled).
[rank3]:[titan] 2025-10-21 05:34:13,798 - root - INFO - Saving a model only checkpoint in torch.float16 at last step, step 500.
[rank0]:[titan] 2025-10-21 05:34:13,801 - root - INFO - [31m step: 500 [32m loss: -16.0000 [38;2;180;60;0m grad_norm:  0.0477 [38;2;54;234;195m memory: 13.87GiB(29.20%) [34m tps: 1,946 [36m tflops: 14.04 [35m mfu: 4.50%[39m
[rank0]:[titan] 2025-10-21 05:34:13,802 - root - INFO - Saving the checkpoint (or staging if async is enabled).
[rank0]:[titan] 2025-10-21 05:34:13,802 - root - INFO - Saving a model only checkpoint in torch.float16 at last step, step 500.
2025-10-21 05:34:16,206 - [GC] GC collection invoked by checkpointer. 0.00 seconds
2025-10-21 05:34:16,207 - Sleeping 2 seconds for other ranks to complete
2025-10-21 05:34:16,208 - Destroying the purge thread.
2025-10-21 05:34:16,208 - Destroying the purge thread.
2025-10-21 05:34:16,208 - Destroying the purge thread.
[rank0]:[titan] 2025-10-21 05:34:16,206 - root - INFO - [GC] GC collection invoked by checkpointer. 0.00 seconds
[rank0]:[titan] 2025-10-21 05:34:16,207 - root - INFO - Sleeping 2 seconds for other ranks to complete
[rank3]:[titan] 2025-10-21 05:34:16,208 - root - INFO - Destroying the purge thread.
[rank3]:wandb: updating run metadata
2025-10-21 05:34:17,217 - Process group destroyed
2025-10-21 05:34:17,221 - Process group destroyed
[rank3]:wandb: 
[rank3]:wandb: Run history:
[rank3]:wandb:                    grad_norm ‚ñà‚ñÑ‚ñÖ‚ñÇ‚ñÑ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
[rank3]:wandb: loss_metrics/global_avg_loss ‚ñà‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[rank3]:wandb: loss_metrics/global_max_loss ‚ñà‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[rank3]:wandb:                           lr ‚ñÅ‚ñÉ‚ñÑ‚ñÜ‚ñà‚ñà‚ñÜ‚ñÖ‚ñÉ‚ñÅ‚ñÅ
[rank3]:wandb:         memory/max_active(%) ‚ñÅ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
[rank3]:wandb:       memory/max_active(GiB) ‚ñÅ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
[rank3]:wandb:       memory/max_reserved(%) ‚ñÅ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
[rank3]:wandb:     memory/max_reserved(GiB) ‚ñÅ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
[rank3]:wandb:     memory/num_alloc_retries ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[rank3]:wandb:              memory/num_ooms ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[rank3]:wandb:                           +7 ...
[rank3]:wandb: 
[rank3]:wandb: Run summary:
[rank3]:wandb:                    grad_norm 0.04766
[rank3]:wandb: loss_metrics/global_avg_loss 4.62395
[rank3]:wandb: loss_metrics/global_max_loss 4.62395
[rank3]:wandb:                           lr 0.0
[rank3]:wandb:         memory/max_active(%) 41.00929
[rank3]:wandb:       memory/max_active(GiB) 19.48227
[rank3]:wandb:       memory/max_reserved(%) 47.9905
[rank3]:wandb:     memory/max_reserved(GiB) 22.79883
[rank3]:wandb:     memory/num_alloc_retries 0
[rank3]:wandb:              memory/num_ooms 0
[rank3]:wandb:                           +7 ...
[rank3]:wandb: 
[rank3]:wandb: üöÄ View run 1020_gpipe_fullrand7_dm1 at: https://wandb.ai/orangingq/torchtitan/runs/fz0aagum
[rank3]:wandb: ‚≠êÔ∏è View project at: https://wandb.ai/orangingq/torchtitan
[rank3]:wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
[rank3]:wandb: Find logs at: /data2/shcho/torchtitan/tb/1020_gpipe_fullrand7_dm1/20251021-0314/wandb/run-20251021_031422-fz0aagum/logs
2025-10-21 05:34:17,689 - Process group destroyed
[rank3]:[titan] 2025-10-21 05:34:17,689 - root - INFO - Process group destroyed
2025-10-21 05:34:18,207 - Training completed
2025-10-21 05:34:18,208 - Destroying the purge thread.
[rank0]:[titan] 2025-10-21 05:34:18,207 - root - INFO - Training completed
[rank0]:[titan] 2025-10-21 05:34:18,208 - root - INFO - Destroying the purge thread.
2025-10-21 05:34:19,047 - Process group destroyed
[rank0]:[titan] 2025-10-21 05:34:19,047 - root - INFO - Process group destroyed
[rank0]:Stage 0: Modules to keep: {'layers.0', 'layers.3', 'layers.2', 'tok_embeddings', 'layers.1'}
[rank3]:Stage 3: Modules to keep: {'layers.15', 'layers.13', 'layers.14', 'output', 'norm'}
[rank0]:[Gloo] Rank 0 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
[rank3]:[Gloo] Rank 3 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
[rank3]:----- TimelyFreeze‚è∞ Configuration:
[rank3]:	- job:
[rank3]:		- config_file: /home/shcho/torchtitan/logs/dmserver1/1020_main/config.toml
[rank3]:		- dump_folder: /data2/shcho/torchtitan
[rank3]:		- description: "Main Table Experiment"
[rank3]:		- use_for_integration_test: False
[rank3]:		- print_args: False
[rank3]:		- basename: 1020_gpipe_fullrand7_dm1
[rank3]:	- profiling:
[rank3]:		- enable_profiling: False
[rank3]:		- save_traces_folder: profile_trace/1020_gpipe_fullrand7_dm1/1020_gpipe_fullrand7_dm1
[rank3]:		- profile_freq: 100
[rank3]:		- enable_memory_snapshot: False
[rank3]:		- save_memory_snapshot_folder: memory_snapshot/1020_gpipe_fullrand7_dm1/1020_gpipe_fullrand7_dm1
[rank3]:	- metrics:
[rank3]:		- log_freq: 50
[rank3]:		- enable_tensorboard: False
[rank3]:		- disable_color_printing: False
[rank3]:		- save_tb_folder: tb/1020_gpipe_fullrand7_dm1/1020_gpipe_fullrand7_dm1
[rank3]:		- save_for_all_ranks: False
[rank3]:		- enable_wandb: True
[rank3]:		- log_file: /home/shcho/torchtitan/logs/dmserver1/1020_main/1020_gpipe_fullrand7.log
[rank3]:		- wandb_name: 1020_gpipe_fullrand7_dm1
[rank3]:		- draw_graph: False
[rank3]:	- model:
[rank3]:		- name: llama3
[rank3]:		- flavor: 1B
[rank3]:		- tokenizer_path: ./assets/tokenizer/Llama-3.2-1B
[rank3]:		- converters: []
[rank3]:		- print_after_conversion: False
[rank3]:	- optimizer:
[rank3]:		- name: AdamW
[rank3]:		- lr: 0.0003
[rank3]:		- beta1: 0.9
[rank3]:		- beta2: 0.95
[rank3]:		- eps: 1e-08
[rank3]:		- weight_decay: 0.1
[rank3]:		- implementation: fused
[rank3]:		- early_step_in_backward: False
[rank3]:	- lr_scheduler:
[rank3]:		- warmup_steps: 200
[rank3]:		- decay_ratio: 0.8
[rank3]:		- decay_type: cosine
[rank3]:		- min_lr_factor: 0.0
[rank3]:	- training:
[rank3]:		- dataset: slimorca
[rank3]:		- dataset_path: None
[rank3]:		- local_batch_size: 8
[rank3]:		- global_batch_size: 128
[rank3]:		- seq_len: 1024
[rank3]:		- max_norm: 1.0
[rank3]:		- steps: 500
[rank3]:		- enable_cpu_offload: False
[rank3]:		- mixed_precision_param: bfloat16
[rank3]:		- mixed_precision_reduce: float32
[rank3]:		- compile: False
[rank3]:		- gc_freq: 50
[rank3]:		- gc_debug: False
[rank3]:		- seed: None
[rank3]:		- deterministic: False
[rank3]:	- parallelism:
[rank3]:		- data_parallel_replicate_degree: 1
[rank3]:		- enable_compiled_autograd: False
[rank3]:		- data_parallel_shard_degree: -1
[rank3]:		- fsdp_reshard_after_forward: default
[rank3]:		- tensor_parallel_degree: 1
[rank3]:		- disable_loss_parallel: False
[rank3]:		- enable_async_tensor_parallel: False
[rank3]:		- pipeline_parallel_degree: 4
[rank3]:		- pipeline_parallel_split_points: []
[rank3]:		- module_fqns_per_model_part: None
[rank3]:		- pipeline_parallel_first_stage_less_layers: 1
[rank3]:		- pipeline_parallel_last_stage_less_layers: 1
[rank3]:		- pipeline_parallel_layers_per_stage: None
[rank3]:		- pipeline_parallel_schedule: gpipe
[rank3]:		- pipeline_parallel_schedule_csv: 
[rank3]:		- pipeline_parallel_microbatch_size: 1
[rank3]:		- context_parallel_degree: 1
[rank3]:		- context_parallel_rotate_method: allgather
[rank3]:		- expert_parallel_degree: 1
[rank3]:		- pp: 1
[rank3]:		- pp_scheduler: None
[rank3]:		- stages_per_rank: 1
[rank3]:		- stages_list: [3]
[rank3]:		- microbatches: 8
[rank3]:	- checkpoint:
[rank3]:		- enable_checkpoint: True
[rank3]:		- folder: checkpoint/1020_gpipe_fullrand7_dm1/1020_gpipe_fullrand7_dm1
[rank3]:		- interval: 500
[rank3]:		- initial_load_path: None
[rank3]:		- initial_load_model_only: True
[rank3]:		- initial_load_in_hf: False
[rank3]:		- last_save_model_only: True
[rank3]:		- last_save_in_hf: False
[rank3]:		- export_dtype: float16
[rank3]:		- async_mode: async
[rank3]:		- keep_latest_k: 2
[rank3]:		- load_step: -1
[rank3]:		- exclude_from_loading: ['dataloader', 'lr_scheduler', 'optimizer', 'train_state']
[rank3]:		- enable_first_step_checkpoint: False
[rank3]:		- create_seed_checkpoint: False
[rank3]:	- activation_checkpoint:
[rank3]:		- mode: none
[rank3]:		- selective_ac_option: op
[rank3]:		- per_op_sac_force_recompute_mm_shapes_by_fqns: ['moe.router.gate']
[rank3]:	- float8:
[rank3]:		- enable_fsdp_float8_all_gather: False
[rank3]:		- precompute_float8_dynamic_scale_for_fsdp: False
[rank3]:		- recipe_name: None
[rank3]:		- filter_fqns: ['output']
[rank3]:		- emulate: False
[rank3]:		- moe_fqns_prototype: []
[rank3]:	- mx:
[rank3]:		- mxfp8_dim1_cast_kernel_choice: triton
[rank3]:		- recipe_name: mxfp8
[rank3]:		- filter_fqns: ['output']
[rank3]:		- moe_fqns_prototype: []
[rank3]:	- comm:
[rank3]:		- init_timeout_seconds: 300
[rank3]:		- train_timeout_seconds: 300
[rank3]:		- trace_buf_size: 20000
[rank3]:		- save_traces_folder: comm_traces/1020_gpipe_fullrand7_dm1/1020_gpipe_fullrand7_dm1
[rank3]:		- world_size: 4
[rank3]:		- global_rank: 3
[rank3]:		- local_rank: 3
[rank3]:		- dp: 1
[rank3]:		- pp: 4
[rank3]:		- pp_rank: 3
[rank3]:		- dp_rank: 0
[rank3]:		- master_dp_rank: 0
[rank3]:	- memory_estimation:
[rank3]:		- enabled: False
[rank3]:		- disable_fake_mode: False
[rank3]:	- fault_tolerance:
[rank3]:		- enable: False
[rank3]:		- process_group: gloo
[rank3]:		- process_group_timeout_ms: 10000
[rank3]:		- replica_id: 0
[rank3]:		- group_size: 0
[rank3]:		- min_replica_size: 1
[rank3]:		- semi_sync_method: None
[rank3]:		- sync_steps: 5
[rank3]:		- should_quantize: False
[rank3]:		- fragment_sync_delay: 0
[rank3]:		- fragment_update_alpha: 0.0
[rank3]:	- experimental:
[rank3]:		- custom_import: 
[rank3]:		- custom_args_module: 
[rank3]:	- validation:
[rank3]:		- enabled: False
[rank3]:		- dataset: c4_validation
[rank3]:		- dataset_path: None
[rank3]:		- local_batch_size: 8
[rank3]:		- seq_len: 2048
[rank3]:		- freq: 10
[rank3]:		- steps: -1
[rank3]:	- freezing:
[rank3]:		- freeze: True
[rank3]:		- metric_type: fullrand7
[rank3]:		- phase_unit: 10
[rank3]:		- stability_check_freq: 50
[rank3]:		- aggressiveness: 0.0
[rank3]:
