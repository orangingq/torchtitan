
ðŸ”¥ðŸ”¥ðŸ”¥ðŸ”¥ðŸ”¥ðŸ”¥ðŸ”¥ðŸ”¥ðŸ”¥ðŸ”¥ðŸ”¥ðŸ”¥ðŸ”¥ðŸ”¥ðŸ”¥ðŸ”¥ðŸ”¥ðŸ”¥ðŸ”¥ðŸ”¥ðŸ”¥ðŸ”¥ðŸ”¥ðŸ”¥ðŸ”¥ðŸ”¥ðŸ”¥ðŸ”¥
âœ”ï¸Current Timestamp: Mon Sep 22 06:58:42 UTC 2025
âœ”ï¸SERVER: 521c56b8c386 (172.19.0.2),  GPUs: 0,1,2,3
âœ”ï¸SCRIPT: 
âœ”ï¸OUTPUT: /workspace/torchtitan/logs/runpod/0922_main/0922_gpipe_nofreeze.ans
âœ”ï¸Main Table Experiment for Llama 3.1 8B on Runpod
âœ”ï¸Running with nofreeze x gpipe ... 
â˜‘ï¸> torchrun --standalone --nnodes=1 --nproc_per_node=4 --local-ranks-filter=0,3 --role=rank --tee=3 -m timelyfreeze.train --job.config_file=/workspace/torchtitan/logs/runpod/0922_main/config.toml --job.description="Main Table Experiment for Llama 3.1 8B on Runpod" --training.global_batch_size=128 --training.local_batch_size=8 --parallelism.pipeline_parallel_microbatch_size=1 --training.seq_len=1024 --training.steps=500 --parallelism.pipeline_parallel_degree=4  --freezing.no-freeze
ðŸ”¥ðŸ”¥ðŸ”¥ðŸ”¥ðŸ”¥ðŸ”¥ðŸ”¥ðŸ”¥ðŸ”¥ðŸ”¥ðŸ”¥ðŸ”¥ðŸ”¥ðŸ”¥ðŸ”¥ðŸ”¥ðŸ”¥ðŸ”¥ðŸ”¥ðŸ”¥ðŸ”¥ðŸ”¥ðŸ”¥ðŸ”¥ðŸ”¥ðŸ”¥ðŸ”¥ðŸ”¥
W0922 06:58:43.790000 16839 torch/distributed/run.py:815] 
W0922 06:58:43.790000 16839 torch/distributed/run.py:815] *****************************************
W0922 06:58:43.790000 16839 torch/distributed/run.py:815] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
W0922 06:58:43.790000 16839 torch/distributed/run.py:815] *****************************************
[rank3]:[titan] 2025-09-22 06:58:48,537 - root - INFO - Starting job: "Main Table Experiment for Llama 3.1 8B on Runpod"
[rank3]:[titan] 2025-09-22 06:58:48,828 - root - WARNING - ENV[TORCH_NCCL_ASYNC_ERROR_HANDLING] = 1 will be overridden to 3 based on job config
[rank3]:[titan] 2025-09-22 06:58:48,833 - root - INFO - Building 1-D device mesh with ['pp'], [4]
[rank3]:[titan] 2025-09-22 06:58:48,838 - root - INFO - [GC] Initial GC collection 0.00 seconds
[rank0]:[titan] 2025-09-22 06:58:48,972 - root - INFO - Starting job: "Main Table Experiment for Llama 3.1 8B on Runpod"
[rank0]:[titan] 2025-09-22 06:58:49,193 - root - WARNING - ENV[TORCH_NCCL_ASYNC_ERROR_HANDLING] = 1 will be overridden to 3 based on job config
[rank0]:[titan] 2025-09-22 06:58:49,198 - root - INFO - Building 1-D device mesh with ['pp'], [4]
[rank0]:[titan] 2025-09-22 06:58:49,203 - root - INFO - [GC] Initial GC collection 0.00 seconds
[rank3]:[titan] 2025-09-22 06:58:49,476 - root - INFO - Loading tokenizer from tokenizer.json
[rank0]:[titan] 2025-09-22 06:58:49,475 - root - INFO - Loading tokenizer from tokenizer.json
[rank3]:[titan] 2025-09-22 06:58:49,788 - root - INFO - Preparing slimorca dataset from Open-Orca/SlimOrca
[rank0]:[titan] 2025-09-22 06:58:49,814 - root - INFO - Preparing slimorca dataset from Open-Orca/SlimOrca
[rank3]:[titan] 2025-09-22 06:58:50,564 - root - INFO - Building llama3 8B with TransformerModelArgs(_enforced='This field is used to enforce all fields have defaults.', dim=4096, n_layers=32, n_heads=32, n_kv_heads=8, vocab_size=128256, multiple_of=1024, ffn_dim_multiplier=1.3, norm_eps=1e-05, rope_theta=500000, max_seq_len=1024, depth_init=True, use_flex_attn=False, attn_mask_type='causal', eos_id=0)
[rank0]:[titan] 2025-09-22 06:58:50,692 - root - INFO - Building llama3 8B with TransformerModelArgs(_enforced='This field is used to enforce all fields have defaults.', dim=4096, n_layers=32, n_heads=32, n_kv_heads=8, vocab_size=128256, multiple_of=1024, ffn_dim_multiplier=1.3, norm_eps=1e-05, rope_theta=500000, max_seq_len=1024, depth_init=True, use_flex_attn=False, attn_mask_type='causal', eos_id=0)
[rank0]:[titan] 2025-09-22 06:58:50,942 - root - INFO - CUDA capacity: NVIDIA A100 80GB PCIe with 79.25GiB memory
[rank0]:[titan] 2025-09-22 06:58:50,963 - root - INFO - [34mModel llama3 8B [31msize: 8,030,261,248 total parameters[39m
[rank0]:[titan] 2025-09-22 06:58:50,984 - root - INFO - PP rank 0 is building stage_idx 0 with modules ['tok_embeddings', 'layers.0', 'layers.1', 'layers.2', 'layers.3', 'layers.4', 'layers.5', 'layers.6', 'layers.7']
[rank0]:[titan] 2025-09-22 06:58:50,984 - root - INFO - Using pipeline schedule gpipe with 8 microbatches and 4 stages.
[rank0]:[titan] 2025-09-22 06:58:51,167 - root - INFO - Peak FLOPS used for computing MFU: 3.120e+14
[rank0]:[titan] 2025-09-22 06:58:51,167 - root - INFO - CUDA memory usage for model: 8.46GiB(10.67%)
[rank0]:[titan] 2025-09-22 06:58:51,168 - root - WARNING - Warmup (200) + decay (400) steps exceed total training steps (500). Adjusting decay steps to 300.
[rank3]:[titan] 2025-09-22 06:58:51,507 - root - ERROR - Failed to create WandB logger: api_key not configured (no-tty). call wandb.login(key=[your_api_key])
[rank3]:[titan] 2025-09-22 06:58:51,509 - root - INFO - TensorBoard logging enabled. Logs will be saved at /workspace/torchtitan_data/tb/0922_gpipe_nofreeze_dm4/20250922-0658
[rank3]:[titan] 2025-09-22 06:58:51,510 - root - INFO - CUDA capacity: NVIDIA A100 80GB PCIe with 79.25GiB memory
[rank3]:[titan] 2025-09-22 06:58:51,533 - root - INFO - [34mModel llama3 8B [31msize: 8,030,261,248 total parameters[39m
[rank3]:[titan] 2025-09-22 06:58:51,555 - root - INFO - PP rank 3 is building stage_idx 3 with modules ['layers.25', 'layers.26', 'layers.27', 'layers.28', 'layers.29', 'layers.30', 'layers.31', 'norm', 'output']
[rank3]:[titan] 2025-09-22 06:58:51,555 - root - INFO - Using pipeline schedule gpipe with 8 microbatches and 4 stages.
[rank0]:[titan] 2025-09-22 06:58:51,761 - root - INFO - Checkpointing active. Checkpoints will be loaded from and saved to /workspace/torchtitan_data/checkpoint/0922_gpipe_nofreeze_dm4
[rank0]:[titan] 2025-09-22 06:58:51,761 - root - WARNING - Mixed precision training with TP or PP is only supported when FSDP/HSDP/CP is enabled.
[rank0]:[titan] 2025-09-22 06:58:51,761 - root - INFO - Mixed precision training is disabled
[rank0]:[titan] 2025-09-22 06:58:51,763 - root - INFO - Trainer is initialized with local batch size 8, global batch size 128, gradient accumulation steps 16, sequence length 1024, total steps 500 (warmup 200)
[rank0]:[titan] 2025-09-22 06:58:51,763 - root - INFO - Loading the checkpoint from /workspace/torchtitan_data/base_model/Llama-3.1-8B/original_dcp.
[rank3]:[titan] 2025-09-22 06:58:51,752 - root - INFO - Peak FLOPS used for computing MFU: 3.120e+14
[rank3]:[titan] 2025-09-22 06:58:51,753 - root - INFO - CUDA memory usage for model: 7.66GiB(9.66%)
[rank3]:[titan] 2025-09-22 06:58:51,753 - root - WARNING - Warmup (200) + decay (400) steps exceed total training steps (500). Adjusting decay steps to 300.
[rank3]:[titan] 2025-09-22 06:58:51,763 - root - INFO - Checkpointing active. Checkpoints will be loaded from and saved to /workspace/torchtitan_data/checkpoint/0922_gpipe_nofreeze_dm4
[rank3]:[titan] 2025-09-22 06:58:51,763 - root - WARNING - Mixed precision training with TP or PP is only supported when FSDP/HSDP/CP is enabled.
[rank3]:[titan] 2025-09-22 06:58:51,763 - root - INFO - Mixed precision training is disabled
[rank3]:[titan] 2025-09-22 06:58:51,765 - root - INFO - Trainer is initialized with local batch size 8, global batch size 128, gradient accumulation steps 16, sequence length 1024, total steps 500 (warmup 200)
[rank3]:[titan] 2025-09-22 06:58:51,765 - root - INFO - Loading the checkpoint from /workspace/torchtitan_data/base_model/Llama-3.1-8B/original_dcp.
[rank0]:[titan] 2025-09-22 06:59:00,657 - root - INFO - [GC] GC collection for checkpoint loading. 0.01 seconds
[rank0]:[titan] 2025-09-22 06:59:00,657 - root - INFO - Finished loading the checkpoint in 8.89 seconds.
[rank0]:[titan] 2025-09-22 06:59:00,657 - root - INFO - Training starts at step 1
[rank0]:[titan] 2025-09-22 06:59:00,657 - root - INFO - Step [1]
[rank3]:[titan] 2025-09-22 06:59:00,704 - root - INFO - [GC] GC collection for checkpoint loading. 0.06 seconds
[rank3]:[titan] 2025-09-22 06:59:00,704 - root - INFO - Finished loading the checkpoint in 8.94 seconds.
[rank3]:[titan] 2025-09-22 06:59:00,704 - root - INFO - Training starts at step 1
[rank3]:[titan] 2025-09-22 06:59:00,704 - root - INFO - Step [1]
[rank0]:/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:841: UserWarning: Attempting to run cuBLAS, but there was no current CUDA context! Attempting to set the primary context... (Triggered internally at /pytorch/aten/src/ATen/cuda/CublasHandlePool.cpp:270.)
[rank0]:  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
[rank3]:[titan] 2025-09-22 07:01:12,899 - root - INFO - [31m step:  1 [32m loss:  1.9227 [38;2;180;60;0m grad_norm:  0.5314 [38;2;54;234;195m memory: 46.16GiB(58.25%) [34m tps: 232 [36m tflops: 10.81 [35m mfu: 3.47%[39m
[rank3]:[titan] 2025-09-22 07:01:12,900 - root - INFO - Synchronizing and adjusting timeout for all ProcessGroups to 0:05:00
[rank3]:[titan] 2025-09-22 07:01:12,920 - root - INFO - Step [2]
[rank0]:[titan] 2025-09-22 07:01:12,918 - root - INFO - [31m step:  1 [32m loss: -16.0000 [38;2;180;60;0m grad_norm:  0.5314 [38;2;54;234;195m memory: 39.56GiB(49.92%) [34m tps: 231 [36m tflops: 10.77 [35m mfu: 3.45%[39m
[rank0]:[titan] 2025-09-22 07:01:12,918 - root - INFO - Synchronizing and adjusting timeout for all ProcessGroups to 0:05:00
[rank0]:[titan] 2025-09-22 07:01:12,919 - root - INFO - Step [2]
[rank3]:[titan] 2025-09-22 07:03:23,255 - root - INFO - Step [3]
[rank0]:[titan] 2025-09-22 07:03:25,444 - root - INFO - Step [3]
[rank3]:[titan] 2025-09-22 07:05:35,864 - root - INFO - Step [4]
[rank0]:[titan] 2025-09-22 07:05:38,052 - root - INFO - Step [4]
[rank3]:[titan] 2025-09-22 07:07:48,468 - root - INFO - Step [5]
[rank0]:[titan] 2025-09-22 07:07:50,658 - root - INFO - Step [5]
[rank3]:[titan] 2025-09-22 07:10:01,110 - root - INFO - Step [6]
[rank0]:[titan] 2025-09-22 07:10:03,299 - root - INFO - Step [6]
[rank3]:[titan] 2025-09-22 07:12:13,788 - root - INFO - Step [7]
[rank0]:[titan] 2025-09-22 07:12:15,977 - root - INFO - Step [7]
[rank3]:[titan] 2025-09-22 07:14:26,451 - root - INFO - Step [8]
[rank0]:[titan] 2025-09-22 07:14:28,641 - root - INFO - Step [8]
[rank3]:[titan] 2025-09-22 07:16:39,116 - root - INFO - Step [9]
[rank0]:[titan] 2025-09-22 07:16:41,308 - root - INFO - Step [9]
[rank3]:[titan] 2025-09-22 07:18:51,792 - root - INFO - Step [10]
[rank0]:[titan] 2025-09-22 07:18:53,980 - root - INFO - Step [10]
[rank3]:[titan] 2025-09-22 07:21:04,422 - root - INFO - Step [11]
[rank0]:[titan] 2025-09-22 07:21:06,610 - root - INFO - Step [11]
[rank3]:[titan] 2025-09-22 07:23:17,051 - root - INFO - Step [12]
[rank0]:[titan] 2025-09-22 07:23:19,242 - root - INFO - Step [12]
[rank3]:[titan] 2025-09-22 07:25:29,714 - root - INFO - Step [13]
[rank0]:[titan] 2025-09-22 07:25:31,907 - root - INFO - Step [13]
[rank3]:[titan] 2025-09-22 07:27:42,339 - root - INFO - Step [14]
[rank0]:[titan] 2025-09-22 07:27:44,533 - root - INFO - Step [14]
[rank3]:[titan] 2025-09-22 07:29:55,044 - root - INFO - Step [15]
[rank0]:[titan] 2025-09-22 07:29:57,233 - root - INFO - Step [15]
[rank3]:[titan] 2025-09-22 07:32:07,690 - root - INFO - Step [16]
[rank0]:[titan] 2025-09-22 07:32:09,877 - root - INFO - Step [16]
[rank3]:[titan] 2025-09-22 07:34:20,320 - root - INFO - Step [17]
[rank0]:[titan] 2025-09-22 07:34:22,509 - root - INFO - Step [17]
[rank3]:[titan] 2025-09-22 07:36:32,930 - root - INFO - Step [18]
[rank0]:[titan] 2025-09-22 07:36:35,120 - root - INFO - Step [18]
