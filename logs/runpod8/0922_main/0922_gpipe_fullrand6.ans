
üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•
‚úîÔ∏èCurrent Timestamp: Tue Sep 23 14:08:59 UTC 2025
‚úîÔ∏èSERVER: 30be631344fa (172.18.0.2),  GPUs: 0,1,2,3,4,5,6,7
‚úîÔ∏èSCRIPT: 
‚úîÔ∏èOUTPUT: /workspace/torchtitan/logs/runpod8/0922_main/0922_gpipe_fullrand6.ans
‚úîÔ∏èMain Table Experiment for Llama 3.1 8B on Runpod with 8 GPUs
‚úîÔ∏èRunning with fullrand6 x gpipe ... 
‚òëÔ∏è> torchrun --standalone --nnodes=1 --nproc_per_node=8 --local-ranks-filter=0,1,2,3,4,5,6,7 --role=rank --tee=3 -m timelyfreeze.train --job.config_file=/workspace/torchtitan/logs/runpod8/0922_main/config.toml --job.description="Main Table Experiment for Llama 3.1 8B on Runpod with 8 GPUs" --training.global_batch_size=128 --training.local_batch_size=8 --parallelism.pipeline_parallel_microbatch_size=1  --freezing.freeze --freezing.metric_type=fullrand6 --freezing.aggressiveness=0.05
üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•
W0923 14:09:00.323000 9646 torch/distributed/run.py:815] 
W0923 14:09:00.323000 9646 torch/distributed/run.py:815] *****************************************
W0923 14:09:00.323000 9646 torch/distributed/run.py:815] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
W0923 14:09:00.323000 9646 torch/distributed/run.py:815] *****************************************
[rank3]:[titan] 2025-09-23 14:09:08,924 - root - INFO - Starting job: "Main Table Experiment for Llama 3.1 8B on Runpod with 8 GPUs"
[rank0]:[titan] 2025-09-23 14:09:09,118 - root - INFO - Starting job: "Main Table Experiment for Llama 3.1 8B on Runpod with 8 GPUs"
[rank3]:[titan] 2025-09-23 14:09:09,206 - root - WARNING - ENV[TORCH_NCCL_ASYNC_ERROR_HANDLING] = 1 will be overridden to 3 based on job config
[rank3]:[titan] 2025-09-23 14:09:09,209 - root - INFO - Building 2-D device mesh with ['pp', 'dp_shard'], [4, 2]
[rank6]:[titan] 2025-09-23 14:09:09,182 - root - INFO - Starting job: "Main Table Experiment for Llama 3.1 8B on Runpod with 8 GPUs"
[rank1]:[titan] 2025-09-23 14:09:09,417 - root - INFO - Starting job: "Main Table Experiment for Llama 3.1 8B on Runpod with 8 GPUs"
[rank5]:[titan] 2025-09-23 14:09:09,419 - root - INFO - Starting job: "Main Table Experiment for Llama 3.1 8B on Runpod with 8 GPUs"
[rank7]:[titan] 2025-09-23 14:09:09,338 - root - INFO - Starting job: "Main Table Experiment for Llama 3.1 8B on Runpod with 8 GPUs"
[rank2]:[titan] 2025-09-23 14:09:09,500 - root - INFO - Starting job: "Main Table Experiment for Llama 3.1 8B on Runpod with 8 GPUs"
[rank0]:[titan] 2025-09-23 14:09:09,636 - root - WARNING - ENV[TORCH_NCCL_ASYNC_ERROR_HANDLING] = 1 will be overridden to 3 based on job config
[rank0]:[titan] 2025-09-23 14:09:09,638 - root - INFO - Building 2-D device mesh with ['pp', 'dp_shard'], [4, 2]
[rank0]:[titan] 2025-09-23 14:09:09,645 - root - INFO - [GC] Initial GC collection 0.00 seconds
[rank4]:[titan] 2025-09-23 14:09:09,649 - root - INFO - Starting job: "Main Table Experiment for Llama 3.1 8B on Runpod with 8 GPUs"
[rank6]:[titan] 2025-09-23 14:09:09,825 - root - WARNING - ENV[TORCH_NCCL_ASYNC_ERROR_HANDLING] = 1 will be overridden to 3 based on job config
[rank6]:[titan] 2025-09-23 14:09:09,829 - root - INFO - Building 2-D device mesh with ['pp', 'dp_shard'], [4, 2]
[rank7]:[titan] 2025-09-23 14:09:10,488 - root - WARNING - ENV[TORCH_NCCL_ASYNC_ERROR_HANDLING] = 1 will be overridden to 3 based on job config
[rank7]:[titan] 2025-09-23 14:09:10,492 - root - INFO - Building 2-D device mesh with ['pp', 'dp_shard'], [4, 2]
[rank1]:[titan] 2025-09-23 14:09:10,611 - root - WARNING - ENV[TORCH_NCCL_ASYNC_ERROR_HANDLING] = 1 will be overridden to 3 based on job config
[rank1]:[titan] 2025-09-23 14:09:10,615 - root - INFO - Building 2-D device mesh with ['pp', 'dp_shard'], [4, 2]
[rank5]:[titan] 2025-09-23 14:09:10,628 - root - WARNING - ENV[TORCH_NCCL_ASYNC_ERROR_HANDLING] = 1 will be overridden to 3 based on job config
[rank2]:[titan] 2025-09-23 14:09:10,636 - root - WARNING - ENV[TORCH_NCCL_ASYNC_ERROR_HANDLING] = 1 will be overridden to 3 based on job config
[rank2]:[titan] 2025-09-23 14:09:10,639 - root - INFO - Building 2-D device mesh with ['pp', 'dp_shard'], [4, 2]
[rank5]:[titan] 2025-09-23 14:09:10,631 - root - INFO - Building 2-D device mesh with ['pp', 'dp_shard'], [4, 2]
[rank4]:[titan] 2025-09-23 14:09:10,789 - root - WARNING - ENV[TORCH_NCCL_ASYNC_ERROR_HANDLING] = 1 will be overridden to 3 based on job config
[rank4]:[titan] 2025-09-23 14:09:10,792 - root - INFO - Building 2-D device mesh with ['pp', 'dp_shard'], [4, 2]
[rank0]:[titan] 2025-09-23 14:09:11,792 - root - INFO - Loading tokenizer from tokenizer.json
[rank0]:[titan] 2025-09-23 14:09:12,122 - root - INFO - Preparing slimorca dataset from Open-Orca/SlimOrca
[rank0]:[titan] 2025-09-23 14:09:13,612 - root - INFO - Building llama3 8B with TransformerModelArgs(_enforced='This field is used to enforce all fields have defaults.', dim=4096, n_layers=32, n_heads=32, n_kv_heads=8, vocab_size=128256, multiple_of=1024, ffn_dim_multiplier=1.3, norm_eps=1e-05, rope_theta=500000, max_seq_len=1024, depth_init=True, use_flex_attn=False, attn_mask_type='causal', eos_id=0)
[rank4]:[titan] 2025-09-23 14:09:13,808 - root - INFO - CUDA capacity: NVIDIA A100-SXM4-80GB with 79.25GiB memory
[rank2]:[titan] 2025-09-23 14:09:13,824 - root - INFO - CUDA capacity: NVIDIA A100-SXM4-80GB with 79.25GiB memory
[rank0]:[titan] 2025-09-23 14:09:13,905 - root - INFO - CUDA capacity: NVIDIA A100-SXM4-80GB with 79.25GiB memory
[rank1]:[titan] 2025-09-23 14:09:13,887 - root - INFO - CUDA capacity: NVIDIA A100-SXM4-80GB with 79.25GiB memory
[rank3]:[titan] 2025-09-23 14:09:13,856 - root - INFO - CUDA capacity: NVIDIA A100-SXM4-80GB with 79.25GiB memory
[rank4]:[titan] 2025-09-23 14:09:13,884 - root - INFO - PP rank 2 is building stage_idx 2 with modules ['layers.17', 'layers.18', 'layers.19', 'layers.20', 'layers.21', 'layers.22', 'layers.23', 'layers.24']
[rank4]:[titan] 2025-09-23 14:09:13,915 - root - INFO - Applied FSDP to the model
[rank4]:[titan] 2025-09-23 14:09:13,915 - root - INFO - Using pipeline schedule gpipe with 8 microbatches and 4 stages.
[rank5]:[titan] 2025-09-23 14:09:13,859 - root - INFO - CUDA capacity: NVIDIA A100-SXM4-80GB with 79.25GiB memory
[rank7]:[titan] 2025-09-23 14:09:13,892 - root - INFO - CUDA capacity: NVIDIA A100-SXM4-80GB with 79.25GiB memory
[rank2]:[titan] 2025-09-23 14:09:13,896 - root - INFO - PP rank 1 is building stage_idx 1 with modules ['layers.8', 'layers.9', 'layers.10', 'layers.11', 'layers.12', 'layers.13', 'layers.14', 'layers.15', 'layers.16']
[rank2]:[titan] 2025-09-23 14:09:13,929 - root - INFO - Applied FSDP to the model
[rank2]:[titan] 2025-09-23 14:09:13,929 - root - INFO - Using pipeline schedule gpipe with 8 microbatches and 4 stages.
[rank0]:[titan] 2025-09-23 14:09:13,965 - root - INFO - [34mModel llama3 8B [31msize: 8,030,261,248 total parameters[39m
[rank0]:[titan] 2025-09-23 14:09:13,993 - root - INFO - PP rank 0 is building stage_idx 0 with modules ['tok_embeddings', 'layers.0', 'layers.1', 'layers.2', 'layers.3', 'layers.4', 'layers.5', 'layers.6', 'layers.7']
[rank0]:[titan] 2025-09-23 14:09:14,025 - root - INFO - Applied FSDP to the model
[rank0]:[titan] 2025-09-23 14:09:14,025 - root - INFO - Using pipeline schedule gpipe with 8 microbatches and 4 stages.
[rank1]:[titan] 2025-09-23 14:09:13,984 - root - INFO - PP rank 0 is building stage_idx 0 with modules ['tok_embeddings', 'layers.0', 'layers.1', 'layers.2', 'layers.3', 'layers.4', 'layers.5', 'layers.6', 'layers.7']
[rank1]:[titan] 2025-09-23 14:09:14,018 - root - INFO - Applied FSDP to the model
[rank1]:[titan] 2025-09-23 14:09:14,018 - root - INFO - Using pipeline schedule gpipe with 8 microbatches and 4 stages.
[rank3]:[titan] 2025-09-23 14:09:13,940 - root - INFO - PP rank 1 is building stage_idx 1 with modules ['layers.8', 'layers.9', 'layers.10', 'layers.11', 'layers.12', 'layers.13', 'layers.14', 'layers.15', 'layers.16']
[rank3]:[titan] 2025-09-23 14:09:13,973 - root - INFO - Applied FSDP to the model
[rank3]:[titan] 2025-09-23 14:09:13,973 - root - INFO - Using pipeline schedule gpipe with 8 microbatches and 4 stages.
[rank5]:[titan] 2025-09-23 14:09:13,944 - root - INFO - PP rank 2 is building stage_idx 2 with modules ['layers.17', 'layers.18', 'layers.19', 'layers.20', 'layers.21', 'layers.22', 'layers.23', 'layers.24']
[rank5]:[titan] 2025-09-23 14:09:13,975 - root - INFO - Applied FSDP to the model
[rank5]:[titan] 2025-09-23 14:09:13,975 - root - INFO - Using pipeline schedule gpipe with 8 microbatches and 4 stages.
[rank7]:[titan] 2025-09-23 14:09:13,988 - root - INFO - PP rank 3 is building stage_idx 3 with modules ['layers.25', 'layers.26', 'layers.27', 'layers.28', 'layers.29', 'layers.30', 'layers.31', 'norm', 'output']
[rank7]:[titan] 2025-09-23 14:09:14,020 - root - INFO - Applied FSDP to the model
[rank7]:[titan] 2025-09-23 14:09:14,021 - root - INFO - Using pipeline schedule gpipe with 8 microbatches and 4 stages.
[rank4]:[titan] 2025-09-23 14:09:14,207 - root - INFO - Peak FLOPS used for computing MFU: 3.120e+14
[rank4]:[titan] 2025-09-23 14:09:14,207 - root - INFO - CUDA memory usage for model: 3.26GiB(4.12%)
[rank2]:[titan] 2025-09-23 14:09:14,283 - root - INFO - Peak FLOPS used for computing MFU: 3.120e+14
[rank2]:[titan] 2025-09-23 14:09:14,283 - root - INFO - CUDA memory usage for model: 3.67GiB(4.64%)
[rank5]:[titan] 2025-09-23 14:09:14,351 - root - INFO - Peak FLOPS used for computing MFU: 3.120e+14
[rank5]:[titan] 2025-09-23 14:09:14,351 - root - INFO - CUDA memory usage for model: 3.26GiB(4.12%)
[rank0]:[titan] 2025-09-23 14:09:14,452 - root - INFO - Peak FLOPS used for computing MFU: 3.120e+14
[rank0]:[titan] 2025-09-23 14:09:14,452 - root - INFO - CUDA memory usage for model: 4.24GiB(5.35%)
[rank1]:[titan] 2025-09-23 14:09:14,453 - root - INFO - Peak FLOPS used for computing MFU: 3.120e+14
[rank1]:[titan] 2025-09-23 14:09:14,453 - root - INFO - CUDA memory usage for model: 4.24GiB(5.35%)
[rank3]:[titan] 2025-09-23 14:09:14,433 - root - INFO - Peak FLOPS used for computing MFU: 3.120e+14
[rank3]:[titan] 2025-09-23 14:09:14,433 - root - INFO - CUDA memory usage for model: 3.67GiB(4.64%)
[rank7]:[titan] 2025-09-23 14:09:14,447 - root - INFO - Peak FLOPS used for computing MFU: 3.120e+14
[rank7]:[titan] 2025-09-23 14:09:14,448 - root - INFO - CUDA memory usage for model: 3.83GiB(4.83%)
[rank6]:wandb: Currently logged in as: orangingq to https://api.wandb.ai. Use `wandb login --relogin` to force relogin
[rank6]:wandb: Tracking run with wandb version 0.22.0
[rank6]:wandb: Run data is saved locally in /workspace/torchtitan_data/tb/0922_gpipe_fullrand6_runpod/20250923-1409/wandb/run-20250923_140914-vfslj3rc
[rank6]:wandb: Run `wandb offline` to turn off syncing.
[rank6]:wandb: Syncing run 0922_gpipe_fullrand6_runpod
[rank6]:wandb: ‚≠êÔ∏è View project at https://wandb.ai/orangingq/torchtitan
[rank6]:wandb: üöÄ View run at https://wandb.ai/orangingq/torchtitan/runs/vfslj3rc
[rank6]:[titan] 2025-09-23 14:09:15,541 - root - INFO - WandB logging enabled
[rank6]:[titan] 2025-09-23 14:09:15,541 - root - INFO - CUDA capacity: NVIDIA A100-SXM4-80GB with 79.25GiB memory
[rank6]:[titan] 2025-09-23 14:09:15,607 - root - INFO - PP rank 3 is building stage_idx 3 with modules ['layers.25', 'layers.26', 'layers.27', 'layers.28', 'layers.29', 'layers.30', 'layers.31', 'norm', 'output']
[rank6]:[titan] 2025-09-23 14:09:15,641 - root - INFO - Applied FSDP to the model
[rank6]:[titan] 2025-09-23 14:09:15,641 - root - INFO - Using pipeline schedule gpipe with 8 microbatches and 4 stages.
[rank0]:[titan] 2025-09-23 14:09:15,897 - root - INFO - Checkpointing active. Checkpoints will be loaded from and saved to /workspace/torchtitan_data/checkpoint/0922_gpipe_fullrand6_runpod
[rank0]:[titan] 2025-09-23 14:09:15,897 - root - INFO - Mixed precision training is handled by fully_shard
[rank0]:[titan] 2025-09-23 14:09:15,899 - root - INFO - Trainer is initialized with local batch size 8, global batch size 128, gradient accumulation steps 8, sequence length 1024, total steps 1000 (warmup 20)
[rank0]:[titan] 2025-09-23 14:09:15,900 - root - INFO - Training starts at step 1
[rank6]:[titan] 2025-09-23 14:09:15,876 - root - INFO - Peak FLOPS used for computing MFU: 3.120e+14
[rank6]:[titan] 2025-09-23 14:09:15,876 - root - INFO - CUDA memory usage for model: 3.83GiB(4.83%)
[rank0]:/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:841: UserWarning: Attempting to run cuBLAS, but there was no current CUDA context! Attempting to set the primary context... (Triggered internally at /pytorch/aten/src/ATen/cuda/CublasHandlePool.cpp:270.)
[rank0]:  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
[rank1]:[titan] 2025-09-23 14:09:30,808 - root - INFO - [31m step:  1 [32m loss: -8.0000 [38;2;180;60;0m grad_norm:  0.6609 [38;2;54;234;195m memory: 35.46GiB(44.74%) [34m tps: 972 [36m tflops: 45.34 [35m mfu: 14.53%[39m
[rank1]:[titan] 2025-09-23 14:09:30,809 - root - INFO - Synchronizing and adjusting timeout for all ProcessGroups to 0:50:00
[rank0]:[titan] 2025-09-23 14:09:30,808 - root - INFO - [31m step:  1 [32m loss: -8.0000 [38;2;180;60;0m grad_norm:  0.6609 [38;2;54;234;195m memory: 35.46GiB(44.74%) [34m tps: 973 [36m tflops: 45.37 [35m mfu: 14.54%[39m
[rank0]:[titan] 2025-09-23 14:09:30,809 - root - INFO - Synchronizing and adjusting timeout for all ProcessGroups to 0:50:00
[rank3]:[titan] 2025-09-23 14:09:30,810 - root - INFO - [31m step:  1 [32m loss: -8.0000 [38;2;180;60;0m grad_norm:  0.6609 [38;2;54;234;195m memory: 31.52GiB(39.77%) [34m tps: 970 [36m tflops: 45.22 [35m mfu: 14.49%[39m
[rank3]:[titan] 2025-09-23 14:09:30,811 - root - INFO - Synchronizing and adjusting timeout for all ProcessGroups to 0:50:00
[rank6]:[titan] 2025-09-23 14:09:30,801 - root - INFO - [31m step:  1 [32m loss: 12.2868 [38;2;180;60;0m grad_norm:  0.6609 [38;2;54;234;195m memory: 38.21GiB(48.22%) [34m tps: 1,076 [36m tflops: 50.20 [35m mfu: 16.09%[39m
[rank6]:[titan] 2025-09-23 14:09:30,802 - root - INFO - Synchronizing and adjusting timeout for all ProcessGroups to 0:50:00
[rank7]:[titan] 2025-09-23 14:09:30,801 - root - INFO - [31m step:  1 [32m loss: 12.2868 [38;2;180;60;0m grad_norm:  0.6609 [38;2;54;234;195m memory: 38.21GiB(48.22%) [34m tps: 973 [36m tflops: 45.38 [35m mfu: 14.54%[39m
[rank7]:[titan] 2025-09-23 14:09:30,801 - root - INFO - Synchronizing and adjusting timeout for all ProcessGroups to 0:50:00
[rank5]:[titan] 2025-09-23 14:09:30,802 - root - INFO - [31m step:  1 [32m loss: -8.0000 [38;2;180;60;0m grad_norm:  0.6609 [38;2;54;234;195m memory: 28.25GiB(35.65%) [34m tps: 970 [36m tflops: 45.25 [35m mfu: 14.50%[39m
[rank5]:[titan] 2025-09-23 14:09:30,803 - root - INFO - Synchronizing and adjusting timeout for all ProcessGroups to 0:50:00
[rank4]:[titan] 2025-09-23 14:09:30,802 - root - INFO - [31m step:  1 [32m loss: -8.0000 [38;2;180;60;0m grad_norm:  0.6609 [38;2;54;234;195m memory: 28.25GiB(35.65%) [34m tps: 967 [36m tflops: 45.09 [35m mfu: 14.45%[39m
[rank4]:[titan] 2025-09-23 14:09:30,803 - root - INFO - Synchronizing and adjusting timeout for all ProcessGroups to 0:50:00
[rank2]:[titan] 2025-09-23 14:09:30,810 - root - INFO - [31m step:  1 [32m loss: -8.0000 [38;2;180;60;0m grad_norm:  0.6609 [38;2;54;234;195m memory: 31.52GiB(39.77%) [34m tps: 967 [36m tflops: 45.10 [35m mfu: 14.46%[39m
[rank2]:[titan] 2025-09-23 14:09:30,811 - root - INFO - Synchronizing and adjusting timeout for all ProcessGroups to 0:50:00
[rank1]:[titan] 2025-09-23 14:11:35,007 - root - INFO - Current/Expected Freeze Ratio per Block: [MB0] 0.00/0.00, [MB1] 0.00/0.00, [MB2] 0.02/0.06, [MB3] 0.40/1.00, [MB4] 0.40/1.00, [MB5] 0.40/1.00, [MB6] 0.40/1.00, [MB7] 0.40/1.00
[rank0]:[titan] 2025-09-23 14:11:34,950 - root - INFO - [Step 120] Setting Upperbound
[rank0]:[titan] 2025-09-23 14:11:35,012 - root - INFO - Current/Expected Freeze Ratio per Block: [MB0] 0.00/0.00, [MB1] 0.00/0.00, [MB2] 0.02/0.05, [MB3] 0.40/1.00, [MB4] 0.40/1.00, [MB5] 0.40/1.00, [MB6] 0.40/1.00, [MB7] 0.40/1.00
[rank3]:[titan] 2025-09-23 14:11:35,013 - root - INFO - Current/Expected Freeze Ratio per Block: [MB0] 0.34/0.85, [MB1] 0.09/0.22, [MB2] 0.06/0.14, [MB3] 0.40/1.00, [MB4] 0.40/1.00, [MB5] 0.40/1.00, [MB6] 0.40/1.00, [MB7] 0.40/1.00
[rank5]:[titan] 2025-09-23 14:11:35,008 - root - INFO - Current/Expected Freeze Ratio per Block: [MB0] 0.28/0.71, [MB1] 0.32/0.80, [MB2] 0.01/0.02, [MB3] 0.05/0.12, [MB4] 0.40/1.00, [MB5] 0.40/1.00, [MB6] 0.40/1.00, [MB7] 0.40/1.00
[rank4]:[titan] 2025-09-23 14:11:35,004 - root - INFO - Current/Expected Freeze Ratio per Block: [MB0] 0.29/0.72, [MB1] 0.32/0.80, [MB2] 0.05/0.11, [MB3] 0.00/0.00, [MB4] 0.40/1.00, [MB5] 0.40/1.00, [MB6] 0.40/1.00, [MB7] 0.40/1.00
[rank2]:[titan] 2025-09-23 14:11:35,006 - root - INFO - Current/Expected Freeze Ratio per Block: [MB0] 0.34/0.85, [MB1] 0.09/0.22, [MB2] 0.03/0.07, [MB3] 0.40/0.99, [MB4] 0.40/1.00, [MB5] 0.40/1.00, [MB6] 0.40/1.00, [MB7] 0.40/1.00
[rank6]:[titan] 2025-09-23 14:11:35,197 - root - INFO - Pipeline schedule is saved as: /workspace/torchtitan_data/images/0922_gpipe_fullrand6_runpod/pipeline_schedule/250923_1411_max_batch_time_rank6.svg
[rank6]:> Batch Time: 1060.67 ms, GPU Bubble Ratio: 40.62%, 38.58%, 45.05%, 35.79%
[rank7]:[titan] 2025-09-23 14:11:35,199 - root - INFO - Pipeline schedule is saved as: /workspace/torchtitan_data/images/0922_gpipe_fullrand6_runpod/pipeline_schedule/250923_1411_max_batch_time_rank7.svg
[rank7]:> Batch Time: 1059.67 ms, GPU Bubble Ratio: 40.77%, 38.15%, 45.11%, 35.71%
[rank6]:[titan] 2025-09-23 14:11:35,386 - root - INFO - Pipeline schedule is saved as: /workspace/torchtitan_data/images/0922_gpipe_fullrand6_runpod/pipeline_schedule/250923_1411_min_batch_time_rank6.svg
[rank6]:> Batch Time: 675.36 ms, GPU Bubble Ratio: 40.43%, 37.89%, 44.39%, 35.99%
[rank7]:[titan] 2025-09-23 14:11:35,387 - root - INFO - Pipeline schedule is saved as: /workspace/torchtitan_data/images/0922_gpipe_fullrand6_runpod/pipeline_schedule/250923_1411_min_batch_time_rank7.svg
[rank7]:> Batch Time: 674.89 ms, GPU Bubble Ratio: 40.66%, 37.45%, 44.48%, 35.83%
[rank6]:[titan] 2025-09-23 14:11:35,597 - root - INFO - Pipeline schedule is saved as: /workspace/torchtitan_data/images/0922_gpipe_fullrand6_runpod/pipeline_schedule/250923_1411_frozen_pipeline_schedule_rank6.svg
[rank6]:> Batch Time: 675.36 ms, GPU Bubble Ratio: 29.47%, 30.56%, 36.09%, 35.99%
[rank6]:[titan] 2025-09-23 14:11:35,598 - root - INFO - > Batch Time: 675.36 ms (Average Freeze Ratio: 0.78, Time Reduction Rate: 0.36)
[rank6]:[titan] 2025-09-23 14:11:35,601 - root - INFO - Current/Expected Freeze Ratio per Block: [MB0] 0.40/1.00, [MB1] 0.40/1.00, [MB2] 0.40/1.00, [MB3] 0.40/1.00, [MB4] 0.40/1.00, [MB5] 0.40/1.00, [MB6] 0.40/1.00, [MB7] 0.40/1.00
[rank7]:[titan] 2025-09-23 14:11:35,605 - root - INFO - Pipeline schedule is saved as: /workspace/torchtitan_data/images/0922_gpipe_fullrand6_runpod/pipeline_schedule/250923_1411_frozen_pipeline_schedule_rank7.svg
[rank7]:> Batch Time: 674.89 ms, GPU Bubble Ratio: 29.77%, 30.39%, 36.20%, 35.83%
[rank7]:[titan] 2025-09-23 14:11:35,605 - root - INFO - > Batch Time: 674.89 ms (Average Freeze Ratio: 0.78, Time Reduction Rate: 0.36)
[rank7]:[titan] 2025-09-23 14:11:35,609 - root - INFO - Current/Expected Freeze Ratio per Block: [MB0] 0.40/1.00, [MB1] 0.40/1.00, [MB2] 0.40/1.00, [MB3] 0.40/1.00, [MB4] 0.40/1.00, [MB5] 0.40/1.00, [MB6] 0.40/1.00, [MB7] 0.40/1.00
[rank7]:[titan] 2025-09-23 14:12:16,882 - root - INFO - Current/Expected Freeze Ratio per Block: [MB0] 0.40/1.00, [MB1] 0.40/1.00, [MB2] 0.40/1.00, [MB3] 0.40/1.00, [MB4] 0.40/1.00, [MB5] 0.40/1.00, [MB6] 0.40/1.00, [MB7] 0.40/1.00
[rank6]:[titan] 2025-09-23 14:12:16,881 - root - INFO - Current/Expected Freeze Ratio per Block: [MB0] 0.40/1.00, [MB1] 0.40/1.00, [MB2] 0.40/1.00, [MB3] 0.40/1.00, [MB4] 0.40/1.00, [MB5] 0.40/1.00, [MB6] 0.40/1.00, [MB7] 0.40/1.00
[rank5]:[titan] 2025-09-23 14:12:16,963 - root - INFO - Current/Expected Freeze Ratio per Block: [MB0] 0.28/0.71, [MB1] 0.32/0.80, [MB2] 0.01/0.02, [MB3] 0.05/0.12, [MB4] 0.40/1.00, [MB5] 0.40/1.00, [MB6] 0.40/1.00, [MB7] 0.40/1.00
[rank4]:[titan] 2025-09-23 14:12:16,963 - root - INFO - Current/Expected Freeze Ratio per Block: [MB0] 0.29/0.72, [MB1] 0.32/0.80, [MB2] 0.05/0.11, [MB3] 0.00/0.00, [MB4] 0.40/1.00, [MB5] 0.40/1.00, [MB6] 0.40/1.00, [MB7] 0.40/1.00
[rank3]:[titan] 2025-09-23 14:12:17,059 - root - INFO - Current/Expected Freeze Ratio per Block: [MB0] 0.34/0.85, [MB1] 0.09/0.22, [MB2] 0.06/0.14, [MB3] 0.40/1.00, [MB4] 0.40/1.00, [MB5] 0.40/1.00, [MB6] 0.40/1.00, [MB7] 0.40/1.00
[rank2]:[titan] 2025-09-23 14:12:17,057 - root - INFO - Current/Expected Freeze Ratio per Block: [MB0] 0.34/0.85, [MB1] 0.09/0.22, [MB2] 0.03/0.07, [MB3] 0.40/0.99, [MB4] 0.40/1.00, [MB5] 0.40/1.00, [MB6] 0.40/1.00, [MB7] 0.40/1.00
[rank0]:[titan] 2025-09-23 14:12:17,157 - root - INFO - Current/Expected Freeze Ratio per Block: [MB0] 0.00/0.00, [MB1] 0.00/0.00, [MB2] 0.02/0.05, [MB3] 0.40/1.00, [MB4] 0.40/1.00, [MB5] 0.40/1.00, [MB6] 0.40/1.00, [MB7] 0.40/1.00
[rank1]:[titan] 2025-09-23 14:12:17,156 - root - INFO - Current/Expected Freeze Ratio per Block: [MB0] 0.00/0.00, [MB1] 0.00/0.00, [MB2] 0.02/0.06, [MB3] 0.40/1.00, [MB4] 0.40/1.00, [MB5] 0.40/1.00, [MB6] 0.40/1.00, [MB7] 0.40/1.00
[rank6]:/workspace/torchtitan/timelyfreeze/core/schedule.py:344: RankWarning: Polyfit may be poorly conditioned
[rank6]:  a, b = np.polyfit(afrs, times, 1)
[rank7]:/workspace/torchtitan/timelyfreeze/core/schedule.py:344: RankWarning: Polyfit may be poorly conditioned
[rank7]:  a, b = np.polyfit(afrs, times, 1)
[rank0]:[titan] 2025-09-23 14:12:58,900 - root - INFO - Observed values (freeze ratio vs time) with Trend Line is saved as: /workspace/torchtitan_data/images/0922_gpipe_fullrand6_runpod/pipeline_schedule_adjustment/250923_1412_rank0_trend_line.svg
[rank3]:[titan] 2025-09-23 14:12:58,895 - root - INFO - Observed values (freeze ratio vs time) with Trend Line is saved as: /workspace/torchtitan_data/images/0922_gpipe_fullrand6_runpod/pipeline_schedule_adjustment/250923_1412_rank3_trend_line.svg
[rank6]:[titan] 2025-09-23 14:12:58,893 - root - INFO - Observed values (freeze ratio vs time) with Trend Line is saved as: /workspace/torchtitan_data/images/0922_gpipe_fullrand6_runpod/pipeline_schedule_adjustment/250923_1412_rank6_trend_line.svg
[rank5]:[titan] 2025-09-23 14:12:58,893 - root - INFO - Observed values (freeze ratio vs time) with Trend Line is saved as: /workspace/torchtitan_data/images/0922_gpipe_fullrand6_runpod/pipeline_schedule_adjustment/250923_1412_rank5_trend_line.svg
[rank5]:[titan] 2025-09-23 14:12:58,905 - root - INFO - Adjusted Freeze Ratio per Block: [MB0] 0.00/0.00, [MB1] 0.00/0.00, [MB2] 0.00/0.00, [MB3] 0.00/0.00, [MB4] 0.00/0.00, [MB5] 0.00/0.00, [MB6] 0.00/0.00, [MB7] 0.00/0.00
[rank5]:[titan] 2025-09-23 14:12:58,906 - root - INFO - Current/Expected Freeze Ratio per Block: [MB0] 0.00/0.00, [MB1] 0.00/0.00, [MB2] 0.00/0.00, [MB3] 0.00/0.00, [MB4] 0.00/0.00, [MB5] 0.00/0.00, [MB6] 0.00/0.00, [MB7] 0.00/0.00
[rank7]:[titan] 2025-09-23 14:12:58,893 - root - INFO - Observed values (freeze ratio vs time) with Trend Line is saved as: /workspace/torchtitan_data/images/0922_gpipe_fullrand6_runpod/pipeline_schedule_adjustment/250923_1412_rank7_trend_line.svg
[rank4]:[titan] 2025-09-23 14:12:58,894 - root - INFO - Observed values (freeze ratio vs time) with Trend Line is saved as: /workspace/torchtitan_data/images/0922_gpipe_fullrand6_runpod/pipeline_schedule_adjustment/250923_1412_rank4_trend_line.svg
[rank4]:[titan] 2025-09-23 14:12:58,905 - root - INFO - Adjusted Freeze Ratio per Block: [MB0] 0.00/0.00, [MB1] 0.00/0.00, [MB2] 0.00/0.00, [MB3] 0.00/0.00, [MB4] 0.00/0.00, [MB5] 0.00/0.00, [MB6] 0.00/0.00, [MB7] 0.00/0.00
[rank4]:[titan] 2025-09-23 14:12:58,906 - root - INFO - Current/Expected Freeze Ratio per Block: [MB0] 0.00/0.00, [MB1] 0.00/0.00, [MB2] 0.00/0.00, [MB3] 0.00/0.00, [MB4] 0.00/0.00, [MB5] 0.00/0.00, [MB6] 0.00/0.00, [MB7] 0.00/0.00
[rank1]:[titan] 2025-09-23 14:12:58,900 - root - INFO - Observed values (freeze ratio vs time) with Trend Line is saved as: /workspace/torchtitan_data/images/0922_gpipe_fullrand6_runpod/pipeline_schedule_adjustment/250923_1412_rank1_trend_line.svg
[rank1]:[titan] 2025-09-23 14:12:58,905 - root - INFO - Adjusted Freeze Ratio per Block: [MB0] 0.00/0.00, [MB1] 0.00/0.00, [MB2] 0.00/0.00, [MB3] 0.00/0.00, [MB4] 0.00/0.00, [MB5] 0.00/0.00, [MB6] 0.00/0.00, [MB7] 0.00/0.00
[rank1]:[titan] 2025-09-23 14:12:58,906 - root - INFO - Current/Expected Freeze Ratio per Block: [MB0] 0.00/0.00, [MB1] 0.00/0.00, [MB2] 0.00/0.00, [MB3] 0.00/0.00, [MB4] 0.00/0.00, [MB5] 0.00/0.00, [MB6] 0.00/0.00, [MB7] 0.00/0.00
[rank2]:[titan] 2025-09-23 14:12:58,897 - root - INFO - Observed values (freeze ratio vs time) with Trend Line is saved as: /workspace/torchtitan_data/images/0922_gpipe_fullrand6_runpod/pipeline_schedule_adjustment/250923_1412_rank2_trend_line.svg
[rank2]:[titan] 2025-09-23 14:12:58,905 - root - INFO - Adjusted Freeze Ratio per Block: [MB0] 0.00/0.00, [MB1] 0.00/0.00, [MB2] 0.00/0.00, [MB3] 0.00/0.00, [MB4] 0.00/0.00, [MB5] 0.00/0.00, [MB6] 0.00/0.00, [MB7] 0.00/0.00
[rank2]:[titan] 2025-09-23 14:12:58,906 - root - INFO - Current/Expected Freeze Ratio per Block: [MB0] 0.00/0.00, [MB1] 0.00/0.00, [MB2] 0.00/0.00, [MB3] 0.00/0.00, [MB4] 0.00/0.00, [MB5] 0.00/0.00, [MB6] 0.00/0.00, [MB7] 0.00/0.00
[rank0]:[titan] 2025-09-23 14:12:58,905 - root - INFO - Adjusted Freeze Ratio per Block: [MB0] 0.00/0.00, [MB1] 0.00/0.00, [MB2] 0.00/0.00, [MB3] 0.00/0.00, [MB4] 0.00/0.00, [MB5] 0.00/0.00, [MB6] 0.00/0.00, [MB7] 0.00/0.00
[rank0]:[titan] 2025-09-23 14:12:58,906 - root - INFO - Current/Expected Freeze Ratio per Block: [MB0] 0.00/0.00, [MB1] 0.00/0.00, [MB2] 0.00/0.00, [MB3] 0.00/0.00, [MB4] 0.00/0.00, [MB5] 0.00/0.00, [MB6] 0.00/0.00, [MB7] 0.00/0.00
[rank3]:[titan] 2025-09-23 14:12:58,905 - root - INFO - Adjusted Freeze Ratio per Block: [MB0] 0.00/0.00, [MB1] 0.00/0.00, [MB2] 0.00/0.00, [MB3] 0.00/0.00, [MB4] 0.00/0.00, [MB5] 0.00/0.00, [MB6] 0.00/0.00, [MB7] 0.00/0.00
[rank3]:[titan] 2025-09-23 14:12:58,906 - root - INFO - Current/Expected Freeze Ratio per Block: [MB0] 0.00/0.00, [MB1] 0.00/0.00, [MB2] 0.00/0.00, [MB3] 0.00/0.00, [MB4] 0.00/0.00, [MB5] 0.00/0.00, [MB6] 0.00/0.00, [MB7] 0.00/0.00
[rank6]:[titan] 2025-09-23 14:12:59,101 - root - INFO - Pipeline schedule is saved as: /workspace/torchtitan_data/images/0922_gpipe_fullrand6_runpod/pipeline_schedule/250923_1412_adjusted_frozen_pipeline_schedule_rank6.svg
[rank6]:> Batch Time: 820.15 ms, GPU Bubble Ratio: 29.94%, 27.67%, 34.63%, 49.98%
[rank6]:[titan] 2025-09-23 14:12:59,101 - root - INFO - > Batch Time: 820.15 ms (Average Freeze Ratio: 0.00)
[rank6]:[titan] 2025-09-23 14:12:59,101 - root - INFO - Adjusted Freeze Ratio per Block: [MB0] 0.00/0.00, [MB1] 0.00/0.00, [MB2] 0.00/0.00, [MB3] 0.00/0.00, [MB4] 0.00/0.00, [MB5] 0.00/0.00, [MB6] 0.00/0.00, [MB7] 0.00/0.00
[rank6]:[titan] 2025-09-23 14:12:59,102 - root - INFO - Current/Expected Freeze Ratio per Block: [MB0] 0.00/0.00, [MB1] 0.00/0.00, [MB2] 0.00/0.00, [MB3] 0.00/0.00, [MB4] 0.00/0.00, [MB5] 0.00/0.00, [MB6] 0.00/0.00, [MB7] 0.00/0.00
[rank7]:[titan] 2025-09-23 14:12:59,099 - root - INFO - Pipeline schedule is saved as: /workspace/torchtitan_data/images/0922_gpipe_fullrand6_runpod/pipeline_schedule/250923_1412_adjusted_frozen_pipeline_schedule_rank7.svg
[rank7]:> Batch Time: 818.16 ms, GPU Bubble Ratio: 30.07%, 27.50%, 34.79%, 49.76%
[rank7]:[titan] 2025-09-23 14:12:59,099 - root - INFO - > Batch Time: 818.16 ms (Average Freeze Ratio: 0.00)
[rank7]:[titan] 2025-09-23 14:12:59,099 - root - INFO - Adjusted Freeze Ratio per Block: [MB0] 0.00/0.00, [MB1] 0.00/0.00, [MB2] 0.00/0.00, [MB3] 0.00/0.00, [MB4] 0.00/0.00, [MB5] 0.00/0.00, [MB6] 0.00/0.00, [MB7] 0.00/0.00
[rank7]:[titan] 2025-09-23 14:12:59,100 - root - INFO - Current/Expected Freeze Ratio per Block: [MB0] 0.00/0.00, [MB1] 0.00/0.00, [MB2] 0.00/0.00, [MB3] 0.00/0.00, [MB4] 0.00/0.00, [MB5] 0.00/0.00, [MB6] 0.00/0.00, [MB7] 0.00/0.00
[rank7]:[titan] 2025-09-23 14:13:42,739 - root - INFO - Current/Expected Freeze Ratio per Block: [MB0] 0.00/0.00, [MB1] 0.00/0.00, [MB2] 0.00/0.00, [MB3] 0.00/0.00, [MB4] 0.00/0.00, [MB5] 0.00/0.00, [MB6] 0.00/0.00, [MB7] 0.00/0.00
[rank6]:[titan] 2025-09-23 14:13:42,738 - root - INFO - Current/Expected Freeze Ratio per Block: [MB0] 0.00/0.00, [MB1] 0.00/0.00, [MB2] 0.00/0.00, [MB3] 0.00/0.00, [MB4] 0.00/0.00, [MB5] 0.00/0.00, [MB6] 0.00/0.00, [MB7] 0.00/0.00
[rank4]:[titan] 2025-09-23 14:13:42,825 - root - INFO - Current/Expected Freeze Ratio per Block: [MB0] 0.00/0.00, [MB1] 0.00/0.00, [MB2] 0.00/0.00, [MB3] 0.00/0.00, [MB4] 0.00/0.00, [MB5] 0.00/0.00, [MB6] 0.00/0.00, [MB7] 0.00/0.00
[rank5]:[titan] 2025-09-23 14:13:42,825 - root - INFO - Current/Expected Freeze Ratio per Block: [MB0] 0.00/0.00, [MB1] 0.00/0.00, [MB2] 0.00/0.00, [MB3] 0.00/0.00, [MB4] 0.00/0.00, [MB5] 0.00/0.00, [MB6] 0.00/0.00, [MB7] 0.00/0.00
[rank3]:[titan] 2025-09-23 14:13:42,922 - root - INFO - Current/Expected Freeze Ratio per Block: [MB0] 0.00/0.00, [MB1] 0.00/0.00, [MB2] 0.00/0.00, [MB3] 0.00/0.00, [MB4] 0.00/0.00, [MB5] 0.00/0.00, [MB6] 0.00/0.00, [MB7] 0.00/0.00
[rank2]:[titan] 2025-09-23 14:13:42,922 - root - INFO - Current/Expected Freeze Ratio per Block: [MB0] 0.00/0.00, [MB1] 0.00/0.00, [MB2] 0.00/0.00, [MB3] 0.00/0.00, [MB4] 0.00/0.00, [MB5] 0.00/0.00, [MB6] 0.00/0.00, [MB7] 0.00/0.00
[rank0]:[titan] 2025-09-23 14:13:43,023 - root - INFO - Current/Expected Freeze Ratio per Block: [MB0] 0.00/0.00, [MB1] 0.00/0.00, [MB2] 0.00/0.00, [MB3] 0.00/0.00, [MB4] 0.00/0.00, [MB5] 0.00/0.00, [MB6] 0.00/0.00, [MB7] 0.00/0.00
[rank1]:[titan] 2025-09-23 14:13:43,025 - root - INFO - Current/Expected Freeze Ratio per Block: [MB0] 0.00/0.00, [MB1] 0.00/0.00, [MB2] 0.00/0.00, [MB3] 0.00/0.00, [MB4] 0.00/0.00, [MB5] 0.00/0.00, [MB6] 0.00/0.00, [MB7] 0.00/0.00
[rank0]:[titan] 2025-09-23 14:15:11,166 - root - INFO - [31m step: 40 [32m loss: -8.0000 [38;2;180;60;0m grad_norm:  1.0794 [38;2;54;234;195m memory: 43.86GiB(55.34%) [34m tps: 1,877 [36m tflops: 87.56 [35m mfu: 28.06%[39m
[rank3]:[titan] 2025-09-23 14:15:11,162 - root - INFO - [31m step: 40 [32m loss: -8.0000 [38;2;180;60;0m grad_norm:  1.0794 [38;2;54;234;195m memory: 38.74GiB(48.88%) [34m tps: 1,877 [36m tflops: 87.56 [35m mfu: 28.06%[39m
[rank2]:[titan] 2025-09-23 14:15:11,162 - root - INFO - [31m step: 40 [32m loss: -8.0000 [38;2;180;60;0m grad_norm:  1.0794 [38;2;54;234;195m memory: 38.74GiB(48.88%) [34m tps: 1,877 [36m tflops: 87.56 [35m mfu: 28.06%[39m
[rank4]:[titan] 2025-09-23 14:15:11,159 - root - INFO - [31m step: 40 [32m loss: -8.0000 [38;2;180;60;0m grad_norm:  1.0794 [38;2;54;234;195m memory: 34.68GiB(43.76%) [34m tps: 1,877 [36m tflops: 87.56 [35m mfu: 28.06%[39m
[rank6]:[titan] 2025-09-23 14:15:11,164 - root - INFO - [31m step: 40 [32m loss:  7.1820 [38;2;180;60;0m grad_norm:  1.0794 [38;2;54;234;195m memory: 45.85GiB(57.85%) [34m tps: 1,877 [36m tflops: 87.56 [35m mfu: 28.06%[39m
[rank1]:[titan] 2025-09-23 14:15:11,166 - root - INFO - [31m step: 40 [32m loss: -8.0000 [38;2;180;60;0m grad_norm:  1.0794 [38;2;54;234;195m memory: 43.86GiB(55.34%) [34m tps: 1,877 [36m tflops: 87.56 [35m mfu: 28.06%[39m
[rank7]:[titan] 2025-09-23 14:15:11,164 - root - INFO - [31m step: 40 [32m loss:  7.1820 [38;2;180;60;0m grad_norm:  1.0794 [38;2;54;234;195m memory: 45.85GiB(57.85%) [34m tps: 1,877 [36m tflops: 87.56 [35m mfu: 28.06%[39m
[rank5]:[titan] 2025-09-23 14:15:11,160 - root - INFO - [31m step: 40 [32m loss: -8.0000 [38;2;180;60;0m grad_norm:  1.0794 [38;2;54;234;195m memory: 34.68GiB(43.76%) [34m tps: 1,877 [36m tflops: 87.56 [35m mfu: 28.06%[39m
[rank6]:[titan] 2025-09-23 14:15:11,364 - root - INFO - Pipeline schedule is saved as: /workspace/torchtitan_data/images/0922_gpipe_fullrand6_runpod/pipeline_schedule/250923_1415_real_step40_rank6.svg
[rank6]:> Batch Time: 1058.44 ms, GPU Bubble Ratio: 40.53%, 38.49%, 44.98%, 35.83%
[rank7]:[titan] 2025-09-23 14:15:11,363 - root - INFO - Pipeline schedule is saved as: /workspace/torchtitan_data/images/0922_gpipe_fullrand6_runpod/pipeline_schedule/250923_1415_real_step40_rank7.svg
[rank7]:> Batch Time: 1057.58 ms, GPU Bubble Ratio: 40.70%, 38.09%, 45.06%, 35.75%
[rank6]:[titan] 2025-09-23 14:15:11,433 - root - INFO - Frozen Ratio History of Rank 6 (Stage 3)  is saved as: /workspace/torchtitan_data/images/0922_gpipe_fullrand6_runpod/freeze_ratio_history/rank6/250923_1415_stage3_step40.svg
[rank7]:[titan] 2025-09-23 14:15:11,433 - root - INFO - Frozen Ratio History of Rank 7 (Stage 3)  is saved as: /workspace/torchtitan_data/images/0922_gpipe_fullrand6_runpod/freeze_ratio_history/rank7/250923_1415_stage3_step40.svg
[rank0]:[titan] 2025-09-23 14:16:30,955 - root - INFO - [GC] Peforming periodical GC collection 0.26 seconds
[rank0]:[titan] 2025-09-23 14:16:39,941 - root - INFO - Observed values (freeze ratio vs time) with Trend Line is saved as: /workspace/torchtitan_data/images/0922_gpipe_fullrand6_runpod/pipeline_schedule_adjustment/250923_1416_rank0_trend_line.svg
[rank0]:[titan] 2025-09-23 14:16:39,947 - root - INFO - Adjusted Freeze Ratio per Block: [MB0] 0.40/1.00, [MB1] 0.40/1.00, [MB2] 0.40/1.00, [MB3] 0.40/1.00, [MB4] 0.40/1.00, [MB5] 0.40/1.00, [MB6] 0.40/1.00, [MB7] 0.40/1.00
[rank4]:[titan] 2025-09-23 14:16:39,935 - root - INFO - Observed values (freeze ratio vs time) with Trend Line is saved as: /workspace/torchtitan_data/images/0922_gpipe_fullrand6_runpod/pipeline_schedule_adjustment/250923_1416_rank4_trend_line.svg
[rank4]:[titan] 2025-09-23 14:16:39,947 - root - INFO - Adjusted Freeze Ratio per Block: [MB0] 0.40/1.00, [MB1] 0.19/0.49, [MB2] 0.00/0.00, [MB3] 0.00/0.00, [MB4] 0.00/0.00, [MB5] 0.00/0.00, [MB6] 0.00/0.00, [MB7] 0.00/0.00
[rank2]:[titan] 2025-09-23 14:16:39,938 - root - INFO - Observed values (freeze ratio vs time) with Trend Line is saved as: /workspace/torchtitan_data/images/0922_gpipe_fullrand6_runpod/pipeline_schedule_adjustment/250923_1416_rank2_trend_line.svg
[rank2]:[titan] 2025-09-23 14:16:39,947 - root - INFO - Adjusted Freeze Ratio per Block: [MB0] 0.40/1.00, [MB1] 0.36/0.91, [MB2] 0.36/0.91, [MB3] 0.36/0.91, [MB4] 0.36/0.91, [MB5] 0.36/0.91, [MB6] 0.26/0.66, [MB7] 0.34/0.86
[rank3]:[titan] 2025-09-23 14:16:39,937 - root - INFO - Observed values (freeze ratio vs time) with Trend Line is saved as: /workspace/torchtitan_data/images/0922_gpipe_fullrand6_runpod/pipeline_schedule_adjustment/250923_1416_rank3_trend_line.svg
[rank3]:[titan] 2025-09-23 14:16:39,945 - root - INFO - Adjusted Freeze Ratio per Block: [MB0] 0.40/1.00, [MB1] 0.38/0.96, [MB2] 0.38/0.96, [MB3] 0.38/0.96, [MB4] 0.38/0.96, [MB5] 0.38/0.96, [MB6] 0.32/0.79, [MB7] 0.37/0.92
[rank5]:[titan] 2025-09-23 14:16:39,932 - root - INFO - Observed values (freeze ratio vs time) with Trend Line is saved as: /workspace/torchtitan_data/images/0922_gpipe_fullrand6_runpod/pipeline_schedule_adjustment/250923_1416_rank5_trend_line.svg
[rank5]:[titan] 2025-09-23 14:16:39,945 - root - INFO - Adjusted Freeze Ratio per Block: [MB0] 0.40/1.00, [MB1] 0.18/0.44, [MB2] 0.00/0.00, [MB3] 0.00/0.00, [MB4] 0.00/0.00, [MB5] 0.00/0.00, [MB6] 0.00/0.00, [MB7] 0.00/0.00
[rank6]:[titan] 2025-09-23 14:16:39,938 - root - INFO - Observed values (freeze ratio vs time) with Trend Line is saved as: /workspace/torchtitan_data/images/0922_gpipe_fullrand6_runpod/pipeline_schedule_adjustment/250923_1416_rank6_trend_line.svg
[rank7]:[titan] 2025-09-23 14:16:39,937 - root - INFO - Observed values (freeze ratio vs time) with Trend Line is saved as: /workspace/torchtitan_data/images/0922_gpipe_fullrand6_runpod/pipeline_schedule_adjustment/250923_1416_rank7_trend_line.svg
[rank1]:[titan] 2025-09-23 14:16:39,939 - root - INFO - Observed values (freeze ratio vs time) with Trend Line is saved as: /workspace/torchtitan_data/images/0922_gpipe_fullrand6_runpod/pipeline_schedule_adjustment/250923_1416_rank1_trend_line.svg
[rank1]:[titan] 2025-09-23 14:16:39,945 - root - INFO - Adjusted Freeze Ratio per Block: [MB0] 0.40/1.00, [MB1] 0.40/1.00, [MB2] 0.40/1.00, [MB3] 0.40/1.00, [MB4] 0.40/1.00, [MB5] 0.40/1.00, [MB6] 0.40/1.00, [MB7] 0.40/1.00
[rank6]:[titan] 2025-09-23 14:16:40,145 - root - INFO - Pipeline schedule is saved as: /workspace/torchtitan_data/images/0922_gpipe_fullrand6_runpod/pipeline_schedule/250923_1416_adjusted_frozen_pipeline_schedule_rank6.svg
[rank6]:> Batch Time: 849.27 ms, GPU Bubble Ratio: 30.75%, 29.41%, 32.66%, 30.74%
[rank6]:[titan] 2025-09-23 14:16:40,145 - root - INFO - > Batch Time: 849.27 ms (Average Freeze Ratio: 0.73)
[rank6]:[titan] 2025-09-23 14:16:40,146 - root - INFO - Adjusted Freeze Ratio per Block: [MB0] 0.40/1.00, [MB1] 0.40/1.00, [MB2] 0.40/1.00, [MB3] 0.40/1.00, [MB4] 0.40/1.00, [MB5] 0.40/1.00, [MB6] 0.06/0.16, [MB7] 0.27/0.67
[rank7]:[titan] 2025-09-23 14:16:40,140 - root - INFO - Pipeline schedule is saved as: /workspace/torchtitan_data/images/0922_gpipe_fullrand6_runpod/pipeline_schedule/250923_1416_adjusted_frozen_pipeline_schedule_rank7.svg
[rank7]:> Batch Time: 847.55 ms, GPU Bubble Ratio: 30.99%, 29.23%, 32.67%, 30.60%
[rank7]:[titan] 2025-09-23 14:16:40,141 - root - INFO - > Batch Time: 847.55 ms (Average Freeze Ratio: 0.74)
[rank7]:[titan] 2025-09-23 14:16:40,141 - root - INFO - Adjusted Freeze Ratio per Block: [MB0] 0.40/1.00, [MB1] 0.40/1.00, [MB2] 0.40/1.00, [MB3] 0.40/1.00, [MB4] 0.40/1.00, [MB5] 0.40/1.00, [MB6] 0.06/0.14, [MB7] 0.28/0.71

üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•
‚úîÔ∏èCurrent Timestamp: Tue Sep 23 14:30:56 UTC 2025
‚úîÔ∏èSERVER: 30be631344fa (172.18.0.2),  GPUs: 0,1,2,3,4,5,6,7
‚úîÔ∏èSCRIPT: 
‚úîÔ∏èOUTPUT: /workspace/torchtitan/logs/runpod8/0922_main/0922_gpipe_fullrand6.ans
‚úîÔ∏èMain Table Experiment for Llama 3.1 8B on Runpod with 8 GPUs
‚úîÔ∏èRunning with fullrand6 x gpipe ... 
‚òëÔ∏è> torchrun --standalone --nnodes=1 --nproc_per_node=8 --local-ranks-filter=0,1,2,3,4,5,6,7 --role=rank --tee=3 -m timelyfreeze.train --job.config_file=/workspace/torchtitan/logs/runpod8/0922_main/config.toml --job.description="Main Table Experiment for Llama 3.1 8B on Runpod with 8 GPUs" --training.global_batch_size=128 --training.local_batch_size=8 --parallelism.pipeline_parallel_microbatch_size=1  --freezing.freeze --freezing.metric_type=fullrand6 --freezing.aggressiveness=0.05
üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•
W0923 14:30:57.581000 15519 torch/distributed/run.py:815] 
W0923 14:30:57.581000 15519 torch/distributed/run.py:815] *****************************************
W0923 14:30:57.581000 15519 torch/distributed/run.py:815] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
W0923 14:30:57.581000 15519 torch/distributed/run.py:815] *****************************************
[rank0]:[titan] 2025-09-23 14:31:06,410 - root - INFO - Starting job: "Main Table Experiment for Llama 3.1 8B on Runpod with 8 GPUs"
[rank0]:[titan] 2025-09-23 14:31:06,675 - root - WARNING - ENV[TORCH_NCCL_ASYNC_ERROR_HANDLING] = 1 will be overridden to 3 based on job config
[rank0]:[titan] 2025-09-23 14:31:06,679 - root - INFO - Building 2-D device mesh with ['pp', 'dp_shard'], [4, 2]
[rank4]:[titan] 2025-09-23 14:31:06,662 - root - INFO - Starting job: "Main Table Experiment for Llama 3.1 8B on Runpod with 8 GPUs"
[rank2]:[titan] 2025-09-23 14:31:06,664 - root - INFO - Starting job: "Main Table Experiment for Llama 3.1 8B on Runpod with 8 GPUs"
[rank5]:[titan] 2025-09-23 14:31:06,650 - root - INFO - Starting job: "Main Table Experiment for Llama 3.1 8B on Runpod with 8 GPUs"
[rank0]:[titan] 2025-09-23 14:31:06,685 - root - INFO - [GC] Initial GC collection 0.00 seconds
[rank1]:[titan] 2025-09-23 14:31:06,759 - root - INFO - Starting job: "Main Table Experiment for Llama 3.1 8B on Runpod with 8 GPUs"
[rank3]:[titan] 2025-09-23 14:31:06,697 - root - INFO - Starting job: "Main Table Experiment for Llama 3.1 8B on Runpod with 8 GPUs"
[rank7]:[titan] 2025-09-23 14:31:06,732 - root - INFO - Starting job: "Main Table Experiment for Llama 3.1 8B on Runpod with 8 GPUs"
[rank6]:[titan] 2025-09-23 14:31:06,788 - root - INFO - Starting job: "Main Table Experiment for Llama 3.1 8B on Runpod with 8 GPUs"
[rank5]:[titan] 2025-09-23 14:31:07,684 - root - WARNING - ENV[TORCH_NCCL_ASYNC_ERROR_HANDLING] = 1 will be overridden to 3 based on job config
[rank5]:[titan] 2025-09-23 14:31:07,687 - root - INFO - Building 2-D device mesh with ['pp', 'dp_shard'], [4, 2]
[rank4]:[titan] 2025-09-23 14:31:07,850 - root - WARNING - ENV[TORCH_NCCL_ASYNC_ERROR_HANDLING] = 1 will be overridden to 3 based on job config
[rank4]:[titan] 2025-09-23 14:31:07,853 - root - INFO - Building 2-D device mesh with ['pp', 'dp_shard'], [4, 2]
[rank2]:[titan] 2025-09-23 14:31:07,875 - root - WARNING - ENV[TORCH_NCCL_ASYNC_ERROR_HANDLING] = 1 will be overridden to 3 based on job config
[rank2]:[titan] 2025-09-23 14:31:07,879 - root - INFO - Building 2-D device mesh with ['pp', 'dp_shard'], [4, 2]
[rank3]:[titan] 2025-09-23 14:31:08,043 - root - WARNING - ENV[TORCH_NCCL_ASYNC_ERROR_HANDLING] = 1 will be overridden to 3 based on job config
[rank3]:[titan] 2025-09-23 14:31:08,047 - root - INFO - Building 2-D device mesh with ['pp', 'dp_shard'], [4, 2]
[rank7]:[titan] 2025-09-23 14:31:08,131 - root - WARNING - ENV[TORCH_NCCL_ASYNC_ERROR_HANDLING] = 1 will be overridden to 3 based on job config
[rank7]:[titan] 2025-09-23 14:31:08,134 - root - INFO - Building 2-D device mesh with ['pp', 'dp_shard'], [4, 2]
[rank1]:[titan] 2025-09-23 14:31:08,242 - root - WARNING - ENV[TORCH_NCCL_ASYNC_ERROR_HANDLING] = 1 will be overridden to 3 based on job config
[rank1]:[titan] 2025-09-23 14:31:08,244 - root - INFO - Building 2-D device mesh with ['pp', 'dp_shard'], [4, 2]
[rank6]:[titan] 2025-09-23 14:31:08,235 - root - WARNING - ENV[TORCH_NCCL_ASYNC_ERROR_HANDLING] = 1 will be overridden to 3 based on job config
[rank6]:[titan] 2025-09-23 14:31:08,238 - root - INFO - Building 2-D device mesh with ['pp', 'dp_shard'], [4, 2]
[rank0]:[titan] 2025-09-23 14:31:09,295 - root - INFO - Loading tokenizer from tokenizer.json
[rank0]:[titan] 2025-09-23 14:31:09,632 - root - INFO - Preparing slimorca dataset from Open-Orca/SlimOrca
[rank0]:[titan] 2025-09-23 14:31:11,088 - root - INFO - Building llama3 8B with TransformerModelArgs(_enforced='This field is used to enforce all fields have defaults.', dim=4096, n_layers=32, n_heads=32, n_kv_heads=8, vocab_size=128256, multiple_of=1024, ffn_dim_multiplier=1.3, norm_eps=1e-05, rope_theta=500000, max_seq_len=1024, depth_init=True, use_flex_attn=False, attn_mask_type='causal', eos_id=0)
[rank0]:[titan] 2025-09-23 14:31:11,378 - root - INFO - CUDA capacity: NVIDIA A100-SXM4-80GB with 79.25GiB memory
[rank4]:[titan] 2025-09-23 14:31:11,376 - root - INFO - CUDA capacity: NVIDIA A100-SXM4-80GB with 79.25GiB memory
[rank0]:[titan] 2025-09-23 14:31:11,455 - root - INFO - [34mModel llama3 8B [31msize: 8,030,261,248 total parameters[39m
[rank0]:[titan] 2025-09-23 14:31:11,482 - root - INFO - PP rank 0 is building stage_idx 0 with modules ['tok_embeddings', 'layers.0', 'layers.1', 'layers.2', 'layers.3', 'layers.4', 'layers.5', 'layers.6', 'layers.7']
[rank1]:[titan] 2025-09-23 14:31:11,460 - root - INFO - CUDA capacity: NVIDIA A100-SXM4-80GB with 79.25GiB memory
[rank3]:[titan] 2025-09-23 14:31:11,410 - root - INFO - CUDA capacity: NVIDIA A100-SXM4-80GB with 79.25GiB memory
[rank4]:[titan] 2025-09-23 14:31:11,473 - root - INFO - PP rank 2 is building stage_idx 2 with modules ['layers.17', 'layers.18', 'layers.19', 'layers.20', 'layers.21', 'layers.22', 'layers.23', 'layers.24']
[rank2]:[titan] 2025-09-23 14:31:11,470 - root - INFO - CUDA capacity: NVIDIA A100-SXM4-80GB with 79.25GiB memory
[rank5]:[titan] 2025-09-23 14:31:11,402 - root - INFO - CUDA capacity: NVIDIA A100-SXM4-80GB with 79.25GiB memory
[rank7]:[titan] 2025-09-23 14:31:11,410 - root - INFO - CUDA capacity: NVIDIA A100-SXM4-80GB with 79.25GiB memory
[rank0]:[titan] 2025-09-23 14:31:11,516 - root - INFO - Applied FSDP to the model
[rank0]:[titan] 2025-09-23 14:31:11,516 - root - INFO - Using pipeline schedule gpipe with 8 microbatches and 4 stages.
[rank1]:[titan] 2025-09-23 14:31:11,547 - root - INFO - PP rank 0 is building stage_idx 0 with modules ['tok_embeddings', 'layers.0', 'layers.1', 'layers.2', 'layers.3', 'layers.4', 'layers.5', 'layers.6', 'layers.7']
[rank1]:[titan] 2025-09-23 14:31:11,581 - root - INFO - Applied FSDP to the model
[rank1]:[titan] 2025-09-23 14:31:11,582 - root - INFO - Using pipeline schedule gpipe with 8 microbatches and 4 stages.
[rank3]:[titan] 2025-09-23 14:31:11,521 - root - INFO - PP rank 1 is building stage_idx 1 with modules ['layers.8', 'layers.9', 'layers.10', 'layers.11', 'layers.12', 'layers.13', 'layers.14', 'layers.15', 'layers.16']
[rank3]:[titan] 2025-09-23 14:31:11,556 - root - INFO - Applied FSDP to the model
[rank3]:[titan] 2025-09-23 14:31:11,556 - root - INFO - Using pipeline schedule gpipe with 8 microbatches and 4 stages.
[rank4]:[titan] 2025-09-23 14:31:11,506 - root - INFO - Applied FSDP to the model
[rank4]:[titan] 2025-09-23 14:31:11,506 - root - INFO - Using pipeline schedule gpipe with 8 microbatches and 4 stages.
[rank2]:[titan] 2025-09-23 14:31:11,549 - root - INFO - PP rank 1 is building stage_idx 1 with modules ['layers.8', 'layers.9', 'layers.10', 'layers.11', 'layers.12', 'layers.13', 'layers.14', 'layers.15', 'layers.16']
[rank2]:[titan] 2025-09-23 14:31:11,582 - root - INFO - Applied FSDP to the model
[rank2]:[titan] 2025-09-23 14:31:11,582 - root - INFO - Using pipeline schedule gpipe with 8 microbatches and 4 stages.
[rank5]:[titan] 2025-09-23 14:31:11,514 - root - INFO - PP rank 2 is building stage_idx 2 with modules ['layers.17', 'layers.18', 'layers.19', 'layers.20', 'layers.21', 'layers.22', 'layers.23', 'layers.24']
[rank5]:[titan] 2025-09-23 14:31:11,546 - root - INFO - Applied FSDP to the model
[rank5]:[titan] 2025-09-23 14:31:11,546 - root - INFO - Using pipeline schedule gpipe with 8 microbatches and 4 stages.
[rank7]:[titan] 2025-09-23 14:31:11,520 - root - INFO - PP rank 3 is building stage_idx 3 with modules ['layers.25', 'layers.26', 'layers.27', 'layers.28', 'layers.29', 'layers.30', 'layers.31', 'norm', 'output']
[rank7]:[titan] 2025-09-23 14:31:11,551 - root - INFO - Applied FSDP to the model
[rank7]:[titan] 2025-09-23 14:31:11,552 - root - INFO - Using pipeline schedule gpipe with 8 microbatches and 4 stages.
[rank4]:[titan] 2025-09-23 14:31:11,804 - root - INFO - Peak FLOPS used for computing MFU: 3.120e+14
[rank4]:[titan] 2025-09-23 14:31:11,805 - root - INFO - CUDA memory usage for model: 3.26GiB(4.12%)
[rank0]:[titan] 2025-09-23 14:31:11,928 - root - INFO - Peak FLOPS used for computing MFU: 3.120e+14
[rank0]:[titan] 2025-09-23 14:31:11,928 - root - INFO - CUDA memory usage for model: 4.24GiB(5.35%)
[rank5]:[titan] 2025-09-23 14:31:11,963 - root - INFO - Peak FLOPS used for computing MFU: 3.120e+14
[rank5]:[titan] 2025-09-23 14:31:11,964 - root - INFO - CUDA memory usage for model: 3.26GiB(4.12%)
[rank1]:[titan] 2025-09-23 14:31:12,043 - root - INFO - Peak FLOPS used for computing MFU: 3.120e+14
[rank1]:[titan] 2025-09-23 14:31:12,044 - root - INFO - CUDA memory usage for model: 4.24GiB(5.35%)
[rank3]:[titan] 2025-09-23 14:31:12,029 - root - INFO - Peak FLOPS used for computing MFU: 3.120e+14
[rank3]:[titan] 2025-09-23 14:31:12,030 - root - INFO - CUDA memory usage for model: 3.67GiB(4.64%)
[rank2]:[titan] 2025-09-23 14:31:12,039 - root - INFO - Peak FLOPS used for computing MFU: 3.120e+14
[rank2]:[titan] 2025-09-23 14:31:12,040 - root - INFO - CUDA memory usage for model: 3.67GiB(4.64%)
[rank7]:[titan] 2025-09-23 14:31:12,036 - root - INFO - Peak FLOPS used for computing MFU: 3.120e+14
[rank7]:[titan] 2025-09-23 14:31:12,037 - root - INFO - CUDA memory usage for model: 3.83GiB(4.83%)
[rank6]:wandb: Currently logged in as: orangingq to https://api.wandb.ai. Use `wandb login --relogin` to force relogin
[rank6]:wandb: creating run
[rank6]:wandb: Tracking run with wandb version 0.22.0
[rank6]:wandb: Run data is saved locally in /workspace/torchtitan_data/tb/0922_gpipe_fullrand6_runpod/20250923-1431/wandb/run-20250923_143112-j41lqzsw
[rank6]:wandb: Run `wandb offline` to turn off syncing.
[rank6]:wandb: Syncing run 0922_gpipe_fullrand6_runpod
[rank6]:wandb: ‚≠êÔ∏è View project at https://wandb.ai/orangingq/torchtitan
[rank6]:wandb: üöÄ View run at https://wandb.ai/orangingq/torchtitan/runs/j41lqzsw
[rank6]:[titan] 2025-09-23 14:31:13,484 - root - INFO - WandB logging enabled
[rank6]:[titan] 2025-09-23 14:31:13,485 - root - INFO - CUDA capacity: NVIDIA A100-SXM4-80GB with 79.25GiB memory
[rank6]:[titan] 2025-09-23 14:31:13,543 - root - INFO - PP rank 3 is building stage_idx 3 with modules ['layers.25', 'layers.26', 'layers.27', 'layers.28', 'layers.29', 'layers.30', 'layers.31', 'norm', 'output']
[rank6]:[titan] 2025-09-23 14:31:13,575 - root - INFO - Applied FSDP to the model
[rank6]:[titan] 2025-09-23 14:31:13,576 - root - INFO - Using pipeline schedule gpipe with 8 microbatches and 4 stages.
[rank0]:[titan] 2025-09-23 14:31:13,828 - root - INFO - Checkpointing active. Checkpoints will be loaded from and saved to /workspace/torchtitan_data/checkpoint/0922_gpipe_fullrand6_runpod
[rank0]:[titan] 2025-09-23 14:31:13,829 - root - INFO - Mixed precision training is handled by fully_shard
[rank0]:[titan] 2025-09-23 14:31:13,831 - root - INFO - Trainer is initialized with local batch size 8, global batch size 128, gradient accumulation steps 8, sequence length 1024, total steps 1000 (warmup 20)
[rank0]:[titan] 2025-09-23 14:31:13,831 - root - INFO - Training starts at step 1
[rank6]:[titan] 2025-09-23 14:31:13,806 - root - INFO - Peak FLOPS used for computing MFU: 3.120e+14
[rank6]:[titan] 2025-09-23 14:31:13,807 - root - INFO - CUDA memory usage for model: 3.83GiB(4.83%)
[rank0]:/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:841: UserWarning: Attempting to run cuBLAS, but there was no current CUDA context! Attempting to set the primary context... (Triggered internally at /pytorch/aten/src/ATen/cuda/CublasHandlePool.cpp:270.)
[rank0]:  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
[rank0]:[titan] 2025-09-23 14:31:28,863 - root - INFO - [31m step:  1 [32m loss: -8.0000 [38;2;180;60;0m grad_norm:  0.6579 [38;2;54;234;195m memory: 35.46GiB(44.74%) [34m tps: 941 [36m tflops: 43.89 [35m mfu: 14.07%[39m
[rank0]:[titan] 2025-09-23 14:31:28,863 - root - INFO - Synchronizing and adjusting timeout for all ProcessGroups to 0:50:00
[rank3]:[titan] 2025-09-23 14:31:28,867 - root - INFO - [31m step:  1 [32m loss: -8.0000 [38;2;180;60;0m grad_norm:  0.6579 [38;2;54;234;195m memory: 31.52GiB(39.77%) [34m tps: 943 [36m tflops: 43.98 [35m mfu: 14.10%[39m
[rank3]:[titan] 2025-09-23 14:31:28,867 - root - INFO - Synchronizing and adjusting timeout for all ProcessGroups to 0:50:00
[rank1]:[titan] 2025-09-23 14:31:28,862 - root - INFO - [31m step:  1 [32m loss: -8.0000 [38;2;180;60;0m grad_norm:  0.6579 [38;2;54;234;195m memory: 35.46GiB(44.74%) [34m tps: 945 [36m tflops: 44.06 [35m mfu: 14.12%[39m
[rank1]:[titan] 2025-09-23 14:31:28,863 - root - INFO - Synchronizing and adjusting timeout for all ProcessGroups to 0:50:00
[rank6]:[titan] 2025-09-23 14:31:28,856 - root - INFO - [31m step:  1 [32m loss: 12.2588 [38;2;180;60;0m grad_norm:  0.6579 [38;2;54;234;195m memory: 38.21GiB(48.22%) [34m tps: 1,068 [36m tflops: 49.82 [35m mfu: 15.97%[39m
[rank6]:[titan] 2025-09-23 14:31:28,857 - root - INFO - Synchronizing and adjusting timeout for all ProcessGroups to 0:50:00
[rank2]:[titan] 2025-09-23 14:31:28,867 - root - INFO - [31m step:  1 [32m loss: -8.0000 [38;2;180;60;0m grad_norm:  0.6579 [38;2;54;234;195m memory: 31.52GiB(39.77%) [34m tps: 945 [36m tflops: 44.06 [35m mfu: 14.12%[39m
[rank2]:[titan] 2025-09-23 14:31:28,867 - root - INFO - Synchronizing and adjusting timeout for all ProcessGroups to 0:50:00
[rank4]:[titan] 2025-09-23 14:31:28,857 - root - INFO - [31m step:  1 [32m loss: -8.0000 [38;2;180;60;0m grad_norm:  0.6579 [38;2;54;234;195m memory: 28.25GiB(35.65%) [34m tps: 941 [36m tflops: 43.89 [35m mfu: 14.07%[39m
[rank4]:[titan] 2025-09-23 14:31:28,857 - root - INFO - Synchronizing and adjusting timeout for all ProcessGroups to 0:50:00
[rank5]:[titan] 2025-09-23 14:31:28,857 - root - INFO - [31m step:  1 [32m loss: -8.0000 [38;2;180;60;0m grad_norm:  0.6579 [38;2;54;234;195m memory: 28.25GiB(35.65%) [34m tps: 943 [36m tflops: 43.99 [35m mfu: 14.10%[39m
[rank5]:[titan] 2025-09-23 14:31:28,857 - root - INFO - Synchronizing and adjusting timeout for all ProcessGroups to 0:50:00
[rank7]:[titan] 2025-09-23 14:31:28,855 - root - INFO - [31m step:  1 [32m loss: 12.2588 [38;2;180;60;0m grad_norm:  0.6579 [38;2;54;234;195m memory: 38.21GiB(48.22%) [34m tps: 944 [36m tflops: 44.01 [35m mfu: 14.11%[39m
[rank7]:[titan] 2025-09-23 14:31:28,855 - root - INFO - Synchronizing and adjusting timeout for all ProcessGroups to 0:50:00
[rank0]:[titan] 2025-09-23 14:33:32,499 - root - INFO - [Step 120] Setting Upperbound
[rank0]:[titan] 2025-09-23 14:33:32,553 - root - INFO - Current/Expected Freeze Ratio per Block: [MB0] 0.00/0.00, [MB1] 0.00/0.00, [MB2] 0.02/0.06, [MB3] 0.40/1.00, [MB4] 0.40/1.00, [MB5] 0.40/1.00, [MB6] 0.40/1.00, [MB7] 0.40/1.00
[rank3]:[titan] 2025-09-23 14:33:32,555 - root - INFO - Current/Expected Freeze Ratio per Block: [MB0] 0.34/0.85, [MB1] 0.09/0.22, [MB2] 0.06/0.15, [MB3] 0.40/1.00, [MB4] 0.40/1.00, [MB5] 0.40/1.00, [MB6] 0.40/1.00, [MB7] 0.40/1.00
[rank4]:[titan] 2025-09-23 14:33:32,563 - root - INFO - Current/Expected Freeze Ratio per Block: [MB0] 0.29/0.72, [MB1] 0.32/0.81, [MB2] 0.32/0.81, [MB3] 0.12/0.31, [MB4] 0.00/0.00, [MB5] 0.40/1.00, [MB6] 0.40/1.00, [MB7] 0.40/1.00
[rank2]:[titan] 2025-09-23 14:33:32,561 - root - INFO - Current/Expected Freeze Ratio per Block: [MB0] 0.34/0.85, [MB1] 0.09/0.21, [MB2] 0.03/0.08, [MB3] 0.40/1.00, [MB4] 0.40/1.00, [MB5] 0.40/1.00, [MB6] 0.40/1.00, [MB7] 0.40/1.00
[rank5]:[titan] 2025-09-23 14:33:32,556 - root - INFO - Current/Expected Freeze Ratio per Block: [MB0] 0.28/0.71, [MB1] 0.32/0.80, [MB2] 0.01/0.01, [MB3] 0.40/1.00, [MB4] 0.05/0.12, [MB5] 0.40/1.00, [MB6] 0.40/1.00, [MB7] 0.40/1.00
[rank1]:[titan] 2025-09-23 14:33:32,552 - root - INFO - Current/Expected Freeze Ratio per Block: [MB0] 0.00/0.00, [MB1] 0.00/0.00, [MB2] 0.03/0.07, [MB3] 0.40/1.00, [MB4] 0.40/1.00, [MB5] 0.40/1.00, [MB6] 0.40/1.00, [MB7] 0.40/1.00
[rank6]:[titan] 2025-09-23 14:33:32,747 - root - INFO - Pipeline schedule is saved as: /workspace/torchtitan_data/images/0922_gpipe_fullrand6_runpod/pipeline_schedule/250923_1433_max_batch_time_rank6.svg
[rank6]:> Batch Time: 1058.20 ms, GPU Bubble Ratio: 40.60%, 38.45%, 44.98%, 35.75%
[rank7]:[titan] 2025-09-23 14:33:32,747 - root - INFO - Pipeline schedule is saved as: /workspace/torchtitan_data/images/0922_gpipe_fullrand6_runpod/pipeline_schedule/250923_1433_max_batch_time_rank7.svg
[rank7]:> Batch Time: 1058.53 ms, GPU Bubble Ratio: 40.66%, 38.12%, 45.14%, 35.78%
[rank6]:[titan] 2025-09-23 14:33:32,937 - root - INFO - Pipeline schedule is saved as: /workspace/torchtitan_data/images/0922_gpipe_fullrand6_runpod/pipeline_schedule/250923_1433_min_batch_time_rank6.svg
[rank6]:> Batch Time: 673.44 ms, GPU Bubble Ratio: 40.43%, 37.72%, 44.30%, 35.90%
[rank7]:[titan] 2025-09-23 14:33:32,937 - root - INFO - Pipeline schedule is saved as: /workspace/torchtitan_data/images/0922_gpipe_fullrand6_runpod/pipeline_schedule/250923_1433_min_batch_time_rank7.svg
[rank7]:> Batch Time: 674.28 ms, GPU Bubble Ratio: 40.53%, 37.43%, 44.52%, 35.92%
[rank6]:[titan] 2025-09-23 14:33:33,147 - root - INFO - Pipeline schedule is saved as: /workspace/torchtitan_data/images/0922_gpipe_fullrand6_runpod/pipeline_schedule/250923_1433_frozen_pipeline_schedule_rank6.svg
[rank6]:> Batch Time: 673.44 ms, GPU Bubble Ratio: 29.48%, 30.42%, 35.99%, 35.90%
[rank6]:[titan] 2025-09-23 14:33:33,147 - root - INFO - > Batch Time: 673.44 ms (Average Freeze Ratio: 0.78, Time Reduction Rate: 0.36)
[rank6]:[titan] 2025-09-23 14:33:33,151 - root - INFO - Current/Expected Freeze Ratio per Block: [MB0] 0.40/1.00, [MB1] 0.40/1.00, [MB2] 0.40/1.00, [MB3] 0.40/1.00, [MB4] 0.40/1.00, [MB5] 0.40/1.00, [MB6] 0.40/1.00, [MB7] 0.40/1.00
[rank7]:[titan] 2025-09-23 14:33:33,146 - root - INFO - Pipeline schedule is saved as: /workspace/torchtitan_data/images/0922_gpipe_fullrand6_runpod/pipeline_schedule/250923_1433_frozen_pipeline_schedule_rank7.svg
[rank7]:> Batch Time: 674.28 ms, GPU Bubble Ratio: 29.68%, 30.41%, 36.26%, 35.92%
[rank7]:[titan] 2025-09-23 14:33:33,147 - root - INFO - > Batch Time: 674.28 ms (Average Freeze Ratio: 0.78, Time Reduction Rate: 0.36)
[rank7]:[titan] 2025-09-23 14:33:33,150 - root - INFO - Current/Expected Freeze Ratio per Block: [MB0] 0.40/1.00, [MB1] 0.40/1.00, [MB2] 0.40/1.00, [MB3] 0.40/1.00, [MB4] 0.40/1.00, [MB5] 0.40/1.00, [MB6] 0.40/1.00, [MB7] 0.40/1.00
[rank6]:[titan] 2025-09-23 14:34:14,358 - root - INFO - Current/Expected Freeze Ratio per Block: [MB0] 0.40/1.00, [MB1] 0.40/1.00, [MB2] 0.40/1.00, [MB3] 0.40/1.00, [MB4] 0.40/1.00, [MB5] 0.40/1.00, [MB6] 0.40/1.00, [MB7] 0.40/1.00
[rank7]:[titan] 2025-09-23 14:34:14,356 - root - INFO - Current/Expected Freeze Ratio per Block: [MB0] 0.40/1.00, [MB1] 0.40/1.00, [MB2] 0.40/1.00, [MB3] 0.40/1.00, [MB4] 0.40/1.00, [MB5] 0.40/1.00, [MB6] 0.40/1.00, [MB7] 0.40/1.00
[rank4]:[titan] 2025-09-23 14:34:14,440 - root - INFO - Current/Expected Freeze Ratio per Block: [MB0] 0.29/0.72, [MB1] 0.32/0.81, [MB2] 0.32/0.81, [MB3] 0.12/0.31, [MB4] 0.00/0.00, [MB5] 0.40/1.00, [MB6] 0.40/1.00, [MB7] 0.40/1.00
[rank3]:[titan] 2025-09-23 14:34:14,531 - root - INFO - Current/Expected Freeze Ratio per Block: [MB0] 0.34/0.85, [MB1] 0.09/0.22, [MB2] 0.06/0.15, [MB3] 0.40/1.00, [MB4] 0.40/1.00, [MB5] 0.40/1.00, [MB6] 0.40/1.00, [MB7] 0.40/1.00
[rank5]:[titan] 2025-09-23 14:34:14,438 - root - INFO - Current/Expected Freeze Ratio per Block: [MB0] 0.28/0.71, [MB1] 0.32/0.80, [MB2] 0.01/0.01, [MB3] 0.40/1.00, [MB4] 0.05/0.12, [MB5] 0.40/1.00, [MB6] 0.40/1.00, [MB7] 0.40/1.00
[rank0]:[titan] 2025-09-23 14:34:14,623 - root - INFO - Current/Expected Freeze Ratio per Block: [MB0] 0.00/0.00, [MB1] 0.00/0.00, [MB2] 0.02/0.06, [MB3] 0.40/1.00, [MB4] 0.40/1.00, [MB5] 0.40/1.00, [MB6] 0.40/1.00, [MB7] 0.40/1.00
[rank2]:[titan] 2025-09-23 14:34:14,531 - root - INFO - Current/Expected Freeze Ratio per Block: [MB0] 0.34/0.85, [MB1] 0.09/0.21, [MB2] 0.03/0.08, [MB3] 0.40/1.00, [MB4] 0.40/1.00, [MB5] 0.40/1.00, [MB6] 0.40/1.00, [MB7] 0.40/1.00
[rank1]:[titan] 2025-09-23 14:34:14,623 - root - INFO - Current/Expected Freeze Ratio per Block: [MB0] 0.00/0.00, [MB1] 0.00/0.00, [MB2] 0.03/0.07, [MB3] 0.40/1.00, [MB4] 0.40/1.00, [MB5] 0.40/1.00, [MB6] 0.40/1.00, [MB7] 0.40/1.00
[rank6]:/workspace/torchtitan/timelyfreeze/core/schedule.py:344: RankWarning: Polyfit may be poorly conditioned
[rank6]:  a, b = np.polyfit(afrs, times, 1)
[rank7]:/workspace/torchtitan/timelyfreeze/core/schedule.py:344: RankWarning: Polyfit may be poorly conditioned
[rank7]:  a, b = np.polyfit(afrs, times, 1)
[rank5]:[titan] 2025-09-23 14:34:56,262 - root - INFO - Observed values (freeze ratio vs time) with Trend Line is saved as: /workspace/torchtitan_data/images/0922_gpipe_fullrand6_runpod/pipeline_schedule_adjustment/250923_1434_rank5_trend_line.svg
[rank7]:[titan] 2025-09-23 14:34:56,263 - root - INFO - Observed values (freeze ratio vs time) with Trend Line is saved as: /workspace/torchtitan_data/images/0922_gpipe_fullrand6_runpod/pipeline_schedule_adjustment/250923_1434_rank7_trend_line.svg
[rank6]:[titan] 2025-09-23 14:34:56,263 - root - INFO - Observed values (freeze ratio vs time) with Trend Line is saved as: /workspace/torchtitan_data/images/0922_gpipe_fullrand6_runpod/pipeline_schedule_adjustment/250923_1434_rank6_trend_line.svg
[rank4]:[titan] 2025-09-23 14:34:56,264 - root - INFO - Observed values (freeze ratio vs time) with Trend Line is saved as: /workspace/torchtitan_data/images/0922_gpipe_fullrand6_runpod/pipeline_schedule_adjustment/250923_1434_rank4_trend_line.svg
[rank4]:[titan] 2025-09-23 14:34:56,272 - root - INFO - Adjusted Freeze Ratio per Block: [MB0] 0.00/0.00, [MB1] 0.00/0.00, [MB2] 0.00/0.00, [MB3] 0.00/0.00, [MB4] 0.00/0.00, [MB5] 0.00/0.00, [MB6] 0.00/0.00, [MB7] 0.00/0.00
[rank4]:[titan] 2025-09-23 14:34:56,273 - root - INFO - Current/Expected Freeze Ratio per Block: [MB0] 0.00/0.00, [MB1] 0.00/0.00, [MB2] 0.00/0.00, [MB3] 0.00/0.00, [MB4] 0.00/0.00, [MB5] 0.00/0.00, [MB6] 0.00/0.00, [MB7] 0.00/0.00
[rank0]:[titan] 2025-09-23 14:34:56,267 - root - INFO - Observed values (freeze ratio vs time) with Trend Line is saved as: /workspace/torchtitan_data/images/0922_gpipe_fullrand6_runpod/pipeline_schedule_adjustment/250923_1434_rank0_trend_line.svg
[rank0]:[titan] 2025-09-23 14:34:56,272 - root - INFO - Adjusted Freeze Ratio per Block: [MB0] 0.00/0.00, [MB1] 0.00/0.00, [MB2] 0.00/0.00, [MB3] 0.00/0.00, [MB4] 0.00/0.00, [MB5] 0.00/0.00, [MB6] 0.00/0.00, [MB7] 0.00/0.00
[rank0]:[titan] 2025-09-23 14:34:56,273 - root - INFO - Current/Expected Freeze Ratio per Block: [MB0] 0.00/0.00, [MB1] 0.00/0.00, [MB2] 0.00/0.00, [MB3] 0.00/0.00, [MB4] 0.00/0.00, [MB5] 0.00/0.00, [MB6] 0.00/0.00, [MB7] 0.00/0.00
[rank2]:[titan] 2025-09-23 14:34:56,264 - root - INFO - Observed values (freeze ratio vs time) with Trend Line is saved as: /workspace/torchtitan_data/images/0922_gpipe_fullrand6_runpod/pipeline_schedule_adjustment/250923_1434_rank2_trend_line.svg
[rank2]:[titan] 2025-09-23 14:34:56,272 - root - INFO - Adjusted Freeze Ratio per Block: [MB0] 0.00/0.00, [MB1] 0.00/0.00, [MB2] 0.00/0.00, [MB3] 0.00/0.00, [MB4] 0.00/0.00, [MB5] 0.00/0.00, [MB6] 0.00/0.00, [MB7] 0.00/0.00
[rank2]:[titan] 2025-09-23 14:34:56,273 - root - INFO - Current/Expected Freeze Ratio per Block: [MB0] 0.00/0.00, [MB1] 0.00/0.00, [MB2] 0.00/0.00, [MB3] 0.00/0.00, [MB4] 0.00/0.00, [MB5] 0.00/0.00, [MB6] 0.00/0.00, [MB7] 0.00/0.00
[rank3]:[titan] 2025-09-23 14:34:56,265 - root - INFO - Observed values (freeze ratio vs time) with Trend Line is saved as: /workspace/torchtitan_data/images/0922_gpipe_fullrand6_runpod/pipeline_schedule_adjustment/250923_1434_rank3_trend_line.svg
[rank3]:[titan] 2025-09-23 14:34:56,274 - root - INFO - Adjusted Freeze Ratio per Block: [MB0] 0.00/0.00, [MB1] 0.00/0.00, [MB2] 0.00/0.00, [MB3] 0.00/0.00, [MB4] 0.00/0.00, [MB5] 0.00/0.00, [MB6] 0.00/0.00, [MB7] 0.00/0.00
[rank3]:[titan] 2025-09-23 14:34:56,275 - root - INFO - Current/Expected Freeze Ratio per Block: [MB0] 0.00/0.00, [MB1] 0.00/0.00, [MB2] 0.00/0.00, [MB3] 0.00/0.00, [MB4] 0.00/0.00, [MB5] 0.00/0.00, [MB6] 0.00/0.00, [MB7] 0.00/0.00
[rank5]:[titan] 2025-09-23 14:34:56,274 - root - INFO - Adjusted Freeze Ratio per Block: [MB0] 0.00/0.00, [MB1] 0.00/0.00, [MB2] 0.00/0.00, [MB3] 0.00/0.00, [MB4] 0.00/0.00, [MB5] 0.00/0.00, [MB6] 0.00/0.00, [MB7] 0.00/0.00
[rank5]:[titan] 2025-09-23 14:34:56,275 - root - INFO - Current/Expected Freeze Ratio per Block: [MB0] 0.00/0.00, [MB1] 0.00/0.00, [MB2] 0.00/0.00, [MB3] 0.00/0.00, [MB4] 0.00/0.00, [MB5] 0.00/0.00, [MB6] 0.00/0.00, [MB7] 0.00/0.00
[rank1]:[titan] 2025-09-23 14:34:56,269 - root - INFO - Observed values (freeze ratio vs time) with Trend Line is saved as: /workspace/torchtitan_data/images/0922_gpipe_fullrand6_runpod/pipeline_schedule_adjustment/250923_1434_rank1_trend_line.svg
[rank1]:[titan] 2025-09-23 14:34:56,274 - root - INFO - Adjusted Freeze Ratio per Block: [MB0] 0.00/0.00, [MB1] 0.00/0.00, [MB2] 0.00/0.00, [MB3] 0.00/0.00, [MB4] 0.00/0.00, [MB5] 0.00/0.00, [MB6] 0.00/0.00, [MB7] 0.00/0.00
[rank1]:[titan] 2025-09-23 14:34:56,275 - root - INFO - Current/Expected Freeze Ratio per Block: [MB0] 0.00/0.00, [MB1] 0.00/0.00, [MB2] 0.00/0.00, [MB3] 0.00/0.00, [MB4] 0.00/0.00, [MB5] 0.00/0.00, [MB6] 0.00/0.00, [MB7] 0.00/0.00
[rank6]:[titan] 2025-09-23 14:34:56,467 - root - INFO - Pipeline schedule is saved as: /workspace/torchtitan_data/images/0922_gpipe_fullrand6_runpod/pipeline_schedule/250923_1434_adjusted_frozen_pipeline_schedule_rank6.svg
[rank6]:> Batch Time: 818.97 ms, GPU Bubble Ratio: 29.98%, 27.35%, 36.04%, 49.92%
[rank6]:[titan] 2025-09-23 14:34:56,467 - root - INFO - > Batch Time: 818.97 ms (Average Freeze Ratio: 0.00)
[rank6]:[titan] 2025-09-23 14:34:56,468 - root - INFO - Adjusted Freeze Ratio per Block: [MB0] 0.00/0.00, [MB1] 0.00/0.00, [MB2] 0.00/0.00, [MB3] 0.00/0.00, [MB4] 0.00/0.00, [MB5] 0.00/0.00, [MB6] 0.00/0.00, [MB7] 0.00/0.00
[rank6]:[titan] 2025-09-23 14:34:56,469 - root - INFO - Current/Expected Freeze Ratio per Block: [MB0] 0.00/0.00, [MB1] 0.00/0.00, [MB2] 0.00/0.00, [MB3] 0.00/0.00, [MB4] 0.00/0.00, [MB5] 0.00/0.00, [MB6] 0.00/0.00, [MB7] 0.00/0.00
[rank7]:[titan] 2025-09-23 14:34:56,472 - root - INFO - Pipeline schedule is saved as: /workspace/torchtitan_data/images/0922_gpipe_fullrand6_runpod/pipeline_schedule/250923_1434_adjusted_frozen_pipeline_schedule_rank7.svg
[rank7]:> Batch Time: 818.47 ms, GPU Bubble Ratio: 30.11%, 27.49%, 34.83%, 49.84%
[rank7]:[titan] 2025-09-23 14:34:56,472 - root - INFO - > Batch Time: 818.47 ms (Average Freeze Ratio: 0.00)
[rank7]:[titan] 2025-09-23 14:34:56,473 - root - INFO - Adjusted Freeze Ratio per Block: [MB0] 0.00/0.00, [MB1] 0.00/0.00, [MB2] 0.00/0.00, [MB3] 0.00/0.00, [MB4] 0.00/0.00, [MB5] 0.00/0.00, [MB6] 0.00/0.00, [MB7] 0.00/0.00
[rank7]:[titan] 2025-09-23 14:34:56,473 - root - INFO - Current/Expected Freeze Ratio per Block: [MB0] 0.00/0.00, [MB1] 0.00/0.00, [MB2] 0.00/0.00, [MB3] 0.00/0.00, [MB4] 0.00/0.00, [MB5] 0.00/0.00, [MB6] 0.00/0.00, [MB7] 0.00/0.00
[rank6]:[titan] 2025-09-23 14:35:40,028 - root - INFO - Current/Expected Freeze Ratio per Block: [MB0] 0.00/0.00, [MB1] 0.00/0.00, [MB2] 0.00/0.00, [MB3] 0.00/0.00, [MB4] 0.00/0.00, [MB5] 0.00/0.00, [MB6] 0.00/0.00, [MB7] 0.00/0.00
[rank7]:[titan] 2025-09-23 14:35:40,027 - root - INFO - Current/Expected Freeze Ratio per Block: [MB0] 0.00/0.00, [MB1] 0.00/0.00, [MB2] 0.00/0.00, [MB3] 0.00/0.00, [MB4] 0.00/0.00, [MB5] 0.00/0.00, [MB6] 0.00/0.00, [MB7] 0.00/0.00
[rank4]:[titan] 2025-09-23 14:35:40,115 - root - INFO - Current/Expected Freeze Ratio per Block: [MB0] 0.00/0.00, [MB1] 0.00/0.00, [MB2] 0.00/0.00, [MB3] 0.00/0.00, [MB4] 0.00/0.00, [MB5] 0.00/0.00, [MB6] 0.00/0.00, [MB7] 0.00/0.00
[rank5]:[titan] 2025-09-23 14:35:40,113 - root - INFO - Current/Expected Freeze Ratio per Block: [MB0] 0.00/0.00, [MB1] 0.00/0.00, [MB2] 0.00/0.00, [MB3] 0.00/0.00, [MB4] 0.00/0.00, [MB5] 0.00/0.00, [MB6] 0.00/0.00, [MB7] 0.00/0.00
[rank3]:[titan] 2025-09-23 14:35:40,212 - root - INFO - Current/Expected Freeze Ratio per Block: [MB0] 0.00/0.00, [MB1] 0.00/0.00, [MB2] 0.00/0.00, [MB3] 0.00/0.00, [MB4] 0.00/0.00, [MB5] 0.00/0.00, [MB6] 0.00/0.00, [MB7] 0.00/0.00
[rank2]:[titan] 2025-09-23 14:35:40,213 - root - INFO - Current/Expected Freeze Ratio per Block: [MB0] 0.00/0.00, [MB1] 0.00/0.00, [MB2] 0.00/0.00, [MB3] 0.00/0.00, [MB4] 0.00/0.00, [MB5] 0.00/0.00, [MB6] 0.00/0.00, [MB7] 0.00/0.00
[rank0]:[titan] 2025-09-23 14:35:40,313 - root - INFO - Current/Expected Freeze Ratio per Block: [MB0] 0.00/0.00, [MB1] 0.00/0.00, [MB2] 0.00/0.00, [MB3] 0.00/0.00, [MB4] 0.00/0.00, [MB5] 0.00/0.00, [MB6] 0.00/0.00, [MB7] 0.00/0.00
[rank1]:[titan] 2025-09-23 14:35:40,312 - root - INFO - Current/Expected Freeze Ratio per Block: [MB0] 0.00/0.00, [MB1] 0.00/0.00, [MB2] 0.00/0.00, [MB3] 0.00/0.00, [MB4] 0.00/0.00, [MB5] 0.00/0.00, [MB6] 0.00/0.00, [MB7] 0.00/0.00
[rank3]:[titan] 2025-09-23 14:37:08,336 - root - INFO - [31m step: 40 [32m loss: -8.0000 [38;2;180;60;0m grad_norm:  0.6089 [38;2;54;234;195m memory: 38.74GiB(48.88%) [34m tps: 1,882 [36m tflops: 87.79 [35m mfu: 28.14%[39m
[rank2]:[titan] 2025-09-23 14:37:08,336 - root - INFO - [31m step: 40 [32m loss: -8.0000 [38;2;180;60;0m grad_norm:  0.6089 [38;2;54;234;195m memory: 38.74GiB(48.88%) [34m tps: 1,882 [36m tflops: 87.79 [35m mfu: 28.14%[39m
[rank0]:[titan] 2025-09-23 14:37:08,339 - root - INFO - [31m step: 40 [32m loss: -8.0000 [38;2;180;60;0m grad_norm:  0.6089 [38;2;54;234;195m memory: 43.86GiB(55.34%) [34m tps: 1,882 [36m tflops: 87.79 [35m mfu: 28.14%[39m
[rank4]:[titan] 2025-09-23 14:37:08,333 - root - INFO - [31m step: 40 [32m loss: -8.0000 [38;2;180;60;0m grad_norm:  0.6089 [38;2;54;234;195m memory: 34.68GiB(43.76%) [34m tps: 1,882 [36m tflops: 87.79 [35m mfu: 28.14%[39m
[rank6]:[titan] 2025-09-23 14:37:08,338 - root - INFO - [31m step: 40 [32m loss:  6.8081 [38;2;180;60;0m grad_norm:  0.6089 [38;2;54;234;195m memory: 45.85GiB(57.85%) [34m tps: 1,882 [36m tflops: 87.79 [35m mfu: 28.14%[39m
[rank5]:[titan] 2025-09-23 14:37:08,333 - root - INFO - [31m step: 40 [32m loss: -8.0000 [38;2;180;60;0m grad_norm:  0.6089 [38;2;54;234;195m memory: 34.68GiB(43.76%) [34m tps: 1,882 [36m tflops: 87.79 [35m mfu: 28.14%[39m
[rank1]:[titan] 2025-09-23 14:37:08,339 - root - INFO - [31m step: 40 [32m loss: -8.0000 [38;2;180;60;0m grad_norm:  0.6089 [38;2;54;234;195m memory: 43.86GiB(55.34%) [34m tps: 1,882 [36m tflops: 87.79 [35m mfu: 28.14%[39m
[rank7]:[titan] 2025-09-23 14:37:08,337 - root - INFO - [31m step: 40 [32m loss:  6.8081 [38;2;180;60;0m grad_norm:  0.6089 [38;2;54;234;195m memory: 45.85GiB(57.85%) [34m tps: 1,882 [36m tflops: 87.79 [35m mfu: 28.14%[39m
[rank6]:[titan] 2025-09-23 14:37:08,540 - root - INFO - Pipeline schedule is saved as: /workspace/torchtitan_data/images/0922_gpipe_fullrand6_runpod/pipeline_schedule/250923_1437_real_step40_rank6.svg
[rank6]:> Batch Time: 1055.88 ms, GPU Bubble Ratio: 40.48%, 38.35%, 44.89%, 35.82%
[rank7]:[titan] 2025-09-23 14:37:08,541 - root - INFO - Pipeline schedule is saved as: /workspace/torchtitan_data/images/0922_gpipe_fullrand6_runpod/pipeline_schedule/250923_1437_real_step40_rank7.svg
[rank7]:> Batch Time: 1056.47 ms, GPU Bubble Ratio: 40.61%, 38.04%, 45.05%, 35.82%
[rank6]:[titan] 2025-09-23 14:37:08,610 - root - INFO - Frozen Ratio History of Rank 6 (Stage 3)  is saved as: /workspace/torchtitan_data/images/0922_gpipe_fullrand6_runpod/freeze_ratio_history/rank6/250923_1437_stage3_step40.svg
[rank7]:[titan] 2025-09-23 14:37:08,612 - root - INFO - Frozen Ratio History of Rank 7 (Stage 3)  is saved as: /workspace/torchtitan_data/images/0922_gpipe_fullrand6_runpod/freeze_ratio_history/rank7/250923_1437_stage3_step40.svg
[rank0]:[titan] 2025-09-23 14:38:28,047 - root - INFO - [GC] Peforming periodical GC collection 0.25 seconds
[rank2]:[titan] 2025-09-23 14:43:01,383 - root - INFO - [31m step: 80 [32m loss: -8.0000 [38;2;180;60;0m grad_norm:  0.1762 [38;2;54;234;195m memory: 38.74GiB(48.88%) [34m tps: 1,856 [36m tflops: 86.58 [35m mfu: 27.75%[39m
[rank0]:[titan] 2025-09-23 14:43:01,386 - root - INFO - [31m step: 80 [32m loss: -8.0000 [38;2;180;60;0m grad_norm:  0.1762 [38;2;54;234;195m memory: 43.86GiB(55.34%) [34m tps: 1,856 [36m tflops: 86.58 [35m mfu: 27.75%[39m
[rank3]:[titan] 2025-09-23 14:43:01,383 - root - INFO - [31m step: 80 [32m loss: -8.0000 [38;2;180;60;0m grad_norm:  0.1762 [38;2;54;234;195m memory: 38.74GiB(48.88%) [34m tps: 1,856 [36m tflops: 86.58 [35m mfu: 27.75%[39m
[rank4]:[titan] 2025-09-23 14:43:01,380 - root - INFO - [31m step: 80 [32m loss: -8.0000 [38;2;180;60;0m grad_norm:  0.1762 [38;2;54;234;195m memory: 34.68GiB(43.76%) [34m tps: 1,856 [36m tflops: 86.58 [35m mfu: 27.75%[39m
[rank1]:[titan] 2025-09-23 14:43:01,386 - root - INFO - [31m step: 80 [32m loss: -8.0000 [38;2;180;60;0m grad_norm:  0.1762 [38;2;54;234;195m memory: 43.86GiB(55.34%) [34m tps: 1,856 [36m tflops: 86.58 [35m mfu: 27.75%[39m
[rank6]:[titan] 2025-09-23 14:43:01,385 - root - INFO - [31m step: 80 [32m loss:  6.2018 [38;2;180;60;0m grad_norm:  0.1762 [38;2;54;234;195m memory: 45.85GiB(57.85%) [34m tps: 1,856 [36m tflops: 86.58 [35m mfu: 27.75%[39m
[rank5]:[titan] 2025-09-23 14:43:01,380 - root - INFO - [31m step: 80 [32m loss: -8.0000 [38;2;180;60;0m grad_norm:  0.1762 [38;2;54;234;195m memory: 34.68GiB(43.76%) [34m tps: 1,856 [36m tflops: 86.58 [35m mfu: 27.75%[39m
[rank7]:[titan] 2025-09-23 14:43:01,384 - root - INFO - [31m step: 80 [32m loss:  6.2018 [38;2;180;60;0m grad_norm:  0.1762 [38;2;54;234;195m memory: 45.85GiB(57.85%) [34m tps: 1,856 [36m tflops: 86.58 [35m mfu: 27.75%[39m
[rank6]:[titan] 2025-09-23 14:43:01,589 - root - INFO - Pipeline schedule is saved as: /workspace/torchtitan_data/images/0922_gpipe_fullrand6_runpod/pipeline_schedule/250923_1443_real_step80_rank6.svg
[rank6]:> Batch Time: 1058.50 ms, GPU Bubble Ratio: 40.58%, 38.44%, 44.95%, 35.77%
[rank7]:[titan] 2025-09-23 14:43:01,590 - root - INFO - Pipeline schedule is saved as: /workspace/torchtitan_data/images/0922_gpipe_fullrand6_runpod/pipeline_schedule/250923_1443_real_step80_rank7.svg
[rank7]:> Batch Time: 1058.64 ms, GPU Bubble Ratio: 40.70%, 38.10%, 45.10%, 35.76%
[rank7]:[titan] 2025-09-23 14:43:01,654 - root - INFO - Frozen Ratio History of Rank 7 (Stage 3)  is saved as: /workspace/torchtitan_data/images/0922_gpipe_fullrand6_runpod/freeze_ratio_history/rank7/250923_1443_stage3_step80.svg
[rank6]:[titan] 2025-09-23 14:43:01,653 - root - INFO - Frozen Ratio History of Rank 6 (Stage 3)  is saved as: /workspace/torchtitan_data/images/0922_gpipe_fullrand6_runpod/freeze_ratio_history/rank6/250923_1443_stage3_step80.svg
[rank0]:[titan] 2025-09-23 14:45:49,519 - root - INFO - [GC] Peforming periodical GC collection 0.35 seconds
[rank7]:[titan] 2025-09-23 14:48:54,855 - root - INFO - [31m step: 120 [32m loss:  5.6905 [38;2;180;60;0m grad_norm:  0.1967 [38;2;54;234;195m memory: 45.85GiB(57.85%) [34m tps: 1,854 [36m tflops: 86.47 [35m mfu: 27.72%[39m
[rank3]:[titan] 2025-09-23 14:48:54,853 - root - INFO - [31m step: 120 [32m loss: -8.0000 [38;2;180;60;0m grad_norm:  0.1967 [38;2;54;234;195m memory: 38.74GiB(48.88%) [34m tps: 1,854 [36m tflops: 86.47 [35m mfu: 27.72%[39m
[rank4]:[titan] 2025-09-23 14:48:54,851 - root - INFO - [31m step: 120 [32m loss: -8.0000 [38;2;180;60;0m grad_norm:  0.1967 [38;2;54;234;195m memory: 34.68GiB(43.76%) [34m tps: 1,854 [36m tflops: 86.47 [35m mfu: 27.72%[39m
[rank1]:[titan] 2025-09-23 14:48:54,857 - root - INFO - [31m step: 120 [32m loss: -8.0000 [38;2;180;60;0m grad_norm:  0.1967 [38;2;54;234;195m memory: 43.86GiB(55.34%) [34m tps: 1,854 [36m tflops: 86.47 [35m mfu: 27.72%[39m
[rank2]:[titan] 2025-09-23 14:48:54,853 - root - INFO - [31m step: 120 [32m loss: -8.0000 [38;2;180;60;0m grad_norm:  0.1967 [38;2;54;234;195m memory: 38.74GiB(48.88%) [34m tps: 1,854 [36m tflops: 86.47 [35m mfu: 27.72%[39m
[rank6]:[titan] 2025-09-23 14:48:54,856 - root - INFO - [31m step: 120 [32m loss:  5.6905 [38;2;180;60;0m grad_norm:  0.1967 [38;2;54;234;195m memory: 45.85GiB(57.85%) [34m tps: 1,854 [36m tflops: 86.47 [35m mfu: 27.72%[39m
[rank0]:[titan] 2025-09-23 14:48:54,857 - root - INFO - [31m step: 120 [32m loss: -8.0000 [38;2;180;60;0m grad_norm:  0.1967 [38;2;54;234;195m memory: 43.86GiB(55.34%) [34m tps: 1,854 [36m tflops: 86.47 [35m mfu: 27.72%[39m
[rank5]:[titan] 2025-09-23 14:48:54,850 - root - INFO - [31m step: 120 [32m loss: -8.0000 [38;2;180;60;0m grad_norm:  0.1967 [38;2;54;234;195m memory: 34.68GiB(43.76%) [34m tps: 1,854 [36m tflops: 86.47 [35m mfu: 27.72%[39m
[rank7]:[titan] 2025-09-23 14:48:55,058 - root - INFO - Pipeline schedule is saved as: /workspace/torchtitan_data/images/0922_gpipe_fullrand6_runpod/pipeline_schedule/250923_1448_real_step120_rank7.svg
[rank7]:> Batch Time: 1059.44 ms, GPU Bubble Ratio: 40.73%, 38.13%, 45.11%, 35.74%
[rank6]:[titan] 2025-09-23 14:48:55,055 - root - INFO - Pipeline schedule is saved as: /workspace/torchtitan_data/images/0922_gpipe_fullrand6_runpod/pipeline_schedule/250923_1448_real_step120_rank6.svg
[rank6]:> Batch Time: 1059.11 ms, GPU Bubble Ratio: 40.60%, 38.46%, 44.97%, 35.75%
[rank7]:[titan] 2025-09-23 14:48:55,127 - root - INFO - Frozen Ratio History of Rank 7 (Stage 3)  is saved as: /workspace/torchtitan_data/images/0922_gpipe_fullrand6_runpod/freeze_ratio_history/rank7/250923_1448_stage3_step120.svg
[rank6]:[titan] 2025-09-23 14:48:55,123 - root - INFO - Frozen Ratio History of Rank 6 (Stage 3)  is saved as: /workspace/torchtitan_data/images/0922_gpipe_fullrand6_runpod/freeze_ratio_history/rank6/250923_1448_stage3_step120.svg
[rank0]:[titan] 2025-09-23 14:53:11,320 - root - INFO - [GC] Peforming periodical GC collection 0.37 seconds
[rank7]:[titan] 2025-09-23 14:54:48,418 - root - INFO - [31m step: 160 [32m loss:  5.3260 [38;2;180;60;0m grad_norm:  0.1874 [38;2;54;234;195m memory: 45.85GiB(57.85%) [34m tps: 1,854 [36m tflops: 86.45 [35m mfu: 27.71%[39m
[rank1]:[titan] 2025-09-23 14:54:48,420 - root - INFO - [31m step: 160 [32m loss: -8.0000 [38;2;180;60;0m grad_norm:  0.1874 [38;2;54;234;195m memory: 43.86GiB(55.34%) [34m tps: 1,854 [36m tflops: 86.45 [35m mfu: 27.71%[39m
[rank4]:[titan] 2025-09-23 14:54:48,413 - root - INFO - [31m step: 160 [32m loss: -8.0000 [38;2;180;60;0m grad_norm:  0.1874 [38;2;54;234;195m memory: 34.68GiB(43.76%) [34m tps: 1,854 [36m tflops: 86.45 [35m mfu: 27.71%[39m
[rank3]:[titan] 2025-09-23 14:54:48,416 - root - INFO - [31m step: 160 [32m loss: -8.0000 [38;2;180;60;0m grad_norm:  0.1874 [38;2;54;234;195m memory: 38.74GiB(48.88%) [34m tps: 1,854 [36m tflops: 86.45 [35m mfu: 27.71%[39m
[rank2]:[titan] 2025-09-23 14:54:48,416 - root - INFO - [31m step: 160 [32m loss: -8.0000 [38;2;180;60;0m grad_norm:  0.1874 [38;2;54;234;195m memory: 38.74GiB(48.88%) [34m tps: 1,854 [36m tflops: 86.45 [35m mfu: 27.71%[39m
[rank0]:[titan] 2025-09-23 14:54:48,420 - root - INFO - [31m step: 160 [32m loss: -8.0000 [38;2;180;60;0m grad_norm:  0.1874 [38;2;54;234;195m memory: 43.86GiB(55.34%) [34m tps: 1,854 [36m tflops: 86.45 [35m mfu: 27.71%[39m
[rank6]:[titan] 2025-09-23 14:54:48,418 - root - INFO - [31m step: 160 [32m loss:  5.3260 [38;2;180;60;0m grad_norm:  0.1874 [38;2;54;234;195m memory: 45.85GiB(57.85%) [34m tps: 1,854 [36m tflops: 86.45 [35m mfu: 27.71%[39m
[rank5]:[titan] 2025-09-23 14:54:48,413 - root - INFO - [31m step: 160 [32m loss: -8.0000 [38;2;180;60;0m grad_norm:  0.1874 [38;2;54;234;195m memory: 34.68GiB(43.76%) [34m tps: 1,854 [36m tflops: 86.45 [35m mfu: 27.71%[39m
[rank6]:[titan] 2025-09-23 14:54:48,619 - root - INFO - Pipeline schedule is saved as: /workspace/torchtitan_data/images/0922_gpipe_fullrand6_runpod/pipeline_schedule/250923_1454_real_step160_rank6.svg
[rank6]:> Batch Time: 1059.53 ms, GPU Bubble Ratio: 40.62%, 38.49%, 44.97%, 35.74%
[rank7]:[titan] 2025-09-23 14:54:48,632 - root - INFO - Pipeline schedule is saved as: /workspace/torchtitan_data/images/0922_gpipe_fullrand6_runpod/pipeline_schedule/250923_1454_real_step160_rank7.svg
[rank7]:> Batch Time: 1059.86 ms, GPU Bubble Ratio: 40.75%, 38.14%, 45.12%, 35.73%
[rank7]:[titan] 2025-09-23 14:54:48,706 - root - INFO - Frozen Ratio History of Rank 7 (Stage 3)  is saved as: /workspace/torchtitan_data/images/0922_gpipe_fullrand6_runpod/freeze_ratio_history/rank7/250923_1454_stage3_step160.svg
[rank6]:[titan] 2025-09-23 14:54:48,692 - root - INFO - Frozen Ratio History of Rank 6 (Stage 3)  is saved as: /workspace/torchtitan_data/images/0922_gpipe_fullrand6_runpod/freeze_ratio_history/rank6/250923_1454_stage3_step160.svg
[rank0]:[titan] 2025-09-23 15:00:33,163 - root - INFO - [GC] Peforming periodical GC collection 0.40 seconds
[rank1]:[titan] 2025-09-23 15:00:42,025 - root - INFO - [31m step: 200 [32m loss: -8.0000 [38;2;180;60;0m grad_norm:  0.1675 [38;2;54;234;195m memory: 43.86GiB(55.34%) [34m tps: 1,853 [36m tflops: 86.44 [35m mfu: 27.71%[39m
[rank4]:[titan] 2025-09-23 15:00:42,018 - root - INFO - [31m step: 200 [32m loss: -8.0000 [38;2;180;60;0m grad_norm:  0.1675 [38;2;54;234;195m memory: 34.68GiB(43.76%) [34m tps: 1,853 [36m tflops: 86.44 [35m mfu: 27.71%[39m
[rank5]:[titan] 2025-09-23 15:00:42,018 - root - INFO - [31m step: 200 [32m loss: -8.0000 [38;2;180;60;0m grad_norm:  0.1675 [38;2;54;234;195m memory: 34.68GiB(43.76%) [34m tps: 1,853 [36m tflops: 86.44 [35m mfu: 27.71%[39m
[rank3]:[titan] 2025-09-23 15:00:42,021 - root - INFO - [31m step: 200 [32m loss: -8.0000 [38;2;180;60;0m grad_norm:  0.1675 [38;2;54;234;195m memory: 38.74GiB(48.88%) [34m tps: 1,853 [36m tflops: 86.44 [35m mfu: 27.71%[39m
[rank2]:[titan] 2025-09-23 15:00:42,021 - root - INFO - [31m step: 200 [32m loss: -8.0000 [38;2;180;60;0m grad_norm:  0.1675 [38;2;54;234;195m memory: 38.74GiB(48.88%) [34m tps: 1,853 [36m tflops: 86.44 [35m mfu: 27.71%[39m
[rank0]:[titan] 2025-09-23 15:00:42,025 - root - INFO - [31m step: 200 [32m loss: -8.0000 [38;2;180;60;0m grad_norm:  0.1675 [38;2;54;234;195m memory: 43.86GiB(55.34%) [34m tps: 1,853 [36m tflops: 86.44 [35m mfu: 27.71%[39m
[rank6]:[titan] 2025-09-23 15:00:42,023 - root - INFO - [31m step: 200 [32m loss:  5.1846 [38;2;180;60;0m grad_norm:  0.1675 [38;2;54;234;195m memory: 45.85GiB(57.85%) [34m tps: 1,853 [36m tflops: 86.44 [35m mfu: 27.71%[39m
[rank7]:[titan] 2025-09-23 15:00:42,023 - root - INFO - [31m step: 200 [32m loss:  5.1846 [38;2;180;60;0m grad_norm:  0.1675 [38;2;54;234;195m memory: 45.85GiB(57.85%) [34m tps: 1,853 [36m tflops: 86.44 [35m mfu: 27.71%[39m
[rank6]:[titan] 2025-09-23 15:00:42,230 - root - INFO - Pipeline schedule is saved as: /workspace/torchtitan_data/images/0922_gpipe_fullrand6_runpod/pipeline_schedule/250923_1500_real_step200_rank6.svg
[rank6]:> Batch Time: 1059.72 ms, GPU Bubble Ratio: 40.63%, 38.49%, 44.98%, 35.73%
[rank7]:[titan] 2025-09-23 15:00:42,230 - root - INFO - Pipeline schedule is saved as: /workspace/torchtitan_data/images/0922_gpipe_fullrand6_runpod/pipeline_schedule/250923_1500_real_step200_rank7.svg
[rank7]:> Batch Time: 1060.06 ms, GPU Bubble Ratio: 40.76%, 38.16%, 45.12%, 35.72%
[rank6]:[titan] 2025-09-23 15:00:42,295 - root - INFO - Frozen Ratio History of Rank 6 (Stage 3)  is saved as: /workspace/torchtitan_data/images/0922_gpipe_fullrand6_runpod/freeze_ratio_history/rank6/250923_1500_stage3_step200.svg
[rank7]:[titan] 2025-09-23 15:00:42,295 - root - INFO - Frozen Ratio History of Rank 7 (Stage 3)  is saved as: /workspace/torchtitan_data/images/0922_gpipe_fullrand6_runpod/freeze_ratio_history/rank7/250923_1500_stage3_step200.svg
[rank7]:[titan] 2025-09-23 15:06:35,257 - root - INFO - [31m step: 240 [32m loss:  4.9490 [38;2;180;60;0m grad_norm:  0.1109 [38;2;54;234;195m memory: 45.85GiB(57.85%) [34m tps: 1,855 [36m tflops: 86.53 [35m mfu: 27.73%[39m
[rank5]:[titan] 2025-09-23 15:06:35,252 - root - INFO - [31m step: 240 [32m loss: -8.0000 [38;2;180;60;0m grad_norm:  0.1109 [38;2;54;234;195m memory: 34.68GiB(43.76%) [34m tps: 1,855 [36m tflops: 86.53 [35m mfu: 27.73%[39m
[rank3]:[titan] 2025-09-23 15:06:35,255 - root - INFO - [31m step: 240 [32m loss: -8.0000 [38;2;180;60;0m grad_norm:  0.1109 [38;2;54;234;195m memory: 38.74GiB(48.88%) [34m tps: 1,855 [36m tflops: 86.53 [35m mfu: 27.73%[39m
[rank2]:[titan] 2025-09-23 15:06:35,255 - root - INFO - [31m step: 240 [32m loss: -8.0000 [38;2;180;60;0m grad_norm:  0.1109 [38;2;54;234;195m memory: 38.74GiB(48.88%) [34m tps: 1,855 [36m tflops: 86.53 [35m mfu: 27.73%[39m
[rank1]:[titan] 2025-09-23 15:06:35,259 - root - INFO - [31m step: 240 [32m loss: -8.0000 [38;2;180;60;0m grad_norm:  0.1109 [38;2;54;234;195m memory: 43.86GiB(55.34%) [34m tps: 1,855 [36m tflops: 86.53 [35m mfu: 27.73%[39m
[rank6]:[titan] 2025-09-23 15:06:35,257 - root - INFO - [31m step: 240 [32m loss:  4.9490 [38;2;180;60;0m grad_norm:  0.1109 [38;2;54;234;195m memory: 45.85GiB(57.85%) [34m tps: 1,855 [36m tflops: 86.53 [35m mfu: 27.73%[39m
[rank4]:[titan] 2025-09-23 15:06:35,252 - root - INFO - [31m step: 240 [32m loss: -8.0000 [38;2;180;60;0m grad_norm:  0.1109 [38;2;54;234;195m memory: 34.68GiB(43.76%) [34m tps: 1,855 [36m tflops: 86.53 [35m mfu: 27.73%[39m
[rank0]:[titan] 2025-09-23 15:06:35,259 - root - INFO - [31m step: 240 [32m loss: -8.0000 [38;2;180;60;0m grad_norm:  0.1109 [38;2;54;234;195m memory: 43.86GiB(55.34%) [34m tps: 1,855 [36m tflops: 86.53 [35m mfu: 27.73%[39m
[rank7]:[titan] 2025-09-23 15:06:35,462 - root - INFO - Pipeline schedule is saved as: /workspace/torchtitan_data/images/0922_gpipe_fullrand6_runpod/pipeline_schedule/250923_1506_real_step240_rank7.svg
[rank7]:> Batch Time: 1060.27 ms, GPU Bubble Ratio: 40.77%, 38.16%, 45.13%, 35.71%
[rank6]:[titan] 2025-09-23 15:06:35,460 - root - INFO - Pipeline schedule is saved as: /workspace/torchtitan_data/images/0922_gpipe_fullrand6_runpod/pipeline_schedule/250923_1506_real_step240_rank6.svg
[rank6]:> Batch Time: 1059.92 ms, GPU Bubble Ratio: 40.64%, 38.50%, 44.98%, 35.73%
[rank7]:[titan] 2025-09-23 15:06:35,528 - root - INFO - Frozen Ratio History of Rank 7 (Stage 3)  is saved as: /workspace/torchtitan_data/images/0922_gpipe_fullrand6_runpod/freeze_ratio_history/rank7/250923_1506_stage3_step240.svg
[rank6]:[titan] 2025-09-23 15:06:35,527 - root - INFO - Frozen Ratio History of Rank 6 (Stage 3)  is saved as: /workspace/torchtitan_data/images/0922_gpipe_fullrand6_runpod/freeze_ratio_history/rank6/250923_1506_stage3_step240.svg
[rank0]:[titan] 2025-09-23 15:07:55,261 - root - INFO - [GC] Peforming periodical GC collection 0.42 seconds
[rank5]:[titan] 2025-09-23 15:12:28,874 - root - INFO - [31m step: 280 [32m loss: -8.0000 [38;2;180;60;0m grad_norm:  0.1675 [38;2;54;234;195m memory: 34.68GiB(43.76%) [34m tps: 1,853 [36m tflops: 86.44 [35m mfu: 27.70%[39m
[rank4]:[titan] 2025-09-23 15:12:28,874 - root - INFO - [31m step: 280 [32m loss: -8.0000 [38;2;180;60;0m grad_norm:  0.1675 [38;2;54;234;195m memory: 34.68GiB(43.76%) [34m tps: 1,853 [36m tflops: 86.44 [35m mfu: 27.70%[39m
[rank7]:[titan] 2025-09-23 15:12:28,879 - root - INFO - [31m step: 280 [32m loss:  5.0292 [38;2;180;60;0m grad_norm:  0.1675 [38;2;54;234;195m memory: 45.85GiB(57.85%) [34m tps: 1,853 [36m tflops: 86.44 [35m mfu: 27.70%[39m
[rank2]:[titan] 2025-09-23 15:12:28,877 - root - INFO - [31m step: 280 [32m loss: -8.0000 [38;2;180;60;0m grad_norm:  0.1675 [38;2;54;234;195m memory: 38.74GiB(48.88%) [34m tps: 1,853 [36m tflops: 86.44 [35m mfu: 27.70%[39m
[rank3]:[titan] 2025-09-23 15:12:28,877 - root - INFO - [31m step: 280 [32m loss: -8.0000 [38;2;180;60;0m grad_norm:  0.1675 [38;2;54;234;195m memory: 38.74GiB(48.88%) [34m tps: 1,853 [36m tflops: 86.44 [35m mfu: 27.70%[39m
[rank0]:[titan] 2025-09-23 15:12:28,881 - root - INFO - [31m step: 280 [32m loss: -8.0000 [38;2;180;60;0m grad_norm:  0.1675 [38;2;54;234;195m memory: 43.86GiB(55.34%) [34m tps: 1,853 [36m tflops: 86.44 [35m mfu: 27.70%[39m
[rank1]:[titan] 2025-09-23 15:12:28,881 - root - INFO - [31m step: 280 [32m loss: -8.0000 [38;2;180;60;0m grad_norm:  0.1675 [38;2;54;234;195m memory: 43.86GiB(55.34%) [34m tps: 1,853 [36m tflops: 86.44 [35m mfu: 27.70%[39m
[rank6]:[titan] 2025-09-23 15:12:28,879 - root - INFO - [31m step: 280 [32m loss:  5.0292 [38;2;180;60;0m grad_norm:  0.1675 [38;2;54;234;195m memory: 45.85GiB(57.85%) [34m tps: 1,853 [36m tflops: 86.44 [35m mfu: 27.70%[39m
[rank7]:[titan] 2025-09-23 15:12:29,084 - root - INFO - Pipeline schedule is saved as: /workspace/torchtitan_data/images/0922_gpipe_fullrand6_runpod/pipeline_schedule/250923_1512_real_step280_rank7.svg
[rank7]:> Batch Time: 1060.41 ms, GPU Bubble Ratio: 40.78%, 38.17%, 45.13%, 35.71%
[rank6]:[titan] 2025-09-23 15:12:29,082 - root - INFO - Pipeline schedule is saved as: /workspace/torchtitan_data/images/0922_gpipe_fullrand6_runpod/pipeline_schedule/250923_1512_real_step280_rank6.svg
[rank6]:> Batch Time: 1060.08 ms, GPU Bubble Ratio: 40.64%, 38.51%, 44.99%, 35.72%
[rank6]:[titan] 2025-09-23 15:12:29,150 - root - INFO - Frozen Ratio History of Rank 6 (Stage 3)  is saved as: /workspace/torchtitan_data/images/0922_gpipe_fullrand6_runpod/freeze_ratio_history/rank6/250923_1512_stage3_step280.svg
[rank7]:[titan] 2025-09-23 15:12:29,152 - root - INFO - Frozen Ratio History of Rank 7 (Stage 3)  is saved as: /workspace/torchtitan_data/images/0922_gpipe_fullrand6_runpod/freeze_ratio_history/rank7/250923_1512_stage3_step280.svg
[rank0]:[titan] 2025-09-23 15:15:17,168 - root - INFO - [GC] Peforming periodical GC collection 0.43 seconds
[rank7]:[titan] 2025-09-23 15:18:22,585 - root - INFO - [31m step: 320 [32m loss:  4.6739 [38;2;180;60;0m grad_norm:  0.1316 [38;2;54;234;195m memory: 45.85GiB(57.85%) [34m tps: 1,853 [36m tflops: 86.42 [35m mfu: 27.70%[39m
[rank3]:[titan] 2025-09-23 15:18:22,583 - root - INFO - [31m step: 320 [32m loss: -8.0000 [38;2;180;60;0m grad_norm:  0.1316 [38;2;54;234;195m memory: 38.74GiB(48.88%) [34m tps: 1,853 [36m tflops: 86.42 [35m mfu: 27.70%[39m
[rank2]:[titan] 2025-09-23 15:18:22,583 - root - INFO - [31m step: 320 [32m loss: -8.0000 [38;2;180;60;0m grad_norm:  0.1316 [38;2;54;234;195m memory: 38.74GiB(48.88%) [34m tps: 1,853 [36m tflops: 86.42 [35m mfu: 27.70%[39m
[rank1]:[titan] 2025-09-23 15:18:22,587 - root - INFO - [31m step: 320 [32m loss: -8.0000 [38;2;180;60;0m grad_norm:  0.1316 [38;2;54;234;195m memory: 43.86GiB(55.34%) [34m tps: 1,853 [36m tflops: 86.42 [35m mfu: 27.70%[39m
[rank5]:[titan] 2025-09-23 15:18:22,580 - root - INFO - [31m step: 320 [32m loss: -8.0000 [38;2;180;60;0m grad_norm:  0.1316 [38;2;54;234;195m memory: 34.68GiB(43.76%) [34m tps: 1,853 [36m tflops: 86.42 [35m mfu: 27.70%[39m
[rank4]:[titan] 2025-09-23 15:18:22,581 - root - INFO - [31m step: 320 [32m loss: -8.0000 [38;2;180;60;0m grad_norm:  0.1316 [38;2;54;234;195m memory: 34.68GiB(43.76%) [34m tps: 1,853 [36m tflops: 86.42 [35m mfu: 27.70%[39m
[rank0]:[titan] 2025-09-23 15:18:22,587 - root - INFO - [31m step: 320 [32m loss: -8.0000 [38;2;180;60;0m grad_norm:  0.1316 [38;2;54;234;195m memory: 43.86GiB(55.34%) [34m tps: 1,853 [36m tflops: 86.42 [35m mfu: 27.70%[39m
[rank6]:[titan] 2025-09-23 15:18:22,585 - root - INFO - [31m step: 320 [32m loss:  4.6739 [38;2;180;60;0m grad_norm:  0.1316 [38;2;54;234;195m memory: 45.85GiB(57.85%) [34m tps: 1,853 [36m tflops: 86.42 [35m mfu: 27.70%[39m
[rank6]:[titan] 2025-09-23 15:18:22,787 - root - INFO - Pipeline schedule is saved as: /workspace/torchtitan_data/images/0922_gpipe_fullrand6_runpod/pipeline_schedule/250923_1518_real_step320_rank6.svg
[rank6]:> Batch Time: 1060.11 ms, GPU Bubble Ratio: 40.65%, 38.51%, 44.99%, 35.72%
[rank6]:[titan] 2025-09-23 15:18:22,858 - root - INFO - Frozen Ratio History of Rank 6 (Stage 3)  is saved as: /workspace/torchtitan_data/images/0922_gpipe_fullrand6_runpod/freeze_ratio_history/rank6/250923_1518_stage3_step320.svg
[rank7]:[titan] 2025-09-23 15:18:22,789 - root - INFO - Pipeline schedule is saved as: /workspace/torchtitan_data/images/0922_gpipe_fullrand6_runpod/pipeline_schedule/250923_1518_real_step320_rank7.svg
[rank7]:> Batch Time: 1060.52 ms, GPU Bubble Ratio: 40.78%, 38.18%, 45.13%, 35.70%
[rank7]:[titan] 2025-09-23 15:18:22,860 - root - INFO - Frozen Ratio History of Rank 7 (Stage 3)  is saved as: /workspace/torchtitan_data/images/0922_gpipe_fullrand6_runpod/freeze_ratio_history/rank7/250923_1518_stage3_step320.svg
[rank0]:[titan] 2025-09-23 15:22:39,242 - root - INFO - [GC] Peforming periodical GC collection 0.45 seconds
[rank7]:[titan] 2025-09-23 15:24:16,422 - root - INFO - [31m step: 360 [32m loss:  4.6423 [38;2;180;60;0m grad_norm:  0.1282 [38;2;54;234;195m memory: 45.85GiB(57.85%) [34m tps: 1,852 [36m tflops: 86.38 [35m mfu: 27.69%[39m
[rank3]:[titan] 2025-09-23 15:24:16,420 - root - INFO - [31m step: 360 [32m loss: -8.0000 [38;2;180;60;0m grad_norm:  0.1282 [38;2;54;234;195m memory: 38.74GiB(48.88%) [34m tps: 1,852 [36m tflops: 86.38 [35m mfu: 27.69%[39m
[rank2]:[titan] 2025-09-23 15:24:16,421 - root - INFO - [31m step: 360 [32m loss: -8.0000 [38;2;180;60;0m grad_norm:  0.1282 [38;2;54;234;195m memory: 38.74GiB(48.88%) [34m tps: 1,852 [36m tflops: 86.38 [35m mfu: 27.69%[39m
[rank1]:[titan] 2025-09-23 15:24:16,424 - root - INFO - [31m step: 360 [32m loss: -8.0000 [38;2;180;60;0m grad_norm:  0.1282 [38;2;54;234;195m memory: 43.86GiB(55.34%) [34m tps: 1,852 [36m tflops: 86.38 [35m mfu: 27.69%[39m
[rank4]:[titan] 2025-09-23 15:24:16,418 - root - INFO - [31m step: 360 [32m loss: -8.0000 [38;2;180;60;0m grad_norm:  0.1282 [38;2;54;234;195m memory: 34.68GiB(43.76%) [34m tps: 1,852 [36m tflops: 86.38 [35m mfu: 27.69%[39m
[rank0]:[titan] 2025-09-23 15:24:16,424 - root - INFO - [31m step: 360 [32m loss: -8.0000 [38;2;180;60;0m grad_norm:  0.1282 [38;2;54;234;195m memory: 43.86GiB(55.34%) [34m tps: 1,852 [36m tflops: 86.38 [35m mfu: 27.69%[39m
[rank5]:[titan] 2025-09-23 15:24:16,418 - root - INFO - [31m step: 360 [32m loss: -8.0000 [38;2;180;60;0m grad_norm:  0.1282 [38;2;54;234;195m memory: 34.68GiB(43.76%) [34m tps: 1,852 [36m tflops: 86.38 [35m mfu: 27.69%[39m
[rank6]:[titan] 2025-09-23 15:24:16,423 - root - INFO - [31m step: 360 [32m loss:  4.6423 [38;2;180;60;0m grad_norm:  0.1282 [38;2;54;234;195m memory: 45.85GiB(57.85%) [34m tps: 1,852 [36m tflops: 86.39 [35m mfu: 27.69%[39m
[rank7]:[titan] 2025-09-23 15:24:16,627 - root - INFO - Pipeline schedule is saved as: /workspace/torchtitan_data/images/0922_gpipe_fullrand6_runpod/pipeline_schedule/250923_1524_real_step360_rank7.svg
[rank7]:> Batch Time: 1060.61 ms, GPU Bubble Ratio: 40.79%, 38.18%, 45.13%, 35.70%
[rank6]:[titan] 2025-09-23 15:24:16,623 - root - INFO - Pipeline schedule is saved as: /workspace/torchtitan_data/images/0922_gpipe_fullrand6_runpod/pipeline_schedule/250923_1524_real_step360_rank6.svg
[rank6]:> Batch Time: 1060.20 ms, GPU Bubble Ratio: 40.65%, 38.52%, 44.98%, 35.72%
[rank6]:[titan] 2025-09-23 15:24:16,695 - root - INFO - Frozen Ratio History of Rank 6 (Stage 3)  is saved as: /workspace/torchtitan_data/images/0922_gpipe_fullrand6_runpod/freeze_ratio_history/rank6/250923_1524_stage3_step360.svg
[rank7]:[titan] 2025-09-23 15:24:16,700 - root - INFO - Frozen Ratio History of Rank 7 (Stage 3)  is saved as: /workspace/torchtitan_data/images/0922_gpipe_fullrand6_runpod/freeze_ratio_history/rank7/250923_1524_stage3_step360.svg
[rank0]:[titan] 2025-09-23 15:30:01,419 - root - INFO - [GC] Peforming periodical GC collection 0.48 seconds
[rank4]:[titan] 2025-09-23 15:30:10,270 - root - INFO - [31m step: 400 [32m loss: -8.0000 [38;2;180;60;0m grad_norm:  0.1047 [38;2;54;234;195m memory: 34.68GiB(43.76%) [34m tps: 1,852 [36m tflops: 86.38 [35m mfu: 27.69%[39m
[rank6]:[titan] 2025-09-23 15:30:10,275 - root - INFO - [31m step: 400 [32m loss:  4.5231 [38;2;180;60;0m grad_norm:  0.1047 [38;2;54;234;195m memory: 45.85GiB(57.85%) [34m tps: 1,852 [36m tflops: 86.38 [35m mfu: 27.69%[39m
[rank5]:[titan] 2025-09-23 15:30:10,270 - root - INFO - [31m step: 400 [32m loss: -8.0000 [38;2;180;60;0m grad_norm:  0.1047 [38;2;54;234;195m memory: 34.68GiB(43.76%) [34m tps: 1,852 [36m tflops: 86.38 [35m mfu: 27.69%[39m
[rank7]:[titan] 2025-09-23 15:30:10,274 - root - INFO - [31m step: 400 [32m loss:  4.5231 [38;2;180;60;0m grad_norm:  0.1047 [38;2;54;234;195m memory: 45.85GiB(57.85%) [34m tps: 1,852 [36m tflops: 86.38 [35m mfu: 27.69%[39m
[rank2]:[titan] 2025-09-23 15:30:10,272 - root - INFO - [31m step: 400 [32m loss: -8.0000 [38;2;180;60;0m grad_norm:  0.1047 [38;2;54;234;195m memory: 38.74GiB(48.88%) [34m tps: 1,852 [36m tflops: 86.38 [35m mfu: 27.69%[39m
[rank3]:[titan] 2025-09-23 15:30:10,272 - root - INFO - [31m step: 400 [32m loss: -8.0000 [38;2;180;60;0m grad_norm:  0.1047 [38;2;54;234;195m memory: 38.74GiB(48.88%) [34m tps: 1,852 [36m tflops: 86.38 [35m mfu: 27.69%[39m
[rank1]:[titan] 2025-09-23 15:30:10,276 - root - INFO - [31m step: 400 [32m loss: -8.0000 [38;2;180;60;0m grad_norm:  0.1047 [38;2;54;234;195m memory: 43.86GiB(55.34%) [34m tps: 1,852 [36m tflops: 86.38 [35m mfu: 27.69%[39m
[rank0]:[titan] 2025-09-23 15:30:10,276 - root - INFO - [31m step: 400 [32m loss: -8.0000 [38;2;180;60;0m grad_norm:  0.1047 [38;2;54;234;195m memory: 43.86GiB(55.34%) [34m tps: 1,852 [36m tflops: 86.38 [35m mfu: 27.69%[39m
[rank7]:[titan] 2025-09-23 15:30:10,481 - root - INFO - Pipeline schedule is saved as: /workspace/torchtitan_data/images/0922_gpipe_fullrand6_runpod/pipeline_schedule/250923_1530_real_step400_rank7.svg
[rank7]:> Batch Time: 1060.67 ms, GPU Bubble Ratio: 40.79%, 38.19%, 45.14%, 35.70%
[rank6]:[titan] 2025-09-23 15:30:10,486 - root - INFO - Pipeline schedule is saved as: /workspace/torchtitan_data/images/0922_gpipe_fullrand6_runpod/pipeline_schedule/250923_1530_real_step400_rank6.svg
[rank6]:> Batch Time: 1060.28 ms, GPU Bubble Ratio: 40.65%, 38.52%, 44.99%, 35.71%
[rank6]:[titan] 2025-09-23 15:30:10,554 - root - INFO - Frozen Ratio History of Rank 6 (Stage 3)  is saved as: /workspace/torchtitan_data/images/0922_gpipe_fullrand6_runpod/freeze_ratio_history/rank6/250923_1530_stage3_step400.svg
[rank7]:[titan] 2025-09-23 15:30:10,548 - root - INFO - Frozen Ratio History of Rank 7 (Stage 3)  is saved as: /workspace/torchtitan_data/images/0922_gpipe_fullrand6_runpod/freeze_ratio_history/rank7/250923_1530_stage3_step400.svg
[rank7]:[titan] 2025-09-23 15:36:03,559 - root - INFO - [31m step: 440 [32m loss:  4.4734 [38;2;180;60;0m grad_norm:  0.1010 [38;2;54;234;195m memory: 45.85GiB(57.85%) [34m tps: 1,855 [36m tflops: 86.52 [35m mfu: 27.73%[39m
[rank2]:[titan] 2025-09-23 15:36:03,557 - root - INFO - [31m step: 440 [32m loss: -8.0000 [38;2;180;60;0m grad_norm:  0.1010 [38;2;54;234;195m memory: 38.74GiB(48.88%) [34m tps: 1,855 [36m tflops: 86.52 [35m mfu: 27.73%[39m
[rank3]:[titan] 2025-09-23 15:36:03,557 - root - INFO - [31m step: 440 [32m loss: -8.0000 [38;2;180;60;0m grad_norm:  0.1010 [38;2;54;234;195m memory: 38.74GiB(48.88%) [34m tps: 1,855 [36m tflops: 86.52 [35m mfu: 27.73%[39m
[rank1]:[titan] 2025-09-23 15:36:03,561 - root - INFO - [31m step: 440 [32m loss: -8.0000 [38;2;180;60;0m grad_norm:  0.1010 [38;2;54;234;195m memory: 43.86GiB(55.34%) [34m tps: 1,855 [36m tflops: 86.52 [35m mfu: 27.73%[39m
[rank0]:[titan] 2025-09-23 15:36:03,561 - root - INFO - [31m step: 440 [32m loss: -8.0000 [38;2;180;60;0m grad_norm:  0.1010 [38;2;54;234;195m memory: 43.86GiB(55.34%) [34m tps: 1,855 [36m tflops: 86.52 [35m mfu: 27.73%[39m
[rank4]:[titan] 2025-09-23 15:36:03,555 - root - INFO - [31m step: 440 [32m loss: -8.0000 [38;2;180;60;0m grad_norm:  0.1010 [38;2;54;234;195m memory: 34.68GiB(43.76%) [34m tps: 1,855 [36m tflops: 86.52 [35m mfu: 27.73%[39m
[rank6]:[titan] 2025-09-23 15:36:03,560 - root - INFO - [31m step: 440 [32m loss:  4.4734 [38;2;180;60;0m grad_norm:  0.1010 [38;2;54;234;195m memory: 45.85GiB(57.85%) [34m tps: 1,855 [36m tflops: 86.52 [35m mfu: 27.73%[39m
[rank5]:[titan] 2025-09-23 15:36:03,555 - root - INFO - [31m step: 440 [32m loss: -8.0000 [38;2;180;60;0m grad_norm:  0.1010 [38;2;54;234;195m memory: 34.68GiB(43.76%) [34m tps: 1,855 [36m tflops: 86.52 [35m mfu: 27.73%[39m
[rank7]:[titan] 2025-09-23 15:36:03,764 - root - INFO - Pipeline schedule is saved as: /workspace/torchtitan_data/images/0922_gpipe_fullrand6_runpod/pipeline_schedule/250923_1536_real_step440_rank7.svg
[rank7]:> Batch Time: 1060.69 ms, GPU Bubble Ratio: 40.79%, 38.19%, 45.14%, 35.70%
[rank6]:[titan] 2025-09-23 15:36:03,762 - root - INFO - Pipeline schedule is saved as: /workspace/torchtitan_data/images/0922_gpipe_fullrand6_runpod/pipeline_schedule/250923_1536_real_step440_rank6.svg
[rank6]:> Batch Time: 1060.31 ms, GPU Bubble Ratio: 40.66%, 38.52%, 44.99%, 35.71%
[rank6]:[titan] 2025-09-23 15:36:03,828 - root - INFO - Frozen Ratio History of Rank 6 (Stage 3)  is saved as: /workspace/torchtitan_data/images/0922_gpipe_fullrand6_runpod/freeze_ratio_history/rank6/250923_1536_stage3_step440.svg
[rank7]:[titan] 2025-09-23 15:36:03,831 - root - INFO - Frozen Ratio History of Rank 7 (Stage 3)  is saved as: /workspace/torchtitan_data/images/0922_gpipe_fullrand6_runpod/freeze_ratio_history/rank7/250923_1536_stage3_step440.svg
[rank0]:[titan] 2025-09-23 15:37:23,646 - root - INFO - [GC] Peforming periodical GC collection 0.48 seconds
[rank2]:[titan] 2025-09-23 15:41:57,337 - root - INFO - [31m step: 480 [32m loss: -8.0000 [38;2;180;60;0m grad_norm:  0.0970 [38;2;54;234;195m memory: 38.74GiB(48.88%) [34m tps: 1,852 [36m tflops: 86.40 [35m mfu: 27.69%[39m
[rank3]:[titan] 2025-09-23 15:41:57,337 - root - INFO - [31m step: 480 [32m loss: -8.0000 [38;2;180;60;0m grad_norm:  0.0970 [38;2;54;234;195m memory: 38.74GiB(48.88%) [34m tps: 1,852 [36m tflops: 86.40 [35m mfu: 27.69%[39m
[rank4]:[titan] 2025-09-23 15:41:57,334 - root - INFO - [31m step: 480 [32m loss: -8.0000 [38;2;180;60;0m grad_norm:  0.0970 [38;2;54;234;195m memory: 34.68GiB(43.76%) [34m tps: 1,852 [36m tflops: 86.40 [35m mfu: 27.69%[39m
[rank0]:[titan] 2025-09-23 15:41:57,341 - root - INFO - [31m step: 480 [32m loss: -8.0000 [38;2;180;60;0m grad_norm:  0.0970 [38;2;54;234;195m memory: 43.86GiB(55.34%) [34m tps: 1,852 [36m tflops: 86.40 [35m mfu: 27.69%[39m
[rank1]:[titan] 2025-09-23 15:41:57,341 - root - INFO - [31m step: 480 [32m loss: -8.0000 [38;2;180;60;0m grad_norm:  0.0970 [38;2;54;234;195m memory: 43.86GiB(55.34%) [34m tps: 1,852 [36m tflops: 86.40 [35m mfu: 27.69%[39m
[rank6]:[titan] 2025-09-23 15:41:57,339 - root - INFO - [31m step: 480 [32m loss:  4.1892 [38;2;180;60;0m grad_norm:  0.0970 [38;2;54;234;195m memory: 45.85GiB(57.85%) [34m tps: 1,852 [36m tflops: 86.40 [35m mfu: 27.69%[39m
[rank5]:[titan] 2025-09-23 15:41:57,334 - root - INFO - [31m step: 480 [32m loss: -8.0000 [38;2;180;60;0m grad_norm:  0.0970 [38;2;54;234;195m memory: 34.68GiB(43.76%) [34m tps: 1,852 [36m tflops: 86.40 [35m mfu: 27.69%[39m
[rank7]:[titan] 2025-09-23 15:41:57,339 - root - INFO - [31m step: 480 [32m loss:  4.1892 [38;2;180;60;0m grad_norm:  0.0970 [38;2;54;234;195m memory: 45.85GiB(57.85%) [34m tps: 1,852 [36m tflops: 86.40 [35m mfu: 27.69%[39m
[rank6]:[titan] 2025-09-23 15:41:57,544 - root - INFO - Pipeline schedule is saved as: /workspace/torchtitan_data/images/0922_gpipe_fullrand6_runpod/pipeline_schedule/250923_1541_real_step480_rank6.svg
[rank6]:> Batch Time: 1060.34 ms, GPU Bubble Ratio: 40.66%, 38.53%, 44.99%, 35.71%
[rank7]:[titan] 2025-09-23 15:41:57,546 - root - INFO - Pipeline schedule is saved as: /workspace/torchtitan_data/images/0922_gpipe_fullrand6_runpod/pipeline_schedule/250923_1541_real_step480_rank7.svg
[rank7]:> Batch Time: 1060.81 ms, GPU Bubble Ratio: 40.80%, 38.19%, 45.14%, 35.69%
[rank7]:[titan] 2025-09-23 15:41:57,615 - root - INFO - Frozen Ratio History of Rank 7 (Stage 3)  is saved as: /workspace/torchtitan_data/images/0922_gpipe_fullrand6_runpod/freeze_ratio_history/rank7/250923_1541_stage3_step480.svg
[rank6]:[titan] 2025-09-23 15:41:57,612 - root - INFO - Frozen Ratio History of Rank 6 (Stage 3)  is saved as: /workspace/torchtitan_data/images/0922_gpipe_fullrand6_runpod/freeze_ratio_history/rank6/250923_1541_stage3_step480.svg
[rank0]:[titan] 2025-09-23 15:44:45,706 - root - INFO - [GC] Peforming periodical GC collection 0.49 seconds
[rank2]:[titan] 2025-09-23 15:47:51,126 - root - INFO - [31m step: 520 [32m loss: -8.0000 [38;2;180;60;0m grad_norm:  0.1113 [38;2;54;234;195m memory: 38.74GiB(48.88%) [34m tps: 1,852 [36m tflops: 86.40 [35m mfu: 27.69%[39m
[rank4]:[titan] 2025-09-23 15:47:51,123 - root - INFO - [31m step: 520 [32m loss: -8.0000 [38;2;180;60;0m grad_norm:  0.1113 [38;2;54;234;195m memory: 34.68GiB(43.76%) [34m tps: 1,852 [36m tflops: 86.40 [35m mfu: 27.69%[39m
[rank3]:[titan] 2025-09-23 15:47:51,126 - root - INFO - [31m step: 520 [32m loss: -8.0000 [38;2;180;60;0m grad_norm:  0.1113 [38;2;54;234;195m memory: 38.74GiB(48.88%) [34m tps: 1,852 [36m tflops: 86.40 [35m mfu: 27.69%[39m
[rank1]:[titan] 2025-09-23 15:47:51,130 - root - INFO - [31m step: 520 [32m loss: -8.0000 [38;2;180;60;0m grad_norm:  0.1113 [38;2;54;234;195m memory: 43.86GiB(55.34%) [34m tps: 1,852 [36m tflops: 86.40 [35m mfu: 27.69%[39m
[rank6]:[titan] 2025-09-23 15:47:51,129 - root - INFO - [31m step: 520 [32m loss:  4.2563 [38;2;180;60;0m grad_norm:  0.1113 [38;2;54;234;195m memory: 45.85GiB(57.85%) [34m tps: 1,852 [36m tflops: 86.40 [35m mfu: 27.69%[39m
[rank7]:[titan] 2025-09-23 15:47:51,128 - root - INFO - [31m step: 520 [32m loss:  4.2563 [38;2;180;60;0m grad_norm:  0.1113 [38;2;54;234;195m memory: 45.85GiB(57.85%) [34m tps: 1,852 [36m tflops: 86.40 [35m mfu: 27.69%[39m
[rank0]:[titan] 2025-09-23 15:47:51,130 - root - INFO - [31m step: 520 [32m loss: -8.0000 [38;2;180;60;0m grad_norm:  0.1113 [38;2;54;234;195m memory: 43.86GiB(55.34%) [34m tps: 1,852 [36m tflops: 86.40 [35m mfu: 27.69%[39m
[rank5]:[titan] 2025-09-23 15:47:51,123 - root - INFO - [31m step: 520 [32m loss: -8.0000 [38;2;180;60;0m grad_norm:  0.1113 [38;2;54;234;195m memory: 34.68GiB(43.76%) [34m tps: 1,852 [36m tflops: 86.40 [35m mfu: 27.69%[39m
[rank6]:[titan] 2025-09-23 15:47:51,334 - root - INFO - Pipeline schedule is saved as: /workspace/torchtitan_data/images/0922_gpipe_fullrand6_runpod/pipeline_schedule/250923_1547_real_step520_rank6.svg
[rank6]:> Batch Time: 1060.48 ms, GPU Bubble Ratio: 40.67%, 38.53%, 44.99%, 35.70%
[rank7]:[titan] 2025-09-23 15:47:51,334 - root - INFO - Pipeline schedule is saved as: /workspace/torchtitan_data/images/0922_gpipe_fullrand6_runpod/pipeline_schedule/250923_1547_real_step520_rank7.svg
[rank7]:> Batch Time: 1060.81 ms, GPU Bubble Ratio: 40.80%, 38.19%, 45.14%, 35.69%
[rank6]:[titan] 2025-09-23 15:47:51,402 - root - INFO - Frozen Ratio History of Rank 6 (Stage 3)  is saved as: /workspace/torchtitan_data/images/0922_gpipe_fullrand6_runpod/freeze_ratio_history/rank6/250923_1547_stage3_step520.svg
[rank7]:[titan] 2025-09-23 15:47:51,402 - root - INFO - Frozen Ratio History of Rank 7 (Stage 3)  is saved as: /workspace/torchtitan_data/images/0922_gpipe_fullrand6_runpod/freeze_ratio_history/rank7/250923_1547_stage3_step520.svg
[rank0]:[titan] 2025-09-23 15:52:08,022 - root - INFO - [GC] Peforming periodical GC collection 0.50 seconds
[rank2]:[titan] 2025-09-23 15:53:45,293 - root - INFO - [31m step: 560 [32m loss: -8.0000 [38;2;180;60;0m grad_norm:  0.0988 [38;2;54;234;195m memory: 38.74GiB(48.88%) [34m tps: 1,850 [36m tflops: 86.30 [35m mfu: 27.66%[39m
[rank4]:[titan] 2025-09-23 15:53:45,291 - root - INFO - [31m step: 560 [32m loss: -8.0000 [38;2;180;60;0m grad_norm:  0.0988 [38;2;54;234;195m memory: 34.68GiB(43.76%) [34m tps: 1,850 [36m tflops: 86.30 [35m mfu: 27.66%[39m
[rank1]:[titan] 2025-09-23 15:53:45,297 - root - INFO - [31m step: 560 [32m loss: -8.0000 [38;2;180;60;0m grad_norm:  0.0988 [38;2;54;234;195m memory: 43.86GiB(55.34%) [34m tps: 1,850 [36m tflops: 86.30 [35m mfu: 27.66%[39m
[rank6]:[titan] 2025-09-23 15:53:45,296 - root - INFO - [31m step: 560 [32m loss:  4.2313 [38;2;180;60;0m grad_norm:  0.0988 [38;2;54;234;195m memory: 45.85GiB(57.85%) [34m tps: 1,850 [36m tflops: 86.30 [35m mfu: 27.66%[39m
[rank3]:[titan] 2025-09-23 15:53:45,293 - root - INFO - [31m step: 560 [32m loss: -8.0000 [38;2;180;60;0m grad_norm:  0.0988 [38;2;54;234;195m memory: 38.74GiB(48.88%) [34m tps: 1,850 [36m tflops: 86.30 [35m mfu: 27.66%[39m
[rank0]:[titan] 2025-09-23 15:53:45,297 - root - INFO - [31m step: 560 [32m loss: -8.0000 [38;2;180;60;0m grad_norm:  0.0988 [38;2;54;234;195m memory: 43.86GiB(55.34%) [34m tps: 1,850 [36m tflops: 86.30 [35m mfu: 27.66%[39m
[rank7]:[titan] 2025-09-23 15:53:45,295 - root - INFO - [31m step: 560 [32m loss:  4.2313 [38;2;180;60;0m grad_norm:  0.0988 [38;2;54;234;195m memory: 45.85GiB(57.85%) [34m tps: 1,850 [36m tflops: 86.30 [35m mfu: 27.66%[39m
[rank5]:[titan] 2025-09-23 15:53:45,291 - root - INFO - [31m step: 560 [32m loss: -8.0000 [38;2;180;60;0m grad_norm:  0.0988 [38;2;54;234;195m memory: 34.68GiB(43.76%) [34m tps: 1,850 [36m tflops: 86.30 [35m mfu: 27.66%[39m
[rank6]:[titan] 2025-09-23 15:53:45,502 - root - INFO - Pipeline schedule is saved as: /workspace/torchtitan_data/images/0922_gpipe_fullrand6_runpod/pipeline_schedule/250923_1553_real_step560_rank6.svg
[rank6]:> Batch Time: 1060.53 ms, GPU Bubble Ratio: 40.67%, 38.54%, 44.99%, 35.71%
[rank7]:[titan] 2025-09-23 15:53:45,502 - root - INFO - Pipeline schedule is saved as: /workspace/torchtitan_data/images/0922_gpipe_fullrand6_runpod/pipeline_schedule/250923_1553_real_step560_rank7.svg
[rank7]:> Batch Time: 1060.83 ms, GPU Bubble Ratio: 40.80%, 38.19%, 45.13%, 35.69%
[rank6]:[titan] 2025-09-23 15:53:45,572 - root - INFO - Frozen Ratio History of Rank 6 (Stage 3)  is saved as: /workspace/torchtitan_data/images/0922_gpipe_fullrand6_runpod/freeze_ratio_history/rank6/250923_1553_stage3_step560.svg
[rank7]:[titan] 2025-09-23 15:53:45,572 - root - INFO - Frozen Ratio History of Rank 7 (Stage 3)  is saved as: /workspace/torchtitan_data/images/0922_gpipe_fullrand6_runpod/freeze_ratio_history/rank7/250923_1553_stage3_step560.svg
[rank0]:[titan] 2025-09-23 15:59:30,349 - root - INFO - [GC] Peforming periodical GC collection 0.50 seconds
[rank4]:[titan] 2025-09-23 15:59:39,224 - root - INFO - [31m step: 600 [32m loss: -8.0000 [38;2;180;60;0m grad_norm:  0.0975 [38;2;54;234;195m memory: 34.68GiB(43.76%) [34m tps: 1,852 [36m tflops: 86.36 [35m mfu: 27.68%[39m
[rank6]:[titan] 2025-09-23 15:59:39,229 - root - INFO - [31m step: 600 [32m loss:  4.0431 [38;2;180;60;0m grad_norm:  0.0975 [38;2;54;234;195m memory: 45.85GiB(57.85%) [34m tps: 1,852 [36m tflops: 86.36 [35m mfu: 27.68%[39m
[rank2]:[titan] 2025-09-23 15:59:39,227 - root - INFO - [31m step: 600 [32m loss: -8.0000 [38;2;180;60;0m grad_norm:  0.0975 [38;2;54;234;195m memory: 38.74GiB(48.88%) [34m tps: 1,852 [36m tflops: 86.36 [35m mfu: 27.68%[39m
[rank1]:[titan] 2025-09-23 15:59:39,231 - root - INFO - [31m step: 600 [32m loss: -8.0000 [38;2;180;60;0m grad_norm:  0.0975 [38;2;54;234;195m memory: 43.86GiB(55.34%) [34m tps: 1,852 [36m tflops: 86.36 [35m mfu: 27.68%[39m
[rank7]:[titan] 2025-09-23 15:59:39,229 - root - INFO - [31m step: 600 [32m loss:  4.0431 [38;2;180;60;0m grad_norm:  0.0975 [38;2;54;234;195m memory: 45.85GiB(57.85%) [34m tps: 1,852 [36m tflops: 86.36 [35m mfu: 27.68%[39m
[rank0]:[titan] 2025-09-23 15:59:39,231 - root - INFO - [31m step: 600 [32m loss: -8.0000 [38;2;180;60;0m grad_norm:  0.0975 [38;2;54;234;195m memory: 43.86GiB(55.34%) [34m tps: 1,852 [36m tflops: 86.36 [35m mfu: 27.68%[39m
[rank3]:[titan] 2025-09-23 15:59:39,227 - root - INFO - [31m step: 600 [32m loss: -8.0000 [38;2;180;60;0m grad_norm:  0.0975 [38;2;54;234;195m memory: 38.74GiB(48.88%) [34m tps: 1,852 [36m tflops: 86.36 [35m mfu: 27.68%[39m
[rank5]:[titan] 2025-09-23 15:59:39,224 - root - INFO - [31m step: 600 [32m loss: -8.0000 [38;2;180;60;0m grad_norm:  0.0975 [38;2;54;234;195m memory: 34.68GiB(43.76%) [34m tps: 1,852 [36m tflops: 86.36 [35m mfu: 27.68%[39m
[rank6]:[titan] 2025-09-23 15:59:39,431 - root - INFO - Pipeline schedule is saved as: /workspace/torchtitan_data/images/0922_gpipe_fullrand6_runpod/pipeline_schedule/250923_1559_real_step600_rank6.svg
[rank6]:> Batch Time: 1060.59 ms, GPU Bubble Ratio: 40.67%, 38.54%, 44.99%, 35.70%
[rank7]:[titan] 2025-09-23 15:59:39,433 - root - INFO - Pipeline schedule is saved as: /workspace/torchtitan_data/images/0922_gpipe_fullrand6_runpod/pipeline_schedule/250923_1559_real_step600_rank7.svg
[rank7]:> Batch Time: 1060.89 ms, GPU Bubble Ratio: 40.80%, 38.20%, 45.14%, 35.69%
[rank6]:[titan] 2025-09-23 15:59:39,501 - root - INFO - Frozen Ratio History of Rank 6 (Stage 3)  is saved as: /workspace/torchtitan_data/images/0922_gpipe_fullrand6_runpod/freeze_ratio_history/rank6/250923_1559_stage3_step600.svg
[rank7]:[titan] 2025-09-23 15:59:39,503 - root - INFO - Frozen Ratio History of Rank 7 (Stage 3)  is saved as: /workspace/torchtitan_data/images/0922_gpipe_fullrand6_runpod/freeze_ratio_history/rank7/250923_1559_stage3_step600.svg
[rank2]:[titan] 2025-09-23 16:05:32,789 - root - INFO - [31m step: 640 [32m loss: -8.0000 [38;2;180;60;0m grad_norm:  0.0916 [38;2;54;234;195m memory: 38.74GiB(48.88%) [34m tps: 1,854 [36m tflops: 86.45 [35m mfu: 27.71%[39m
[rank6]:[titan] 2025-09-23 16:05:32,791 - root - INFO - [31m step: 640 [32m loss:  4.0198 [38;2;180;60;0m grad_norm:  0.0916 [38;2;54;234;195m memory: 45.85GiB(57.85%) [34m tps: 1,854 [36m tflops: 86.45 [35m mfu: 27.71%[39m
[rank4]:[titan] 2025-09-23 16:05:32,786 - root - INFO - [31m step: 640 [32m loss: -8.0000 [38;2;180;60;0m grad_norm:  0.0916 [38;2;54;234;195m memory: 34.68GiB(43.76%) [34m tps: 1,854 [36m tflops: 86.45 [35m mfu: 27.71%[39m
[rank1]:[titan] 2025-09-23 16:05:32,792 - root - INFO - [31m step: 640 [32m loss: -8.0000 [38;2;180;60;0m grad_norm:  0.0916 [38;2;54;234;195m memory: 43.86GiB(55.34%) [34m tps: 1,854 [36m tflops: 86.45 [35m mfu: 27.71%[39m
[rank0]:[titan] 2025-09-23 16:05:32,792 - root - INFO - [31m step: 640 [32m loss: -8.0000 [38;2;180;60;0m grad_norm:  0.0916 [38;2;54;234;195m memory: 43.86GiB(55.34%) [34m tps: 1,854 [36m tflops: 86.45 [35m mfu: 27.71%[39m
[rank7]:[titan] 2025-09-23 16:05:32,790 - root - INFO - [31m step: 640 [32m loss:  4.0198 [38;2;180;60;0m grad_norm:  0.0916 [38;2;54;234;195m memory: 45.85GiB(57.85%) [34m tps: 1,854 [36m tflops: 86.45 [35m mfu: 27.71%[39m
[rank5]:[titan] 2025-09-23 16:05:32,786 - root - INFO - [31m step: 640 [32m loss: -8.0000 [38;2;180;60;0m grad_norm:  0.0916 [38;2;54;234;195m memory: 34.68GiB(43.76%) [34m tps: 1,854 [36m tflops: 86.45 [35m mfu: 27.71%[39m
[rank3]:[titan] 2025-09-23 16:05:32,789 - root - INFO - [31m step: 640 [32m loss: -8.0000 [38;2;180;60;0m grad_norm:  0.0916 [38;2;54;234;195m memory: 38.74GiB(48.88%) [34m tps: 1,854 [36m tflops: 86.45 [35m mfu: 27.71%[39m
[rank6]:[titan] 2025-09-23 16:05:32,995 - root - INFO - Pipeline schedule is saved as: /workspace/torchtitan_data/images/0922_gpipe_fullrand6_runpod/pipeline_schedule/250923_1605_real_step640_rank6.svg
[rank6]:> Batch Time: 1060.69 ms, GPU Bubble Ratio: 40.67%, 38.54%, 44.99%, 35.70%
[rank6]:[titan] 2025-09-23 16:05:33,067 - root - INFO - Frozen Ratio History of Rank 6 (Stage 3)  is saved as: /workspace/torchtitan_data/images/0922_gpipe_fullrand6_runpod/freeze_ratio_history/rank6/250923_1605_stage3_step640.svg
[rank7]:[titan] 2025-09-23 16:05:32,996 - root - INFO - Pipeline schedule is saved as: /workspace/torchtitan_data/images/0922_gpipe_fullrand6_runpod/pipeline_schedule/250923_1605_real_step640_rank7.svg
[rank7]:> Batch Time: 1060.86 ms, GPU Bubble Ratio: 40.80%, 38.19%, 45.13%, 35.69%
[rank7]:[titan] 2025-09-23 16:05:33,068 - root - INFO - Frozen Ratio History of Rank 7 (Stage 3)  is saved as: /workspace/torchtitan_data/images/0922_gpipe_fullrand6_runpod/freeze_ratio_history/rank7/250923_1605_stage3_step640.svg
[rank0]:[titan] 2025-09-23 16:06:52,920 - root - INFO - [GC] Peforming periodical GC collection 0.51 seconds
[rank2]:[titan] 2025-09-23 16:11:26,972 - root - INFO - [31m step: 680 [32m loss: -8.0000 [38;2;180;60;0m grad_norm:  0.1339 [38;2;54;234;195m memory: 38.74GiB(48.88%) [34m tps: 1,850 [36m tflops: 86.30 [35m mfu: 27.66%[39m
[rank6]:[titan] 2025-09-23 16:11:26,974 - root - INFO - [31m step: 680 [32m loss:  4.0706 [38;2;180;60;0m grad_norm:  0.1339 [38;2;54;234;195m memory: 45.85GiB(57.85%) [34m tps: 1,850 [36m tflops: 86.30 [35m mfu: 27.66%[39m
[rank0]:[titan] 2025-09-23 16:11:26,975 - root - INFO - [31m step: 680 [32m loss: -8.0000 [38;2;180;60;0m grad_norm:  0.1339 [38;2;54;234;195m memory: 43.86GiB(55.34%) [34m tps: 1,850 [36m tflops: 86.30 [35m mfu: 27.66%[39m
[rank4]:[titan] 2025-09-23 16:11:26,969 - root - INFO - [31m step: 680 [32m loss: -8.0000 [38;2;180;60;0m grad_norm:  0.1339 [38;2;54;234;195m memory: 34.68GiB(43.76%) [34m tps: 1,850 [36m tflops: 86.30 [35m mfu: 27.66%[39m
[rank7]:[titan] 2025-09-23 16:11:26,973 - root - INFO - [31m step: 680 [32m loss:  4.0706 [38;2;180;60;0m grad_norm:  0.1339 [38;2;54;234;195m memory: 45.85GiB(57.85%) [34m tps: 1,850 [36m tflops: 86.30 [35m mfu: 27.66%[39m
[rank1]:[titan] 2025-09-23 16:11:26,975 - root - INFO - [31m step: 680 [32m loss: -8.0000 [38;2;180;60;0m grad_norm:  0.1339 [38;2;54;234;195m memory: 43.86GiB(55.34%) [34m tps: 1,850 [36m tflops: 86.30 [35m mfu: 27.66%[39m
[rank5]:[titan] 2025-09-23 16:11:26,969 - root - INFO - [31m step: 680 [32m loss: -8.0000 [38;2;180;60;0m grad_norm:  0.1339 [38;2;54;234;195m memory: 34.68GiB(43.76%) [34m tps: 1,850 [36m tflops: 86.30 [35m mfu: 27.66%[39m
[rank3]:[titan] 2025-09-23 16:11:26,972 - root - INFO - [31m step: 680 [32m loss: -8.0000 [38;2;180;60;0m grad_norm:  0.1339 [38;2;54;234;195m memory: 38.74GiB(48.88%) [34m tps: 1,850 [36m tflops: 86.30 [35m mfu: 27.66%[39m
[rank6]:[titan] 2025-09-23 16:11:27,179 - root - INFO - Pipeline schedule is saved as: /workspace/torchtitan_data/images/0922_gpipe_fullrand6_runpod/pipeline_schedule/250923_1611_real_step680_rank6.svg
[rank6]:> Batch Time: 1060.77 ms, GPU Bubble Ratio: 40.68%, 38.55%, 44.99%, 35.70%
[rank7]:[titan] 2025-09-23 16:11:27,184 - root - INFO - Pipeline schedule is saved as: /workspace/torchtitan_data/images/0922_gpipe_fullrand6_runpod/pipeline_schedule/250923_1611_real_step680_rank7.svg
[rank7]:> Batch Time: 1060.89 ms, GPU Bubble Ratio: 40.81%, 38.20%, 45.13%, 35.69%
[rank6]:[titan] 2025-09-23 16:11:27,251 - root - INFO - Frozen Ratio History of Rank 6 (Stage 3)  is saved as: /workspace/torchtitan_data/images/0922_gpipe_fullrand6_runpod/freeze_ratio_history/rank6/250923_1611_stage3_step680.svg
[rank7]:[titan] 2025-09-23 16:11:27,257 - root - INFO - Frozen Ratio History of Rank 7 (Stage 3)  is saved as: /workspace/torchtitan_data/images/0922_gpipe_fullrand6_runpod/freeze_ratio_history/rank7/250923_1611_stage3_step680.svg
[rank0]:[titan] 2025-09-23 16:14:15,425 - root - INFO - [GC] Peforming periodical GC collection 0.52 seconds
[rank2]:[titan] 2025-09-23 16:17:20,852 - root - INFO - [31m step: 720 [32m loss: -8.0000 [38;2;180;60;0m grad_norm:  0.0918 [38;2;54;234;195m memory: 38.74GiB(48.88%) [34m tps: 1,852 [36m tflops: 86.37 [35m mfu: 27.68%[39m
[rank6]:[titan] 2025-09-23 16:17:20,855 - root - INFO - [31m step: 720 [32m loss:  3.9597 [38;2;180;60;0m grad_norm:  0.0918 [38;2;54;234;195m memory: 45.85GiB(57.85%) [34m tps: 1,852 [36m tflops: 86.37 [35m mfu: 27.68%[39m
[rank4]:[titan] 2025-09-23 16:17:20,850 - root - INFO - [31m step: 720 [32m loss: -8.0000 [38;2;180;60;0m grad_norm:  0.0918 [38;2;54;234;195m memory: 34.68GiB(43.76%) [34m tps: 1,852 [36m tflops: 86.37 [35m mfu: 27.68%[39m
[rank1]:[titan] 2025-09-23 16:17:20,856 - root - INFO - [31m step: 720 [32m loss: -8.0000 [38;2;180;60;0m grad_norm:  0.0918 [38;2;54;234;195m memory: 43.86GiB(55.34%) [34m tps: 1,852 [36m tflops: 86.37 [35m mfu: 27.68%[39m
[rank0]:[titan] 2025-09-23 16:17:20,856 - root - INFO - [31m step: 720 [32m loss: -8.0000 [38;2;180;60;0m grad_norm:  0.0918 [38;2;54;234;195m memory: 43.86GiB(55.34%) [34m tps: 1,852 [36m tflops: 86.37 [35m mfu: 27.68%[39m
[rank7]:[titan] 2025-09-23 16:17:20,854 - root - INFO - [31m step: 720 [32m loss:  3.9597 [38;2;180;60;0m grad_norm:  0.0918 [38;2;54;234;195m memory: 45.85GiB(57.85%) [34m tps: 1,852 [36m tflops: 86.37 [35m mfu: 27.68%[39m
[rank5]:[titan] 2025-09-23 16:17:20,850 - root - INFO - [31m step: 720 [32m loss: -8.0000 [38;2;180;60;0m grad_norm:  0.0918 [38;2;54;234;195m memory: 34.68GiB(43.76%) [34m tps: 1,852 [36m tflops: 86.37 [35m mfu: 27.68%[39m
[rank3]:[titan] 2025-09-23 16:17:20,852 - root - INFO - [31m step: 720 [32m loss: -8.0000 [38;2;180;60;0m grad_norm:  0.0918 [38;2;54;234;195m memory: 38.74GiB(48.88%) [34m tps: 1,852 [36m tflops: 86.37 [35m mfu: 27.68%[39m
[rank6]:[titan] 2025-09-23 16:17:21,062 - root - INFO - Pipeline schedule is saved as: /workspace/torchtitan_data/images/0922_gpipe_fullrand6_runpod/pipeline_schedule/250923_1617_real_step720_rank6.svg
[rank6]:> Batch Time: 1060.83 ms, GPU Bubble Ratio: 40.68%, 38.55%, 44.99%, 35.69%
[rank7]:[titan] 2025-09-23 16:17:21,063 - root - INFO - Pipeline schedule is saved as: /workspace/torchtitan_data/images/0922_gpipe_fullrand6_runpod/pipeline_schedule/250923_1617_real_step720_rank7.svg
[rank7]:> Batch Time: 1060.94 ms, GPU Bubble Ratio: 40.81%, 38.20%, 45.13%, 35.69%
[rank6]:[titan] 2025-09-23 16:17:21,135 - root - INFO - Frozen Ratio History of Rank 6 (Stage 3)  is saved as: /workspace/torchtitan_data/images/0922_gpipe_fullrand6_runpod/freeze_ratio_history/rank6/250923_1617_stage3_step720.svg
[rank7]:[titan] 2025-09-23 16:17:21,136 - root - INFO - Frozen Ratio History of Rank 7 (Stage 3)  is saved as: /workspace/torchtitan_data/images/0922_gpipe_fullrand6_runpod/freeze_ratio_history/rank7/250923_1617_stage3_step720.svg
[rank0]:[titan] 2025-09-23 16:21:37,622 - root - INFO - [GC] Peforming periodical GC collection 0.53 seconds
[rank3]:[titan] 2025-09-23 16:23:14,792 - root - INFO - [31m step: 760 [32m loss: -8.0000 [38;2;180;60;0m grad_norm:  0.0823 [38;2;54;234;195m memory: 38.74GiB(48.88%) [34m tps: 1,852 [36m tflops: 86.36 [35m mfu: 27.68%[39m
[rank5]:[titan] 2025-09-23 16:23:14,790 - root - INFO - [31m step: 760 [32m loss: -8.0000 [38;2;180;60;0m grad_norm:  0.0823 [38;2;54;234;195m memory: 34.68GiB(43.76%) [34m tps: 1,852 [36m tflops: 86.36 [35m mfu: 27.68%[39m
[rank6]:[titan] 2025-09-23 16:23:14,795 - root - INFO - [31m step: 760 [32m loss:  3.9059 [38;2;180;60;0m grad_norm:  0.0823 [38;2;54;234;195m memory: 45.85GiB(57.85%) [34m tps: 1,852 [36m tflops: 86.36 [35m mfu: 27.68%[39m
[rank4]:[titan] 2025-09-23 16:23:14,790 - root - INFO - [31m step: 760 [32m loss: -8.0000 [38;2;180;60;0m grad_norm:  0.0823 [38;2;54;234;195m memory: 34.68GiB(43.76%) [34m tps: 1,852 [36m tflops: 86.36 [35m mfu: 27.68%[39m
[rank2]:[titan] 2025-09-23 16:23:14,792 - root - INFO - [31m step: 760 [32m loss: -8.0000 [38;2;180;60;0m grad_norm:  0.0823 [38;2;54;234;195m memory: 38.74GiB(48.88%) [34m tps: 1,852 [36m tflops: 86.36 [35m mfu: 27.68%[39m
[rank1]:[titan] 2025-09-23 16:23:14,796 - root - INFO - [31m step: 760 [32m loss: -8.0000 [38;2;180;60;0m grad_norm:  0.0823 [38;2;54;234;195m memory: 43.86GiB(55.34%) [34m tps: 1,852 [36m tflops: 86.36 [35m mfu: 27.68%[39m
[rank0]:[titan] 2025-09-23 16:23:14,796 - root - INFO - [31m step: 760 [32m loss: -8.0000 [38;2;180;60;0m grad_norm:  0.0823 [38;2;54;234;195m memory: 43.86GiB(55.34%) [34m tps: 1,852 [36m tflops: 86.36 [35m mfu: 27.68%[39m
[rank7]:[titan] 2025-09-23 16:23:14,794 - root - INFO - [31m step: 760 [32m loss:  3.9059 [38;2;180;60;0m grad_norm:  0.0823 [38;2;54;234;195m memory: 45.85GiB(57.85%) [34m tps: 1,852 [36m tflops: 86.36 [35m mfu: 27.68%[39m
[rank6]:[titan] 2025-09-23 16:23:15,001 - root - INFO - Pipeline schedule is saved as: /workspace/torchtitan_data/images/0922_gpipe_fullrand6_runpod/pipeline_schedule/250923_1623_real_step760_rank6.svg
[rank6]:> Batch Time: 1060.84 ms, GPU Bubble Ratio: 40.68%, 38.55%, 44.99%, 35.69%
[rank7]:[titan] 2025-09-23 16:23:15,010 - root - INFO - Pipeline schedule is saved as: /workspace/torchtitan_data/images/0922_gpipe_fullrand6_runpod/pipeline_schedule/250923_1623_real_step760_rank7.svg
[rank7]:> Batch Time: 1060.94 ms, GPU Bubble Ratio: 40.81%, 38.20%, 45.13%, 35.69%
[rank6]:[titan] 2025-09-23 16:23:15,077 - root - INFO - Frozen Ratio History of Rank 6 (Stage 3)  is saved as: /workspace/torchtitan_data/images/0922_gpipe_fullrand6_runpod/freeze_ratio_history/rank6/250923_1623_stage3_step760.svg
[rank7]:[titan] 2025-09-23 16:23:15,085 - root - INFO - Frozen Ratio History of Rank 7 (Stage 3)  is saved as: /workspace/torchtitan_data/images/0922_gpipe_fullrand6_runpod/freeze_ratio_history/rank7/250923_1623_stage3_step760.svg
[rank0]:[titan] 2025-09-23 16:29:00,056 - root - INFO - [GC] Peforming periodical GC collection 0.54 seconds
[rank4]:[titan] 2025-09-23 16:29:08,914 - root - INFO - [31m step: 800 [32m loss: -8.0000 [38;2;180;60;0m grad_norm:  0.0813 [38;2;54;234;195m memory: 34.68GiB(43.76%) [34m tps: 1,851 [36m tflops: 86.31 [35m mfu: 27.66%[39m
[rank2]:[titan] 2025-09-23 16:29:08,917 - root - INFO - [31m step: 800 [32m loss: -8.0000 [38;2;180;60;0m grad_norm:  0.0813 [38;2;54;234;195m memory: 38.74GiB(48.88%) [34m tps: 1,851 [36m tflops: 86.31 [35m mfu: 27.66%[39m
[rank0]:[titan] 2025-09-23 16:29:08,920 - root - INFO - [31m step: 800 [32m loss: -8.0000 [38;2;180;60;0m grad_norm:  0.0813 [38;2;54;234;195m memory: 43.86GiB(55.34%) [34m tps: 1,851 [36m tflops: 86.31 [35m mfu: 27.66%[39m
[rank1]:[titan] 2025-09-23 16:29:08,921 - root - INFO - [31m step: 800 [32m loss: -8.0000 [38;2;180;60;0m grad_norm:  0.0813 [38;2;54;234;195m memory: 43.86GiB(55.34%) [34m tps: 1,851 [36m tflops: 86.31 [35m mfu: 27.66%[39m
[rank7]:[titan] 2025-09-23 16:29:08,919 - root - INFO - [31m step: 800 [32m loss:  3.8600 [38;2;180;60;0m grad_norm:  0.0813 [38;2;54;234;195m memory: 45.85GiB(57.85%) [34m tps: 1,851 [36m tflops: 86.31 [35m mfu: 27.67%[39m
[rank5]:[titan] 2025-09-23 16:29:08,914 - root - INFO - [31m step: 800 [32m loss: -8.0000 [38;2;180;60;0m grad_norm:  0.0813 [38;2;54;234;195m memory: 34.68GiB(43.76%) [34m tps: 1,851 [36m tflops: 86.31 [35m mfu: 27.66%[39m
[rank3]:[titan] 2025-09-23 16:29:08,917 - root - INFO - [31m step: 800 [32m loss: -8.0000 [38;2;180;60;0m grad_norm:  0.0813 [38;2;54;234;195m memory: 38.74GiB(48.88%) [34m tps: 1,851 [36m tflops: 86.31 [35m mfu: 27.66%[39m
[rank6]:[titan] 2025-09-23 16:29:08,919 - root - INFO - [31m step: 800 [32m loss:  3.8600 [38;2;180;60;0m grad_norm:  0.0813 [38;2;54;234;195m memory: 45.85GiB(57.85%) [34m tps: 1,851 [36m tflops: 86.32 [35m mfu: 27.67%[39m
[rank7]:[titan] 2025-09-23 16:29:09,126 - root - INFO - Pipeline schedule is saved as: /workspace/torchtitan_data/images/0922_gpipe_fullrand6_runpod/pipeline_schedule/250923_1629_real_step800_rank7.svg
[rank7]:> Batch Time: 1060.97 ms, GPU Bubble Ratio: 40.80%, 38.20%, 45.13%, 35.69%
[rank6]:[titan] 2025-09-23 16:29:09,126 - root - INFO - Pipeline schedule is saved as: /workspace/torchtitan_data/images/0922_gpipe_fullrand6_runpod/pipeline_schedule/250923_1629_real_step800_rank6.svg
[rank6]:> Batch Time: 1060.88 ms, GPU Bubble Ratio: 40.68%, 38.55%, 44.99%, 35.69%
[rank6]:[titan] 2025-09-23 16:29:09,199 - root - INFO - Frozen Ratio History of Rank 6 (Stage 3)  is saved as: /workspace/torchtitan_data/images/0922_gpipe_fullrand6_runpod/freeze_ratio_history/rank6/250923_1629_stage3_step800.svg
[rank7]:[titan] 2025-09-23 16:29:09,198 - root - INFO - Frozen Ratio History of Rank 7 (Stage 3)  is saved as: /workspace/torchtitan_data/images/0922_gpipe_fullrand6_runpod/freeze_ratio_history/rank7/250923_1629_stage3_step800.svg
[rank4]:[titan] 2025-09-23 16:35:02,482 - root - INFO - [31m step: 840 [32m loss: -8.0000 [38;2;180;60;0m grad_norm:  0.0867 [38;2;54;234;195m memory: 34.68GiB(43.76%) [34m tps: 1,854 [36m tflops: 86.45 [35m mfu: 27.71%[39m
[rank1]:[titan] 2025-09-23 16:35:02,489 - root - INFO - [31m step: 840 [32m loss: -8.0000 [38;2;180;60;0m grad_norm:  0.0867 [38;2;54;234;195m memory: 43.86GiB(55.34%) [34m tps: 1,854 [36m tflops: 86.45 [35m mfu: 27.71%[39m
[rank0]:[titan] 2025-09-23 16:35:02,489 - root - INFO - [31m step: 840 [32m loss: -8.0000 [38;2;180;60;0m grad_norm:  0.0867 [38;2;54;234;195m memory: 43.86GiB(55.34%) [34m tps: 1,854 [36m tflops: 86.45 [35m mfu: 27.71%[39m
[rank7]:[titan] 2025-09-23 16:35:02,487 - root - INFO - [31m step: 840 [32m loss:  3.7279 [38;2;180;60;0m grad_norm:  0.0867 [38;2;54;234;195m memory: 45.85GiB(57.85%) [34m tps: 1,854 [36m tflops: 86.45 [35m mfu: 27.71%[39m
[rank5]:[titan] 2025-09-23 16:35:02,482 - root - INFO - [31m step: 840 [32m loss: -8.0000 [38;2;180;60;0m grad_norm:  0.0867 [38;2;54;234;195m memory: 34.68GiB(43.76%) [34m tps: 1,854 [36m tflops: 86.45 [35m mfu: 27.71%[39m
[rank3]:[titan] 2025-09-23 16:35:02,485 - root - INFO - [31m step: 840 [32m loss: -8.0000 [38;2;180;60;0m grad_norm:  0.0867 [38;2;54;234;195m memory: 38.74GiB(48.88%) [34m tps: 1,854 [36m tflops: 86.45 [35m mfu: 27.71%[39m
[rank2]:[titan] 2025-09-23 16:35:02,485 - root - INFO - [31m step: 840 [32m loss: -8.0000 [38;2;180;60;0m grad_norm:  0.0867 [38;2;54;234;195m memory: 38.74GiB(48.88%) [34m tps: 1,854 [36m tflops: 86.45 [35m mfu: 27.71%[39m
[rank6]:[titan] 2025-09-23 16:35:02,487 - root - INFO - [31m step: 840 [32m loss:  3.7279 [38;2;180;60;0m grad_norm:  0.0867 [38;2;54;234;195m memory: 45.85GiB(57.85%) [34m tps: 1,854 [36m tflops: 86.45 [35m mfu: 27.71%[39m
[rank6]:[titan] 2025-09-23 16:35:02,698 - root - INFO - Pipeline schedule is saved as: /workspace/torchtitan_data/images/0922_gpipe_fullrand6_runpod/pipeline_schedule/250923_1635_real_step840_rank6.svg
[rank6]:> Batch Time: 1060.95 ms, GPU Bubble Ratio: 40.69%, 38.56%, 44.99%, 35.69%
[rank6]:[titan] 2025-09-23 16:35:02,772 - root - INFO - Frozen Ratio History of Rank 6 (Stage 3)  is saved as: /workspace/torchtitan_data/images/0922_gpipe_fullrand6_runpod/freeze_ratio_history/rank6/250923_1635_stage3_step840.svg
[rank7]:[titan] 2025-09-23 16:35:02,699 - root - INFO - Pipeline schedule is saved as: /workspace/torchtitan_data/images/0922_gpipe_fullrand6_runpod/pipeline_schedule/250923_1635_real_step840_rank7.svg
[rank7]:> Batch Time: 1061.08 ms, GPU Bubble Ratio: 40.81%, 38.21%, 45.13%, 35.68%
[rank7]:[titan] 2025-09-23 16:35:02,773 - root - INFO - Frozen Ratio History of Rank 7 (Stage 3)  is saved as: /workspace/torchtitan_data/images/0922_gpipe_fullrand6_runpod/freeze_ratio_history/rank7/250923_1635_stage3_step840.svg
[rank0]:[titan] 2025-09-23 16:36:22,720 - root - INFO - [GC] Peforming periodical GC collection 0.54 seconds
[rank2]:[titan] 2025-09-23 16:40:56,620 - root - INFO - [31m step: 880 [32m loss: -8.0000 [38;2;180;60;0m grad_norm:  0.0791 [38;2;54;234;195m memory: 38.74GiB(48.88%) [34m tps: 1,851 [36m tflops: 86.31 [35m mfu: 27.66%[39m
[rank6]:[titan] 2025-09-23 16:40:56,622 - root - INFO - [31m step: 880 [32m loss:  3.3895 [38;2;180;60;0m grad_norm:  0.0791 [38;2;54;234;195m memory: 45.85GiB(57.85%) [34m tps: 1,851 [36m tflops: 86.31 [35m mfu: 27.66%[39m
[rank7]:[titan] 2025-09-23 16:40:56,621 - root - INFO - [31m step: 880 [32m loss:  3.3895 [38;2;180;60;0m grad_norm:  0.0791 [38;2;54;234;195m memory: 45.85GiB(57.85%) [34m tps: 1,851 [36m tflops: 86.31 [35m mfu: 27.66%[39m
[rank4]:[titan] 2025-09-23 16:40:56,617 - root - INFO - [31m step: 880 [32m loss: -8.0000 [38;2;180;60;0m grad_norm:  0.0791 [38;2;54;234;195m memory: 34.68GiB(43.76%) [34m tps: 1,851 [36m tflops: 86.31 [35m mfu: 27.66%[39m
[rank0]:[titan] 2025-09-23 16:40:56,623 - root - INFO - [31m step: 880 [32m loss: -8.0000 [38;2;180;60;0m grad_norm:  0.0791 [38;2;54;234;195m memory: 43.86GiB(55.34%) [34m tps: 1,851 [36m tflops: 86.31 [35m mfu: 27.66%[39m
[rank1]:[titan] 2025-09-23 16:40:56,623 - root - INFO - [31m step: 880 [32m loss: -8.0000 [38;2;180;60;0m grad_norm:  0.0791 [38;2;54;234;195m memory: 43.86GiB(55.34%) [34m tps: 1,851 [36m tflops: 86.31 [35m mfu: 27.66%[39m
[rank5]:[titan] 2025-09-23 16:40:56,617 - root - INFO - [31m step: 880 [32m loss: -8.0000 [38;2;180;60;0m grad_norm:  0.0791 [38;2;54;234;195m memory: 34.68GiB(43.76%) [34m tps: 1,851 [36m tflops: 86.31 [35m mfu: 27.66%[39m
[rank3]:[titan] 2025-09-23 16:40:56,620 - root - INFO - [31m step: 880 [32m loss: -8.0000 [38;2;180;60;0m grad_norm:  0.0791 [38;2;54;234;195m memory: 38.74GiB(48.88%) [34m tps: 1,851 [36m tflops: 86.31 [35m mfu: 27.66%[39m
[rank6]:[titan] 2025-09-23 16:40:56,829 - root - INFO - Pipeline schedule is saved as: /workspace/torchtitan_data/images/0922_gpipe_fullrand6_runpod/pipeline_schedule/250923_1640_real_step880_rank6.svg
[rank6]:> Batch Time: 1061.05 ms, GPU Bubble Ratio: 40.69%, 38.56%, 44.99%, 35.69%
[rank7]:[titan] 2025-09-23 16:40:56,829 - root - INFO - Pipeline schedule is saved as: /workspace/torchtitan_data/images/0922_gpipe_fullrand6_runpod/pipeline_schedule/250923_1640_real_step880_rank7.svg
[rank7]:> Batch Time: 1061.09 ms, GPU Bubble Ratio: 40.81%, 38.21%, 45.13%, 35.68%
[rank6]:[titan] 2025-09-23 16:40:56,901 - root - INFO - Frozen Ratio History of Rank 6 (Stage 3)  is saved as: /workspace/torchtitan_data/images/0922_gpipe_fullrand6_runpod/freeze_ratio_history/rank6/250923_1640_stage3_step880.svg
[rank7]:[titan] 2025-09-23 16:40:56,902 - root - INFO - Frozen Ratio History of Rank 7 (Stage 3)  is saved as: /workspace/torchtitan_data/images/0922_gpipe_fullrand6_runpod/freeze_ratio_history/rank7/250923_1640_stage3_step880.svg
[rank0]:[titan] 2025-09-23 16:43:45,156 - root - INFO - [GC] Peforming periodical GC collection 0.55 seconds
[rank2]:[titan] 2025-09-23 16:46:50,593 - root - INFO - [31m step: 920 [32m loss: -8.0000 [38;2;180;60;0m grad_norm:  0.0789 [38;2;54;234;195m memory: 38.74GiB(48.88%) [34m tps: 1,851 [36m tflops: 86.35 [35m mfu: 27.68%[39m
[rank6]:[titan] 2025-09-23 16:46:50,595 - root - INFO - [31m step: 920 [32m loss:  3.3297 [38;2;180;60;0m grad_norm:  0.0789 [38;2;54;234;195m memory: 45.85GiB(57.85%) [34m tps: 1,851 [36m tflops: 86.35 [35m mfu: 27.68%[39m
[rank7]:[titan] 2025-09-23 16:46:50,594 - root - INFO - [31m step: 920 [32m loss:  3.3297 [38;2;180;60;0m grad_norm:  0.0789 [38;2;54;234;195m memory: 45.85GiB(57.85%) [34m tps: 1,851 [36m tflops: 86.35 [35m mfu: 27.68%[39m
[rank1]:[titan] 2025-09-23 16:46:50,596 - root - INFO - [31m step: 920 [32m loss: -8.0000 [38;2;180;60;0m grad_norm:  0.0789 [38;2;54;234;195m memory: 43.86GiB(55.34%) [34m tps: 1,851 [36m tflops: 86.35 [35m mfu: 27.68%[39m
[rank0]:[titan] 2025-09-23 16:46:50,596 - root - INFO - [31m step: 920 [32m loss: -8.0000 [38;2;180;60;0m grad_norm:  0.0789 [38;2;54;234;195m memory: 43.86GiB(55.34%) [34m tps: 1,851 [36m tflops: 86.35 [35m mfu: 27.68%[39m
[rank4]:[titan] 2025-09-23 16:46:50,590 - root - INFO - [31m step: 920 [32m loss: -8.0000 [38;2;180;60;0m grad_norm:  0.0789 [38;2;54;234;195m memory: 34.68GiB(43.76%) [34m tps: 1,851 [36m tflops: 86.35 [35m mfu: 27.68%[39m
[rank5]:[titan] 2025-09-23 16:46:50,590 - root - INFO - [31m step: 920 [32m loss: -8.0000 [38;2;180;60;0m grad_norm:  0.0789 [38;2;54;234;195m memory: 34.68GiB(43.76%) [34m tps: 1,851 [36m tflops: 86.35 [35m mfu: 27.68%[39m
[rank3]:[titan] 2025-09-23 16:46:50,593 - root - INFO - [31m step: 920 [32m loss: -8.0000 [38;2;180;60;0m grad_norm:  0.0789 [38;2;54;234;195m memory: 38.74GiB(48.88%) [34m tps: 1,851 [36m tflops: 86.35 [35m mfu: 27.68%[39m
[rank6]:[titan] 2025-09-23 16:46:50,830 - root - INFO - Pipeline schedule is saved as: /workspace/torchtitan_data/images/0922_gpipe_fullrand6_runpod/pipeline_schedule/250923_1646_real_step920_rank6.svg
[rank6]:> Batch Time: 1061.11 ms, GPU Bubble Ratio: 40.70%, 38.56%, 44.99%, 35.69%
[rank7]:[titan] 2025-09-23 16:46:50,828 - root - INFO - Pipeline schedule is saved as: /workspace/torchtitan_data/images/0922_gpipe_fullrand6_runpod/pipeline_schedule/250923_1646_real_step920_rank7.svg
[rank7]:> Batch Time: 1061.12 ms, GPU Bubble Ratio: 40.82%, 38.21%, 45.13%, 35.68%
[rank7]:[titan] 2025-09-23 16:46:50,918 - root - INFO - Frozen Ratio History of Rank 7 (Stage 3)  is saved as: /workspace/torchtitan_data/images/0922_gpipe_fullrand6_runpod/freeze_ratio_history/rank7/250923_1646_stage3_step920.svg
[rank6]:[titan] 2025-09-23 16:46:50,929 - root - INFO - Frozen Ratio History of Rank 6 (Stage 3)  is saved as: /workspace/torchtitan_data/images/0922_gpipe_fullrand6_runpod/freeze_ratio_history/rank6/250923_1646_stage3_step920.svg
[rank0]:[titan] 2025-09-23 16:51:07,427 - root - INFO - [GC] Peforming periodical GC collection 0.56 seconds
[rank5]:[titan] 2025-09-23 16:52:44,585 - root - INFO - [31m step: 960 [32m loss: -8.0000 [38;2;180;60;0m grad_norm:  0.0716 [38;2;54;234;195m memory: 34.68GiB(43.76%) [34m tps: 1,851 [36m tflops: 86.35 [35m mfu: 27.68%[39m
[rank3]:[titan] 2025-09-23 16:52:44,588 - root - INFO - [31m step: 960 [32m loss: -8.0000 [38;2;180;60;0m grad_norm:  0.0716 [38;2;54;234;195m memory: 38.74GiB(48.88%) [34m tps: 1,851 [36m tflops: 86.35 [35m mfu: 27.68%[39m
[rank2]:[titan] 2025-09-23 16:52:44,589 - root - INFO - [31m step: 960 [32m loss: -8.0000 [38;2;180;60;0m grad_norm:  0.0716 [38;2;54;234;195m memory: 38.74GiB(48.88%) [34m tps: 1,851 [36m tflops: 86.35 [35m mfu: 27.67%[39m
[rank4]:[titan] 2025-09-23 16:52:44,586 - root - INFO - [31m step: 960 [32m loss: -8.0000 [38;2;180;60;0m grad_norm:  0.0716 [38;2;54;234;195m memory: 34.68GiB(43.76%) [34m tps: 1,851 [36m tflops: 86.35 [35m mfu: 27.68%[39m
[rank1]:[titan] 2025-09-23 16:52:44,592 - root - INFO - [31m step: 960 [32m loss: -8.0000 [38;2;180;60;0m grad_norm:  0.0716 [38;2;54;234;195m memory: 43.86GiB(55.34%) [34m tps: 1,851 [36m tflops: 86.35 [35m mfu: 27.68%[39m
[rank6]:[titan] 2025-09-23 16:52:44,592 - root - INFO - [31m step: 960 [32m loss:  3.2457 [38;2;180;60;0m grad_norm:  0.0716 [38;2;54;234;195m memory: 45.85GiB(57.85%) [34m tps: 1,851 [36m tflops: 86.35 [35m mfu: 27.68%[39m
[rank0]:[titan] 2025-09-23 16:52:44,592 - root - INFO - [31m step: 960 [32m loss: -8.0000 [38;2;180;60;0m grad_norm:  0.0716 [38;2;54;234;195m memory: 43.86GiB(55.34%) [34m tps: 1,851 [36m tflops: 86.35 [35m mfu: 27.68%[39m
[rank7]:[titan] 2025-09-23 16:52:44,590 - root - INFO - [31m step: 960 [32m loss:  3.2457 [38;2;180;60;0m grad_norm:  0.0716 [38;2;54;234;195m memory: 45.85GiB(57.85%) [34m tps: 1,851 [36m tflops: 86.35 [35m mfu: 27.68%[39m
[rank6]:[titan] 2025-09-23 16:52:44,800 - root - INFO - Pipeline schedule is saved as: /workspace/torchtitan_data/images/0922_gpipe_fullrand6_runpod/pipeline_schedule/250923_1652_real_step960_rank6.svg
[rank6]:> Batch Time: 1061.11 ms, GPU Bubble Ratio: 40.70%, 38.57%, 44.99%, 35.68%
[rank6]:[titan] 2025-09-23 16:52:44,875 - root - INFO - Frozen Ratio History of Rank 6 (Stage 3)  is saved as: /workspace/torchtitan_data/images/0922_gpipe_fullrand6_runpod/freeze_ratio_history/rank6/250923_1652_stage3_step960.svg
[rank7]:[titan] 2025-09-23 16:52:44,799 - root - INFO - Pipeline schedule is saved as: /workspace/torchtitan_data/images/0922_gpipe_fullrand6_runpod/pipeline_schedule/250923_1652_real_step960_rank7.svg
[rank7]:> Batch Time: 1061.14 ms, GPU Bubble Ratio: 40.82%, 38.21%, 45.13%, 35.68%
[rank7]:[titan] 2025-09-23 16:52:44,874 - root - INFO - Frozen Ratio History of Rank 7 (Stage 3)  is saved as: /workspace/torchtitan_data/images/0922_gpipe_fullrand6_runpod/freeze_ratio_history/rank7/250923_1652_stage3_step960.svg
[rank0]:[titan] 2025-09-23 16:58:29,656 - root - INFO - [GC] Peforming periodical GC collection 0.56 seconds
[rank5]:[titan] 2025-09-23 16:58:38,503 - root - INFO - [31m step: 1000 [32m loss: -8.0000 [38;2;180;60;0m grad_norm:  0.0725 [38;2;54;234;195m memory: 34.68GiB(43.76%) [34m tps: 1,852 [36m tflops: 86.37 [35m mfu: 27.68%[39m
[rank5]:[titan] 2025-09-23 16:58:38,504 - root - INFO - Saving the checkpoint (or staging if async is enabled).
[rank3]:[titan] 2025-09-23 16:58:38,506 - root - INFO - [31m step: 1000 [32m loss: -8.0000 [38;2;180;60;0m grad_norm:  0.0725 [38;2;54;234;195m memory: 38.74GiB(48.88%) [34m tps: 1,852 [36m tflops: 86.37 [35m mfu: 27.68%[39m
[rank3]:[titan] 2025-09-23 16:58:38,506 - root - INFO - Saving the checkpoint (or staging if async is enabled).
[rank3]:[titan] 2025-09-23 16:58:38,522 - root - INFO - Saving a model only checkpoint in torch.float16 at last step, step 1000.
[rank2]:[titan] 2025-09-23 16:58:38,506 - root - INFO - [31m step: 1000 [32m loss: -8.0000 [38;2;180;60;0m grad_norm:  0.0725 [38;2;54;234;195m memory: 38.74GiB(48.88%) [34m tps: 1,852 [36m tflops: 86.37 [35m mfu: 27.68%[39m
[rank2]:[titan] 2025-09-23 16:58:38,506 - root - INFO - Saving the checkpoint (or staging if async is enabled).
[rank6]:[titan] 2025-09-23 16:58:38,508 - root - INFO - [31m step: 1000 [32m loss:  3.2818 [38;2;180;60;0m grad_norm:  0.0725 [38;2;54;234;195m memory: 45.85GiB(57.85%) [34m tps: 1,852 [36m tflops: 86.37 [35m mfu: 27.68%[39m
[rank6]:[titan] 2025-09-23 16:58:38,509 - root - INFO - Saving the checkpoint (or staging if async is enabled).
[rank2]:[titan] 2025-09-23 16:58:38,522 - root - INFO - Saving a model only checkpoint in torch.float16 at last step, step 1000.
[rank6]:[titan] 2025-09-23 16:58:38,525 - root - INFO - Saving a model only checkpoint in torch.float16 at last step, step 1000.
[rank1]:[titan] 2025-09-23 16:58:38,510 - root - INFO - [31m step: 1000 [32m loss: -8.0000 [38;2;180;60;0m grad_norm:  0.0725 [38;2;54;234;195m memory: 43.86GiB(55.34%) [34m tps: 1,852 [36m tflops: 86.37 [35m mfu: 27.68%[39m
[rank1]:[titan] 2025-09-23 16:58:38,510 - root - INFO - Saving the checkpoint (or staging if async is enabled).
[rank1]:[titan] 2025-09-23 16:58:38,527 - root - INFO - Saving a model only checkpoint in torch.float16 at last step, step 1000.
[rank4]:[titan] 2025-09-23 16:58:38,504 - root - INFO - [31m step: 1000 [32m loss: -8.0000 [38;2;180;60;0m grad_norm:  0.0725 [38;2;54;234;195m memory: 34.68GiB(43.76%) [34m tps: 1,852 [36m tflops: 86.37 [35m mfu: 27.68%[39m
[rank4]:[titan] 2025-09-23 16:58:38,504 - root - INFO - Saving the checkpoint (or staging if async is enabled).
[rank4]:[titan] 2025-09-23 16:58:38,522 - root - INFO - Saving a model only checkpoint in torch.float16 at last step, step 1000.
[rank7]:[titan] 2025-09-23 16:58:38,508 - root - INFO - [31m step: 1000 [32m loss:  3.2818 [38;2;180;60;0m grad_norm:  0.0725 [38;2;54;234;195m memory: 45.85GiB(57.85%) [34m tps: 1,852 [36m tflops: 86.37 [35m mfu: 27.68%[39m
[rank7]:[titan] 2025-09-23 16:58:38,508 - root - INFO - Saving the checkpoint (or staging if async is enabled).
[rank7]:[titan] 2025-09-23 16:58:38,524 - root - INFO - Saving a model only checkpoint in torch.float16 at last step, step 1000.
[rank0]:[titan] 2025-09-23 16:58:38,510 - root - INFO - [31m step: 1000 [32m loss: -8.0000 [38;2;180;60;0m grad_norm:  0.0725 [38;2;54;234;195m memory: 43.86GiB(55.34%) [34m tps: 1,852 [36m tflops: 86.36 [35m mfu: 27.68%[39m
[rank0]:[titan] 2025-09-23 16:58:38,510 - root - INFO - Saving the checkpoint (or staging if async is enabled).
[rank0]:[titan] 2025-09-23 16:58:38,527 - root - INFO - Saving a model only checkpoint in torch.float16 at last step, step 1000.
[rank5]:[titan] 2025-09-23 16:58:38,521 - root - INFO - Saving a model only checkpoint in torch.float16 at last step, step 1000.
[rank5]:[rank5]: Traceback (most recent call last):
[rank5]:[rank5]:   File "<frozen runpy>", line 198, in _run_module_as_main
[rank5]:[rank5]:   File "<frozen runpy>", line 88, in _run_code
[rank5]:[rank5]:   File "/workspace/torchtitan/timelyfreeze/train.py", line 727, in <module>
[rank5]:[rank5]:     trainer.train()
[rank5]:[rank5]:   File "/usr/local/lib/python3.11/dist-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 357, in wrapper
[rank5]:[rank5]:     return f(*args, **kwargs)
[rank5]:[rank5]:            ^^^^^^^^^^^^^^^^^^
[rank5]:[rank5]:   File "/workspace/torchtitan/timelyfreeze/train.py", line 586, in train
[rank5]:[rank5]:     self.checkpointer.save(
[rank5]:[rank5]:   File "/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[rank5]:[rank5]:     return func(*args, **kwargs)
[rank5]:[rank5]:            ^^^^^^^^^^^^^^^^^^^^^
[rank5]:[rank5]:   File "/workspace/torchtitan/torchtitan/components/checkpoint.py", line 479, in save
[rank5]:[rank5]:     self._save_last_step(curr_step)
[rank5]:[rank5]:   File "/workspace/torchtitan/torchtitan/components/checkpoint.py", line 733, in _save_last_step
[rank5]:[rank5]:     self.dcp_save(
[rank5]:[rank5]:   File "/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[rank5]:[rank5]:     return func(*args, **kwargs)
[rank5]:[rank5]:            ^^^^^^^^^^^^^^^^^^^^^
[rank5]:[rank5]:   File "/workspace/torchtitan/torchtitan/components/checkpoint.py", line 401, in dcp_save
[rank5]:[rank5]:     ret = dcp.save(
[rank5]:[rank5]:           ^^^^^^^^^
[rank5]:[rank5]:   File "/usr/local/lib/python3.11/dist-packages/torch/distributed/checkpoint/logger.py", line 87, in wrapper
[rank5]:[rank5]:     result = func(*args, **kwargs)
[rank5]:[rank5]:              ^^^^^^^^^^^^^^^^^^^^^
[rank5]:[rank5]:   File "/usr/local/lib/python3.11/dist-packages/torch/distributed/checkpoint/utils.py", line 475, in inner_func
[rank5]:[rank5]:     return func(*args, **kwargs)
[rank5]:[rank5]:            ^^^^^^^^^^^^^^^^^^^^^
[rank5]:[rank5]:   File "/usr/local/lib/python3.11/dist-packages/torch/distributed/checkpoint/state_dict_saver.py", line 193, in save
[rank5]:[rank5]:     return _save_state_dict(
[rank5]:[rank5]:            ^^^^^^^^^^^^^^^^^
[rank5]:[rank5]:   File "/usr/local/lib/python3.11/dist-packages/torch/distributed/checkpoint/state_dict_saver.py", line 475, in _save_state_dict
[rank5]:[rank5]:     metadata = distW.all_reduce("write", write_data, finish_checkpoint)
[rank5]:[rank5]:                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank5]:[rank5]:   File "/usr/local/lib/python3.11/dist-packages/torch/distributed/checkpoint/utils.py", line 259, in all_reduce
[rank5]:[rank5]:     raise final_result
[rank5]:[rank5]: torch.distributed.checkpoint.api.CheckpointException: CheckpointException ranks:dict_keys([2, 3, 4, 5, 6, 7])
[rank5]:[rank5]: Traceback (most recent call last): (RANK 2)
[rank5]:[rank5]:   File "/usr/local/lib/python3.11/dist-packages/torch/distributed/checkpoint/utils.py", line 239, in all_reduce
[rank5]:[rank5]:     local_data = map_fun()
[rank5]:[rank5]:                  ^^^^^^^^^
[rank5]:[rank5]:   File "/usr/local/lib/python3.11/dist-packages/torch/distributed/checkpoint/logger.py", line 87, in wrapper
[rank5]:[rank5]:     result = func(*args, **kwargs)
[rank5]:[rank5]:              ^^^^^^^^^^^^^^^^^^^^^
[rank5]:[rank5]:   File "/usr/local/lib/python3.11/dist-packages/torch/distributed/checkpoint/state_dict_saver.py", line 463, in write_data
[rank5]:[rank5]:     all_writes = storage_writer.write_data(final_local_plan, planner)
[rank5]:[rank5]:                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank5]:[rank5]:   File "/usr/local/lib/python3.11/dist-packages/torch/distributed/checkpoint/hf_storage.py", line 127, in write_data
[rank5]:[rank5]:     buckets = self._split_by_storage_plan(storage_plan, plan.items)
[rank5]:[rank5]:               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank5]:[rank5]:   File "/usr/local/lib/python3.11/dist-packages/torch/distributed/checkpoint/hf_storage.py", line 189, in _split_by_storage_plan
[rank5]:[rank5]:     idx = storage_plan[key]
[rank5]:[rank5]:           ~~~~~~~~~~~~^^^^^
[rank5]:[rank5]: KeyError: 'model.layers.8.self_attn.q_proj.weight'
[rank5]:[rank5]: Traceback (most recent call last): (RANK 3)
[rank5]:[rank5]:   File "/usr/local/lib/python3.11/dist-packages/torch/distributed/checkpoint/utils.py", line 239, in all_reduce
[rank5]:[rank5]:     local_data = map_fun()
[rank5]:[rank5]:                  ^^^^^^^^^
[rank5]:[rank5]:   File "/usr/local/lib/python3.11/dist-packages/torch/distributed/checkpoint/logger.py", line 87, in wrapper
[rank5]:[rank5]:     result = func(*args, **kwargs)
[rank5]:[rank5]:              ^^^^^^^^^^^^^^^^^^^^^
[rank5]:[rank5]:   File "/usr/local/lib/python3.11/dist-packages/torch/distributed/checkpoint/state_dict_saver.py", line 463, in write_data
[rank5]:[rank5]:     all_writes = storage_writer.write_data(final_local_plan, planner)
[rank5]:[rank5]:                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank5]:[rank5]:   File "/usr/local/lib/python3.11/dist-packages/torch/distributed/checkpoint/hf_storage.py", line 127, in write_data
[rank5]:[rank5]:     buckets = self._split_by_storage_plan(storage_plan, plan.items)
[rank5]:[rank5]:               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank5]:[rank5]:   File "/usr/local/lib/python3.11/dist-packages/torch/distributed/checkpoint/hf_storage.py", line 189, in _split_by_storage_plan
[rank5]:[rank5]:     idx = storage_plan[key]
[rank5]:[rank5]:           ~~~~~~~~~~~~^^^^^
[rank5]:[rank5]: KeyError: 'model.layers.8.self_attn.q_proj.weight'
[rank5]:[rank5]: Traceback (most recent call last): (RANK 4)
[rank5]:[rank5]:   File "/usr/local/lib/python3.11/dist-packages/torch/distributed/checkpoint/utils.py", line 239, in all_reduce
[rank5]:[rank5]:     local_data = map_fun()
[rank5]:[rank5]:                  ^^^^^^^^^
[rank5]:[rank5]:   File "/usr/local/lib/python3.11/dist-packages/torch/distributed/checkpoint/logger.py", line 87, in wrapper
[rank5]:[rank5]:     result = func(*args, **kwargs)
[rank5]:[rank5]:              ^^^^^^^^^^^^^^^^^^^^^
[rank5]:[rank5]:   File "/usr/local/lib/python3.11/dist-packages/torch/distributed/checkpoint/state_dict_saver.py", line 463, in write_data
[rank5]:[rank5]:     all_writes = storage_writer.write_data(final_local_plan, planner)
[rank5]:[rank5]:                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank5]:[rank5]:   File "/usr/local/lib/python3.11/dist-packages/torch/distributed/checkpoint/hf_storage.py", line 127, in write_data
[rank5]:[rank5]:     buckets = self._split_by_storage_plan(storage_plan, plan.items)
[rank5]:[rank5]:               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank5]:[rank5]:   File "/usr/local/lib/python3.11/dist-packages/torch/distributed/checkpoint/hf_storage.py", line 189, in _split_by_storage_plan
[rank5]:[rank5]:     idx = storage_plan[key]
[rank5]:[rank5]:           ~~~~~~~~~~~~^^^^^
[rank5]:[rank5]: KeyError: 'model.layers.17.self_attn.q_proj.weight'
[rank5]:[rank5]: Traceback (most recent call last): (RANK 5)
[rank5]:[rank5]:   File "/usr/local/lib/python3.11/dist-packages/torch/distributed/checkpoint/utils.py", line 239, in all_reduce
[rank5]:[rank5]:     local_data = map_fun()
[rank5]:[rank5]:                  ^^^^^^^^^
[rank5]:[rank5]:   File "/usr/local/lib/python3.11/dist-packages/torch/distributed/checkpoint/logger.py", line 87, in wrapper
[rank5]:[rank5]:     result = func(*args, **kwargs)
[rank5]:[rank5]:              ^^^^^^^^^^^^^^^^^^^^^
[rank5]:[rank5]:   File "/usr/local/lib/python3.11/dist-packages/torch/distributed/checkpoint/state_dict_saver.py", line 463, in write_data
[rank5]:[rank5]:     all_writes = storage_writer.write_data(final_local_plan, planner)
[rank5]:[rank5]:                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank5]:[rank5]:   File "/usr/local/lib/python3.11/dist-packages/torch/distributed/checkpoint/hf_storage.py", line 127, in write_data
[rank5]:[rank5]:     buckets = self._split_by_storage_plan(storage_plan, plan.items)
[rank5]:[rank5]:               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank5]:[rank5]:   File "/usr/local/lib/python3.11/dist-packages/torch/distributed/checkpoint/hf_storage.py", line 189, in _split_by_storage_plan
[rank5]:[rank5]:     idx = storage_plan[key]
[rank5]:[rank5]:           ~~~~~~~~~~~~^^^^^
[rank5]:[rank5]: KeyError: 'model.layers.17.self_attn.q_proj.weight'
[rank5]:[rank5]: Traceback (most recent call last): (RANK 6)
[rank5]:[rank5]:   File "/usr/local/lib/python3.11/dist-packages/torch/distributed/checkpoint/utils.py", line 239, in all_reduce
[rank5]:[rank5]:     local_data = map_fun()
[rank5]:[rank5]:                  ^^^^^^^^^
[rank5]:[rank5]:   File "/usr/local/lib/python3.11/dist-packages/torch/distributed/checkpoint/logger.py", line 87, in wrapper
[rank5]:[rank5]:     result = func(*args, **kwargs)
[rank5]:[rank5]:              ^^^^^^^^^^^^^^^^^^^^^
[rank5]:[rank5]:   File "/usr/local/lib/python3.11/dist-packages/torch/distributed/checkpoint/state_dict_saver.py", line 463, in write_data
[rank5]:[rank5]:     all_writes = storage_writer.write_data(final_local_plan, planner)
[rank5]:[rank5]:                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank5]:[rank5]:   File "/usr/local/lib/python3.11/dist-packages/torch/distributed/checkpoint/hf_storage.py", line 127, in write_data
[rank5]:[rank5]:     buckets = self._split_by_storage_plan(storage_plan, plan.items)
[rank5]:[rank5]:               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank5]:[rank5]:   File "/usr/local/lib/python3.11/dist-packages/torch/distributed/checkpoint/hf_storage.py", line 189, in _split_by_storage_plan
[rank5]:[rank5]:     idx = storage_plan[key]
[rank5]:[rank5]:           ~~~~~~~~~~~~^^^^^
[rank5]:[rank5]: KeyError: 'model.layers.25.self_attn.q_proj.weight'
[rank5]:[rank5]: Traceback (most recent call last): (RANK 7)
[rank5]:[rank5]:   File "/usr/local/lib/python3.11/dist-packages/torch/distributed/checkpoint/utils.py", line 239, in all_reduce
[rank5]:[rank5]:     local_data = map_fun()
[rank5]:[rank5]:                  ^^^^^^^^^
[rank5]:[rank5]:   File "/usr/local/lib/python3.11/dist-packages/torch/distributed/checkpoint/logger.py", line 87, in wrapper
[rank5]:[rank5]:     result = func(*args, **kwargs)
[rank5]:[rank5]:              ^^^^^^^^^^^^^^^^^^^^^
[rank5]:[rank5]:   File "/usr/local/lib/python3.11/dist-packages/torch/distributed/checkpoint/state_dict_saver.py", line 463, in write_data
[rank5]:[rank5]:     all_writes = storage_writer.write_data(final_local_plan, planner)
[rank5]:[rank5]:                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank5]:[rank5]:   File "/usr/local/lib/python3.11/dist-packages/torch/distributed/checkpoint/hf_storage.py", line 127, in write_data
[rank5]:[rank5]:     buckets = self._split_by_storage_plan(storage_plan, plan.items)
[rank5]:[rank5]:               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank5]:[rank5]:   File "/usr/local/lib/python3.11/dist-packages/torch/distributed/checkpoint/hf_storage.py", line 189, in _split_by_storage_plan
[rank5]:[rank5]:     idx = storage_plan[key]
[rank5]:[rank5]:           ~~~~~~~~~~~~^^^^^
[rank5]:[rank5]: KeyError: 'model.layers.25.self_attn.q_proj.weight'
[rank5]:
[rank3]:[rank3]: Traceback (most recent call last):
[rank3]:[rank3]:   File "<frozen runpy>", line 198, in _run_module_as_main
[rank3]:[rank3]:   File "<frozen runpy>", line 88, in _run_code
[rank3]:[rank3]:   File "/workspace/torchtitan/timelyfreeze/train.py", line 727, in <module>
[rank3]:[rank3]:     trainer.train()
[rank3]:[rank3]:   File "/usr/local/lib/python3.11/dist-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 357, in wrapper
[rank3]:[rank3]:     return f(*args, **kwargs)
[rank3]:[rank3]:            ^^^^^^^^^^^^^^^^^^
[rank3]:[rank3]:   File "/workspace/torchtitan/timelyfreeze/train.py", line 586, in train
[rank3]:[rank3]:     self.checkpointer.save(
[rank3]:[rank3]:   File "/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[rank3]:[rank3]:     return func(*args, **kwargs)
[rank3]:[rank3]:            ^^^^^^^^^^^^^^^^^^^^^
[rank3]:[rank3]:   File "/workspace/torchtitan/torchtitan/components/checkpoint.py", line 479, in save
[rank3]:[rank3]:     self._save_last_step(curr_step)
[rank3]:[rank3]:   File "/workspace/torchtitan/torchtitan/components/checkpoint.py", line 733, in _save_last_step
[rank3]:[rank3]:     self.dcp_save(
[rank3]:[rank3]:   File "/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[rank3]:[rank3]:     return func(*args, **kwargs)
[rank3]:[rank3]:            ^^^^^^^^^^^^^^^^^^^^^
[rank3]:[rank3]:   File "/workspace/torchtitan/torchtitan/components/checkpoint.py", line 401, in dcp_save
[rank3]:[rank3]:     ret = dcp.save(
[rank3]:[rank3]:           ^^^^^^^^^
[rank3]:[rank3]:   File "/usr/local/lib/python3.11/dist-packages/torch/distributed/checkpoint/logger.py", line 87, in wrapper
[rank3]:[rank3]:     result = func(*args, **kwargs)
[rank3]:[rank3]:              ^^^^^^^^^^^^^^^^^^^^^
[rank3]:[rank3]:   File "/usr/local/lib/python3.11/dist-packages/torch/distributed/checkpoint/utils.py", line 475, in inner_func
[rank3]:[rank3]:     return func(*args, **kwargs)
[rank3]:[rank3]:            ^^^^^^^^^^^^^^^^^^^^^
[rank3]:[rank3]:   File "/usr/local/lib/python3.11/dist-packages/torch/distributed/checkpoint/state_dict_saver.py", line 193, in save
[rank3]:[rank3]:     return _save_state_dict(
[rank3]:[rank3]:            ^^^^^^^^^^^^^^^^^
[rank3]:[rank3]:   File "/usr/local/lib/python3.11/dist-packages/torch/distributed/checkpoint/state_dict_saver.py", line 475, in _save_state_dict
[rank3]:[rank3]:     metadata = distW.all_reduce("write", write_data, finish_checkpoint)
[rank3]:[rank3]:                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank3]:[rank3]:   File "/usr/local/lib/python3.11/dist-packages/torch/distributed/checkpoint/utils.py", line 259, in all_reduce
[rank3]:[rank3]:     raise final_result
[rank3]:[rank3]: torch.distributed.checkpoint.api.CheckpointException: CheckpointException ranks:dict_keys([2, 3, 4, 5, 6, 7])
[rank3]:[rank3]: Traceback (most recent call last): (RANK 2)
[rank3]:[rank3]:   File "/usr/local/lib/python3.11/dist-packages/torch/distributed/checkpoint/utils.py", line 239, in all_reduce
[rank3]:[rank3]:     local_data = map_fun()
[rank3]:[rank3]:                  ^^^^^^^^^
[rank3]:[rank3]:   File "/usr/local/lib/python3.11/dist-packages/torch/distributed/checkpoint/logger.py", line 87, in wrapper
[rank3]:[rank3]:     result = func(*args, **kwargs)
[rank3]:[rank3]:              ^^^^^^^^^^^^^^^^^^^^^
[rank3]:[rank3]:   File "/usr/local/lib/python3.11/dist-packages/torch/distributed/checkpoint/state_dict_saver.py", line 463, in write_data
[rank3]:[rank3]:     all_writes = storage_writer.write_data(final_local_plan, planner)
[rank3]:[rank3]:                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank3]:[rank3]:   File "/usr/local/lib/python3.11/dist-packages/torch/distributed/checkpoint/hf_storage.py", line 127, in write_data
[rank3]:[rank3]:     buckets = self._split_by_storage_plan(storage_plan, plan.items)
[rank3]:[rank3]:               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank3]:[rank3]:   File "/usr/local/lib/python3.11/dist-packages/torch/distributed/checkpoint/hf_storage.py", line 189, in _split_by_storage_plan
[rank3]:[rank3]:     idx = storage_plan[key]
[rank3]:[rank3]:           ~~~~~~~~~~~~^^^^^
[rank3]:[rank3]: KeyError: 'model.layers.8.self_attn.q_proj.weight'
[rank3]:[rank3]: Traceback (most recent call last): (RANK 3)
[rank3]:[rank3]:   File "/usr/local/lib/python3.11/dist-packages/torch/distributed/checkpoint/utils.py", line 239, in all_reduce
[rank3]:[rank3]:     local_data = map_fun()
[rank3]:[rank3]:                  ^^^^^^^^^
[rank3]:[rank3]:   File "/usr/local/lib/python3.11/dist-packages/torch/distributed/checkpoint/logger.py", line 87, in wrapper
[rank3]:[rank3]:     result = func(*args, **kwargs)
[rank3]:[rank3]:              ^^^^^^^^^^^^^^^^^^^^^
[rank3]:[rank3]:   File "/usr/local/lib/python3.11/dist-packages/torch/distributed/checkpoint/state_dict_saver.py", line 463, in write_data
[rank3]:[rank3]:     all_writes = storage_writer.write_data(final_local_plan, planner)
[rank3]:[rank3]:                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank3]:[rank3]:   File "/usr/local/lib/python3.11/dist-packages/torch/distributed/checkpoint/hf_storage.py", line 127, in write_data
[rank3]:[rank3]:     buckets = self._split_by_storage_plan(storage_plan, plan.items)
[rank3]:[rank3]:               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank3]:[rank3]:   File "/usr/local/lib/python3.11/dist-packages/torch/distributed/checkpoint/hf_storage.py", line 189, in _split_by_storage_plan
[rank3]:[rank3]:     idx = storage_plan[key]
[rank3]:[rank3]:           ~~~~~~~~~~~~^^^^^
[rank3]:[rank3]: KeyError: 'model.layers.8.self_attn.q_proj.weight'
[rank3]:[rank3]: Traceback (most recent call last): (RANK 4)
[rank3]:[rank3]:   File "/usr/local/lib/python3.11/dist-packages/torch/distributed/checkpoint/utils.py", line 239, in all_reduce
[rank3]:[rank3]:     local_data = map_fun()
[rank3]:[rank3]:                  ^^^^^^^^^
[rank3]:[rank3]:   File "/usr/local/lib/python3.11/dist-packages/torch/distributed/checkpoint/logger.py", line 87, in wrapper
[rank3]:[rank3]:     result = func(*args, **kwargs)
[rank3]:[rank3]:              ^^^^^^^^^^^^^^^^^^^^^
[rank3]:[rank3]:   File "/usr/local/lib/python3.11/dist-packages/torch/distributed/checkpoint/state_dict_saver.py", line 463, in write_data
[rank3]:[rank3]:     all_writes = storage_writer.write_data(final_local_plan, planner)
[rank3]:[rank3]:                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank3]:[rank3]:   File "/usr/local/lib/python3.11/dist-packages/torch/distributed/checkpoint/hf_storage.py", line 127, in write_data
[rank3]:[rank3]:     buckets = self._split_by_storage_plan(storage_plan, plan.items)
[rank3]:[rank3]:               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank3]:[rank3]:   File "/usr/local/lib/python3.11/dist-packages/torch/distributed/checkpoint/hf_storage.py", line 189, in _split_by_storage_plan
[rank3]:[rank3]:     idx = storage_plan[key]
[rank3]:[rank3]:           ~~~~~~~~~~~~^^^^^
[rank3]:[rank3]: KeyError: 'model.layers.17.self_attn.q_proj.weight'
[rank3]:[rank3]: Traceback (most recent call last): (RANK 5)
[rank3]:[rank3]:   File "/usr/local/lib/python3.11/dist-packages/torch/distributed/checkpoint/utils.py", line 239, in all_reduce
[rank3]:[rank3]:     local_data = map_fun()
[rank3]:[rank3]:                  ^^^^^^^^^
[rank3]:[rank3]:   File "/usr/local/lib/python3.11/dist-packages/torch/distributed/checkpoint/logger.py", line 87, in wrapper
[rank3]:[rank3]:     result = func(*args, **kwargs)
[rank3]:[rank3]:              ^^^^^^^^^^^^^^^^^^^^^
[rank3]:[rank3]:   File "/usr/local/lib/python3.11/dist-packages/torch/distributed/checkpoint/state_dict_saver.py", line 463, in write_data
[rank3]:[rank3]:     all_writes = storage_writer.write_data(final_local_plan, planner)
[rank3]:[rank3]:                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank3]:[rank3]:   File "/usr/local/lib/python3.11/dist-packages/torch/distributed/checkpoint/hf_storage.py", line 127, in write_data
[rank3]:[rank3]:     buckets = self._split_by_storage_plan(storage_plan, plan.items)
[rank3]:[rank3]:               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank3]:[rank3]:   File "/usr/local/lib/python3.11/dist-packages/torch/distributed/checkpoint/hf_storage.py", line 189, in _split_by_storage_plan
[rank3]:[rank3]:     idx = storage_plan[key]
[rank3]:[rank3]:           ~~~~~~~~~~~~^^^^^
[rank3]:[rank3]: KeyError: 'model.layers.17.self_attn.q_proj.weight'
[rank3]:[rank3]: Traceback (most recent call last): (RANK 6)
[rank3]:[rank3]:   File "/usr/local/lib/python3.11/dist-packages/torch/distributed/checkpoint/utils.py", line 239, in all_reduce
[rank3]:[rank3]:     local_data = map_fun()
[rank3]:[rank3]:                  ^^^^^^^^^
[rank3]:[rank3]:   File "/usr/local/lib/python3.11/dist-packages/torch/distributed/checkpoint/logger.py", line 87, in wrapper
[rank3]:[rank3]:     result = func(*args, **kwargs)
[rank3]:[rank3]:              ^^^^^^^^^^^^^^^^^^^^^
[rank3]:[rank3]:   File "/usr/local/lib/python3.11/dist-packages/torch/distributed/checkpoint/state_dict_saver.py", line 463, in write_data
[rank3]:[rank3]:     all_writes = storage_writer.write_data(final_local_plan, planner)
[rank3]:[rank3]:                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank3]:[rank3]:   File "/usr/local/lib/python3.11/dist-packages/torch/distributed/checkpoint/hf_storage.py", line 127, in write_data
[rank3]:[rank3]:     buckets = self._split_by_storage_plan(storage_plan, plan.items)
[rank3]:[rank3]:               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank3]:[rank3]:   File "/usr/local/lib/python3.11/dist-packages/torch/distributed/checkpoint/hf_storage.py", line 189, in _split_by_storage_plan
[rank3]:[rank3]:     idx = storage_plan[key]
[rank3]:[rank3]:           ~~~~~~~~~~~~^^^^^
[rank3]:[rank3]: KeyError: 'model.layers.25.self_attn.q_proj.weight'
[rank3]:[rank3]: Traceback (most recent call last): (RANK 7)
[rank3]:[rank3]:   File "/usr/local/lib/python3.11/dist-packages/torch/distributed/checkpoint/utils.py", line 239, in all_reduce
[rank3]:[rank3]:     local_data = map_fun()
[rank3]:[rank3]:                  ^^^^^^^^^
[rank3]:[rank3]:   File "/usr/local/lib/python3.11/dist-packages/torch/distributed/checkpoint/logger.py", line 87, in wrapper
[rank3]:[rank3]:     result = func(*args, **kwargs)
[rank3]:[rank3]:              ^^^^^^^^^^^^^^^^^^^^^
[rank3]:[rank3]:   File "/usr/local/lib/python3.11/dist-packages/torch/distributed/checkpoint/state_dict_saver.py", line 463, in write_data
[rank3]:[rank3]:     all_writes = storage_writer.write_data(final_local_plan, planner)
[rank3]:[rank3]:                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank3]:[rank3]:   File "/usr/local/lib/python3.11/dist-packages/torch/distributed/checkpoint/hf_storage.py", line 127, in write_data
[rank3]:[rank3]:     buckets = self._split_by_storage_plan(storage_plan, plan.items)
[rank3]:[rank3]:               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank3]:[rank3]:   File "/usr/local/lib/python3.11/dist-packages/torch/distributed/checkpoint/hf_storage.py", line 189, in _split_by_storage_plan
[rank3]:[rank3]:     idx = storage_plan[key]
[rank3]:[rank3]:           ~~~~~~~~~~~~^^^^^
[rank3]:[rank3]: KeyError: 'model.layers.25.self_attn.q_proj.weight'
[rank3]:
[rank2]:[rank2]: Traceback (most recent call last):
[rank2]:[rank2]:   File "<frozen runpy>", line 198, in _run_module_as_main
[rank2]:[rank2]:   File "<frozen runpy>", line 88, in _run_code
[rank2]:[rank2]:   File "/workspace/torchtitan/timelyfreeze/train.py", line 727, in <module>
[rank2]:[rank2]:     trainer.train()
[rank2]:[rank2]:   File "/usr/local/lib/python3.11/dist-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 357, in wrapper
[rank2]:[rank2]:     return f(*args, **kwargs)
[rank2]:[rank2]:            ^^^^^^^^^^^^^^^^^^
[rank2]:[rank2]:   File "/workspace/torchtitan/timelyfreeze/train.py", line 586, in train
[rank2]:[rank2]:     self.checkpointer.save(
[rank6]:Traceback (most recent call last):
[rank6]:  File "<frozen runpy>", line 198, in _run_module_as_main
[rank6]:  File "<frozen runpy>", line 88, in _run_code
[rank6]:  File "/workspace/torchtitan/timelyfreeze/train.py", line 727, in <module>
[rank6]:    trainer.train()
[rank2]:[rank2]:   File "/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[rank2]:[rank2]:     return func(*args, **kwargs)
[rank6]:  File "/usr/local/lib/python3.11/dist-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 357, in wrapper
[rank6]:    return f(*args, **kwargs)
[rank6]:           ^^^^^^^^^^^^^^^^^^
[rank6]:  File "/workspace/torchtitan/timelyfreeze/train.py", line 586, in train
[rank2]:[rank2]:            ^^^^^^^^^^^^^^^^^^^^^
[rank6]:    self.checkpointer.save(
[rank2]:[rank2]:   File "/workspace/torchtitan/torchtitan/components/checkpoint.py", line 479, in save
[rank2]:[rank2]:     self._save_last_step(curr_step)
[rank6]:  File "/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[rank6]:    return func(*args, **kwargs)
[rank2]:[rank2]:   File "/workspace/torchtitan/torchtitan/components/checkpoint.py", line 733, in _save_last_step
[rank6]:           ^^^^^^^^^^^^^^^^^^^^^
[rank6]:  File "/workspace/torchtitan/torchtitan/components/checkpoint.py", line 479, in save
[rank6]:    self._save_last_step(curr_step)
[rank6]:  File "/workspace/torchtitan/torchtitan/components/checkpoint.py", line 733, in _save_last_step
[rank2]:[rank2]:     self.dcp_save(
[rank2]:[rank2]:   File "/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[rank6]:    self.dcp_save(
[rank6]:  File "/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[rank2]:[rank2]:     return func(*args, **kwargs)
[rank6]:    return func(*args, **kwargs)
[rank6]:           ^^^^^^^^^^^^^^^^^^^^^
[rank6]:  File "/workspace/torchtitan/torchtitan/components/checkpoint.py", line 401, in dcp_save
[rank6]:    ret = dcp.save(
[rank6]:          ^^^^^^^^^
[rank6]:  File "/usr/local/lib/python3.11/dist-packages/torch/distributed/checkpoint/logger.py", line 87, in wrapper
[rank2]:[rank2]:            ^^^^^^^^^^^^^^^^^^^^^
[rank2]:[rank2]:   File "/workspace/torchtitan/torchtitan/components/checkpoint.py", line 401, in dcp_save
[rank6]:    result = func(*args, **kwargs)
[rank6]:             ^^^^^^^^^^^^^^^^^^^^^
[rank6]:  File "/usr/local/lib/python3.11/dist-packages/torch/distributed/checkpoint/utils.py", line 475, in inner_func
[rank6]:    return func(*args, **kwargs)
[rank2]:[rank2]:     ret = dcp.save(
[rank6]:           ^^^^^^^^^^^^^^^^^^^^^
[rank6]:  File "/usr/local/lib/python3.11/dist-packages/torch/distributed/checkpoint/state_dict_saver.py", line 193, in save
[rank2]:[rank2]:           ^^^^^^^^^
[rank6]:    return _save_state_dict(
[rank2]:[rank2]:   File "/usr/local/lib/python3.11/dist-packages/torch/distributed/checkpoint/logger.py", line 87, in wrapper
[rank6]:           ^^^^^^^^^^^^^^^^^
[rank6]:  File "/usr/local/lib/python3.11/dist-packages/torch/distributed/checkpoint/state_dict_saver.py", line 475, in _save_state_dict
[rank2]:[rank2]:     result = func(*args, **kwargs)
[rank2]:[rank2]:              ^^^^^^^^^^^^^^^^^^^^^
[rank2]:[rank2]:   File "/usr/local/lib/python3.11/dist-packages/torch/distributed/checkpoint/utils.py", line 475, in inner_func
[rank2]:[rank2]:     return func(*args, **kwargs)
[rank6]:    metadata = distW.all_reduce("write", write_data, finish_checkpoint)
[rank2]:[rank2]:            ^^^^^^^^^^^^^^^^^^^^^
[rank2]:[rank2]:   File "/usr/local/lib/python3.11/dist-packages/torch/distributed/checkpoint/state_dict_saver.py", line 193, in save
[rank2]:[rank2]:     return _save_state_dict(
[rank2]:[rank2]:            ^^^^^^^^^^^^^^^^^
[rank2]:[rank2]:   File "/usr/local/lib/python3.11/dist-packages/torch/distributed/checkpoint/state_dict_saver.py", line 475, in _save_state_dict
[rank2]:[rank2]:     metadata = distW.all_reduce("write", write_data, finish_checkpoint)
[rank2]:[rank2]:                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank2]:[rank2]:   File "/usr/local/lib/python3.11/dist-packages/torch/distributed/checkpoint/utils.py", line 259, in all_reduce
[rank2]:[rank2]:     raise final_result
[rank2]:[rank2]: torch.distributed.checkpoint.api.CheckpointException: CheckpointException ranks:dict_keys([2, 3, 4, 5, 6, 7])
[rank2]:[rank2]: Traceback (most recent call last): (RANK 2)
[rank2]:[rank2]:   File "/usr/local/lib/python3.11/dist-packages/torch/distributed/checkpoint/utils.py", line 239, in all_reduce
[rank2]:[rank2]:     local_data = map_fun()
[rank2]:[rank2]:                  ^^^^^^^^^
[rank2]:[rank2]:   File "/usr/local/lib/python3.11/dist-packages/torch/distributed/checkpoint/logger.py", line 87, in wrapper
[rank2]:[rank2]:     result = func(*args, **kwargs)
[rank2]:[rank2]:              ^^^^^^^^^^^^^^^^^^^^^
[rank2]:[rank2]:   File "/usr/local/lib/python3.11/dist-packages/torch/distributed/checkpoint/state_dict_saver.py", line 463, in write_data
[rank6]:               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank6]:  File "/usr/local/lib/python3.11/dist-packages/torch/distributed/checkpoint/utils.py", line 259, in all_reduce
[rank6]:    raise final_result
[rank2]:[rank2]:     all_writes = storage_writer.write_data(final_local_plan, planner)
[rank2]:[rank2]:                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank2]:[rank2]:   File "/usr/local/lib/python3.11/dist-packages/torch/distributed/checkpoint/hf_storage.py", line 127, in write_data
[rank6]:torch.distributed.checkpoint.api.CheckpointException: CheckpointException ranks:dict_keys([2, 3, 4, 5, 6, 7])
[rank2]:[rank2]:     buckets = self._split_by_storage_plan(storage_plan, plan.items)
[rank2]:[rank2]:               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank2]:[rank2]:   File "/usr/local/lib/python3.11/dist-packages/torch/distributed/checkpoint/hf_storage.py", line 189, in _split_by_storage_plan
[rank6]:Traceback (most recent call last): (RANK 2)
[rank6]:  File "/usr/local/lib/python3.11/dist-packages/torch/distributed/checkpoint/utils.py", line 239, in all_reduce
[rank6]:    local_data = map_fun()
[rank2]:[rank2]:     idx = storage_plan[key]
[rank2]:[rank2]:           ~~~~~~~~~~~~^^^^^
[rank2]:[rank2]: KeyError: 'model.layers.8.self_attn.q_proj.weight'
[rank2]:[rank2]: Traceback (most recent call last): (RANK 3)
[rank6]:                 ^^^^^^^^^
[rank6]:  File "/usr/local/lib/python3.11/dist-packages/torch/distributed/checkpoint/logger.py", line 87, in wrapper
[rank6]:    result = func(*args, **kwargs)
[rank6]:             ^^^^^^^^^^^^^^^^^^^^^
[rank2]:[rank2]:   File "/usr/local/lib/python3.11/dist-packages/torch/distributed/checkpoint/utils.py", line 239, in all_reduce
[rank6]:  File "/usr/local/lib/python3.11/dist-packages/torch/distributed/checkpoint/state_dict_saver.py", line 463, in write_data
[rank6]:    all_writes = storage_writer.write_data(final_local_plan, planner)
[rank2]:[rank2]:     local_data = map_fun()
[rank2]:[rank2]:                  ^^^^^^^^^
[rank2]:[rank2]:   File "/usr/local/lib/python3.11/dist-packages/torch/distributed/checkpoint/logger.py", line 87, in wrapper
[rank6]:                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank2]:[rank2]:     result = func(*args, **kwargs)
[rank2]:[rank2]:              ^^^^^^^^^^^^^^^^^^^^^
[rank6]:  File "/usr/local/lib/python3.11/dist-packages/torch/distributed/checkpoint/hf_storage.py", line 127, in write_data
[rank6]:    buckets = self._split_by_storage_plan(storage_plan, plan.items)
[rank2]:[rank2]:   File "/usr/local/lib/python3.11/dist-packages/torch/distributed/checkpoint/state_dict_saver.py", line 463, in write_data
[rank2]:[rank2]:     all_writes = storage_writer.write_data(final_local_plan, planner)
[rank2]:[rank2]:                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank2]:[rank2]:   File "/usr/local/lib/python3.11/dist-packages/torch/distributed/checkpoint/hf_storage.py", line 127, in write_data
[rank2]:[rank2]:     buckets = self._split_by_storage_plan(storage_plan, plan.items)
[rank2]:[rank2]:               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank6]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank6]:  File "/usr/local/lib/python3.11/dist-packages/torch/distributed/checkpoint/hf_storage.py", line 189, in _split_by_storage_plan
[rank6]:    idx = storage_plan[key]
[rank6]:          ~~~~~~~~~~~~^^^^^
[rank2]:[rank2]:   File "/usr/local/lib/python3.11/dist-packages/torch/distributed/checkpoint/hf_storage.py", line 189, in _split_by_storage_plan
[rank2]:[rank2]:     idx = storage_plan[key]
[rank2]:[rank2]:           ~~~~~~~~~~~~^^^^^
[rank6]:KeyError: 'model.layers.8.self_attn.q_proj.weight'
[rank6]:Traceback (most recent call last): (RANK 3)
[rank2]:[rank2]: KeyError: 'model.layers.8.self_attn.q_proj.weight'
[rank2]:[rank2]: Traceback (most recent call last): (RANK 4)
[rank6]:  File "/usr/local/lib/python3.11/dist-packages/torch/distributed/checkpoint/utils.py", line 239, in all_reduce
[rank2]:[rank2]:   File "/usr/local/lib/python3.11/dist-packages/torch/distributed/checkpoint/utils.py", line 239, in all_reduce
[rank6]:    local_data = map_fun()
[rank6]:                 ^^^^^^^^^
[rank2]:[rank2]:     local_data = map_fun()
[rank2]:[rank2]:                  ^^^^^^^^^
[rank6]:  File "/usr/local/lib/python3.11/dist-packages/torch/distributed/checkpoint/logger.py", line 87, in wrapper
[rank6]:    result = func(*args, **kwargs)
[rank6]:             ^^^^^^^^^^^^^^^^^^^^^
[rank6]:  File "/usr/local/lib/python3.11/dist-packages/torch/distributed/checkpoint/state_dict_saver.py", line 463, in write_data
[rank2]:[rank2]:   File "/usr/local/lib/python3.11/dist-packages/torch/distributed/checkpoint/logger.py", line 87, in wrapper
[rank2]:[rank2]:     result = func(*args, **kwargs)
[rank6]:    all_writes = storage_writer.write_data(final_local_plan, planner)
[rank6]:                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank2]:[rank2]:              ^^^^^^^^^^^^^^^^^^^^^
[rank2]:[rank2]:   File "/usr/local/lib/python3.11/dist-packages/torch/distributed/checkpoint/state_dict_saver.py", line 463, in write_data
[rank6]:  File "/usr/local/lib/python3.11/dist-packages/torch/distributed/checkpoint/hf_storage.py", line 127, in write_data
[rank6]:    buckets = self._split_by_storage_plan(storage_plan, plan.items)
[rank6]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank6]:  File "/usr/local/lib/python3.11/dist-packages/torch/distributed/checkpoint/hf_storage.py", line 189, in _split_by_storage_plan
[rank2]:[rank2]:     all_writes = storage_writer.write_data(final_local_plan, planner)
[rank2]:[rank2]:                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank6]:    idx = storage_plan[key]
[rank6]:          ~~~~~~~~~~~~^^^^^
[rank6]:KeyError: 'model.layers.8.self_attn.q_proj.weight'
[rank6]:Traceback (most recent call last): (RANK 4)
[rank2]:[rank2]:   File "/usr/local/lib/python3.11/dist-packages/torch/distributed/checkpoint/hf_storage.py", line 127, in write_data
[rank6]:  File "/usr/local/lib/python3.11/dist-packages/torch/distributed/checkpoint/utils.py", line 239, in all_reduce
[rank6]:    local_data = map_fun()
[rank6]:                 ^^^^^^^^^
[rank6]:  File "/usr/local/lib/python3.11/dist-packages/torch/distributed/checkpoint/logger.py", line 87, in wrapper
[rank2]:[rank2]:     buckets = self._split_by_storage_plan(storage_plan, plan.items)
[rank6]:    result = func(*args, **kwargs)
[rank2]:[rank2]:               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank2]:[rank2]:   File "/usr/local/lib/python3.11/dist-packages/torch/distributed/checkpoint/hf_storage.py", line 189, in _split_by_storage_plan
[rank6]:             ^^^^^^^^^^^^^^^^^^^^^
[rank6]:  File "/usr/local/lib/python3.11/dist-packages/torch/distributed/checkpoint/state_dict_saver.py", line 463, in write_data
[rank6]:    all_writes = storage_writer.write_data(final_local_plan, planner)
[rank2]:[rank2]:     idx = storage_plan[key]
[rank6]:                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank6]:  File "/usr/local/lib/python3.11/dist-packages/torch/distributed/checkpoint/hf_storage.py", line 127, in write_data
[rank6]:    buckets = self._split_by_storage_plan(storage_plan, plan.items)
[rank6]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank2]:[rank2]:           ~~~~~~~~~~~~^^^^^
[rank2]:[rank2]: KeyError: 'model.layers.17.self_attn.q_proj.weight'
[rank2]:[rank2]: Traceback (most recent call last): (RANK 5)
[rank6]:  File "/usr/local/lib/python3.11/dist-packages/torch/distributed/checkpoint/hf_storage.py", line 189, in _split_by_storage_plan
[rank2]:[rank2]:   File "/usr/local/lib/python3.11/dist-packages/torch/distributed/checkpoint/utils.py", line 239, in all_reduce
[rank2]:[rank2]:     local_data = map_fun()
[rank6]:    idx = storage_plan[key]
[rank6]:          ~~~~~~~~~~~~^^^^^
[rank6]:KeyError: 'model.layers.17.self_attn.q_proj.weight'
[rank2]:[rank2]:                  ^^^^^^^^^
[rank6]:Traceback (most recent call last): (RANK 5)
[rank6]:  File "/usr/local/lib/python3.11/dist-packages/torch/distributed/checkpoint/utils.py", line 239, in all_reduce
[rank6]:    local_data = map_fun()
[rank6]:                 ^^^^^^^^^
[rank2]:[rank2]:   File "/usr/local/lib/python3.11/dist-packages/torch/distributed/checkpoint/logger.py", line 87, in wrapper
[rank6]:  File "/usr/local/lib/python3.11/dist-packages/torch/distributed/checkpoint/logger.py", line 87, in wrapper
[rank2]:[rank2]:     result = func(*args, **kwargs)
[rank2]:[rank2]:              ^^^^^^^^^^^^^^^^^^^^^
[rank2]:[rank2]:   File "/usr/local/lib/python3.11/dist-packages/torch/distributed/checkpoint/state_dict_saver.py", line 463, in write_data
[rank2]:[rank2]:     all_writes = storage_writer.write_data(final_local_plan, planner)
[rank6]:    result = func(*args, **kwargs)
[rank6]:             ^^^^^^^^^^^^^^^^^^^^^
[rank6]:  File "/usr/local/lib/python3.11/dist-packages/torch/distributed/checkpoint/state_dict_saver.py", line 463, in write_data
[rank2]:[rank2]:                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank2]:[rank2]:   File "/usr/local/lib/python3.11/dist-packages/torch/distributed/checkpoint/hf_storage.py", line 127, in write_data
[rank6]:    all_writes = storage_writer.write_data(final_local_plan, planner)
[rank6]:                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank6]:  File "/usr/local/lib/python3.11/dist-packages/torch/distributed/checkpoint/hf_storage.py", line 127, in write_data
[rank6]:    buckets = self._split_by_storage_plan(storage_plan, plan.items)
[rank2]:[rank2]:     buckets = self._split_by_storage_plan(storage_plan, plan.items)
[rank2]:[rank2]:               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank2]:[rank2]:   File "/usr/local/lib/python3.11/dist-packages/torch/distributed/checkpoint/hf_storage.py", line 189, in _split_by_storage_plan
[rank6]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank6]:  File "/usr/local/lib/python3.11/dist-packages/torch/distributed/checkpoint/hf_storage.py", line 189, in _split_by_storage_plan
[rank6]:    idx = storage_plan[key]
[rank2]:[rank2]:     idx = storage_plan[key]
[rank2]:[rank2]:           ~~~~~~~~~~~~^^^^^
[rank2]:[rank2]: KeyError: 'model.layers.17.self_attn.q_proj.weight'
[rank2]:[rank2]: Traceback (most recent call last): (RANK 6)
[rank6]:          ~~~~~~~~~~~~^^^^^
[rank6]:KeyError: 'model.layers.17.self_attn.q_proj.weight'
[rank2]:[rank2]:   File "/usr/local/lib/python3.11/dist-packages/torch/distributed/checkpoint/utils.py", line 239, in all_reduce
[rank2]:[rank2]:     local_data = map_fun()
[rank2]:[rank2]:                  ^^^^^^^^^
[rank2]:[rank2]:   File "/usr/local/lib/python3.11/dist-packages/torch/distributed/checkpoint/logger.py", line 87, in wrapper
[rank6]:Traceback (most recent call last): (RANK 6)
[rank6]:  File "/usr/local/lib/python3.11/dist-packages/torch/distributed/checkpoint/utils.py", line 239, in all_reduce
[rank6]:    local_data = map_fun()
[rank6]:                 ^^^^^^^^^
[rank6]:  File "/usr/local/lib/python3.11/dist-packages/torch/distributed/checkpoint/logger.py", line 87, in wrapper
[rank6]:    result = func(*args, **kwargs)
[rank6]:             ^^^^^^^^^^^^^^^^^^^^^
[rank2]:[rank2]:     result = func(*args, **kwargs)
[rank2]:[rank2]:              ^^^^^^^^^^^^^^^^^^^^^
[rank6]:  File "/usr/local/lib/python3.11/dist-packages/torch/distributed/checkpoint/state_dict_saver.py", line 463, in write_data
[rank6]:    all_writes = storage_writer.write_data(final_local_plan, planner)
[rank2]:[rank2]:   File "/usr/local/lib/python3.11/dist-packages/torch/distributed/checkpoint/state_dict_saver.py", line 463, in write_data
[rank6]:                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank2]:[rank2]:     all_writes = storage_writer.write_data(final_local_plan, planner)
[rank2]:[rank2]:                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank2]:[rank2]:   File "/usr/local/lib/python3.11/dist-packages/torch/distributed/checkpoint/hf_storage.py", line 127, in write_data
[rank2]:[rank2]:     buckets = self._split_by_storage_plan(storage_plan, plan.items)
[rank6]:  File "/usr/local/lib/python3.11/dist-packages/torch/distributed/checkpoint/hf_storage.py", line 127, in write_data
[rank6]:    buckets = self._split_by_storage_plan(storage_plan, plan.items)
[rank6]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank6]:  File "/usr/local/lib/python3.11/dist-packages/torch/distributed/checkpoint/hf_storage.py", line 189, in _split_by_storage_plan
[rank6]:    idx = storage_plan[key]
[rank2]:[rank2]:               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank6]:          ~~~~~~~~~~~~^^^^^
[rank6]:KeyError: 'model.layers.25.self_attn.q_proj.weight'
[rank2]:[rank2]:   File "/usr/local/lib/python3.11/dist-packages/torch/distributed/checkpoint/hf_storage.py", line 189, in _split_by_storage_plan
[rank2]:[rank2]:     idx = storage_plan[key]
[rank6]:Traceback (most recent call last): (RANK 7)
[rank6]:  File "/usr/local/lib/python3.11/dist-packages/torch/distributed/checkpoint/utils.py", line 239, in all_reduce
[rank2]:[rank2]:           ~~~~~~~~~~~~^^^^^
[rank2]:[rank2]: KeyError: 'model.layers.25.self_attn.q_proj.weight'
[rank2]:[rank2]: Traceback (most recent call last): (RANK 7)
[rank6]:    local_data = map_fun()
[rank2]:[rank2]:   File "/usr/local/lib/python3.11/dist-packages/torch/distributed/checkpoint/utils.py", line 239, in all_reduce
[rank2]:[rank2]:     local_data = map_fun()
[rank2]:[rank2]:                  ^^^^^^^^^
[rank2]:[rank2]:   File "/usr/local/lib/python3.11/dist-packages/torch/distributed/checkpoint/logger.py", line 87, in wrapper
[rank2]:[rank2]:     result = func(*args, **kwargs)
[rank6]:                 ^^^^^^^^^
[rank6]:  File "/usr/local/lib/python3.11/dist-packages/torch/distributed/checkpoint/logger.py", line 87, in wrapper
[rank6]:    result = func(*args, **kwargs)
[rank6]:             ^^^^^^^^^^^^^^^^^^^^^
[rank2]:[rank2]:              ^^^^^^^^^^^^^^^^^^^^^
[rank2]:[rank2]:   File "/usr/local/lib/python3.11/dist-packages/torch/distributed/checkpoint/state_dict_saver.py", line 463, in write_data
[rank6]:  File "/usr/local/lib/python3.11/dist-packages/torch/distributed/checkpoint/state_dict_saver.py", line 463, in write_data
[rank6]:    all_writes = storage_writer.write_data(final_local_plan, planner)
[rank2]:[rank2]:     all_writes = storage_writer.write_data(final_local_plan, planner)
[rank2]:[rank2]:                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank2]:[rank2]:   File "/usr/local/lib/python3.11/dist-packages/torch/distributed/checkpoint/hf_storage.py", line 127, in write_data
[rank2]:[rank2]:     buckets = self._split_by_storage_plan(storage_plan, plan.items)
[rank2]:[rank2]:               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank6]:                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank6]:  File "/usr/local/lib/python3.11/dist-packages/torch/distributed/checkpoint/hf_storage.py", line 127, in write_data
[rank6]:    buckets = self._split_by_storage_plan(storage_plan, plan.items)
[rank6]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank2]:[rank2]:   File "/usr/local/lib/python3.11/dist-packages/torch/distributed/checkpoint/hf_storage.py", line 189, in _split_by_storage_plan
[rank6]:  File "/usr/local/lib/python3.11/dist-packages/torch/distributed/checkpoint/hf_storage.py", line 189, in _split_by_storage_plan
[rank6]:    idx = storage_plan[key]
[rank2]:[rank2]:     idx = storage_plan[key]
[rank2]:[rank2]:           ~~~~~~~~~~~~^^^^^
[rank6]:          ~~~~~~~~~~~~^^^^^
[rank6]:KeyError: 'model.layers.25.self_attn.q_proj.weight'
[rank2]:[rank2]: KeyError: 'model.layers.25.self_attn.q_proj.weight'
[rank6]:
[rank6]:[rank6]: Traceback (most recent call last):
[rank2]:
[rank6]:[rank6]:   File "<frozen runpy>", line 198, in _run_module_as_main
[rank6]:[rank6]:   File "<frozen runpy>", line 88, in _run_code
[rank6]:[rank6]:   File "/workspace/torchtitan/timelyfreeze/train.py", line 727, in <module>
[rank6]:[rank6]:     trainer.train()
[rank6]:[rank6]:   File "/usr/local/lib/python3.11/dist-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 357, in wrapper
[rank6]:[rank6]:     return f(*args, **kwargs)
[rank6]:[rank6]:            ^^^^^^^^^^^^^^^^^^
[rank6]:[rank6]:   File "/workspace/torchtitan/timelyfreeze/train.py", line 586, in train
[rank6]:[rank6]:     self.checkpointer.save(
[rank6]:[rank6]:   File "/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[rank6]:[rank6]:     return func(*args, **kwargs)
[rank6]:[rank6]:            ^^^^^^^^^^^^^^^^^^^^^
[rank6]:[rank6]:   File "/workspace/torchtitan/torchtitan/components/checkpoint.py", line 479, in save
[rank6]:[rank6]:     self._save_last_step(curr_step)
[rank6]:[rank6]:   File "/workspace/torchtitan/torchtitan/components/checkpoint.py", line 733, in _save_last_step
[rank6]:[rank6]:     self.dcp_save(
[rank6]:[rank6]:   File "/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[rank6]:[rank6]:     return func(*args, **kwargs)
[rank6]:[rank6]:            ^^^^^^^^^^^^^^^^^^^^^
[rank6]:[rank6]:   File "/workspace/torchtitan/torchtitan/components/checkpoint.py", line 401, in dcp_save
[rank6]:[rank6]:     ret = dcp.save(
[rank6]:[rank6]:           ^^^^^^^^^
[rank6]:[rank6]:   File "/usr/local/lib/python3.11/dist-packages/torch/distributed/checkpoint/logger.py", line 87, in wrapper
[rank6]:[rank6]:     result = func(*args, **kwargs)
[rank6]:[rank6]:              ^^^^^^^^^^^^^^^^^^^^^
[rank6]:[rank6]:   File "/usr/local/lib/python3.11/dist-packages/torch/distributed/checkpoint/utils.py", line 475, in inner_func
[rank6]:[rank6]:     return func(*args, **kwargs)
[rank6]:[rank6]:            ^^^^^^^^^^^^^^^^^^^^^
[rank6]:[rank6]:   File "/usr/local/lib/python3.11/dist-packages/torch/distributed/checkpoint/state_dict_saver.py", line 193, in save
[rank6]:[rank6]:     return _save_state_dict(
[rank6]:[rank6]:            ^^^^^^^^^^^^^^^^^
[rank6]:[rank6]:   File "/usr/local/lib/python3.11/dist-packages/torch/distributed/checkpoint/state_dict_saver.py", line 475, in _save_state_dict
[rank6]:[rank6]:     metadata = distW.all_reduce("write", write_data, finish_checkpoint)
[rank6]:[rank6]:                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank6]:[rank6]:   File "/usr/local/lib/python3.11/dist-packages/torch/distributed/checkpoint/utils.py", line 259, in all_reduce
[rank6]:[rank6]:     raise final_result
[rank6]:[rank6]: torch.distributed.checkpoint.api.CheckpointException: CheckpointException ranks:dict_keys([2, 3, 4, 5, 6, 7])
[rank6]:[rank6]: Traceback (most recent call last): (RANK 2)
[rank6]:[rank6]:   File "/usr/local/lib/python3.11/dist-packages/torch/distributed/checkpoint/utils.py", line 239, in all_reduce
[rank6]:[rank6]:     local_data = map_fun()
[rank6]:[rank6]:                  ^^^^^^^^^
[rank6]:[rank6]:   File "/usr/local/lib/python3.11/dist-packages/torch/distributed/checkpoint/logger.py", line 87, in wrapper
[rank6]:[rank6]:     result = func(*args, **kwargs)
[rank6]:[rank6]:              ^^^^^^^^^^^^^^^^^^^^^
[rank6]:[rank6]:   File "/usr/local/lib/python3.11/dist-packages/torch/distributed/checkpoint/state_dict_saver.py", line 463, in write_data
[rank6]:[rank6]:     all_writes = storage_writer.write_data(final_local_plan, planner)
[rank6]:[rank6]:                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank6]:[rank6]:   File "/usr/local/lib/python3.11/dist-packages/torch/distributed/checkpoint/hf_storage.py", line 127, in write_data
[rank6]:[rank6]:     buckets = self._split_by_storage_plan(storage_plan, plan.items)
[rank6]:[rank6]:               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank6]:[rank6]:   File "/usr/local/lib/python3.11/dist-packages/torch/distributed/checkpoint/hf_storage.py", line 189, in _split_by_storage_plan
[rank6]:[rank6]:     idx = storage_plan[key]
[rank6]:[rank6]:           ~~~~~~~~~~~~^^^^^
[rank6]:[rank6]: KeyError: 'model.layers.8.self_attn.q_proj.weight'
[rank6]:[rank6]: Traceback (most recent call last): (RANK 3)
[rank6]:[rank6]:   File "/usr/local/lib/python3.11/dist-packages/torch/distributed/checkpoint/utils.py", line 239, in all_reduce
[rank6]:[rank6]:     local_data = map_fun()
[rank6]:[rank6]:                  ^^^^^^^^^
[rank6]:[rank6]:   File "/usr/local/lib/python3.11/dist-packages/torch/distributed/checkpoint/logger.py", line 87, in wrapper
[rank6]:[rank6]:     result = func(*args, **kwargs)
[rank6]:[rank6]:              ^^^^^^^^^^^^^^^^^^^^^
[rank6]:[rank6]:   File "/usr/local/lib/python3.11/dist-packages/torch/distributed/checkpoint/state_dict_saver.py", line 463, in write_data
[rank6]:[rank6]:     all_writes = storage_writer.write_data(final_local_plan, planner)
[rank6]:[rank6]:                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank6]:[rank6]:   File "/usr/local/lib/python3.11/dist-packages/torch/distributed/checkpoint/hf_storage.py", line 127, in write_data
[rank6]:[rank6]:     buckets = self._split_by_storage_plan(storage_plan, plan.items)
[rank6]:[rank6]:               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank6]:[rank6]:   File "/usr/local/lib/python3.11/dist-packages/torch/distributed/checkpoint/hf_storage.py", line 189, in _split_by_storage_plan
[rank6]:[rank6]:     idx = storage_plan[key]
[rank6]:[rank6]:           ~~~~~~~~~~~~^^^^^
[rank6]:[rank6]: KeyError: 'model.layers.8.self_attn.q_proj.weight'
[rank6]:[rank6]: Traceback (most recent call last): (RANK 4)
[rank6]:[rank6]:   File "/usr/local/lib/python3.11/dist-packages/torch/distributed/checkpoint/utils.py", line 239, in all_reduce
[rank6]:[rank6]:     local_data = map_fun()
[rank6]:[rank6]:                  ^^^^^^^^^
[rank6]:[rank6]:   File "/usr/local/lib/python3.11/dist-packages/torch/distributed/checkpoint/logger.py", line 87, in wrapper
[rank6]:[rank6]:     result = func(*args, **kwargs)
[rank6]:[rank6]:              ^^^^^^^^^^^^^^^^^^^^^
[rank6]:[rank6]:   File "/usr/local/lib/python3.11/dist-packages/torch/distributed/checkpoint/state_dict_saver.py", line 463, in write_data
[rank6]:[rank6]:     all_writes = storage_writer.write_data(final_local_plan, planner)
[rank6]:[rank6]:                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank6]:[rank6]:   File "/usr/local/lib/python3.11/dist-packages/torch/distributed/checkpoint/hf_storage.py", line 127, in write_data
[rank6]:[rank6]:     buckets = self._split_by_storage_plan(storage_plan, plan.items)
[rank6]:[rank6]:               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank6]:[rank6]:   File "/usr/local/lib/python3.11/dist-packages/torch/distributed/checkpoint/hf_storage.py", line 189, in _split_by_storage_plan
[rank6]:[rank6]:     idx = storage_plan[key]
[rank6]:[rank6]:           ~~~~~~~~~~~~^^^^^
[rank6]:[rank6]: KeyError: 'model.layers.17.self_attn.q_proj.weight'
[rank6]:[rank6]: Traceback (most recent call last): (RANK 5)
[rank6]:[rank6]:   File "/usr/local/lib/python3.11/dist-packages/torch/distributed/checkpoint/utils.py", line 239, in all_reduce
[rank6]:[rank6]:     local_data = map_fun()
[rank6]:[rank6]:                  ^^^^^^^^^
[rank6]:[rank6]:   File "/usr/local/lib/python3.11/dist-packages/torch/distributed/checkpoint/logger.py", line 87, in wrapper
[rank6]:[rank6]:     result = func(*args, **kwargs)
[rank6]:[rank6]:              ^^^^^^^^^^^^^^^^^^^^^
[rank6]:[rank6]:   File "/usr/local/lib/python3.11/dist-packages/torch/distributed/checkpoint/state_dict_saver.py", line 463, in write_data
[rank6]:[rank6]:     all_writes = storage_writer.write_data(final_local_plan, planner)
[rank6]:[rank6]:                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank6]:[rank6]:   File "/usr/local/lib/python3.11/dist-packages/torch/distributed/checkpoint/hf_storage.py", line 127, in write_data
[rank6]:[rank6]:     buckets = self._split_by_storage_plan(storage_plan, plan.items)
[rank6]:[rank6]:               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank6]:[rank6]:   File "/usr/local/lib/python3.11/dist-packages/torch/distributed/checkpoint/hf_storage.py", line 189, in _split_by_storage_plan
[rank6]:[rank6]:     idx = storage_plan[key]
[rank6]:[rank6]:           ~~~~~~~~~~~~^^^^^
[rank6]:[rank6]: KeyError: 'model.layers.17.self_attn.q_proj.weight'
[rank6]:[rank6]: Traceback (most recent call last): (RANK 6)
[rank6]:[rank6]:   File "/usr/local/lib/python3.11/dist-packages/torch/distributed/checkpoint/utils.py", line 239, in all_reduce
[rank6]:[rank6]:     local_data = map_fun()
[rank6]:[rank6]:                  ^^^^^^^^^
[rank6]:[rank6]:   File "/usr/local/lib/python3.11/dist-packages/torch/distributed/checkpoint/logger.py", line 87, in wrapper
[rank6]:[rank6]:     result = func(*args, **kwargs)
[rank6]:[rank6]:              ^^^^^^^^^^^^^^^^^^^^^
[rank6]:[rank6]:   File "/usr/local/lib/python3.11/dist-packages/torch/distributed/checkpoint/state_dict_saver.py", line 463, in write_data
[rank6]:[rank6]:     all_writes = storage_writer.write_data(final_local_plan, planner)
[rank6]:[rank6]:                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank6]:[rank6]:   File "/usr/local/lib/python3.11/dist-packages/torch/distributed/checkpoint/hf_storage.py", line 127, in write_data
[rank6]:[rank6]:     buckets = self._split_by_storage_plan(storage_plan, plan.items)
[rank6]:[rank6]:               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank6]:[rank6]:   File "/usr/local/lib/python3.11/dist-packages/torch/distributed/checkpoint/hf_storage.py", line 189, in _split_by_storage_plan
[rank6]:[rank6]:     idx = storage_plan[key]
[rank6]:[rank6]:           ~~~~~~~~~~~~^^^^^
[rank6]:[rank6]: KeyError: 'model.layers.25.self_attn.q_proj.weight'
[rank6]:[rank6]: Traceback (most recent call last): (RANK 7)
[rank6]:[rank6]:   File "/usr/local/lib/python3.11/dist-packages/torch/distributed/checkpoint/utils.py", line 239, in all_reduce
[rank6]:[rank6]:     local_data = map_fun()
[rank6]:[rank6]:                  ^^^^^^^^^
[rank6]:[rank6]:   File "/usr/local/lib/python3.11/dist-packages/torch/distributed/checkpoint/logger.py", line 87, in wrapper
[rank6]:[rank6]:     result = func(*args, **kwargs)
[rank6]:[rank6]:              ^^^^^^^^^^^^^^^^^^^^^
[rank6]:[rank6]:   File "/usr/local/lib/python3.11/dist-packages/torch/distributed/checkpoint/state_dict_saver.py", line 463, in write_data
[rank6]:[rank6]:     all_writes = storage_writer.write_data(final_local_plan, planner)
[rank6]:[rank6]:                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank6]:[rank6]:   File "/usr/local/lib/python3.11/dist-packages/torch/distributed/checkpoint/hf_storage.py", line 127, in write_data
[rank6]:[rank6]:     buckets = self._split_by_storage_plan(storage_plan, plan.items)
[rank6]:[rank6]:               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank6]:[rank6]:   File "/usr/local/lib/python3.11/dist-packages/torch/distributed/checkpoint/hf_storage.py", line 189, in _split_by_storage_plan
[rank6]:[rank6]:     idx = storage_plan[key]
[rank6]:[rank6]:           ~~~~~~~~~~~~^^^^^
[rank6]:[rank6]: KeyError: 'model.layers.25.self_attn.q_proj.weight'
[rank6]:
[rank1]:[rank1]: Traceback (most recent call last):
[rank1]:[rank1]:   File "<frozen runpy>", line 198, in _run_module_as_main
[rank1]:[rank1]:   File "<frozen runpy>", line 88, in _run_code
[rank1]:[rank1]:   File "/workspace/torchtitan/timelyfreeze/train.py", line 727, in <module>
[rank1]:[rank1]:     trainer.train()
[rank1]:[rank1]:   File "/usr/local/lib/python3.11/dist-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 357, in wrapper
[rank1]:[rank1]:     return f(*args, **kwargs)
[rank1]:[rank1]:            ^^^^^^^^^^^^^^^^^^
[rank1]:[rank1]:   File "/workspace/torchtitan/timelyfreeze/train.py", line 586, in train
[rank1]:[rank1]:     self.checkpointer.save(
[rank1]:[rank1]:   File "/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[rank1]:[rank1]:     return func(*args, **kwargs)
[rank1]:[rank1]:            ^^^^^^^^^^^^^^^^^^^^^
[rank1]:[rank1]:   File "/workspace/torchtitan/torchtitan/components/checkpoint.py", line 479, in save
[rank1]:[rank1]:     self._save_last_step(curr_step)
[rank1]:[rank1]:   File "/workspace/torchtitan/torchtitan/components/checkpoint.py", line 733, in _save_last_step
[rank1]:[rank1]:     self.dcp_save(
[rank1]:[rank1]:   File "/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[rank1]:[rank1]:     return func(*args, **kwargs)
[rank1]:[rank1]:            ^^^^^^^^^^^^^^^^^^^^^
[rank1]:[rank1]:   File "/workspace/torchtitan/torchtitan/components/checkpoint.py", line 401, in dcp_save
[rank1]:[rank1]:     ret = dcp.save(
[rank1]:[rank1]:           ^^^^^^^^^
[rank1]:[rank1]:   File "/usr/local/lib/python3.11/dist-packages/torch/distributed/checkpoint/logger.py", line 87, in wrapper
[rank1]:[rank1]:     result = func(*args, **kwargs)
[rank1]:[rank1]:              ^^^^^^^^^^^^^^^^^^^^^
[rank1]:[rank1]:   File "/usr/local/lib/python3.11/dist-packages/torch/distributed/checkpoint/utils.py", line 475, in inner_func
[rank1]:[rank1]:     return func(*args, **kwargs)
[rank1]:[rank1]:            ^^^^^^^^^^^^^^^^^^^^^
[rank1]:[rank1]:   File "/usr/local/lib/python3.11/dist-packages/torch/distributed/checkpoint/state_dict_saver.py", line 193, in save
[rank1]:[rank1]:     return _save_state_dict(
[rank1]:[rank1]:            ^^^^^^^^^^^^^^^^^
[rank1]:[rank1]:   File "/usr/local/lib/python3.11/dist-packages/torch/distributed/checkpoint/state_dict_saver.py", line 475, in _save_state_dict
[rank1]:[rank1]:     metadata = distW.all_reduce("write", write_data, finish_checkpoint)
[rank1]:[rank1]:                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank1]:[rank1]:   File "/usr/local/lib/python3.11/dist-packages/torch/distributed/checkpoint/utils.py", line 259, in all_reduce
[rank1]:[rank1]:     raise final_result
[rank1]:[rank1]: torch.distributed.checkpoint.api.CheckpointException: CheckpointException ranks:dict_keys([2, 3, 4, 5, 6, 7])
[rank1]:[rank1]: Traceback (most recent call last): (RANK 2)
[rank1]:[rank1]:   File "/usr/local/lib/python3.11/dist-packages/torch/distributed/checkpoint/utils.py", line 239, in all_reduce
[rank1]:[rank1]:     local_data = map_fun()
[rank1]:[rank1]:                  ^^^^^^^^^
[rank1]:[rank1]:   File "/usr/local/lib/python3.11/dist-packages/torch/distributed/checkpoint/logger.py", line 87, in wrapper
[rank1]:[rank1]:     result = func(*args, **kwargs)
[rank1]:[rank1]:              ^^^^^^^^^^^^^^^^^^^^^
[rank1]:[rank1]:   File "/usr/local/lib/python3.11/dist-packages/torch/distributed/checkpoint/state_dict_saver.py", line 463, in write_data
[rank1]:[rank1]:     all_writes = storage_writer.write_data(final_local_plan, planner)
[rank1]:[rank1]:                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank1]:[rank1]:   File "/usr/local/lib/python3.11/dist-packages/torch/distributed/checkpoint/hf_storage.py", line 127, in write_data
[rank1]:[rank1]:     buckets = self._split_by_storage_plan(storage_plan, plan.items)
[rank1]:[rank1]:               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank1]:[rank1]:   File "/usr/local/lib/python3.11/dist-packages/torch/distributed/checkpoint/hf_storage.py", line 189, in _split_by_storage_plan
[rank1]:[rank1]:     idx = storage_plan[key]
[rank1]:[rank1]:           ~~~~~~~~~~~~^^^^^
[rank1]:[rank1]: KeyError: 'model.layers.8.self_attn.q_proj.weight'
[rank1]:[rank1]: Traceback (most recent call last): (RANK 3)
[rank1]:[rank1]:   File "/usr/local/lib/python3.11/dist-packages/torch/distributed/checkpoint/utils.py", line 239, in all_reduce
[rank1]:[rank1]:     local_data = map_fun()
[rank1]:[rank1]:                  ^^^^^^^^^
[rank1]:[rank1]:   File "/usr/local/lib/python3.11/dist-packages/torch/distributed/checkpoint/logger.py", line 87, in wrapper
[rank1]:[rank1]:     result = func(*args, **kwargs)
[rank1]:[rank1]:              ^^^^^^^^^^^^^^^^^^^^^
[rank1]:[rank1]:   File "/usr/local/lib/python3.11/dist-packages/torch/distributed/checkpoint/state_dict_saver.py", line 463, in write_data
[rank1]:[rank1]:     all_writes = storage_writer.write_data(final_local_plan, planner)
[rank1]:[rank1]:                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank1]:[rank1]:   File "/usr/local/lib/python3.11/dist-packages/torch/distributed/checkpoint/hf_storage.py", line 127, in write_data
[rank1]:[rank1]:     buckets = self._split_by_storage_plan(storage_plan, plan.items)
[rank1]:[rank1]:               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank1]:[rank1]:   File "/usr/local/lib/python3.11/dist-packages/torch/distributed/checkpoint/hf_storage.py", line 189, in _split_by_storage_plan
[rank1]:[rank1]:     idx = storage_plan[key]
[rank1]:[rank1]:           ~~~~~~~~~~~~^^^^^
[rank1]:[rank1]: KeyError: 'model.layers.8.self_attn.q_proj.weight'
[rank1]:[rank1]: Traceback (most recent call last): (RANK 4)
[rank1]:[rank1]:   File "/usr/local/lib/python3.11/dist-packages/torch/distributed/checkpoint/utils.py", line 239, in all_reduce
[rank1]:[rank1]:     local_data = map_fun()
[rank1]:[rank1]:                  ^^^^^^^^^
[rank1]:[rank1]:   File "/usr/local/lib/python3.11/dist-packages/torch/distributed/checkpoint/logger.py", line 87, in wrapper
[rank1]:[rank1]:     result = func(*args, **kwargs)
[rank1]:[rank1]:              ^^^^^^^^^^^^^^^^^^^^^
[rank1]:[rank1]:   File "/usr/local/lib/python3.11/dist-packages/torch/distributed/checkpoint/state_dict_saver.py", line 463, in write_data
[rank1]:[rank1]:     all_writes = storage_writer.write_data(final_local_plan, planner)
[rank1]:[rank1]:                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank1]:[rank1]:   File "/usr/local/lib/python3.11/dist-packages/torch/distributed/checkpoint/hf_storage.py", line 127, in write_data
[rank1]:[rank1]:     buckets = self._split_by_storage_plan(storage_plan, plan.items)
[rank1]:[rank1]:               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank1]:[rank1]:   File "/usr/local/lib/python3.11/dist-packages/torch/distributed/checkpoint/hf_storage.py", line 189, in _split_by_storage_plan
[rank1]:[rank1]:     idx = storage_plan[key]
[rank1]:[rank1]:           ~~~~~~~~~~~~^^^^^
[rank1]:[rank1]: KeyError: 'model.layers.17.self_attn.q_proj.weight'
[rank1]:[rank1]: Traceback (most recent call last): (RANK 5)
[rank1]:[rank1]:   File "/usr/local/lib/python3.11/dist-packages/torch/distributed/checkpoint/utils.py", line 239, in all_reduce
[rank1]:[rank1]:     local_data = map_fun()
[rank1]:[rank1]:                  ^^^^^^^^^
[rank1]:[rank1]:   File "/usr/local/lib/python3.11/dist-packages/torch/distributed/checkpoint/logger.py", line 87, in wrapper
[rank1]:[rank1]:     result = func(*args, **kwargs)
[rank1]:[rank1]:              ^^^^^^^^^^^^^^^^^^^^^
[rank1]:[rank1]:   File "/usr/local/lib/python3.11/dist-packages/torch/distributed/checkpoint/state_dict_saver.py", line 463, in write_data
[rank1]:[rank1]:     all_writes = storage_writer.write_data(final_local_plan, planner)
[rank1]:[rank1]:                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank1]:[rank1]:   File "/usr/local/lib/python3.11/dist-packages/torch/distributed/checkpoint/hf_storage.py", line 127, in write_data
[rank1]:[rank1]:     buckets = self._split_by_storage_plan(storage_plan, plan.items)
[rank1]:[rank1]:               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank1]:[rank1]:   File "/usr/local/lib/python3.11/dist-packages/torch/distributed/checkpoint/hf_storage.py", line 189, in _split_by_storage_plan
[rank1]:[rank1]:     idx = storage_plan[key]
[rank1]:[rank1]:           ~~~~~~~~~~~~^^^^^
[rank1]:[rank1]: KeyError: 'model.layers.17.self_attn.q_proj.weight'
[rank1]:[rank1]: Traceback (most recent call last): (RANK 6)
[rank1]:[rank1]:   File "/usr/local/lib/python3.11/dist-packages/torch/distributed/checkpoint/utils.py", line 239, in all_reduce
[rank1]:[rank1]:     local_data = map_fun()
[rank1]:[rank1]:                  ^^^^^^^^^
[rank1]:[rank1]:   File "/usr/local/lib/python3.11/dist-packages/torch/distributed/checkpoint/logger.py", line 87, in wrapper
[rank1]:[rank1]:     result = func(*args, **kwargs)
[rank1]:[rank1]:              ^^^^^^^^^^^^^^^^^^^^^
[rank1]:[rank1]:   File "/usr/local/lib/python3.11/dist-packages/torch/distributed/checkpoint/state_dict_saver.py", line 463, in write_data
[rank1]:[rank1]:     all_writes = storage_writer.write_data(final_local_plan, planner)
[rank1]:[rank1]:                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank1]:[rank1]:   File "/usr/local/lib/python3.11/dist-packages/torch/distributed/checkpoint/hf_storage.py", line 127, in write_data
[rank1]:[rank1]:     buckets = self._split_by_storage_plan(storage_plan, plan.items)
[rank1]:[rank1]:               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank1]:[rank1]:   File "/usr/local/lib/python3.11/dist-packages/torch/distributed/checkpoint/hf_storage.py", line 189, in _split_by_storage_plan
[rank1]:[rank1]:     idx = storage_plan[key]
[rank1]:[rank1]:           ~~~~~~~~~~~~^^^^^
[rank1]:[rank1]: KeyError: 'model.layers.25.self_attn.q_proj.weight'
[rank1]:[rank1]: Traceback (most recent call last): (RANK 7)
[rank1]:[rank1]:   File "/usr/local/lib/python3.11/dist-packages/torch/distributed/checkpoint/utils.py", line 239, in all_reduce
[rank1]:[rank1]:     local_data = map_fun()
[rank1]:[rank1]:                  ^^^^^^^^^
[rank1]:[rank1]:   File "/usr/local/lib/python3.11/dist-packages/torch/distributed/checkpoint/logger.py", line 87, in wrapper
[rank1]:[rank1]:     result = func(*args, **kwargs)
[rank1]:[rank1]:              ^^^^^^^^^^^^^^^^^^^^^
[rank1]:[rank1]:   File "/usr/local/lib/python3.11/dist-packages/torch/distributed/checkpoint/state_dict_saver.py", line 463, in write_data
[rank1]:[rank1]:     all_writes = storage_writer.write_data(final_local_plan, planner)
[rank1]:[rank1]:                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank1]:[rank1]:   File "/usr/local/lib/python3.11/dist-packages/torch/distributed/checkpoint/hf_storage.py", line 127, in write_data
[rank1]:[rank1]:     buckets = self._split_by_storage_plan(storage_plan, plan.items)
[rank1]:[rank1]:               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank1]:[rank1]:   File "/usr/local/lib/python3.11/dist-packages/torch/distributed/checkpoint/hf_storage.py", line 189, in _split_by_storage_plan
[rank1]:[rank1]:     idx = storage_plan[key]
[rank1]:[rank1]:           ~~~~~~~~~~~~^^^^^
[rank1]:[rank1]: KeyError: 'model.layers.25.self_attn.q_proj.weight'
[rank1]:
[rank4]:[rank4]: Traceback (most recent call last):
[rank4]:[rank4]:   File "<frozen runpy>", line 198, in _run_module_as_main
[rank4]:[rank4]:   File "<frozen runpy>", line 88, in _run_code
[rank4]:[rank4]:   File "/workspace/torchtitan/timelyfreeze/train.py", line 727, in <module>
[rank4]:[rank4]:     trainer.train()
[rank4]:[rank4]:   File "/usr/local/lib/python3.11/dist-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 357, in wrapper
[rank4]:[rank4]:     return f(*args, **kwargs)
[rank4]:[rank4]:            ^^^^^^^^^^^^^^^^^^
[rank4]:[rank4]:   File "/workspace/torchtitan/timelyfreeze/train.py", line 586, in train
[rank4]:[rank4]:     self.checkpointer.save(
[rank4]:[rank4]:   File "/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[rank4]:[rank4]:     return func(*args, **kwargs)
[rank4]:[rank4]:            ^^^^^^^^^^^^^^^^^^^^^
[rank4]:[rank4]:   File "/workspace/torchtitan/torchtitan/components/checkpoint.py", line 479, in save
[rank4]:[rank4]:     self._save_last_step(curr_step)
[rank4]:[rank4]:   File "/workspace/torchtitan/torchtitan/components/checkpoint.py", line 733, in _save_last_step
[rank4]:[rank4]:     self.dcp_save(
[rank4]:[rank4]:   File "/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[rank4]:[rank4]:     return func(*args, **kwargs)
[rank4]:[rank4]:            ^^^^^^^^^^^^^^^^^^^^^
[rank4]:[rank4]:   File "/workspace/torchtitan/torchtitan/components/checkpoint.py", line 401, in dcp_save
[rank4]:[rank4]:     ret = dcp.save(
[rank4]:[rank4]:           ^^^^^^^^^
[rank4]:[rank4]:   File "/usr/local/lib/python3.11/dist-packages/torch/distributed/checkpoint/logger.py", line 87, in wrapper
[rank4]:[rank4]:     result = func(*args, **kwargs)
[rank4]:[rank4]:              ^^^^^^^^^^^^^^^^^^^^^
[rank4]:[rank4]:   File "/usr/local/lib/python3.11/dist-packages/torch/distributed/checkpoint/utils.py", line 475, in inner_func
[rank4]:[rank4]:     return func(*args, **kwargs)
[rank4]:[rank4]:            ^^^^^^^^^^^^^^^^^^^^^
[rank4]:[rank4]:   File "/usr/local/lib/python3.11/dist-packages/torch/distributed/checkpoint/state_dict_saver.py", line 193, in save
[rank4]:[rank4]:     return _save_state_dict(
[rank4]:[rank4]:            ^^^^^^^^^^^^^^^^^
[rank4]:[rank4]:   File "/usr/local/lib/python3.11/dist-packages/torch/distributed/checkpoint/state_dict_saver.py", line 475, in _save_state_dict
[rank4]:[rank4]:     metadata = distW.all_reduce("write", write_data, finish_checkpoint)
[rank4]:[rank4]:                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank4]:[rank4]:   File "/usr/local/lib/python3.11/dist-packages/torch/distributed/checkpoint/utils.py", line 259, in all_reduce
[rank4]:[rank4]:     raise final_result
[rank4]:[rank4]: torch.distributed.checkpoint.api.CheckpointException: CheckpointException ranks:dict_keys([2, 3, 4, 5, 6, 7])
[rank4]:[rank4]: Traceback (most recent call last): (RANK 2)
[rank4]:[rank4]:   File "/usr/local/lib/python3.11/dist-packages/torch/distributed/checkpoint/utils.py", line 239, in all_reduce
[rank4]:[rank4]:     local_data = map_fun()
[rank4]:[rank4]:                  ^^^^^^^^^
[rank4]:[rank4]:   File "/usr/local/lib/python3.11/dist-packages/torch/distributed/checkpoint/logger.py", line 87, in wrapper
[rank4]:[rank4]:     result = func(*args, **kwargs)
[rank4]:[rank4]:              ^^^^^^^^^^^^^^^^^^^^^
[rank4]:[rank4]:   File "/usr/local/lib/python3.11/dist-packages/torch/distributed/checkpoint/state_dict_saver.py", line 463, in write_data
[rank4]:[rank4]:     all_writes = storage_writer.write_data(final_local_plan, planner)
[rank4]:[rank4]:                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank4]:[rank4]:   File "/usr/local/lib/python3.11/dist-packages/torch/distributed/checkpoint/hf_storage.py", line 127, in write_data
[rank4]:[rank4]:     buckets = self._split_by_storage_plan(storage_plan, plan.items)
[rank4]:[rank4]:               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank4]:[rank4]:   File "/usr/local/lib/python3.11/dist-packages/torch/distributed/checkpoint/hf_storage.py", line 189, in _split_by_storage_plan
[rank4]:[rank4]:     idx = storage_plan[key]
[rank4]:[rank4]:           ~~~~~~~~~~~~^^^^^
[rank4]:[rank4]: KeyError: 'model.layers.8.self_attn.q_proj.weight'
[rank4]:[rank4]: Traceback (most recent call last): (RANK 3)
[rank4]:[rank4]:   File "/usr/local/lib/python3.11/dist-packages/torch/distributed/checkpoint/utils.py", line 239, in all_reduce
[rank4]:[rank4]:     local_data = map_fun()
[rank4]:[rank4]:                  ^^^^^^^^^
[rank4]:[rank4]:   File "/usr/local/lib/python3.11/dist-packages/torch/distributed/checkpoint/logger.py", line 87, in wrapper
[rank4]:[rank4]:     result = func(*args, **kwargs)
[rank4]:[rank4]:              ^^^^^^^^^^^^^^^^^^^^^
[rank4]:[rank4]:   File "/usr/local/lib/python3.11/dist-packages/torch/distributed/checkpoint/state_dict_saver.py", line 463, in write_data
[rank4]:[rank4]:     all_writes = storage_writer.write_data(final_local_plan, planner)
[rank4]:[rank4]:                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank4]:[rank4]:   File "/usr/local/lib/python3.11/dist-packages/torch/distributed/checkpoint/hf_storage.py", line 127, in write_data
[rank4]:[rank4]:     buckets = self._split_by_storage_plan(storage_plan, plan.items)
[rank4]:[rank4]:               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank4]:[rank4]:   File "/usr/local/lib/python3.11/dist-packages/torch/distributed/checkpoint/hf_storage.py", line 189, in _split_by_storage_plan
[rank4]:[rank4]:     idx = storage_plan[key]
[rank4]:[rank4]:           ~~~~~~~~~~~~^^^^^
[rank4]:[rank4]: KeyError: 'model.layers.8.self_attn.q_proj.weight'
[rank4]:[rank4]: Traceback (most recent call last): (RANK 4)
[rank4]:[rank4]:   File "/usr/local/lib/python3.11/dist-packages/torch/distributed/checkpoint/utils.py", line 239, in all_reduce
[rank4]:[rank4]:     local_data = map_fun()
[rank4]:[rank4]:                  ^^^^^^^^^
[rank4]:[rank4]:   File "/usr/local/lib/python3.11/dist-packages/torch/distributed/checkpoint/logger.py", line 87, in wrapper
[rank4]:[rank4]:     result = func(*args, **kwargs)
[rank4]:[rank4]:              ^^^^^^^^^^^^^^^^^^^^^
[rank4]:[rank4]:   File "/usr/local/lib/python3.11/dist-packages/torch/distributed/checkpoint/state_dict_saver.py", line 463, in write_data
[rank4]:[rank4]:     all_writes = storage_writer.write_data(final_local_plan, planner)
[rank4]:[rank4]:                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank4]:[rank4]:   File "/usr/local/lib/python3.11/dist-packages/torch/distributed/checkpoint/hf_storage.py", line 127, in write_data
[rank4]:[rank4]:     buckets = self._split_by_storage_plan(storage_plan, plan.items)
[rank4]:[rank4]:               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank4]:[rank4]:   File "/usr/local/lib/python3.11/dist-packages/torch/distributed/checkpoint/hf_storage.py", line 189, in _split_by_storage_plan
[rank4]:[rank4]:     idx = storage_plan[key]
[rank4]:[rank4]:           ~~~~~~~~~~~~^^^^^
[rank4]:[rank4]: KeyError: 'model.layers.17.self_attn.q_proj.weight'
[rank4]:[rank4]: Traceback (most recent call last): (RANK 5)
[rank4]:[rank4]:   File "/usr/local/lib/python3.11/dist-packages/torch/distributed/checkpoint/utils.py", line 239, in all_reduce
[rank4]:[rank4]:     local_data = map_fun()
[rank4]:[rank4]:                  ^^^^^^^^^
[rank4]:[rank4]:   File "/usr/local/lib/python3.11/dist-packages/torch/distributed/checkpoint/logger.py", line 87, in wrapper
[rank4]:[rank4]:     result = func(*args, **kwargs)
[rank4]:[rank4]:              ^^^^^^^^^^^^^^^^^^^^^
[rank4]:[rank4]:   File "/usr/local/lib/python3.11/dist-packages/torch/distributed/checkpoint/state_dict_saver.py", line 463, in write_data
[rank4]:[rank4]:     all_writes = storage_writer.write_data(final_local_plan, planner)
[rank4]:[rank4]:                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank4]:[rank4]:   File "/usr/local/lib/python3.11/dist-packages/torch/distributed/checkpoint/hf_storage.py", line 127, in write_data
[rank4]:[rank4]:     buckets = self._split_by_storage_plan(storage_plan, plan.items)
[rank4]:[rank4]:               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank4]:[rank4]:   File "/usr/local/lib/python3.11/dist-packages/torch/distributed/checkpoint/hf_storage.py", line 189, in _split_by_storage_plan
[rank4]:[rank4]:     idx = storage_plan[key]
[rank4]:[rank4]:           ~~~~~~~~~~~~^^^^^
[rank4]:[rank4]: KeyError: 'model.layers.17.self_attn.q_proj.weight'
[rank4]:[rank4]: Traceback (most recent call last): (RANK 6)
[rank4]:[rank4]:   File "/usr/local/lib/python3.11/dist-packages/torch/distributed/checkpoint/utils.py", line 239, in all_reduce
[rank4]:[rank4]:     local_data = map_fun()
[rank4]:[rank4]:                  ^^^^^^^^^
[rank4]:[rank4]:   File "/usr/local/lib/python3.11/dist-packages/torch/distributed/checkpoint/logger.py", line 87, in wrapper
[rank4]:[rank4]:     result = func(*args, **kwargs)
[rank4]:[rank4]:              ^^^^^^^^^^^^^^^^^^^^^
[rank4]:[rank4]:   File "/usr/local/lib/python3.11/dist-packages/torch/distributed/checkpoint/state_dict_saver.py", line 463, in write_data
[rank4]:[rank4]:     all_writes = storage_writer.write_data(final_local_plan, planner)
[rank4]:[rank4]:                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank4]:[rank4]:   File "/usr/local/lib/python3.11/dist-packages/torch/distributed/checkpoint/hf_storage.py", line 127, in write_data
[rank4]:[rank4]:     buckets = self._split_by_storage_plan(storage_plan, plan.items)
[rank4]:[rank4]:               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank4]:[rank4]:   File "/usr/local/lib/python3.11/dist-packages/torch/distributed/checkpoint/hf_storage.py", line 189, in _split_by_storage_plan
[rank4]:[rank4]:     idx = storage_plan[key]
[rank4]:[rank4]:           ~~~~~~~~~~~~^^^^^
[rank4]:[rank4]: KeyError: 'model.layers.25.self_attn.q_proj.weight'
[rank4]:[rank4]: Traceback (most recent call last): (RANK 7)
[rank4]:[rank4]:   File "/usr/local/lib/python3.11/dist-packages/torch/distributed/checkpoint/utils.py", line 239, in all_reduce
[rank4]:[rank4]:     local_data = map_fun()
[rank4]:[rank4]:                  ^^^^^^^^^
[rank4]:[rank4]:   File "/usr/local/lib/python3.11/dist-packages/torch/distributed/checkpoint/logger.py", line 87, in wrapper
[rank4]:[rank4]:     result = func(*args, **kwargs)
[rank4]:[rank4]:              ^^^^^^^^^^^^^^^^^^^^^
[rank4]:[rank4]:   File "/usr/local/lib/python3.11/dist-packages/torch/distributed/checkpoint/state_dict_saver.py", line 463, in write_data
[rank4]:[rank4]:     all_writes = storage_writer.write_data(final_local_plan, planner)
[rank4]:[rank4]:                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank4]:[rank4]:   File "/usr/local/lib/python3.11/dist-packages/torch/distributed/checkpoint/hf_storage.py", line 127, in write_data
[rank4]:[rank4]:     buckets = self._split_by_storage_plan(storage_plan, plan.items)
[rank4]:[rank4]:               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank4]:[rank4]:   File "/usr/local/lib/python3.11/dist-packages/torch/distributed/checkpoint/hf_storage.py", line 189, in _split_by_storage_plan
[rank4]:[rank4]:     idx = storage_plan[key]
[rank4]:[rank4]:           ~~~~~~~~~~~~^^^^^
[rank4]:[rank4]: KeyError: 'model.layers.25.self_attn.q_proj.weight'
[rank4]:
[rank7]:[rank7]: Traceback (most recent call last):
[rank7]:[rank7]:   File "<frozen runpy>", line 198, in _run_module_as_main
[rank7]:[rank7]:   File "<frozen runpy>", line 88, in _run_code
[rank7]:[rank7]:   File "/workspace/torchtitan/timelyfreeze/train.py", line 727, in <module>
[rank7]:[rank7]:     trainer.train()
[rank7]:[rank7]:   File "/usr/local/lib/python3.11/dist-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 357, in wrapper
[rank7]:[rank7]:     return f(*args, **kwargs)
[rank7]:[rank7]:            ^^^^^^^^^^^^^^^^^^
[rank7]:[rank7]:   File "/workspace/torchtitan/timelyfreeze/train.py", line 586, in train
[rank7]:[rank7]:     self.checkpointer.save(
[rank7]:[rank7]:   File "/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[rank7]:[rank7]:     return func(*args, **kwargs)
[rank7]:[rank7]:            ^^^^^^^^^^^^^^^^^^^^^
[rank7]:[rank7]:   File "/workspace/torchtitan/torchtitan/components/checkpoint.py", line 479, in save
[rank7]:[rank7]:     self._save_last_step(curr_step)
[rank7]:[rank7]:   File "/workspace/torchtitan/torchtitan/components/checkpoint.py", line 733, in _save_last_step
[rank7]:[rank7]:     self.dcp_save(
[rank7]:[rank7]:   File "/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[rank7]:[rank7]:     return func(*args, **kwargs)
[rank7]:[rank7]:            ^^^^^^^^^^^^^^^^^^^^^
[rank7]:[rank7]:   File "/workspace/torchtitan/torchtitan/components/checkpoint.py", line 401, in dcp_save
[rank7]:[rank7]:     ret = dcp.save(
[rank7]:[rank7]:           ^^^^^^^^^
[rank7]:[rank7]:   File "/usr/local/lib/python3.11/dist-packages/torch/distributed/checkpoint/logger.py", line 87, in wrapper
[rank7]:[rank7]:     result = func(*args, **kwargs)
[rank7]:[rank7]:              ^^^^^^^^^^^^^^^^^^^^^
[rank7]:[rank7]:   File "/usr/local/lib/python3.11/dist-packages/torch/distributed/checkpoint/utils.py", line 475, in inner_func
[rank7]:[rank7]:     return func(*args, **kwargs)
[rank7]:[rank7]:            ^^^^^^^^^^^^^^^^^^^^^
[rank7]:[rank7]:   File "/usr/local/lib/python3.11/dist-packages/torch/distributed/checkpoint/state_dict_saver.py", line 193, in save
[rank7]:[rank7]:     return _save_state_dict(
[rank7]:[rank7]:            ^^^^^^^^^^^^^^^^^
[rank7]:[rank7]:   File "/usr/local/lib/python3.11/dist-packages/torch/distributed/checkpoint/state_dict_saver.py", line 475, in _save_state_dict
[rank7]:[rank7]:     metadata = distW.all_reduce("write", write_data, finish_checkpoint)
[rank7]:[rank7]:                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank7]:[rank7]:   File "/usr/local/lib/python3.11/dist-packages/torch/distributed/checkpoint/utils.py", line 259, in all_reduce
[rank7]:[rank7]:     raise final_result
[rank7]:[rank7]: torch.distributed.checkpoint.api.CheckpointException: CheckpointException ranks:dict_keys([2, 3, 4, 5, 6, 7])
[rank7]:[rank7]: Traceback (most recent call last): (RANK 2)
[rank7]:[rank7]:   File "/usr/local/lib/python3.11/dist-packages/torch/distributed/checkpoint/utils.py", line 239, in all_reduce
[rank7]:[rank7]:     local_data = map_fun()
[rank7]:[rank7]:                  ^^^^^^^^^
[rank7]:[rank7]:   File "/usr/local/lib/python3.11/dist-packages/torch/distributed/checkpoint/logger.py", line 87, in wrapper
[rank7]:[rank7]:     result = func(*args, **kwargs)
[rank7]:[rank7]:              ^^^^^^^^^^^^^^^^^^^^^
[rank7]:[rank7]:   File "/usr/local/lib/python3.11/dist-packages/torch/distributed/checkpoint/state_dict_saver.py", line 463, in write_data
[rank7]:[rank7]:     all_writes = storage_writer.write_data(final_local_plan, planner)
[rank7]:[rank7]:                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank7]:[rank7]:   File "/usr/local/lib/python3.11/dist-packages/torch/distributed/checkpoint/hf_storage.py", line 127, in write_data
[rank7]:[rank7]:     buckets = self._split_by_storage_plan(storage_plan, plan.items)
[rank7]:[rank7]:               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank7]:[rank7]:   File "/usr/local/lib/python3.11/dist-packages/torch/distributed/checkpoint/hf_storage.py", line 189, in _split_by_storage_plan
[rank7]:[rank7]:     idx = storage_plan[key]
[rank7]:[rank7]:           ~~~~~~~~~~~~^^^^^
[rank7]:[rank7]: KeyError: 'model.layers.8.self_attn.q_proj.weight'
[rank7]:[rank7]: Traceback (most recent call last): (RANK 3)
[rank7]:[rank7]:   File "/usr/local/lib/python3.11/dist-packages/torch/distributed/checkpoint/utils.py", line 239, in all_reduce
[rank7]:[rank7]:     local_data = map_fun()
[rank7]:[rank7]:                  ^^^^^^^^^
[rank7]:[rank7]:   File "/usr/local/lib/python3.11/dist-packages/torch/distributed/checkpoint/logger.py", line 87, in wrapper
[rank7]:[rank7]:     result = func(*args, **kwargs)
[rank7]:[rank7]:              ^^^^^^^^^^^^^^^^^^^^^
[rank7]:[rank7]:   File "/usr/local/lib/python3.11/dist-packages/torch/distributed/checkpoint/state_dict_saver.py", line 463, in write_data
[rank7]:[rank7]:     all_writes = storage_writer.write_data(final_local_plan, planner)
[rank7]:[rank7]:                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank7]:[rank7]:   File "/usr/local/lib/python3.11/dist-packages/torch/distributed/checkpoint/hf_storage.py", line 127, in write_data
[rank7]:[rank7]:     buckets = self._split_by_storage_plan(storage_plan, plan.items)
[rank7]:[rank7]:               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank7]:[rank7]:   File "/usr/local/lib/python3.11/dist-packages/torch/distributed/checkpoint/hf_storage.py", line 189, in _split_by_storage_plan
[rank7]:[rank7]:     idx = storage_plan[key]
[rank7]:[rank7]:           ~~~~~~~~~~~~^^^^^
[rank7]:[rank7]: KeyError: 'model.layers.8.self_attn.q_proj.weight'
[rank7]:[rank7]: Traceback (most recent call last): (RANK 4)
[rank7]:[rank7]:   File "/usr/local/lib/python3.11/dist-packages/torch/distributed/checkpoint/utils.py", line 239, in all_reduce
[rank7]:[rank7]:     local_data = map_fun()
[rank7]:[rank7]:                  ^^^^^^^^^
[rank7]:[rank7]:   File "/usr/local/lib/python3.11/dist-packages/torch/distributed/checkpoint/logger.py", line 87, in wrapper
[rank7]:[rank7]:     result = func(*args, **kwargs)
[rank7]:[rank7]:              ^^^^^^^^^^^^^^^^^^^^^
[rank7]:[rank7]:   File "/usr/local/lib/python3.11/dist-packages/torch/distributed/checkpoint/state_dict_saver.py", line 463, in write_data
[rank7]:[rank7]:     all_writes = storage_writer.write_data(final_local_plan, planner)
[rank7]:[rank7]:                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank7]:[rank7]:   File "/usr/local/lib/python3.11/dist-packages/torch/distributed/checkpoint/hf_storage.py", line 127, in write_data
[rank7]:[rank7]:     buckets = self._split_by_storage_plan(storage_plan, plan.items)
[rank7]:[rank7]:               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank7]:[rank7]:   File "/usr/local/lib/python3.11/dist-packages/torch/distributed/checkpoint/hf_storage.py", line 189, in _split_by_storage_plan
[rank7]:[rank7]:     idx = storage_plan[key]
[rank7]:[rank7]:           ~~~~~~~~~~~~^^^^^
[rank7]:[rank7]: KeyError: 'model.layers.17.self_attn.q_proj.weight'
[rank7]:[rank7]: Traceback (most recent call last): (RANK 5)
[rank7]:[rank7]:   File "/usr/local/lib/python3.11/dist-packages/torch/distributed/checkpoint/utils.py", line 239, in all_reduce
[rank7]:[rank7]:     local_data = map_fun()
[rank7]:[rank7]:                  ^^^^^^^^^
[rank7]:[rank7]:   File "/usr/local/lib/python3.11/dist-packages/torch/distributed/checkpoint/logger.py", line 87, in wrapper
[rank7]:[rank7]:     result = func(*args, **kwargs)
[rank7]:[rank7]:              ^^^^^^^^^^^^^^^^^^^^^
[rank7]:[rank7]:   File "/usr/local/lib/python3.11/dist-packages/torch/distributed/checkpoint/state_dict_saver.py", line 463, in write_data
[rank7]:[rank7]:     all_writes = storage_writer.write_data(final_local_plan, planner)
[rank7]:[rank7]:                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank7]:[rank7]:   File "/usr/local/lib/python3.11/dist-packages/torch/distributed/checkpoint/hf_storage.py", line 127, in write_data
[rank7]:[rank7]:     buckets = self._split_by_storage_plan(storage_plan, plan.items)
[rank7]:[rank7]:               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank7]:[rank7]:   File "/usr/local/lib/python3.11/dist-packages/torch/distributed/checkpoint/hf_storage.py", line 189, in _split_by_storage_plan
[rank7]:[rank7]:     idx = storage_plan[key]
[rank7]:[rank7]:           ~~~~~~~~~~~~^^^^^
[rank7]:[rank7]: KeyError: 'model.layers.17.self_attn.q_proj.weight'
[rank7]:[rank7]: Traceback (most recent call last): (RANK 6)
[rank7]:[rank7]:   File "/usr/local/lib/python3.11/dist-packages/torch/distributed/checkpoint/utils.py", line 239, in all_reduce
[rank7]:[rank7]:     local_data = map_fun()
[rank7]:[rank7]:                  ^^^^^^^^^
[rank7]:[rank7]:   File "/usr/local/lib/python3.11/dist-packages/torch/distributed/checkpoint/logger.py", line 87, in wrapper
[rank7]:[rank7]:     result = func(*args, **kwargs)
[rank7]:[rank7]:              ^^^^^^^^^^^^^^^^^^^^^
[rank7]:[rank7]:   File "/usr/local/lib/python3.11/dist-packages/torch/distributed/checkpoint/state_dict_saver.py", line 463, in write_data
[rank7]:[rank7]:     all_writes = storage_writer.write_data(final_local_plan, planner)
[rank7]:[rank7]:                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank7]:[rank7]:   File "/usr/local/lib/python3.11/dist-packages/torch/distributed/checkpoint/hf_storage.py", line 127, in write_data
[rank7]:[rank7]:     buckets = self._split_by_storage_plan(storage_plan, plan.items)
[rank7]:[rank7]:               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank7]:[rank7]:   File "/usr/local/lib/python3.11/dist-packages/torch/distributed/checkpoint/hf_storage.py", line 189, in _split_by_storage_plan
[rank7]:[rank7]:     idx = storage_plan[key]
[rank7]:[rank7]:           ~~~~~~~~~~~~^^^^^
[rank7]:[rank7]: KeyError: 'model.layers.25.self_attn.q_proj.weight'
[rank7]:[rank7]: Traceback (most recent call last): (RANK 7)
[rank7]:[rank7]:   File "/usr/local/lib/python3.11/dist-packages/torch/distributed/checkpoint/utils.py", line 239, in all_reduce
[rank7]:[rank7]:     local_data = map_fun()
[rank7]:[rank7]:                  ^^^^^^^^^
[rank7]:[rank7]:   File "/usr/local/lib/python3.11/dist-packages/torch/distributed/checkpoint/logger.py", line 87, in wrapper
[rank7]:[rank7]:     result = func(*args, **kwargs)
[rank7]:[rank7]:              ^^^^^^^^^^^^^^^^^^^^^
[rank7]:[rank7]:   File "/usr/local/lib/python3.11/dist-packages/torch/distributed/checkpoint/state_dict_saver.py", line 463, in write_data
[rank7]:[rank7]:     all_writes = storage_writer.write_data(final_local_plan, planner)
[rank7]:[rank7]:                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank7]:[rank7]:   File "/usr/local/lib/python3.11/dist-packages/torch/distributed/checkpoint/hf_storage.py", line 127, in write_data
[rank7]:[rank7]:     buckets = self._split_by_storage_plan(storage_plan, plan.items)
[rank7]:[rank7]:               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank7]:[rank7]:   File "/usr/local/lib/python3.11/dist-packages/torch/distributed/checkpoint/hf_storage.py", line 189, in _split_by_storage_plan
[rank7]:[rank7]:     idx = storage_plan[key]
[rank7]:[rank7]:           ~~~~~~~~~~~~^^^^^
[rank7]:[rank7]: KeyError: 'model.layers.25.self_attn.q_proj.weight'
[rank7]:
[rank0]:[rank0]: Traceback (most recent call last):
[rank0]:[rank0]:   File "<frozen runpy>", line 198, in _run_module_as_main
[rank0]:[rank0]:   File "<frozen runpy>", line 88, in _run_code
[rank0]:[rank0]:   File "/workspace/torchtitan/timelyfreeze/train.py", line 727, in <module>
[rank0]:[rank0]:     trainer.train()
[rank0]:[rank0]:   File "/usr/local/lib/python3.11/dist-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 357, in wrapper
[rank0]:[rank0]:     return f(*args, **kwargs)
[rank0]:[rank0]:            ^^^^^^^^^^^^^^^^^^
[rank0]:[rank0]:   File "/workspace/torchtitan/timelyfreeze/train.py", line 586, in train
[rank0]:[rank0]:     self.checkpointer.save(
[rank0]:[rank0]:   File "/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[rank0]:[rank0]:     return func(*args, **kwargs)
[rank0]:[rank0]:            ^^^^^^^^^^^^^^^^^^^^^
[rank0]:[rank0]:   File "/workspace/torchtitan/torchtitan/components/checkpoint.py", line 479, in save
[rank0]:[rank0]:     self._save_last_step(curr_step)
[rank0]:[rank0]:   File "/workspace/torchtitan/torchtitan/components/checkpoint.py", line 733, in _save_last_step
[rank0]:[rank0]:     self.dcp_save(
[rank0]:[rank0]:   File "/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[rank0]:[rank0]:     return func(*args, **kwargs)
[rank0]:[rank0]:            ^^^^^^^^^^^^^^^^^^^^^
[rank0]:[rank0]:   File "/workspace/torchtitan/torchtitan/components/checkpoint.py", line 401, in dcp_save
[rank0]:[rank0]:     ret = dcp.save(
[rank0]:[rank0]:           ^^^^^^^^^
[rank0]:[rank0]:   File "/usr/local/lib/python3.11/dist-packages/torch/distributed/checkpoint/logger.py", line 87, in wrapper
[rank0]:[rank0]:     result = func(*args, **kwargs)
[rank0]:[rank0]:              ^^^^^^^^^^^^^^^^^^^^^
[rank0]:[rank0]:   File "/usr/local/lib/python3.11/dist-packages/torch/distributed/checkpoint/utils.py", line 475, in inner_func
[rank0]:[rank0]:     return func(*args, **kwargs)
[rank0]:[rank0]:            ^^^^^^^^^^^^^^^^^^^^^
[rank0]:[rank0]:   File "/usr/local/lib/python3.11/dist-packages/torch/distributed/checkpoint/state_dict_saver.py", line 193, in save
[rank0]:[rank0]:     return _save_state_dict(
[rank0]:[rank0]:            ^^^^^^^^^^^^^^^^^
[rank0]:[rank0]:   File "/usr/local/lib/python3.11/dist-packages/torch/distributed/checkpoint/state_dict_saver.py", line 475, in _save_state_dict
[rank0]:[rank0]:     metadata = distW.all_reduce("write", write_data, finish_checkpoint)
[rank0]:[rank0]:                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank0]:[rank0]:   File "/usr/local/lib/python3.11/dist-packages/torch/distributed/checkpoint/utils.py", line 259, in all_reduce
[rank0]:[rank0]:     raise final_result
[rank0]:[rank0]: torch.distributed.checkpoint.api.CheckpointException: CheckpointException ranks:dict_keys([2, 3, 4, 5, 6, 7])
[rank0]:[rank0]: Traceback (most recent call last): (RANK 2)
[rank0]:[rank0]:   File "/usr/local/lib/python3.11/dist-packages/torch/distributed/checkpoint/utils.py", line 239, in all_reduce
[rank0]:[rank0]:     local_data = map_fun()
[rank0]:[rank0]:                  ^^^^^^^^^
[rank0]:[rank0]:   File "/usr/local/lib/python3.11/dist-packages/torch/distributed/checkpoint/logger.py", line 87, in wrapper
[rank0]:[rank0]:     result = func(*args, **kwargs)
[rank0]:[rank0]:              ^^^^^^^^^^^^^^^^^^^^^
[rank0]:[rank0]:   File "/usr/local/lib/python3.11/dist-packages/torch/distributed/checkpoint/state_dict_saver.py", line 463, in write_data
[rank0]:[rank0]:     all_writes = storage_writer.write_data(final_local_plan, planner)
[rank0]:[rank0]:                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank0]:[rank0]:   File "/usr/local/lib/python3.11/dist-packages/torch/distributed/checkpoint/hf_storage.py", line 127, in write_data
[rank0]:[rank0]:     buckets = self._split_by_storage_plan(storage_plan, plan.items)
[rank0]:[rank0]:               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank0]:[rank0]:   File "/usr/local/lib/python3.11/dist-packages/torch/distributed/checkpoint/hf_storage.py", line 189, in _split_by_storage_plan
[rank0]:[rank0]:     idx = storage_plan[key]
[rank0]:[rank0]:           ~~~~~~~~~~~~^^^^^
[rank0]:[rank0]: KeyError: 'model.layers.8.self_attn.q_proj.weight'
[rank0]:[rank0]: Traceback (most recent call last): (RANK 3)
[rank0]:[rank0]:   File "/usr/local/lib/python3.11/dist-packages/torch/distributed/checkpoint/utils.py", line 239, in all_reduce
[rank0]:[rank0]:     local_data = map_fun()
[rank0]:[rank0]:                  ^^^^^^^^^
[rank0]:[rank0]:   File "/usr/local/lib/python3.11/dist-packages/torch/distributed/checkpoint/logger.py", line 87, in wrapper
[rank0]:[rank0]:     result = func(*args, **kwargs)
[rank0]:[rank0]:              ^^^^^^^^^^^^^^^^^^^^^
[rank0]:[rank0]:   File "/usr/local/lib/python3.11/dist-packages/torch/distributed/checkpoint/state_dict_saver.py", line 463, in write_data
[rank0]:[rank0]:     all_writes = storage_writer.write_data(final_local_plan, planner)
[rank0]:[rank0]:                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank0]:[rank0]:   File "/usr/local/lib/python3.11/dist-packages/torch/distributed/checkpoint/hf_storage.py", line 127, in write_data
[rank0]:[rank0]:     buckets = self._split_by_storage_plan(storage_plan, plan.items)
[rank0]:[rank0]:               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank0]:[rank0]:   File "/usr/local/lib/python3.11/dist-packages/torch/distributed/checkpoint/hf_storage.py", line 189, in _split_by_storage_plan
[rank0]:[rank0]:     idx = storage_plan[key]
[rank0]:[rank0]:           ~~~~~~~~~~~~^^^^^
[rank0]:[rank0]: KeyError: 'model.layers.8.self_attn.q_proj.weight'
[rank0]:[rank0]: Traceback (most recent call last): (RANK 4)
[rank0]:[rank0]:   File "/usr/local/lib/python3.11/dist-packages/torch/distributed/checkpoint/utils.py", line 239, in all_reduce
[rank0]:[rank0]:     local_data = map_fun()
[rank0]:[rank0]:                  ^^^^^^^^^
[rank0]:[rank0]:   File "/usr/local/lib/python3.11/dist-packages/torch/distributed/checkpoint/logger.py", line 87, in wrapper
[rank0]:[rank0]:     result = func(*args, **kwargs)
[rank0]:[rank0]:              ^^^^^^^^^^^^^^^^^^^^^
[rank0]:[rank0]:   File "/usr/local/lib/python3.11/dist-packages/torch/distributed/checkpoint/state_dict_saver.py", line 463, in write_data
[rank0]:[rank0]:     all_writes = storage_writer.write_data(final_local_plan, planner)
[rank0]:[rank0]:                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank0]:[rank0]:   File "/usr/local/lib/python3.11/dist-packages/torch/distributed/checkpoint/hf_storage.py", line 127, in write_data
[rank0]:[rank0]:     buckets = self._split_by_storage_plan(storage_plan, plan.items)
[rank0]:[rank0]:               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank0]:[rank0]:   File "/usr/local/lib/python3.11/dist-packages/torch/distributed/checkpoint/hf_storage.py", line 189, in _split_by_storage_plan
[rank0]:[rank0]:     idx = storage_plan[key]
[rank0]:[rank0]:           ~~~~~~~~~~~~^^^^^
[rank0]:[rank0]: KeyError: 'model.layers.17.self_attn.q_proj.weight'
[rank0]:[rank0]: Traceback (most recent call last): (RANK 5)
[rank0]:[rank0]:   File "/usr/local/lib/python3.11/dist-packages/torch/distributed/checkpoint/utils.py", line 239, in all_reduce
[rank0]:[rank0]:     local_data = map_fun()
[rank0]:[rank0]:                  ^^^^^^^^^
[rank0]:[rank0]:   File "/usr/local/lib/python3.11/dist-packages/torch/distributed/checkpoint/logger.py", line 87, in wrapper
[rank0]:[rank0]:     result = func(*args, **kwargs)
[rank0]:[rank0]:              ^^^^^^^^^^^^^^^^^^^^^
[rank0]:[rank0]:   File "/usr/local/lib/python3.11/dist-packages/torch/distributed/checkpoint/state_dict_saver.py", line 463, in write_data
[rank0]:[rank0]:     all_writes = storage_writer.write_data(final_local_plan, planner)
[rank0]:[rank0]:                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank0]:[rank0]:   File "/usr/local/lib/python3.11/dist-packages/torch/distributed/checkpoint/hf_storage.py", line 127, in write_data
[rank0]:[rank0]:     buckets = self._split_by_storage_plan(storage_plan, plan.items)
[rank0]:[rank0]:               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank0]:[rank0]:   File "/usr/local/lib/python3.11/dist-packages/torch/distributed/checkpoint/hf_storage.py", line 189, in _split_by_storage_plan
[rank0]:[rank0]:     idx = storage_plan[key]
[rank0]:[rank0]:           ~~~~~~~~~~~~^^^^^
[rank0]:[rank0]: KeyError: 'model.layers.17.self_attn.q_proj.weight'
[rank0]:[rank0]: Traceback (most recent call last): (RANK 6)
[rank0]:[rank0]:   File "/usr/local/lib/python3.11/dist-packages/torch/distributed/checkpoint/utils.py", line 239, in all_reduce
[rank0]:[rank0]:     local_data = map_fun()
[rank0]:[rank0]:                  ^^^^^^^^^
[rank0]:[rank0]:   File "/usr/local/lib/python3.11/dist-packages/torch/distributed/checkpoint/logger.py", line 87, in wrapper
[rank0]:[rank0]:     result = func(*args, **kwargs)
[rank0]:[rank0]:              ^^^^^^^^^^^^^^^^^^^^^
[rank0]:[rank0]:   File "/usr/local/lib/python3.11/dist-packages/torch/distributed/checkpoint/state_dict_saver.py", line 463, in write_data
[rank0]:[rank0]:     all_writes = storage_writer.write_data(final_local_plan, planner)
[rank0]:[rank0]:                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank0]:[rank0]:   File "/usr/local/lib/python3.11/dist-packages/torch/distributed/checkpoint/hf_storage.py", line 127, in write_data
[rank0]:[rank0]:     buckets = self._split_by_storage_plan(storage_plan, plan.items)
[rank0]:[rank0]:               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank0]:[rank0]:   File "/usr/local/lib/python3.11/dist-packages/torch/distributed/checkpoint/hf_storage.py", line 189, in _split_by_storage_plan
[rank0]:[rank0]:     idx = storage_plan[key]
[rank0]:[rank0]:           ~~~~~~~~~~~~^^^^^
[rank0]:[rank0]: KeyError: 'model.layers.25.self_attn.q_proj.weight'
[rank0]:[rank0]: Traceback (most recent call last): (RANK 7)
[rank0]:[rank0]:   File "/usr/local/lib/python3.11/dist-packages/torch/distributed/checkpoint/utils.py", line 239, in all_reduce
[rank0]:[rank0]:     local_data = map_fun()
[rank0]:[rank0]:                  ^^^^^^^^^
[rank0]:[rank0]:   File "/usr/local/lib/python3.11/dist-packages/torch/distributed/checkpoint/logger.py", line 87, in wrapper
[rank0]:[rank0]:     result = func(*args, **kwargs)
[rank0]:[rank0]:              ^^^^^^^^^^^^^^^^^^^^^
[rank0]:[rank0]:   File "/usr/local/lib/python3.11/dist-packages/torch/distributed/checkpoint/state_dict_saver.py", line 463, in write_data
[rank0]:[rank0]:     all_writes = storage_writer.write_data(final_local_plan, planner)
[rank0]:[rank0]:                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank0]:[rank0]:   File "/usr/local/lib/python3.11/dist-packages/torch/distributed/checkpoint/hf_storage.py", line 127, in write_data
[rank0]:[rank0]:     buckets = self._split_by_storage_plan(storage_plan, plan.items)
[rank0]:[rank0]:               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank0]:[rank0]:   File "/usr/local/lib/python3.11/dist-packages/torch/distributed/checkpoint/hf_storage.py", line 189, in _split_by_storage_plan
[rank0]:[rank0]:     idx = storage_plan[key]
[rank0]:[rank0]:           ~~~~~~~~~~~~^^^^^
[rank0]:[rank0]: KeyError: 'model.layers.25.self_attn.q_proj.weight'
[rank0]:
[rank0]:[rank0]:[W923 16:59:04.828046515 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
[rank2]:[rank2]:[W923 16:59:04.845118467 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
[rank4]:[rank4]:[W923 16:59:04.908714000 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
[rank6]:[rank6]:[W923 16:59:04.536325239 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
[rank3]:[rank3]:[W923 16:59:05.899817882 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[rank5]:[rank5]:[W923 16:59:05.941422698 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[rank1]:[rank1]:[W923 16:59:05.029542830 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[rank7]:[rank7]:[W923 16:59:05.041615826 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[rank0]:[rank0]:[W923 16:59:05.047351699 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[rank2]:[rank2]:[W923 16:59:05.143288628 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[rank4]:[rank4]:[W923 16:59:05.254186679 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[rank6]:[rank6]:[W923 16:59:06.903277455 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
W0923 16:59:06.476000 15519 torch/distributed/elastic/multiprocessing/api.py:939] Sending process 15624 closing signal SIGTERM
W0923 16:59:06.477000 15519 torch/distributed/elastic/multiprocessing/api.py:939] Sending process 15625 closing signal SIGTERM
W0923 16:59:06.478000 15519 torch/distributed/elastic/multiprocessing/api.py:939] Sending process 15626 closing signal SIGTERM
W0923 16:59:06.478000 15519 torch/distributed/elastic/multiprocessing/api.py:939] Sending process 15628 closing signal SIGTERM
W0923 16:59:06.478000 15519 torch/distributed/elastic/multiprocessing/api.py:939] Sending process 15629 closing signal SIGTERM
W0923 16:59:06.479000 15519 torch/distributed/elastic/multiprocessing/api.py:939] Sending process 15630 closing signal SIGTERM
W0923 16:59:06.479000 15519 torch/distributed/elastic/multiprocessing/api.py:939] Sending process 15631 closing signal SIGTERM
E0923 16:59:09.171000 15519 torch/distributed/elastic/multiprocessing/api.py:913] failed (exitcode: 1) local_rank: 3 (pid: 15627) of binary: /usr/bin/python
[rank0]:Stage 0: Modules to keep: {'layers.3', 'layers.4', 'layers.5', 'layers.7', 'layers.0', 'layers.6', 'tok_embeddings', 'layers.1', 'layers.2'}
[rank4]:Stage 2: Modules to keep: {'layers.17', 'layers.24', 'layers.19', 'layers.20', 'layers.18', 'layers.21', 'layers.23', 'layers.22'}
[rank1]:Stage 0: Modules to keep: {'tok_embeddings', 'layers.6', 'layers.3', 'layers.5', 'layers.7', 'layers.2', 'layers.4', 'layers.1', 'layers.0'}
[rank5]:Stage 2: Modules to keep: {'layers.17', 'layers.19', 'layers.20', 'layers.18', 'layers.21', 'layers.23', 'layers.22', 'layers.24'}
[rank2]:Stage 1: Modules to keep: {'layers.8', 'layers.15', 'layers.11', 'layers.13', 'layers.16', 'layers.10', 'layers.12', 'layers.9', 'layers.14'}
[rank3]:Stage 1: Modules to keep: {'layers.10', 'layers.11', 'layers.8', 'layers.13', 'layers.12', 'layers.15', 'layers.14', 'layers.16', 'layers.9'}
[rank7]:Stage 3: Modules to keep: {'norm', 'layers.27', 'layers.31', 'layers.29', 'layers.28', 'layers.30', 'output', 'layers.25', 'layers.26'}
[rank6]:Stage 3: Modules to keep: {'layers.25', 'layers.29', 'layers.30', 'layers.27', 'layers.31', 'norm', 'layers.28', 'output', 'layers.26'}
[rank1]:[Gloo] Rank 1 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[rank0]:[Gloo] Rank 0 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[rank4]:[Gloo] Rank 4 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[rank5]:[Gloo] Rank 5 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[rank6]:[Gloo] Rank 6 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[rank2]:[Gloo] Rank 2 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[rank3]:[Gloo] Rank 3 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[rank7]:[Gloo] Rank 7 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[rank6]:[1;34mwandb[0m: 
[rank6]:[1;34mwandb[0m: üöÄ View run [33m0922_gpipe_fullrand6_runpod[0m at: [34m[0m
[rank6]:[1;34mwandb[0m: Find logs at: [1;35m../torchtitan_data/tb/0922_gpipe_fullrand6_runpod/20250923-1431/wandb/run-20250923_143112-j41lqzsw/logs[0m
Traceback (most recent call last):
  File "/usr/local/bin/torchrun", line 8, in <module>
    sys.exit(main())
             ^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 357, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/distributed/run.py", line 949, in main
    run(args)
  File "/usr/local/lib/python3.11/dist-packages/torch/distributed/run.py", line 940, in run
    elastic_launch(
  File "/usr/local/lib/python3.11/dist-packages/torch/distributed/launcher/api.py", line 158, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/distributed/launcher/api.py", line 299, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
timelyfreeze.train FAILED
------------------------------------------------------------
Failures:
[1]:
  time      : 2025-09-23_16:59:09
  host      : 30be631344fa
  rank      : 0 (local_rank: 0)
  exitcode  : 1 (pid: 15624)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
[2]:
  time      : 2025-09-23_16:59:09
  host      : 30be631344fa
  rank      : 1 (local_rank: 1)
  exitcode  : 1 (pid: 15625)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
[3]:
  time      : 2025-09-23_16:59:09
  host      : 30be631344fa
  rank      : 2 (local_rank: 2)
  exitcode  : 1 (pid: 15626)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
[4]:
  time      : 2025-09-23_16:59:09
  host      : 30be631344fa
  rank      : 4 (local_rank: 4)
  exitcode  : 1 (pid: 15628)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
[5]:
  time      : 2025-09-23_16:59:09
  host      : 30be631344fa
  rank      : 5 (local_rank: 5)
  exitcode  : 1 (pid: 15629)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
[6]:
  time      : 2025-09-23_16:59:09
  host      : 30be631344fa
  rank      : 6 (local_rank: 6)
  exitcode  : 1 (pid: 15630)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
[7]:
  time      : 2025-09-23_16:59:09
  host      : 30be631344fa
  rank      : 7 (local_rank: 7)
  exitcode  : 1 (pid: 15631)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2025-09-23_16:59:06
  host      : 30be631344fa
  rank      : 3 (local_rank: 3)
  exitcode  : 1 (pid: 15627)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================
[W923 16:59:09.022255187 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
