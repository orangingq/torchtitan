
üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•
‚úîÔ∏èCurrent Timestamp: Fri Nov 28 18:38:07 UTC 2025
‚úîÔ∏èSERVER: wbl-kaist-gpu-2 (172.16.131.118),  GPUs: 4,5,6,7
‚úîÔ∏èSCRIPT: /opt/dlami/nvme/DMLAB/shcho/torchtitan/logs/h200/1104_llama8b/run.sh
‚úîÔ∏èOUTPUT: /opt/dlami/nvme/DMLAB/shcho/torchtitan/logs/h200/1104_llama8b/1128_Interleaved1F1B_timelyauto.log
‚úîÔ∏èLlama 3.1 8B Experiment
1109: 1) resolved timelyapf issue, 2) seed fixed to 42 for all runs, 3) 3000 steps -> 2000 steps (better benchmark scores!)
1116: everything same, but with seed=11
1128: everything same as 1109, but with th=1e-3, and solve DAG with QP. 

‚úîÔ∏èRunning with timelyauto x Interleaved1F1B ... 
‚òëÔ∏è> torchrun --standalone --nnodes=1 --nproc_per_node=4 --local_addr=127.0.0.1 --local-ranks-filter=0,1,2,3 --role=rank --tee=3 -m timelyfreeze.train --job.config_file=/opt/dlami/nvme/DMLAB/shcho/torchtitan/logs/h200/1104_llama8b/config_1128.toml --job.description="Llama 3.1 8B Experiment
1109: 1) resolved timelyapf issue, 2) seed fixed to 42 for all runs, 3) 3000 steps -> 2000 steps (better benchmark scores!)
1116: everything same, but with seed=11
1128: everything same as 1109, but with th=1e-3, and solve DAG with QP. 
" --parallelism.pipeline_parallel_degree=4  --freezing.freeze --freezing.metric_type=timelyauto --freezing.threshold=1e-4 --freezing.max_freeze_ratio=0.7 --freezing.percentile=80
üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•
W1128 18:38:09.054000 1039860 site-packages/torch/distributed/run.py:811] 
W1128 18:38:09.054000 1039860 site-packages/torch/distributed/run.py:811] *****************************************
W1128 18:38:09.054000 1039860 site-packages/torch/distributed/run.py:811] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
W1128 18:38:09.054000 1039860 site-packages/torch/distributed/run.py:811] *****************************************
[rank0]:2025-11-28 18:38:15,828 - INFO - Starting job: "Llama 3.1 8B Experiment
[rank0]:1109: 1) resolved timelyapf issue, 2) seed fixed to 42 for all runs, 3) 3000 steps -> 2000 steps (better benchmark scores!)
[rank0]:1116: everything same, but with seed=11
[rank0]:1128: everything same as 1109, but with th=1e-3, and solve DAG with QP. 
[rank0]:"
[rank3]:2025-11-28 18:38:15,862 - INFO - Starting job: "Llama 3.1 8B Experiment
[rank3]:1109: 1) resolved timelyapf issue, 2) seed fixed to 42 for all runs, 3) 3000 steps -> 2000 steps (better benchmark scores!)
[rank3]:1116: everything same, but with seed=11
[rank3]:1128: everything same as 1109, but with th=1e-3, and solve DAG with QP. 
[rank3]:"
[rank2]:2025-11-28 18:38:15,816 - INFO - Starting job: "Llama 3.1 8B Experiment
[rank2]:1109: 1) resolved timelyapf issue, 2) seed fixed to 42 for all runs, 3) 3000 steps -> 2000 steps (better benchmark scores!)
[rank2]:1116: everything same, but with seed=11
[rank2]:1128: everything same as 1109, but with th=1e-3, and solve DAG with QP. 
[rank2]:"
[rank1]:2025-11-28 18:38:16,014 - INFO - Starting job: "Llama 3.1 8B Experiment
[rank1]:1109: 1) resolved timelyapf issue, 2) seed fixed to 42 for all runs, 3) 3000 steps -> 2000 steps (better benchmark scores!)
[rank1]:1116: everything same, but with seed=11
[rank1]:1128: everything same as 1109, but with th=1e-3, and solve DAG with QP. 
[rank1]:"
[rank0]:2025-11-28 18:38:16,764 - WARNING - ENV[TORCH_NCCL_ASYNC_ERROR_HANDLING] = 1 will be overridden to 3 based on job config
[rank0]:2025-11-28 18:38:16,767 - INFO - Building 1-D device mesh with ['pp'], [4]
[rank0]:2025-11-28 18:38:16,772 - INFO - [GC] Initial GC collection 0.00 seconds
[rank0]:2025-11-28 18:38:16,772 - INFO - Deterministic algorithm enabled (expect perf degradation).
[rank0]:2025-11-28 18:38:16,774 - INFO - Loading tokenizer from tokenizer.json
[rank3]:2025-11-28 18:38:16,791 - WARNING - ENV[TORCH_NCCL_ASYNC_ERROR_HANDLING] = 1 will be overridden to 3 based on job config
[rank3]:2025-11-28 18:38:16,793 - INFO - Building 1-D device mesh with ['pp'], [4]
[rank3]:2025-11-28 18:38:16,798 - INFO - Deterministic algorithm enabled (expect perf degradation).
[rank2]:2025-11-28 18:38:16,778 - WARNING - ENV[TORCH_NCCL_ASYNC_ERROR_HANDLING] = 1 will be overridden to 3 based on job config
[rank2]:2025-11-28 18:38:16,780 - INFO - Building 1-D device mesh with ['pp'], [4]
[rank2]:2025-11-28 18:38:16,786 - INFO - Deterministic algorithm enabled (expect perf degradation).
[rank1]:2025-11-28 18:38:16,835 - WARNING - ENV[TORCH_NCCL_ASYNC_ERROR_HANDLING] = 1 will be overridden to 3 based on job config
[rank1]:2025-11-28 18:38:16,837 - INFO - Building 1-D device mesh with ['pp'], [4]
[rank1]:2025-11-28 18:38:16,842 - INFO - Deterministic algorithm enabled (expect perf degradation).
[rank0]:2025-11-28 18:38:17,070 - INFO - Preparing openhermes dataset from teknium/OpenHermes-2.5
[rank0]:2025-11-28 18:38:18,864 - INFO - Building llama3 8B with TransformerModelArgs(_enforced='This field is used to enforce all fields have defaults.', dim=4096, n_layers=32, n_heads=32, n_kv_heads=8, vocab_size=128256, multiple_of=1024, ffn_dim_multiplier=1.3, norm_eps=1e-05, rope_theta=500000, max_seq_len=1024, depth_init=True, use_flex_attn=False, attn_mask_type='causal', eos_id=0)
[rank0]:2025-11-28 18:38:19,117 - INFO - CUDA capacity: NVIDIA H200 with 139.81GiB memory
[rank0]:2025-11-28 18:38:19,184 - INFO - Model llama3 8B size: 8,030,261,248 total parameters
[rank0]:2025-11-28 18:38:19,207 - INFO - PP rank 0 is building stage_idx 0 with modules ['tok_embeddings', 'layers.0', 'layers.1', 'layers.2', 'layers.3']
[rank1]:2025-11-28 18:38:19,109 - INFO - CUDA capacity: NVIDIA H200 with 139.81GiB memory
[rank1]:2025-11-28 18:38:19,199 - INFO - PP rank 1 is building stage_idx 1 with modules ['layers.4', 'layers.5', 'layers.6', 'layers.7', 'layers.8']
[rank0]:2025-11-28 18:38:19,227 - INFO - PP rank 0 is building stage_idx 4 with modules ['layers.17', 'layers.18', 'layers.19', 'layers.20']
[rank0]:2025-11-28 18:38:19,229 - INFO - Using pipeline schedule Interleaved1F1B with 8 microbatches and 8 stages.
[rank1]:2025-11-28 18:38:19,219 - INFO - PP rank 1 is building stage_idx 5 with modules ['layers.21', 'layers.22', 'layers.23', 'layers.24']
[rank1]:2025-11-28 18:38:19,221 - INFO - Using pipeline schedule Interleaved1F1B with 8 microbatches and 8 stages.
[rank3]:/opt/dlami/nvme/DMLAB/shcho/miniforge3/envs/llm/lib/python3.13/site-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
[rank3]:  warnings.warn(
[rank3]:/opt/dlami/nvme/DMLAB/shcho/miniforge3/envs/llm/lib/python3.13/site-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
[rank3]:  warnings.warn(
[rank0]:2025-11-28 18:38:19,420 - INFO - Peak FLOPS used for computing MFU: 9.890e+14
[rank0]:2025-11-28 18:38:19,420 - INFO - CUDA memory usage for model: 8.46GiB(6.05%)
[rank1]:2025-11-28 18:38:19,409 - INFO - Peak FLOPS used for computing MFU: 9.890e+14
[rank1]:2025-11-28 18:38:19,409 - INFO - CUDA memory usage for model: 7.32GiB(5.23%)
[rank2]:2025-11-28 18:38:19,583 - INFO - CUDA capacity: NVIDIA H200 with 139.81GiB memory
[rank2]:2025-11-28 18:38:19,656 - INFO - PP rank 2 is building stage_idx 2 with modules ['layers.9', 'layers.10', 'layers.11', 'layers.12']
[rank2]:2025-11-28 18:38:19,677 - INFO - PP rank 2 is building stage_idx 6 with modules ['layers.25', 'layers.26', 'layers.27', 'layers.28']
[rank2]:2025-11-28 18:38:19,678 - INFO - Using pipeline schedule Interleaved1F1B with 8 microbatches and 8 stages.
[rank2]:2025-11-28 18:38:19,860 - INFO - Peak FLOPS used for computing MFU: 9.890e+14
[rank2]:2025-11-28 18:38:19,860 - INFO - CUDA memory usage for model: 6.50GiB(4.65%)
[rank3]:wandb: Currently logged in as: orangingq to https://api.wandb.ai. Use `wandb login --relogin` to force relogin
[rank3]:wandb: setting up run ciukwr99
[rank3]:wandb: Tracking run with wandb version 0.22.2
[rank3]:wandb: Run data is saved locally in /opt/dlami/nvme/DMLAB/shcho/torchtitan_data/tb/1128_Interleaved1F1B_timelyauto_h200/20251128-1838/wandb/run-20251128_183819-ciukwr99
[rank3]:wandb: Run `wandb offline` to turn off syncing.
[rank3]:wandb: Syncing run 1128_Interleaved1F1B_timelyauto_h200
[rank3]:wandb: ‚≠êÔ∏è View project at https://wandb.ai/orangingq/torchtitan
[rank3]:wandb: üöÄ View run at https://wandb.ai/orangingq/torchtitan/runs/ciukwr99
[rank3]:2025-11-28 18:38:21,052 - INFO - WandB logging enabled
[rank3]:2025-11-28 18:38:21,053 - INFO - CUDA capacity: NVIDIA H200 with 139.81GiB memory
[rank3]:2025-11-28 18:38:21,125 - INFO - PP rank 3 is building stage_idx 3 with modules ['layers.13', 'layers.14', 'layers.15', 'layers.16']
[rank3]:2025-11-28 18:38:21,146 - INFO - PP rank 3 is building stage_idx 7 with modules ['layers.29', 'layers.30', 'layers.31', 'norm', 'output']
[rank3]:2025-11-28 18:38:21,148 - INFO - Using pipeline schedule Interleaved1F1B with 8 microbatches and 8 stages.
[rank0]:2025-11-28 18:38:21,336 - INFO - Checkpointing active. Checkpoints will be loaded from and saved to /opt/dlami/nvme/DMLAB/shcho/torchtitan_data/checkpoint/1128_Interleaved1F1B_timelyauto_h200
[rank0]:2025-11-28 18:38:21,336 - INFO - Mixed precision training with TP or PP is handled by autocast
[rank0]:2025-11-28 18:38:21,337 - INFO - Trainer is initialized with local batch size 16, global batch size 64, gradient accumulation steps 4, sequence length 1024, total steps 2000 (warmup 200)
[rank0]:2025-11-28 18:38:21,337 - INFO - Loading the checkpoint from /opt/dlami/nvme/DMLAB/shcho/torchtitan_data/base_model/Llama-3.1-8B/original_dcp.
[rank3]:2025-11-28 18:38:21,321 - INFO - Peak FLOPS used for computing MFU: 9.890e+14
[rank3]:2025-11-28 18:38:21,322 - INFO - CUDA memory usage for model: 7.65GiB(5.47%)
[rank3]:2025-11-28 18:38:21,335 - INFO - Mixed precision training with TP or PP is handled by autocast
[rank2]:2025-11-28 18:38:21,335 - INFO - Mixed precision training with TP or PP is handled by autocast
[rank1]:2025-11-28 18:38:21,335 - INFO - Mixed precision training with TP or PP is handled by autocast
[rank0]:2025-11-28 18:38:32,055 - INFO - [GC] GC collection for checkpoint loading. 0.01 seconds
[rank0]:2025-11-28 18:38:32,055 - INFO - Finished loading the checkpoint in 10.72 seconds.
[rank0]:2025-11-28 18:38:32,055 - INFO - Training starts at step 1
[rank1]:2025-11-28 18:38:35,913 - INFO -  step:  1  loss: -4.0000  grad_norm:     inf  memory: 52.49GiB(37.55%)  tps: 979  tflops: 45.65  mfu: 4.62%
[rank1]:2025-11-28 18:38:35,913 - INFO - Synchronizing and adjusting timeout for all ProcessGroups to 0:05:00
[rank3]:2025-11-28 18:38:35,896 - INFO -  step:  1  loss:  8.2933  grad_norm:     inf  memory: 45.21GiB(32.34%)  tps: 1,107  tflops: 51.65  mfu: 5.22%
[rank3]:2025-11-28 18:38:35,896 - INFO - Synchronizing and adjusting timeout for all ProcessGroups to 0:05:00
[rank2]:2025-11-28 18:38:35,911 - INFO -  step:  1  loss: -4.0000  grad_norm:     inf  memory: 41.85GiB(29.93%)  tps: 1,006  tflops: 46.94  mfu: 4.75%
[rank2]:2025-11-28 18:38:35,911 - INFO - Synchronizing and adjusting timeout for all ProcessGroups to 0:05:00
[rank0]:2025-11-28 18:38:35,925 - INFO -  step:  1  loss: -4.0000  grad_norm:     inf  memory: 54.05GiB(38.66%)  tps: 979  tflops: 45.64  mfu: 4.62%
[rank0]:2025-11-28 18:38:35,926 - INFO - Synchronizing and adjusting timeout for all ProcessGroups to 0:05:00
[rank0]:2025-11-28 18:40:58,301 - INFO - [GC] Peforming periodical GC collection 0.00 seconds
[rank3]:2025-11-28 18:41:01,118 - INFO - Avg. fwd time: 8.0174 / Avg. bwd time: 24.2666 / Avg. batch time: 598.8996 (ms) / GPU bubble ratio: 13.75%
[rank1]:2025-11-28 18:41:01,187 - INFO - Avg. fwd time: 8.7050 / Avg. bwd time: 22.6375 / Avg. batch time: 684.4523 (ms) / GPU bubble ratio: 26.73%
[rank0]:2025-11-28 18:41:01,197 - INFO - Avg. fwd time: 8.9340 / Avg. bwd time: 22.1822 / Avg. batch time: 716.9637 (ms) / GPU bubble ratio: 30.56%
[rank2]:2025-11-28 18:41:01,151 - INFO - Avg. fwd time: 8.4048 / Avg. bwd time: 19.9450 / Avg. batch time: 637.5124 (ms) / GPU bubble ratio: 28.85%
[rank1]:2025-11-28 18:41:01,291 - INFO -  step: 50  loss: -4.0000  grad_norm: 5745.0029  memory: 55.52GiB(39.71%)  tps: 5,522  tflops: 257.56  mfu: 26.04%
[rank0]:2025-11-28 18:41:01,295 - INFO -  step: 50  loss: -4.0000  grad_norm: 5745.0029  memory: 61.00GiB(43.63%)  tps: 5,523  tflops: 257.57  mfu: 26.04%
[rank3]:2025-11-28 18:41:01,293 - INFO -  step: 50  loss:  9.4337  grad_norm: 5745.0029  memory: 57.93GiB(41.44%)  tps: 5,522  tflops: 257.53  mfu: 26.04%
[rank2]:2025-11-28 18:41:01,288 - INFO -  step: 50  loss: -4.0000  grad_norm: 5745.0029  memory: 45.32GiB(32.41%)  tps: 5,522  tflops: 257.56  mfu: 26.04%
[rank0]:2025-11-28 18:43:26,891 - INFO - [GC] Peforming periodical GC collection 0.00 seconds
[rank3]:2025-11-28 18:43:29,708 - INFO - Avg. fwd time: 8.0378 / Avg. bwd time: 24.3433 / Avg. batch time: 600.5307 (ms) / GPU bubble ratio: 13.73%
[rank2]:2025-11-28 18:43:29,742 - INFO - Avg. fwd time: 8.4221 / Avg. bwd time: 20.0079 / Avg. batch time: 639.2088 (ms) / GPU bubble ratio: 28.84%
[rank0]:2025-11-28 18:43:29,787 - INFO - Avg. fwd time: 8.9349 / Avg. bwd time: 22.2641 / Avg. batch time: 718.8363 (ms) / GPU bubble ratio: 30.56%
[rank1]:2025-11-28 18:43:29,777 - INFO - Avg. fwd time: 8.7198 / Avg. bwd time: 22.7040 / Avg. batch time: 686.2230 (ms) / GPU bubble ratio: 26.73%
[rank0]:2025-11-28 18:43:29,885 - INFO -  step: 100  loss: -4.0000  grad_norm: 50.8381  memory: 61.00GiB(43.63%)  tps: 5,513  tflops: 257.13  mfu: 26.00%
[rank0]:2025-11-28 18:43:29,886 - WARNING - Nothing to draw before the end of warmup.
[rank1]:2025-11-28 18:43:29,882 - INFO -  step: 100  loss: -4.0000  grad_norm: 50.8381  memory: 55.52GiB(39.71%)  tps: 5,513  tflops: 257.13  mfu: 26.00%
[rank1]:2025-11-28 18:43:29,882 - WARNING - Nothing to draw before the end of warmup.
[rank3]:2025-11-28 18:43:29,883 - INFO -  step: 100  loss:  4.3525  grad_norm: 50.8381  memory: 57.93GiB(41.44%)  tps: 5,513  tflops: 257.14  mfu: 26.00%
[rank3]:2025-11-28 18:43:29,884 - WARNING - Nothing to draw before the end of warmup.
[rank2]:2025-11-28 18:43:29,879 - INFO -  step: 100  loss: -4.0000  grad_norm: 50.8381  memory: 45.32GiB(32.41%)  tps: 5,513  tflops: 257.13  mfu: 26.00%
[rank2]:2025-11-28 18:43:29,879 - WARNING - Nothing to draw before the end of warmup.
[rank0]:2025-11-28 18:45:55,453 - INFO - [GC] Peforming periodical GC collection 0.00 seconds
[rank3]:2025-11-28 18:45:58,335 - INFO - Avg. fwd time: 8.0337 / Avg. bwd time: 24.3657 / Avg. batch time: 600.7930 (ms) / GPU bubble ratio: 13.72%
[rank2]:2025-11-28 18:45:58,365 - INFO - Avg. fwd time: 8.4212 / Avg. bwd time: 20.0402 / Avg. batch time: 639.5309 (ms) / GPU bubble ratio: 28.79%
[rank3]:2025-11-28 18:45:58,467 - INFO -  step: 150  loss:  2.0426  grad_norm: 22.5118  memory: 57.93GiB(41.44%)  tps: 5,513  tflops: 257.15  mfu: 26.00%
[rank0]:2025-11-28 18:45:58,434 - INFO - Avg. fwd time: 8.9311 / Avg. bwd time: 22.2987 / Avg. batch time: 719.2332 (ms) / GPU bubble ratio: 30.53%
[rank1]:2025-11-28 18:45:58,402 - INFO - Avg. fwd time: 8.7176 / Avg. bwd time: 22.7330 / Avg. batch time: 686.5758 (ms) / GPU bubble ratio: 26.71%
[rank1]:2025-11-28 18:45:58,465 - INFO -  step: 150  loss: -4.0000  grad_norm: 22.5118  memory: 55.52GiB(39.71%)  tps: 5,513  tflops: 257.15  mfu: 26.00%
[rank2]:2025-11-28 18:45:58,463 - INFO -  step: 150  loss: -4.0000  grad_norm: 22.5118  memory: 45.32GiB(32.41%)  tps: 5,513  tflops: 257.15  mfu: 26.00%
[rank0]:2025-11-28 18:45:58,469 - INFO -  step: 150  loss: -4.0000  grad_norm: 22.5118  memory: 61.00GiB(43.63%)  tps: 5,513  tflops: 257.15  mfu: 26.00%
[rank3]:2025-11-28 18:46:28,027 - INFO - [Step 160] „Ä∞Ô∏è Monitoring Upperbound
[rank3]:2025-11-28 18:46:57,677 - INFO - [Step 170] ‚úîÔ∏è  Setting Upperbound
[rank3]:2025-11-28 18:46:57,847 - INFO - [Step 170] „Ä∞Ô∏è Monitoring Lowerbound
[rank3]:2025-11-28 18:47:18,184 - INFO - [Step 180] ‚úîÔ∏è  Setting Lowerbound
[rank3]:2025-11-28 18:47:18,466 - INFO - 
[rank3]:Pipeline schedule is saved as: /opt/dlami/nvme/DMLAB/shcho/torchtitan_data/images/1128_Interleaved1F1B_timelyauto_h200/pipeline_schedule/251128_1847_max_batch_time.svg
[rank3]:			> Batch Time: 635.07 ms, GPU Bubble Ratio: 20.78%, 20.34%, 27.86%, 17.96%
[rank3]:			  [Rank 0]	[S0,MB0,F]  0-9-9ms        | [S0,MB1,F]  9-9-18ms       | [S0,MB2,F]  18-9-28ms      | [S0,MB3,F]  28-9-37ms      | [S4,MB0,F]  38-11-49ms     | [S4,MB1,F]  49-9-58ms      | [S4,MB2,F]  58-9-67ms      | [S4,MB3,F]  67-9-77ms      | [S0,MB4,F]  77-8-85ms      | [S0,MB5,F]  85-8-94ms      | [S0,MB6,F]  94-9-103ms     | [S4,MB0,B]  143-20-163ms   | [S0,MB7,F]  163-9-172ms    | [S4,MB1,B]  178-24-203ms   | [S4,MB4,F]  213-7-220ms    | [S4,MB2,B]  220-24-245ms   | [S4,MB5,F]  245-7-252ms    | [S4,MB3,B]  252-24-277ms   | [S4,MB6,F]  277-8-285ms    | [S0,MB0,B]  285-25-310ms   | [S4,MB7,F]  310-8-319ms    | [S0,MB1,B]  319-22-341ms   | [S0,MB2,B]  348-22-371ms   | [S0,MB3,B]  381-22-404ms   | [S4,MB4,B]  404-20-425ms   | [S4,MB5,B]  430-20-450ms   | [S4,MB6,B]  470-20-490ms   | [S4,MB7,B]  506-20-526ms   | [S0,MB4,B]  536-22-559ms   | [S0,MB5,B]  561-22-584ms   | [S0,MB6,B]  586-22-609ms   | [S0,MB7,B]  612-22-635ms  
[rank3]:			  [Rank 1]	[S1,MB0,F]  9-11-20ms      | [S1,MB1,F]  20-8-29ms      | [S1,MB2,F]  29-8-37ms      | [S1,MB3,F]  37-8-46ms      | [S5,MB0,F]  49-8-58ms      | [S5,MB1,F]  58-6-65ms      | [S5,MB2,F]  67-6-74ms      | [S5,MB3,F]  77-6-84ms      | [S1,MB4,F]  85-8-94ms      | [S5,MB0,B]  122-20-143ms   | [S1,MB5,F]  143-9-152ms    | [S5,MB1,B]  158-20-178ms   | [S1,MB6,F]  178-11-189ms   | [S5,MB2,B]  192-20-212ms   | [S1,MB7,F]  212-12-224ms   | [S5,MB3,B]  226-20-247ms   | [S5,MB4,F]  247-9-256ms    | [S1,MB0,B]  256-25-281ms   | [S5,MB5,F]  281-7-289ms    | [S1,MB1,B]  289-25-315ms   | [S5,MB6,F]  315-8-323ms    | [S1,MB2,B]  323-25-348ms   | [S5,MB7,F]  348-7-356ms    | [S1,MB3,B]  356-25-381ms   | [S5,MB4,B]  381-20-402ms   | [S5,MB5,B]  410-20-430ms   | [S5,MB6,B]  449-20-470ms   | [S5,MB7,B]  486-20-506ms   | [S1,MB4,B]  511-25-536ms   | [S1,MB5,B]  536-25-561ms   | [S1,MB6,B]  561-25-586ms   | [S1,MB7,B]  586-25-612ms  
[rank3]:			  [Rank 2]	[S2,MB0,F]  20-8-29ms      | [S2,MB1,F]  29-6-36ms      | [S2,MB2,F]  37-6-44ms      | [S2,MB3,F]  46-6-53ms      | [S6,MB0,F]  58-8-66ms      | [S6,MB1,F]  66-6-73ms      | [S6,MB2,F]  74-6-81ms      | [S6,MB0,B]  102-20-122ms   | [S6,MB3,F]  122-9-132ms    | [S6,MB1,B]  138-20-158ms   | [S2,MB4,F]  158-9-167ms    | [S6,MB2,B]  172-20-192ms   | [S2,MB5,F]  192-9-201ms    | [S6,MB3,B]  206-20-226ms   | [S2,MB6,F]  226-8-235ms    | [S2,MB0,B]  235-20-255ms   | [S2,MB7,F]  255-8-264ms    | [S2,MB1,B]  264-20-284ms   | [S6,MB4,F]  284-9-294ms    | [S2,MB2,B]  294-20-314ms   | [S6,MB5,F]  314-9-323ms    | [S2,MB3,B]  323-20-344ms   | [S6,MB6,F]  344-9-353ms    | [S6,MB4,B]  355-20-375ms   | [S6,MB7,F]  375-9-385ms    | [S6,MB5,B]  389-20-410ms   | [S6,MB6,B]  429-20-449ms   | [S6,MB7,B]  466-20-486ms   | [S2,MB4,B]  490-20-511ms   | [S2,MB5,B]  515-20-535ms   | [S2,MB6,B]  538-20-558ms   | [S2,MB7,B]  558-20-578ms  
[rank3]:			  [Rank 3]	[S3,MB0,F]  29-8-38ms      | [S3,MB1,F]  38-6-44ms      | [S3,MB2,F]  44-6-51ms      | [S3,MB3,F]  53-6-59ms      | [S7,MB0,F]  66-10-77ms     | [S7,MB0,B]  77-25-102ms    AFR(10):0.9655 | [S7,MB1,F]  102-9-112ms    | [S7,MB1,B]  112-25-138ms   AFR(10):0.9655 | [S7,MB2,F]  138-8-146ms    | [S7,MB2,B]  146-25-172ms   AFR(10):0.9655 | [S7,MB3,F]  172-8-180ms    | [S7,MB3,B]  180-26-206ms   AFR(10):0.9655 | [S3,MB4,F]  206-7-213ms    | [S3,MB0,B]  213-20-234ms   AFR(10):1.0000 | [S3,MB5,F]  234-7-241ms    | [S3,MB1,B]  241-21-263ms   AFR(10):1.0000 | [S3,MB6,F]  263-7-270ms    | [S3,MB2,B]  270-22-292ms   AFR(10):1.0000 | [S3,MB7,F]  292-7-300ms    | [S3,MB3,B]  300-20-320ms   AFR(10):1.0000 | [S7,MB4,F]  320-8-329ms    | [S7,MB4,B]  329-26-355ms   AFR(10):0.9655 | [S7,MB5,F]  355-8-363ms    | [S7,MB5,B]  363-26-389ms   AFR(10):0.9655 | [S7,MB6,F]  389-8-398ms    | [S7,MB6,B]  398-31-429ms   AFR(10):0.9655 | [S7,MB7,F]  429-7-437ms    | [S7,MB7,B]  437-28-466ms   AFR(10):0.9655 | [S3,MB4,B]  466-24-490ms   AFR(10):1.0000 | [S3,MB5,B]  490-24-515ms   AFR(10):1.0000 | [S3,MB6,B]  515-22-538ms   AFR(10):1.0000 | [S3,MB7,B]  538-20-558ms   AFR(10):1.0000
[rank3]:2025-11-28 18:47:18,676 - INFO - 
[rank3]:Pipeline schedule is saved as: /opt/dlami/nvme/DMLAB/shcho/torchtitan_data/images/1128_Interleaved1F1B_timelyauto_h200/pipeline_schedule/251128_1847_min_batch_time.svg
[rank3]:			> Batch Time: 365.58 ms, GPU Bubble Ratio: 38.32%, 15.93%, 22.10%, 16.72%
[rank3]:			  [Rank 0]	[S0,MB0,F]  0-9-9ms        | [S0,MB1,F]  9-9-18ms       | [S0,MB2,F]  18-9-28ms      | [S0,MB3,F]  28-9-37ms      | [S4,MB0,F]  38-11-49ms     | [S4,MB1,F]  49-9-58ms      | [S4,MB2,F]  58-9-67ms      | [S4,MB3,F]  67-9-77ms      | [S0,MB4,F]  77-8-85ms      | [S0,MB5,F]  85-8-94ms      | [S0,MB6,F]  94-9-103ms     | [S4,MB0,B]  107-9-116ms    | [S0,MB7,F]  116-9-126ms    | [S4,MB1,B]  128-12-140ms   | [S4,MB4,F]  156-7-163ms    | [S4,MB2,B]  163-11-175ms   | [S4,MB5,F]  175-7-182ms    | [S4,MB3,B]  182-11-194ms   | [S4,MB6,F]  194-8-202ms    | [S0,MB0,B]  202-0-202ms    | [S4,MB7,F]  208-8-216ms    | [S0,MB1,B]  216-0-216ms    | [S0,MB2,B]  230-0-230ms    | [S0,MB3,B]  249-0-249ms    | [S4,MB4,B]  261-9-271ms    | [S4,MB5,B]  280-9-289ms    | [S4,MB6,B]  296-9-306ms    | [S4,MB7,B]  316-9-326ms    | [S0,MB4,B]  329-0-329ms    | [S0,MB5,B]  342-0-342ms    | [S0,MB6,B]  354-0-354ms    | [S0,MB7,B]  365-0-365ms   
[rank3]:			  [Rank 1]	[S1,MB0,F]  9-11-20ms      | [S1,MB1,F]  20-8-29ms      | [S1,MB2,F]  29-8-37ms      | [S1,MB3,F]  37-8-46ms      | [S5,MB0,F]  49-8-58ms      | [S5,MB1,F]  58-6-65ms      | [S5,MB2,F]  67-6-74ms      | [S5,MB3,F]  77-6-84ms      | [S1,MB4,F]  85-8-94ms      | [S5,MB0,B]  98-9-107ms     | [S1,MB5,F]  107-9-116ms    | [S5,MB1,B]  119-9-128ms    | [S1,MB6,F]  128-11-139ms   | [S5,MB2,B]  139-9-149ms    | [S1,MB7,F]  149-12-161ms   | [S5,MB3,B]  161-9-170ms    | [S5,MB4,F]  170-9-179ms    | [S1,MB0,B]  179-11-191ms   | [S5,MB5,F]  191-7-199ms    | [S1,MB1,B]  199-11-211ms   | [S5,MB6,F]  211-8-219ms    | [S1,MB2,B]  219-11-230ms   | [S5,MB7,F]  230-7-238ms    | [S1,MB3,B]  238-11-249ms   | [S5,MB4,B]  252-9-261ms    | [S5,MB5,B]  271-9-280ms    | [S5,MB6,B]  287-9-296ms    | [S5,MB7,B]  307-9-316ms    | [S1,MB4,B]  318-11-329ms   | [S1,MB5,B]  330-11-342ms   | [S1,MB6,B]  342-11-354ms   | [S1,MB7,B]  354-11-365ms  
[rank3]:			  [Rank 2]	[S2,MB0,F]  20-8-29ms      | [S2,MB1,F]  29-6-36ms      | [S2,MB2,F]  37-6-44ms      | [S2,MB3,F]  46-6-53ms      | [S6,MB0,F]  58-8-66ms      | [S6,MB1,F]  66-6-73ms      | [S6,MB2,F]  74-6-81ms      | [S6,MB0,B]  88-9-98ms      | [S6,MB3,F]  98-9-107ms     | [S6,MB1,B]  110-9-119ms    | [S2,MB4,F]  119-9-128ms    | [S6,MB2,B]  129-9-138ms    | [S2,MB5,F]  138-9-148ms    | [S6,MB3,B]  149-9-158ms    | [S2,MB6,F]  158-8-167ms    | [S2,MB0,B]  167-9-176ms    | [S2,MB7,F]  176-8-185ms    | [S2,MB1,B]  185-9-194ms    | [S6,MB4,F]  194-9-203ms    | [S2,MB2,B]  203-9-213ms    | [S6,MB5,F]  213-9-223ms    | [S2,MB3,B]  223-9-233ms    | [S6,MB6,F]  233-9-242ms    | [S6,MB4,B]  242-9-252ms    | [S6,MB7,F]  252-9-261ms    | [S6,MB5,B]  261-9-271ms    | [S6,MB6,B]  278-9-287ms    | [S6,MB7,B]  298-9-307ms    | [S2,MB4,B]  309-9-318ms    | [S2,MB5,B]  321-9-330ms    | [S2,MB6,B]  332-9-341ms    | [S2,MB7,B]  342-9-351ms   
[rank3]:			  [Rank 3]	[S3,MB0,F]  29-8-38ms      | [S3,MB1,F]  38-6-44ms      | [S3,MB2,F]  44-6-51ms      | [S3,MB3,F]  53-6-59ms      | [S7,MB0,F]  66-10-77ms     | [S7,MB0,B]  77-11-88ms     AFR(10):0.9655 | [S7,MB1,F]  88-9-98ms      | [S7,MB1,B]  98-11-110ms    AFR(10):0.9655 | [S7,MB2,F]  110-8-118ms    | [S7,MB2,B]  118-11-129ms   AFR(10):0.9655 | [S7,MB3,F]  129-8-137ms    | [S7,MB3,B]  137-11-149ms   AFR(10):0.9655 | [S3,MB4,F]  149-7-156ms    | [S3,MB0,B]  156-9-166ms    AFR(10):1.0000 | [S3,MB5,F]  166-7-173ms    | [S3,MB1,B]  173-10-183ms   AFR(10):1.0000 | [S3,MB6,F]  183-7-191ms    | [S3,MB2,B]  191-10-201ms   AFR(10):1.0000 | [S3,MB7,F]  201-7-208ms    | [S3,MB3,B]  208-9-217ms    AFR(10):1.0000 | [S7,MB4,F]  217-8-226ms    | [S7,MB4,B]  226-11-238ms   AFR(10):0.9655 | [S7,MB5,F]  238-8-246ms    | [S7,MB5,B]  246-11-258ms   AFR(10):0.9655 | [S7,MB6,F]  258-8-266ms    | [S7,MB6,B]  266-11-278ms   AFR(10):0.9655 | [S7,MB7,F]  278-7-286ms    | [S7,MB7,B]  286-12-298ms   AFR(10):0.9655 | [S3,MB4,B]  298-10-309ms   AFR(10):1.0000 | [S3,MB5,B]  309-12-321ms   AFR(10):1.0000 | [S3,MB6,B]  321-10-332ms   AFR(10):1.0000 | [S3,MB7,B]  332-9-342ms    AFR(10):1.0000
[rank0]:2025-11-28 18:48:38,939 - INFO - Destroying the purge thread.
[rank0]:[rank0]: Traceback (most recent call last):
[rank0]:[rank0]:   File "<frozen runpy>", line 198, in _run_module_as_main
[rank0]:[rank0]:   File "<frozen runpy>", line 88, in _run_code
[rank0]:[rank0]:   File "/opt/dlami/nvme/DMLAB/shcho/torchtitan/timelyfreeze/train.py", line 754, in <module>
[rank0]:[rank0]:     trainer.train()
[rank0]:[rank0]:     ~~~~~~~~~~~~~^^
[rank0]:[rank0]:   File "/opt/dlami/nvme/DMLAB/shcho/miniforge3/envs/llm/lib/python3.13/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 362, in wrapper
[rank0]:[rank0]:     return f(*args, **kwargs)
[rank0]:[rank0]:   File "/opt/dlami/nvme/DMLAB/shcho/torchtitan/timelyfreeze/train.py", line 584, in train
[rank0]:[rank0]:     self.train_step(data_iterator)
[rank0]:[rank0]:     ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^
[rank0]:[rank0]:   File "/opt/dlami/nvme/DMLAB/shcho/torchtitan/timelyfreeze/train.py", line 509, in train_step
[rank0]:[rank0]:     self.freezer.freeze_update(self.step) # this should be called after optimizer.step()
[rank0]:[rank0]:     ~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^
[rank0]:[rank0]:   File "/opt/dlami/nvme/DMLAB/shcho/torchtitan/timelyfreeze/core/freezer.py", line 703, in freeze_update
[rank0]:[rank0]:     self.set_expected_freeze_ratio()
[rank0]:[rank0]:     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^
[rank0]:[rank0]:   File "/opt/dlami/nvme/DMLAB/shcho/torchtitan/timelyfreeze/core/freezer.py", line 717, in set_expected_freeze_ratio
[rank0]:[rank0]:     super().set_expected_freeze_ratio()
[rank0]:[rank0]:     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^
[rank0]:[rank0]:   File "/opt/dlami/nvme/DMLAB/shcho/torchtitan/timelyfreeze/core/freezer.py", line 165, in set_expected_freeze_ratio
[rank0]:[rank0]:     self._set_lowerbound()
[rank0]:[rank0]:     ~~~~~~~~~~~~~~~~~~~~^^
[rank0]:[rank0]:   File "/opt/dlami/nvme/DMLAB/shcho/torchtitan/timelyfreeze/core/freezer.py", line 335, in _set_lowerbound
[rank0]:[rank0]:     self.pipeline_schedule = set_freeze_ratio(self.pipeline_schedule, config=self.config)
[rank0]:[rank0]:                              ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank0]:[rank0]:   File "/opt/dlami/nvme/DMLAB/shcho/torchtitan/timelyfreeze/core/schedule.py", line 532, in set_freeze_ratio
[rank0]:[rank0]:     pipeline_schedule_freezing = solve_dag_qp(pipeline_schedule_freezing, max_freeze_ratio=max_freeze_ratio) # solve the DAG LP problem to find the optimal schedule
[rank0]:[rank0]:   File "/opt/dlami/nvme/DMLAB/shcho/torchtitan/timelyfreeze/core/schedule.py", line 400, in solve_dag_qp
[rank0]:[rank0]:     raise RuntimeError(f"Quadratic programming failed: {res.message}")
[rank0]:[rank0]: RuntimeError: Quadratic programming failed: The maximum number of function evaluations is exceeded.
[rank2]:2025-11-28 18:48:39,161 - INFO - Destroying the purge thread.
[rank2]:[rank2]: Traceback (most recent call last):
[rank2]:[rank2]:   File "<frozen runpy>", line 198, in _run_module_as_main
[rank2]:[rank2]:   File "<frozen runpy>", line 88, in _run_code
[rank2]:[rank2]:   File "/opt/dlami/nvme/DMLAB/shcho/torchtitan/timelyfreeze/train.py", line 754, in <module>
[rank2]:[rank2]:     trainer.train()
[rank2]:[rank2]:     ~~~~~~~~~~~~~^^
[rank2]:[rank2]:   File "/opt/dlami/nvme/DMLAB/shcho/miniforge3/envs/llm/lib/python3.13/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 362, in wrapper
[rank2]:[rank2]:     return f(*args, **kwargs)
[rank2]:[rank2]:   File "/opt/dlami/nvme/DMLAB/shcho/torchtitan/timelyfreeze/train.py", line 584, in train
[rank2]:[rank2]:     self.train_step(data_iterator)
[rank2]:[rank2]:     ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^
[rank2]:[rank2]:   File "/opt/dlami/nvme/DMLAB/shcho/torchtitan/timelyfreeze/train.py", line 509, in train_step
[rank2]:[rank2]:     self.freezer.freeze_update(self.step) # this should be called after optimizer.step()
[rank2]:[rank2]:     ~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^
[rank2]:[rank2]:   File "/opt/dlami/nvme/DMLAB/shcho/torchtitan/timelyfreeze/core/freezer.py", line 703, in freeze_update
[rank2]:[rank2]:     self.set_expected_freeze_ratio()
[rank2]:[rank2]:     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^
[rank2]:[rank2]:   File "/opt/dlami/nvme/DMLAB/shcho/torchtitan/timelyfreeze/core/freezer.py", line 717, in set_expected_freeze_ratio
[rank2]:[rank2]:     super().set_expected_freeze_ratio()
[rank2]:[rank2]:     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^
[rank2]:[rank2]:   File "/opt/dlami/nvme/DMLAB/shcho/torchtitan/timelyfreeze/core/freezer.py", line 165, in set_expected_freeze_ratio
[rank2]:[rank2]:     self._set_lowerbound()
[rank2]:[rank2]:     ~~~~~~~~~~~~~~~~~~~~^^
[rank2]:[rank2]:   File "/opt/dlami/nvme/DMLAB/shcho/torchtitan/timelyfreeze/core/freezer.py", line 335, in _set_lowerbound
[rank2]:[rank2]:     self.pipeline_schedule = set_freeze_ratio(self.pipeline_schedule, config=self.config)
[rank2]:[rank2]:                              ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank2]:[rank2]:   File "/opt/dlami/nvme/DMLAB/shcho/torchtitan/timelyfreeze/core/schedule.py", line 532, in set_freeze_ratio
[rank2]:[rank2]:     pipeline_schedule_freezing = solve_dag_qp(pipeline_schedule_freezing, max_freeze_ratio=max_freeze_ratio) # solve the DAG LP problem to find the optimal schedule
[rank2]:[rank2]:   File "/opt/dlami/nvme/DMLAB/shcho/torchtitan/timelyfreeze/core/schedule.py", line 400, in solve_dag_qp
[rank2]:[rank2]:     raise RuntimeError(f"Quadratic programming failed: {res.message}")
[rank2]:[rank2]: RuntimeError: Quadratic programming failed: The maximum number of function evaluations is exceeded.
[rank3]:2025-11-28 18:48:39,381 - INFO - Destroying the purge thread.
[rank3]:wandb: updating run metadata
[rank0]:[rank0]:[W1128 18:48:39.973115614 ProcessGroupNCCL.cpp:1552] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
[rank1]:2025-11-28 18:48:39,789 - INFO - Destroying the purge thread.
[rank1]:[rank1]: Traceback (most recent call last):
[rank1]:[rank1]:   File "<frozen runpy>", line 198, in _run_module_as_main
[rank1]:[rank1]:   File "<frozen runpy>", line 88, in _run_code
[rank1]:[rank1]:   File "/opt/dlami/nvme/DMLAB/shcho/torchtitan/timelyfreeze/train.py", line 754, in <module>
[rank1]:[rank1]:     trainer.train()
[rank1]:[rank1]:     ~~~~~~~~~~~~~^^
[rank1]:[rank1]:   File "/opt/dlami/nvme/DMLAB/shcho/miniforge3/envs/llm/lib/python3.13/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 362, in wrapper
[rank1]:[rank1]:     return f(*args, **kwargs)
[rank1]:[rank1]:   File "/opt/dlami/nvme/DMLAB/shcho/torchtitan/timelyfreeze/train.py", line 584, in train
[rank1]:[rank1]:     self.train_step(data_iterator)
[rank1]:[rank1]:     ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^
[rank1]:[rank1]:   File "/opt/dlami/nvme/DMLAB/shcho/torchtitan/timelyfreeze/train.py", line 509, in train_step
[rank1]:[rank1]:     self.freezer.freeze_update(self.step) # this should be called after optimizer.step()
[rank1]:[rank1]:     ~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^
[rank1]:[rank1]:   File "/opt/dlami/nvme/DMLAB/shcho/torchtitan/timelyfreeze/core/freezer.py", line 703, in freeze_update
[rank1]:[rank1]:     self.set_expected_freeze_ratio()
[rank1]:[rank1]:     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^
[rank1]:[rank1]:   File "/opt/dlami/nvme/DMLAB/shcho/torchtitan/timelyfreeze/core/freezer.py", line 717, in set_expected_freeze_ratio
[rank1]:[rank1]:     super().set_expected_freeze_ratio()
[rank1]:[rank1]:     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^
[rank1]:[rank1]:   File "/opt/dlami/nvme/DMLAB/shcho/torchtitan/timelyfreeze/core/freezer.py", line 165, in set_expected_freeze_ratio
[rank1]:[rank1]:     self._set_lowerbound()
[rank1]:[rank1]:     ~~~~~~~~~~~~~~~~~~~~^^
[rank1]:[rank1]:   File "/opt/dlami/nvme/DMLAB/shcho/torchtitan/timelyfreeze/core/freezer.py", line 335, in _set_lowerbound
[rank1]:[rank1]:     self.pipeline_schedule = set_freeze_ratio(self.pipeline_schedule, config=self.config)
[rank1]:[rank1]:                              ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank1]:[rank1]:   File "/opt/dlami/nvme/DMLAB/shcho/torchtitan/timelyfreeze/core/schedule.py", line 532, in set_freeze_ratio
[rank1]:[rank1]:     pipeline_schedule_freezing = solve_dag_qp(pipeline_schedule_freezing, max_freeze_ratio=max_freeze_ratio) # solve the DAG LP problem to find the optimal schedule
[rank1]:[rank1]:   File "/opt/dlami/nvme/DMLAB/shcho/torchtitan/timelyfreeze/core/schedule.py", line 400, in solve_dag_qp
[rank1]:[rank1]:     raise RuntimeError(f"Quadratic programming failed: {res.message}")
[rank1]:[rank1]: RuntimeError: Quadratic programming failed: The maximum number of function evaluations is exceeded.
[rank3]:wandb: uploading history steps 3-3, summary, console lines 207-207
[rank3]:wandb: 
[rank3]:wandb: Run history:
[rank3]:wandb:                    grad_norm  ‚ñà‚ñÅ‚ñÅ
[rank3]:wandb: loss_metrics/global_avg_loss ‚ñá‚ñà‚ñÉ‚ñÅ
[rank3]:wandb: loss_metrics/global_max_loss ‚ñá‚ñà‚ñÉ‚ñÅ
[rank3]:wandb:                           lr ‚ñÅ‚ñÉ‚ñÜ‚ñà
[rank3]:wandb:         memory/max_active(%) ‚ñÅ‚ñà‚ñà‚ñà
[rank3]:wandb:       memory/max_active(GiB) ‚ñÅ‚ñà‚ñà‚ñà
[rank3]:wandb:       memory/max_reserved(%) ‚ñÅ‚ñà‚ñà‚ñà
[rank3]:wandb:     memory/max_reserved(GiB) ‚ñÅ‚ñà‚ñà‚ñà
[rank3]:wandb:     memory/num_alloc_retries ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[rank3]:wandb:              memory/num_ooms ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[rank3]:wandb:                           +7 ...
[rank3]:wandb: 
[rank3]:wandb: Run summary:
[rank3]:wandb:                    grad_norm 22.51176
[rank3]:wandb: loss_metrics/global_avg_loss 2.04264
[rank3]:wandb: loss_metrics/global_max_loss 2.04264
[rank3]:wandb:                           lr 0.0
[rank3]:wandb:         memory/max_active(%) 35.87933
[rank3]:wandb:       memory/max_active(GiB) 50.16338
[rank3]:wandb:       memory/max_reserved(%) 41.43558
[rank3]:wandb:     memory/max_reserved(GiB) 57.93164
[rank3]:wandb:     memory/num_alloc_retries 0
[rank3]:wandb:              memory/num_ooms 0
[rank3]:wandb:                           +7 ...
[rank3]:wandb: 
[rank3]:wandb: üöÄ View run 1128_Interleaved1F1B_timelyauto_h200 at: https://wandb.ai/orangingq/torchtitan/runs/ciukwr99
[rank3]:wandb: ‚≠êÔ∏è View project at: https://wandb.ai/orangingq/torchtitan
[rank3]:wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
[rank3]:wandb: Find logs at: ._data/tb/1128_Interleaved1F1B_timelyauto_h200/20251128-1838/wandb/run-20251128_183819-ciukwr99/logs
[rank3]:Traceback (most recent call last):
[rank3]:  File "<frozen runpy>", line 198, in _run_module_as_main
[rank3]:  File "<frozen runpy>", line 88, in _run_code
[rank3]:  File "/opt/dlami/nvme/DMLAB/shcho/torchtitan/timelyfreeze/train.py", line 754, in <module>
[rank3]:    trainer.train()
[rank3]:    ~~~~~~~~~~~~~^^
[rank3]:  File "/opt/dlami/nvme/DMLAB/shcho/miniforge3/envs/llm/lib/python3.13/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 362, in wrapper
[rank3]:    return f(*args, **kwargs)
[rank3]:  File "/opt/dlami/nvme/DMLAB/shcho/torchtitan/timelyfreeze/train.py", line 584, in train
[rank3]:    self.train_step(data_iterator)
[rank3]:    ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^
[rank3]:  File "/opt/dlami/nvme/DMLAB/shcho/torchtitan/timelyfreeze/train.py", line 509, in train_step
[rank3]:    self.freezer.freeze_update(self.step) # this should be called after optimizer.step()
[rank3]:    ~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^
[rank3]:  File "/opt/dlami/nvme/DMLAB/shcho/torchtitan/timelyfreeze/core/freezer.py", line 703, in freeze_update
[rank3]:    self.set_expected_freeze_ratio()
[rank3]:    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^
[rank3]:  File "/opt/dlami/nvme/DMLAB/shcho/torchtitan/timelyfreeze/core/freezer.py", line 717, in set_expected_freeze_ratio
[rank3]:    super().set_expected_freeze_ratio()
[rank3]:    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^
[rank3]:  File "/opt/dlami/nvme/DMLAB/shcho/torchtitan/timelyfreeze/core/freezer.py", line 165, in set_expected_freeze_ratio
[rank3]:    self._set_lowerbound()
[rank3]:    ~~~~~~~~~~~~~~~~~~~~^^
[rank3]:  File "/opt/dlami/nvme/DMLAB/shcho/torchtitan/timelyfreeze/core/freezer.py", line 335, in _set_lowerbound
[rank3]:    self.pipeline_schedule = set_freeze_ratio(self.pipeline_schedule, config=self.config)
[rank3]:                             ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank3]:  File "/opt/dlami/nvme/DMLAB/shcho/torchtitan/timelyfreeze/core/schedule.py", line 532, in set_freeze_ratio
[rank3]:    pipeline_schedule_freezing = solve_dag_qp(pipeline_schedule_freezing, max_freeze_ratio=max_freeze_ratio) # solve the DAG LP problem to find the optimal schedule
[rank3]:  File "/opt/dlami/nvme/DMLAB/shcho/torchtitan/timelyfreeze/core/schedule.py", line 400, in solve_dag_qp
[rank3]:    raise RuntimeError(f"Quadratic programming failed: {res.message}")
[rank3]:RuntimeError: Quadratic programming failed: The maximum number of function evaluations is exceeded.
[rank3]:[rank3]: Traceback (most recent call last):
[rank3]:[rank3]:   File "<frozen runpy>", line 198, in _run_module_as_main
[rank3]:[rank3]:   File "<frozen runpy>", line 88, in _run_code
[rank3]:[rank3]:   File "/opt/dlami/nvme/DMLAB/shcho/torchtitan/timelyfreeze/train.py", line 754, in <module>
[rank3]:[rank3]:     trainer.train()
[rank3]:[rank3]:     ~~~~~~~~~~~~~^^
[rank3]:[rank3]:   File "/opt/dlami/nvme/DMLAB/shcho/miniforge3/envs/llm/lib/python3.13/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 362, in wrapper
[rank3]:[rank3]:     return f(*args, **kwargs)
[rank3]:[rank3]:   File "/opt/dlami/nvme/DMLAB/shcho/torchtitan/timelyfreeze/train.py", line 584, in train
[rank3]:[rank3]:     self.train_step(data_iterator)
[rank3]:[rank3]:     ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^
[rank3]:[rank3]:   File "/opt/dlami/nvme/DMLAB/shcho/torchtitan/timelyfreeze/train.py", line 509, in train_step
[rank3]:[rank3]:     self.freezer.freeze_update(self.step) # this should be called after optimizer.step()
[rank3]:[rank3]:     ~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^
[rank3]:[rank3]:   File "/opt/dlami/nvme/DMLAB/shcho/torchtitan/timelyfreeze/core/freezer.py", line 703, in freeze_update
[rank3]:[rank3]:     self.set_expected_freeze_ratio()
[rank3]:[rank3]:     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^
[rank3]:[rank3]:   File "/opt/dlami/nvme/DMLAB/shcho/torchtitan/timelyfreeze/core/freezer.py", line 717, in set_expected_freeze_ratio
[rank3]:[rank3]:     super().set_expected_freeze_ratio()
[rank3]:[rank3]:     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^
[rank3]:[rank3]:   File "/opt/dlami/nvme/DMLAB/shcho/torchtitan/timelyfreeze/core/freezer.py", line 165, in set_expected_freeze_ratio
[rank3]:[rank3]:     self._set_lowerbound()
[rank3]:[rank3]:     ~~~~~~~~~~~~~~~~~~~~^^
[rank3]:[rank3]:   File "/opt/dlami/nvme/DMLAB/shcho/torchtitan/timelyfreeze/core/freezer.py", line 335, in _set_lowerbound
[rank3]:[rank3]:     self.pipeline_schedule = set_freeze_ratio(self.pipeline_schedule, config=self.config)
[rank3]:[rank3]:                              ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank3]:[rank3]:   File "/opt/dlami/nvme/DMLAB/shcho/torchtitan/timelyfreeze/core/schedule.py", line 532, in set_freeze_ratio
[rank3]:[rank3]:     pipeline_schedule_freezing = solve_dag_qp(pipeline_schedule_freezing, max_freeze_ratio=max_freeze_ratio) # solve the DAG LP problem to find the optimal schedule
[rank3]:[rank3]:   File "/opt/dlami/nvme/DMLAB/shcho/torchtitan/timelyfreeze/core/schedule.py", line 400, in solve_dag_qp
[rank3]:[rank3]:     raise RuntimeError(f"Quadratic programming failed: {res.message}")
[rank3]:[rank3]: RuntimeError: Quadratic programming failed: The maximum number of function evaluations is exceeded.
W1128 18:48:41.642000 1039860 site-packages/torch/distributed/elastic/multiprocessing/api.py:940] Sending process 1039980 closing signal SIGTERM
W1128 18:48:41.643000 1039860 site-packages/torch/distributed/elastic/multiprocessing/api.py:940] Sending process 1039981 closing signal SIGTERM
W1128 18:48:41.643000 1039860 site-packages/torch/distributed/elastic/multiprocessing/api.py:940] Sending process 1039982 closing signal SIGTERM
E1128 18:48:43.310000 1039860 site-packages/torch/distributed/elastic/multiprocessing/api.py:914] failed (exitcode: 1) local_rank: 0 (pid: 1039979) of binary: /opt/dlami/nvme/DMLAB/shcho/miniforge3/envs/llm/bin/python3.13
E1128 18:48:43.327000 1039860 site-packages/torch/distributed/elastic/multiprocessing/errors/error_handler.py:141] no error file defined for parent, to copy child error file (/tmp/torchelastic_zqw3wlee/9f16cdde-5f0d-43ce-95e1-a29cf8b86202_bl0u21oo/attempt_0/0/error.json)
[rank0]:Stage 0: Modules to keep: {'tok_embeddings', 'layers.3', 'layers.2', 'layers.0', 'layers.1'}
[rank1]:Stage 1: Modules to keep: {'layers.6', 'layers.5', 'layers.7', 'layers.4', 'layers.8'}
[rank0]:Stage 4: Modules to keep: {'layers.20', 'layers.18', 'layers.17', 'layers.19'}
[rank1]:Stage 5: Modules to keep: {'layers.22', 'layers.24', 'layers.21', 'layers.23'}
[rank2]:Stage 2: Modules to keep: {'layers.12', 'layers.11', 'layers.9', 'layers.10'}
[rank2]:Stage 6: Modules to keep: {'layers.25', 'layers.28', 'layers.27', 'layers.26'}
[rank3]:Stage 3: Modules to keep: {'layers.16', 'layers.15', 'layers.13', 'layers.14'}
[rank3]:Stage 7: Modules to keep: {'norm', 'layers.29', 'layers.30', 'output', 'layers.31'}
[rank3]:----- TimelyFreeze‚è∞ Configuration:
[rank3]:	- job:
[rank3]:		- config_file: /opt/dlami/nvme/DMLAB/shcho/torchtitan/logs/h200/1104_llama8b/config_1128.toml
[rank3]:		- dump_folder: /opt/dlami/nvme/DMLAB/shcho/torchtitan_data
[rank3]:		- description: "Llama 3.1 8B Experiment
[rank3]:1109: 1) resolved timelyapf issue, 2) seed fixed to 42 for all runs, 3) 3000 steps -> 2000 steps (better benchmark scores!)
[rank3]:1116: everything same, but with seed=11
[rank3]:1128: everything same as 1109, but with th=1e-3, and solve DAG with QP. 
[rank3]:"
[rank3]:		- use_for_integration_test: False
[rank3]:		- print_args: False
[rank3]:		- basename: 1128_Interleaved1F1B_timelyauto_h200
[rank3]:	- profiling:
[rank3]:		- enable_profiling: False
[rank3]:		- save_traces_folder: /opt/dlami/nvme/DMLAB/shcho/torchtitan_data/profile_trace/1128_Interleaved1F1B_timelyauto_h200
[rank3]:		- profile_freq: 100
[rank3]:		- enable_memory_snapshot: False
[rank3]:		- save_memory_snapshot_folder: /opt/dlami/nvme/DMLAB/shcho/torchtitan_data/memory_snapshot/1128_Interleaved1F1B_timelyauto_h200
[rank3]:	- metrics:
[rank3]:		- log_freq: 50
[rank3]:		- enable_tensorboard: False
[rank3]:		- disable_color_printing: True
[rank3]:		- save_tb_folder: /opt/dlami/nvme/DMLAB/shcho/torchtitan_data/tb/1128_Interleaved1F1B_timelyauto_h200
[rank3]:		- save_for_all_ranks: False
[rank3]:		- enable_wandb: True
[rank3]:		- image_folder: /opt/dlami/nvme/DMLAB/shcho/torchtitan_data/images/1128_Interleaved1F1B_timelyauto_h200
[rank3]:		- pplog_freq: 200
[rank3]:		- draw_freq: 100
[rank3]:		- wandb_name: 1128_Interleaved1F1B_timelyauto_h200
[rank3]:		- draw_graph: True
[rank3]:	- model:
[rank3]:		- name: llama3
[rank3]:		- flavor: 8B
[rank3]:		- tokenizer_path: ./assets/tokenizer/Llama-3.1-8B
[rank3]:		- converters: []
[rank3]:		- print_after_conversion: False
[rank3]:	- optimizer:
[rank3]:		- name: AdamW
[rank3]:		- lr: 3e-06
[rank3]:		- beta1: 0.9
[rank3]:		- beta2: 0.999
[rank3]:		- eps: 1e-08
[rank3]:		- weight_decay: 0.1
[rank3]:		- implementation: fused
[rank3]:		- early_step_in_backward: False
[rank3]:	- lr_scheduler:
[rank3]:		- warmup_steps: 200
[rank3]:		- decay_ratio: 0.8
[rank3]:		- decay_type: cosine
[rank3]:		- min_lr_factor: 0.0
[rank3]:	- training:
[rank3]:		- dataset: openhermes
[rank3]:		- dataset_path: None
[rank3]:		- local_batch_size: 16
[rank3]:		- global_batch_size: 64
[rank3]:		- seq_len: 1024
[rank3]:		- max_norm: 1.0
[rank3]:		- steps: 2000
[rank3]:		- enable_cpu_offload: False
[rank3]:		- mixed_precision_param: bfloat16
[rank3]:		- mixed_precision_reduce: float32
[rank3]:		- compile: False
[rank3]:		- gc_freq: 50
[rank3]:		- gc_debug: False
[rank3]:		- seed: 42
[rank3]:		- deterministic: True
[rank3]:	- parallelism:
[rank3]:		- data_parallel_replicate_degree: 1
[rank3]:		- enable_compiled_autograd: False
[rank3]:		- data_parallel_shard_degree: -1
[rank3]:		- fsdp_reshard_after_forward: default
[rank3]:		- tensor_parallel_degree: 1
[rank3]:		- disable_loss_parallel: False
[rank3]:		- enable_async_tensor_parallel: False
[rank3]:		- pipeline_parallel_degree: 4
[rank3]:		- pipeline_parallel_split_points: []
[rank3]:		- module_fqns_per_model_part: None
[rank3]:		- pipeline_parallel_first_stage_less_layers: 1
[rank3]:		- pipeline_parallel_last_stage_less_layers: 1
[rank3]:		- pipeline_parallel_layers_per_stage: None
[rank3]:		- pipeline_parallel_schedule: Interleaved1F1B
[rank3]:		- pipeline_parallel_schedule_csv: 
[rank3]:		- pipeline_parallel_microbatch_size: 2
[rank3]:		- context_parallel_degree: 1
[rank3]:		- context_parallel_rotate_method: allgather
[rank3]:		- expert_parallel_degree: 1
[rank3]:		- pp: 4
[rank3]:		- stages_per_rank: 2
[rank3]:		- stages_list: [3, 7]
[rank3]:		- microbatches: 8
[rank3]:	- checkpoint:
[rank3]:		- enable_checkpoint: True
[rank3]:		- checkpoint_folder: /opt/dlami/nvme/DMLAB/shcho/torchtitan_data/checkpoint/1128_Interleaved1F1B_timelyauto_h200
[rank3]:		- interval: 1000
[rank3]:		- initial_load_path: /opt/dlami/nvme/DMLAB/shcho/torchtitan_data/base_model/Llama-3.1-8B/original_dcp
[rank3]:		- initial_load_model_only: True
[rank3]:		- initial_load_in_hf: False
[rank3]:		- last_save_model_only: True
[rank3]:		- last_save_in_hf: False
[rank3]:		- export_dtype: float16
[rank3]:		- async_mode: async
[rank3]:		- keep_latest_k: 2
[rank3]:		- load_step: -1
[rank3]:		- exclude_from_loading: ['dataloader', 'lr_scheduler', 'optimizer', 'train_state']
[rank3]:		- enable_first_step_checkpoint: False
[rank3]:		- create_seed_checkpoint: False
[rank3]:	- activation_checkpoint:
[rank3]:		- mode: none
[rank3]:		- selective_ac_option: op
[rank3]:		- per_op_sac_force_recompute_mm_shapes_by_fqns: ['moe.router.gate']
[rank3]:	- float8:
[rank3]:		- enable_fsdp_float8_all_gather: False
[rank3]:		- precompute_float8_dynamic_scale_for_fsdp: False
[rank3]:		- recipe_name: None
[rank3]:		- filter_fqns: ['output']
[rank3]:		- emulate: False
[rank3]:		- moe_fqns_prototype: []
[rank3]:	- mx:
[rank3]:		- mxfp8_dim1_cast_kernel_choice: triton
[rank3]:		- recipe_name: mxfp8
[rank3]:		- filter_fqns: ['output']
[rank3]:		- moe_fqns_prototype: []
[rank3]:	- comm:
[rank3]:		- init_timeout_seconds: 300
[rank3]:		- train_timeout_seconds: 300
[rank3]:		- trace_buf_size: 20000
[rank3]:		- save_traces_folder: /opt/dlami/nvme/DMLAB/shcho/torchtitan_data/comm_traces/1128_Interleaved1F1B_timelyauto_h200
[rank3]:		- world_size: 4
[rank3]:		- global_rank: 3
[rank3]:		- local_rank: 3
[rank3]:		- dp: 1
[rank3]:		- pp: 4
[rank3]:		- pp_rank: 3
[rank3]:		- dp_rank: 0
[rank3]:		- master_dp_rank: 0
[rank3]:	- memory_estimation:
[rank3]:		- enabled: False
[rank3]:		- disable_fake_mode: False
[rank3]:	- fault_tolerance:
[rank3]:		- enable: False
[rank3]:		- process_group: gloo
[rank3]:		- process_group_timeout_ms: 10000
[rank3]:		- replica_id: 0
[rank3]:		- group_size: 0
[rank3]:		- min_replica_size: 1
[rank3]:		- semi_sync_method: None
[rank3]:		- sync_steps: 5
[rank3]:		- should_quantize: False
[rank3]:		- fragment_sync_delay: 0
[rank3]:		- fragment_update_alpha: 0.0
[rank3]:	- experimental:
[rank3]:		- custom_import: 
[rank3]:		- custom_args_module: 
[rank3]:	- validation:
[rank3]:		- enabled: False
[rank3]:		- dataset: c4_validation
[rank3]:		- dataset_path: None
[rank3]:		- local_batch_size: 8
[rank3]:		- seq_len: 2048
[rank3]:		- freq: 10
[rank3]:		- steps: -1
[rank3]:	- freezing:
[rank3]:		- freeze: True
[rank3]:		- metric_type: timelyauto
[rank3]:		- phase_unit: 50
[rank3]:		- stability_check_freq: 10
[rank3]:		- max_freeze_ratio: 0.7
[rank3]:		- adjustment: False
[rank3]:		- threshold: 0.0001
[rank3]:		- percentile: 80
[rank3]:
[rank0]:[Gloo] Rank 0 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
[rank2]:[Gloo] Rank 2 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
[rank3]:[Gloo] Rank 3 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
[rank1]:[Gloo] Rank 1 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
Traceback (most recent call last):
  File "/opt/dlami/nvme/DMLAB/shcho/miniforge3/envs/llm/bin/torchrun", line 7, in <module>
    sys.exit(main())
             ~~~~^^
  File "/opt/dlami/nvme/DMLAB/shcho/miniforge3/envs/llm/lib/python3.13/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 362, in wrapper
    return f(*args, **kwargs)
  File "/opt/dlami/nvme/DMLAB/shcho/miniforge3/envs/llm/lib/python3.13/site-packages/torch/distributed/run.py", line 946, in main
    run(args)
    ~~~^^^^^^
  File "/opt/dlami/nvme/DMLAB/shcho/miniforge3/envs/llm/lib/python3.13/site-packages/torch/distributed/run.py", line 937, in run
    elastic_launch(
    ~~~~~~~~~~~~~~~
        config=config,
        ~~~~~~~~~~~~~~
        entrypoint=cmd,
        ~~~~~~~~~~~~~~~
    )(*cmd_args)
    ~^^^^^^^^^^^
  File "/opt/dlami/nvme/DMLAB/shcho/miniforge3/envs/llm/lib/python3.13/site-packages/torch/distributed/launcher/api.py", line 159, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/opt/dlami/nvme/DMLAB/shcho/miniforge3/envs/llm/lib/python3.13/site-packages/torch/distributed/launcher/api.py", line 300, in launch_agent
    raise ChildFailedError(
    ...<2 lines>...
    )
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
timelyfreeze.train FAILED
------------------------------------------------------------
Failures:
[1]:
  time      : 2025-11-28_18:48:39
  host      : ip-172-16-131-118.sa-east-1.compute.internal
  rank      : 1 (local_rank: 1)
  exitcode  : 1 (pid: 1039980)
  error_file: /tmp/torchelastic_zqw3wlee/9f16cdde-5f0d-43ce-95e1-a29cf8b86202_bl0u21oo/attempt_0/1/error.json
  traceback : Traceback (most recent call last):
    File "/opt/dlami/nvme/DMLAB/shcho/miniforge3/envs/llm/lib/python3.13/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 362, in wrapper
      return f(*args, **kwargs)
    File "/opt/dlami/nvme/DMLAB/shcho/torchtitan/timelyfreeze/train.py", line 584, in train
      self.train_step(data_iterator)
      ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^
    File "/opt/dlami/nvme/DMLAB/shcho/torchtitan/timelyfreeze/train.py", line 509, in train_step
      self.freezer.freeze_update(self.step) # this should be called after optimizer.step()
      ~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^
    File "/opt/dlami/nvme/DMLAB/shcho/torchtitan/timelyfreeze/core/freezer.py", line 703, in freeze_update
      self.set_expected_freeze_ratio()
      ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^
    File "/opt/dlami/nvme/DMLAB/shcho/torchtitan/timelyfreeze/core/freezer.py", line 717, in set_expected_freeze_ratio
      super().set_expected_freeze_ratio()
      ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^
    File "/opt/dlami/nvme/DMLAB/shcho/torchtitan/timelyfreeze/core/freezer.py", line 165, in set_expected_freeze_ratio
      self._set_lowerbound()
      ~~~~~~~~~~~~~~~~~~~~^^
    File "/opt/dlami/nvme/DMLAB/shcho/torchtitan/timelyfreeze/core/freezer.py", line 335, in _set_lowerbound
      self.pipeline_schedule = set_freeze_ratio(self.pipeline_schedule, config=self.config)
                               ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    File "/opt/dlami/nvme/DMLAB/shcho/torchtitan/timelyfreeze/core/schedule.py", line 532, in set_freeze_ratio
      pipeline_schedule_freezing = solve_dag_qp(pipeline_schedule_freezing, max_freeze_ratio=max_freeze_ratio) # solve the DAG LP problem to find the optimal schedule
    File "/opt/dlami/nvme/DMLAB/shcho/torchtitan/timelyfreeze/core/schedule.py", line 400, in solve_dag_qp
      raise RuntimeError(f"Quadratic programming failed: {res.message}")
  RuntimeError: Quadratic programming failed: The maximum number of function evaluations is exceeded.
  
[2]:
  time      : 2025-11-28_18:48:39
  host      : ip-172-16-131-118.sa-east-1.compute.internal
  rank      : 2 (local_rank: 2)
  exitcode  : 1 (pid: 1039981)
  error_file: /tmp/torchelastic_zqw3wlee/9f16cdde-5f0d-43ce-95e1-a29cf8b86202_bl0u21oo/attempt_0/2/error.json
  traceback : Traceback (most recent call last):
    File "/opt/dlami/nvme/DMLAB/shcho/miniforge3/envs/llm/lib/python3.13/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 362, in wrapper
      return f(*args, **kwargs)
    File "/opt/dlami/nvme/DMLAB/shcho/torchtitan/timelyfreeze/train.py", line 584, in train
      self.train_step(data_iterator)
      ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^
    File "/opt/dlami/nvme/DMLAB/shcho/torchtitan/timelyfreeze/train.py", line 509, in train_step
      self.freezer.freeze_update(self.step) # this should be called after optimizer.step()
      ~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^
    File "/opt/dlami/nvme/DMLAB/shcho/torchtitan/timelyfreeze/core/freezer.py", line 703, in freeze_update
      self.set_expected_freeze_ratio()
      ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^
    File "/opt/dlami/nvme/DMLAB/shcho/torchtitan/timelyfreeze/core/freezer.py", line 717, in set_expected_freeze_ratio
      super().set_expected_freeze_ratio()
      ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^
    File "/opt/dlami/nvme/DMLAB/shcho/torchtitan/timelyfreeze/core/freezer.py", line 165, in set_expected_freeze_ratio
      self._set_lowerbound()
      ~~~~~~~~~~~~~~~~~~~~^^
    File "/opt/dlami/nvme/DMLAB/shcho/torchtitan/timelyfreeze/core/freezer.py", line 335, in _set_lowerbound
      self.pipeline_schedule = set_freeze_ratio(self.pipeline_schedule, config=self.config)
                               ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    File "/opt/dlami/nvme/DMLAB/shcho/torchtitan/timelyfreeze/core/schedule.py", line 532, in set_freeze_ratio
      pipeline_schedule_freezing = solve_dag_qp(pipeline_schedule_freezing, max_freeze_ratio=max_freeze_ratio) # solve the DAG LP problem to find the optimal schedule
    File "/opt/dlami/nvme/DMLAB/shcho/torchtitan/timelyfreeze/core/schedule.py", line 400, in solve_dag_qp
      raise RuntimeError(f"Quadratic programming failed: {res.message}")
  RuntimeError: Quadratic programming failed: The maximum number of function evaluations is exceeded.
  
[3]:
  time      : 2025-11-28_18:48:39
  host      : ip-172-16-131-118.sa-east-1.compute.internal
  rank      : 3 (local_rank: 3)
  exitcode  : -15 (pid: 1039982)
  error_file: /tmp/torchelastic_zqw3wlee/9f16cdde-5f0d-43ce-95e1-a29cf8b86202_bl0u21oo/attempt_0/3/error.json
  traceback : Traceback (most recent call last):
    File "/opt/dlami/nvme/DMLAB/shcho/miniforge3/envs/llm/lib/python3.13/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 362, in wrapper
      return f(*args, **kwargs)
    File "/opt/dlami/nvme/DMLAB/shcho/torchtitan/timelyfreeze/train.py", line 584, in train
      self.train_step(data_iterator)
      ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^
    File "/opt/dlami/nvme/DMLAB/shcho/torchtitan/timelyfreeze/train.py", line 509, in train_step
      self.freezer.freeze_update(self.step) # this should be called after optimizer.step()
      ~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^
    File "/opt/dlami/nvme/DMLAB/shcho/torchtitan/timelyfreeze/core/freezer.py", line 703, in freeze_update
      self.set_expected_freeze_ratio()
      ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^
    File "/opt/dlami/nvme/DMLAB/shcho/torchtitan/timelyfreeze/core/freezer.py", line 717, in set_expected_freeze_ratio
      super().set_expected_freeze_ratio()
      ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^
    File "/opt/dlami/nvme/DMLAB/shcho/torchtitan/timelyfreeze/core/freezer.py", line 165, in set_expected_freeze_ratio
      self._set_lowerbound()
      ~~~~~~~~~~~~~~~~~~~~^^
    File "/opt/dlami/nvme/DMLAB/shcho/torchtitan/timelyfreeze/core/freezer.py", line 335, in _set_lowerbound
      self.pipeline_schedule = set_freeze_ratio(self.pipeline_schedule, config=self.config)
                               ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    File "/opt/dlami/nvme/DMLAB/shcho/torchtitan/timelyfreeze/core/schedule.py", line 532, in set_freeze_ratio
      pipeline_schedule_freezing = solve_dag_qp(pipeline_schedule_freezing, max_freeze_ratio=max_freeze_ratio) # solve the DAG LP problem to find the optimal schedule
    File "/opt/dlami/nvme/DMLAB/shcho/torchtitan/timelyfreeze/core/schedule.py", line 400, in solve_dag_qp
      raise RuntimeError(f"Quadratic programming failed: {res.message}")
  RuntimeError: Quadratic programming failed: The maximum number of function evaluations is exceeded.
  
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2025-11-28_18:48:38
  host      : ip-172-16-131-118.sa-east-1.compute.internal
  rank      : 0 (local_rank: 0)
  exitcode  : 1 (pid: 1039979)
  error_file: /tmp/torchelastic_zqw3wlee/9f16cdde-5f0d-43ce-95e1-a29cf8b86202_bl0u21oo/attempt_0/0/error.json
  traceback : Traceback (most recent call last):
    File "/opt/dlami/nvme/DMLAB/shcho/miniforge3/envs/llm/lib/python3.13/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 362, in wrapper
      return f(*args, **kwargs)
    File "/opt/dlami/nvme/DMLAB/shcho/torchtitan/timelyfreeze/train.py", line 584, in train
      self.train_step(data_iterator)
      ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^
    File "/opt/dlami/nvme/DMLAB/shcho/torchtitan/timelyfreeze/train.py", line 509, in train_step
      self.freezer.freeze_update(self.step) # this should be called after optimizer.step()
      ~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^
    File "/opt/dlami/nvme/DMLAB/shcho/torchtitan/timelyfreeze/core/freezer.py", line 703, in freeze_update
      self.set_expected_freeze_ratio()
      ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^
    File "/opt/dlami/nvme/DMLAB/shcho/torchtitan/timelyfreeze/core/freezer.py", line 717, in set_expected_freeze_ratio
      super().set_expected_freeze_ratio()
      ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^
    File "/opt/dlami/nvme/DMLAB/shcho/torchtitan/timelyfreeze/core/freezer.py", line 165, in set_expected_freeze_ratio
      self._set_lowerbound()
      ~~~~~~~~~~~~~~~~~~~~^^
    File "/opt/dlami/nvme/DMLAB/shcho/torchtitan/timelyfreeze/core/freezer.py", line 335, in _set_lowerbound
      self.pipeline_schedule = set_freeze_ratio(self.pipeline_schedule, config=self.config)
                               ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    File "/opt/dlami/nvme/DMLAB/shcho/torchtitan/timelyfreeze/core/schedule.py", line 532, in set_freeze_ratio
      pipeline_schedule_freezing = solve_dag_qp(pipeline_schedule_freezing, max_freeze_ratio=max_freeze_ratio) # solve the DAG LP problem to find the optimal schedule
    File "/opt/dlami/nvme/DMLAB/shcho/torchtitan/timelyfreeze/core/schedule.py", line 400, in solve_dag_qp
      raise RuntimeError(f"Quadratic programming failed: {res.message}")
  RuntimeError: Quadratic programming failed: The maximum number of function evaluations is exceeded.
  
============================================================
