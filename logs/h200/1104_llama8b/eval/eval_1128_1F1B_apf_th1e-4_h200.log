➡️No .safetensors files found in /opt/dlami/nvme/DMLAB/shcho/torchtitan_data/checkpoint/1128_1F1B_apf_th1e-4_h200/step-2000. Converting to HuggingFace format...
➡️No .safetensors files found in /opt/dlami/nvme/DMLAB/shcho/torchtitan_data/checkpoint/1128_1F1B_apf_th1e-4_h200/step-2000. Converting to HuggingFace format...

❄️❄️❄️❄️❄️❄️❄️❄️❄️❄️❄️❄️❄️❄️❄️❄️❄️❄️❄️❄️❄️❄️❄️❄️❄️❄️❄️❄️
✔️Current Timestamp: Fri Nov 28 18:53:24 UTC 2025
✔️SERVER: wbl-kaist-gpu-2 (172.16.131.118),  GPUs: 0
✔️SCRIPT: /opt/dlami/nvme/DMLAB/shcho/torchtitan/logs/h200/1104_llama8b/eval/eval.sh
✔️OUTPUT: /opt/dlami/nvme/DMLAB/shcho/torchtitan/logs/h200/1104_llama8b/eval/eval_1128_1F1B_apf_th1e-4_h200.log
✔️RESULT: /opt/dlami/nvme/DMLAB/shcho/torchtitan_data/checkpoint/1128_1F1B_apf_th1e-4_h200/step-2000/eval_1128_1F1B_apf_th1e-4_h200.json
✔️Main Table Experiment
☑️> python3 -m timelyfreeze.evaluation --model_path=/opt/dlami/nvme/DMLAB/shcho/torchtitan_data/checkpoint/1128_1F1B_apf_th1e-4_h200/step-2000 --dtype=float16 --model_type=Llama-3.1-8B --batch_size=32 --device_map=cuda --tasks=mmlu,hellaswag,arc_challenge,truthfulqa_mc1 --num_fewshot 0 --num_fewshot_task mmlu=5,arc_challenge=10 --output_json=/opt/dlami/nvme/DMLAB/shcho/torchtitan_data/checkpoint/1128_1F1B_apf_th1e-4_h200/step-2000/eval_1128_1F1B_apf_th1e-4_h200.json
❄️❄️❄️❄️❄️❄️❄️❄️❄️❄️❄️❄️❄️❄️❄️❄️❄️❄️❄️❄️❄️❄️❄️❄️❄️❄️❄️❄️
generation_kwargs: {'max_new_tokens': 512, 'temperature': 0.0} specified through cli, these settings will update set parameters in yaml tasks. Ensure 'do_sample=True' for non-greedy decoding!
`torch_dtype` is deprecated! Use `dtype` instead!
config.json not found in /opt/dlami/nvme/DMLAB/shcho/torchtitan_data/checkpoint/1128_1F1B_apf_th1e-4_h200/step-2000. Downloading from meta-llama/Llama-3.1-8B...
Config OK: llama
Downloaded config.json to /opt/dlami/nvme/DMLAB/shcho/torchtitan_data/checkpoint/1128_1F1B_apf_th1e-4_h200/step-2000
Loading checkpoint shards:   0%|          | 0/10 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/10 [00:00<?, ?it/s]
Traceback (most recent call last):
  File "<frozen runpy>", line 198, in _run_module_as_main
  File "<frozen runpy>", line 88, in _run_code
  File "/opt/dlami/nvme/DMLAB/shcho/torchtitan/timelyfreeze/evaluation.py", line 154, in <module>
    main()
    ~~~~^^
  File "/opt/dlami/nvme/DMLAB/shcho/torchtitan/timelyfreeze/evaluation.py", line 88, in main
    part = evaluator.simple_evaluate(
        model="hf",
    ...<7 lines>...
        gen_kwargs={ "max_new_tokens": 512, "temperature": 0.0 },
    )
  File "/opt/dlami/nvme/DMLAB/shcho/miniforge3/envs/llm/lib/python3.13/site-packages/lm_eval/utils.py", line 439, in _wrapper
    return fn(*args, **kwargs)
  File "/opt/dlami/nvme/DMLAB/shcho/miniforge3/envs/llm/lib/python3.13/site-packages/lm_eval/evaluator.py", line 230, in simple_evaluate
    lm = lm_eval.api.registry.get_model(model).create_from_arg_string(
        model_args,
    ...<4 lines>...
        },
    )
  File "/opt/dlami/nvme/DMLAB/shcho/miniforge3/envs/llm/lib/python3.13/site-packages/lm_eval/api/model.py", line 151, in create_from_arg_string
    return cls(**args, **args2)
  File "/opt/dlami/nvme/DMLAB/shcho/miniforge3/envs/llm/lib/python3.13/site-packages/lm_eval/models/huggingface.py", line 193, in __init__
    self._create_model(
    ~~~~~~~~~~~~~~~~~~^
        pretrained=pretrained,
        ^^^^^^^^^^^^^^^^^^^^^^
    ...<14 lines>...
        **kwargs,
        ^^^^^^^^^
    )
    ^
  File "/opt/dlami/nvme/DMLAB/shcho/miniforge3/envs/llm/lib/python3.13/site-packages/lm_eval/models/huggingface.py", line 594, in _create_model
    self._model = self.AUTO_MODEL_CLASS.from_pretrained(
                  ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^
        pretrained,
        ^^^^^^^^^^^
    ...<5 lines>...
        **model_kwargs,
        ^^^^^^^^^^^^^^^
    )
    ^
  File "/opt/dlami/nvme/DMLAB/shcho/miniforge3/envs/llm/lib/python3.13/site-packages/transformers/models/auto/auto_factory.py", line 604, in from_pretrained
    return model_class.from_pretrained(
           ~~~~~~~~~~~~~~~~~~~~~~~~~~~^
        pretrained_model_name_or_path, *model_args, config=config, **hub_kwargs, **kwargs
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/opt/dlami/nvme/DMLAB/shcho/miniforge3/envs/llm/lib/python3.13/site-packages/transformers/modeling_utils.py", line 277, in _wrapper
    return func(*args, **kwargs)
  File "/opt/dlami/nvme/DMLAB/shcho/miniforge3/envs/llm/lib/python3.13/site-packages/transformers/modeling_utils.py", line 5048, in from_pretrained
    ) = cls._load_pretrained_model(
        ~~~~~~~~~~~~~~~~~~~~~~~~~~^
        model,
        ^^^^^^
    ...<12 lines>...
        weights_only=weights_only,
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/opt/dlami/nvme/DMLAB/shcho/miniforge3/envs/llm/lib/python3.13/site-packages/transformers/modeling_utils.py", line 5468, in _load_pretrained_model
    _error_msgs, disk_offload_index = load_shard_file(args)
                                      ~~~~~~~~~~~~~~~^^^^^^
  File "/opt/dlami/nvme/DMLAB/shcho/miniforge3/envs/llm/lib/python3.13/site-packages/transformers/modeling_utils.py", line 831, in load_shard_file
    state_dict = load_state_dict(
        shard_file, is_quantized=is_quantized, map_location=map_location, weights_only=weights_only
    )
  File "/opt/dlami/nvme/DMLAB/shcho/miniforge3/envs/llm/lib/python3.13/site-packages/transformers/modeling_utils.py", line 484, in load_state_dict
    with safe_open(checkpoint_file, framework="pt") as f:
         ~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
safetensors_rust.SafetensorError: Error while deserializing header: incomplete metadata, file not fully covered

❄️❄️❄️❄️❄️❄️❄️❄️❄️❄️❄️❄️❄️❄️❄️❄️❄️❄️❄️❄️❄️❄️❄️❄️❄️❄️❄️❄️
✔️Current Timestamp: Fri Nov 28 18:53:37 UTC 2025
✔️SERVER: wbl-kaist-gpu-2 (172.16.131.118),  GPUs: 1
✔️SCRIPT: /opt/dlami/nvme/DMLAB/shcho/torchtitan/logs/h200/1104_llama8b/eval/eval.sh
✔️OUTPUT: /opt/dlami/nvme/DMLAB/shcho/torchtitan/logs/h200/1104_llama8b/eval/eval_1128_1F1B_apf_th1e-4_h200.log
✔️RESULT: /opt/dlami/nvme/DMLAB/shcho/torchtitan_data/checkpoint/1128_1F1B_apf_th1e-4_h200/step-2000/eval_1128_1F1B_apf_th1e-4_h200.json
✔️Main Table Experiment
☑️> python3 -m timelyfreeze.evaluation --model_path=/opt/dlami/nvme/DMLAB/shcho/torchtitan_data/checkpoint/1128_1F1B_apf_th1e-4_h200/step-2000 --dtype=float16 --model_type=Llama-3.1-8B --batch_size=32 --device_map=cuda --tasks=mmlu,hellaswag,arc_challenge,truthfulqa_mc1 --num_fewshot 0 --num_fewshot_task mmlu=5,arc_challenge=10 --output_json=/opt/dlami/nvme/DMLAB/shcho/torchtitan_data/checkpoint/1128_1F1B_apf_th1e-4_h200/step-2000/eval_1128_1F1B_apf_th1e-4_h200.json
❄️❄️❄️❄️❄️❄️❄️❄️❄️❄️❄️❄️❄️❄️❄️❄️❄️❄️❄️❄️❄️❄️❄️❄️❄️❄️❄️❄️
generation_kwargs: {'max_new_tokens': 512, 'temperature': 0.0} specified through cli, these settings will update set parameters in yaml tasks. Ensure 'do_sample=True' for non-greedy decoding!
`torch_dtype` is deprecated! Use `dtype` instead!
Loading checkpoint shards:   0%|          | 0/10 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/10 [00:00<?, ?it/s]
Traceback (most recent call last):
  File "<frozen runpy>", line 198, in _run_module_as_main
  File "<frozen runpy>", line 88, in _run_code
  File "/opt/dlami/nvme/DMLAB/shcho/torchtitan/timelyfreeze/evaluation.py", line 154, in <module>
    main()
    ~~~~^^
  File "/opt/dlami/nvme/DMLAB/shcho/torchtitan/timelyfreeze/evaluation.py", line 88, in main
    part = evaluator.simple_evaluate(
        model="hf",
    ...<7 lines>...
        gen_kwargs={ "max_new_tokens": 512, "temperature": 0.0 },
    )
  File "/opt/dlami/nvme/DMLAB/shcho/miniforge3/envs/llm/lib/python3.13/site-packages/lm_eval/utils.py", line 439, in _wrapper
    return fn(*args, **kwargs)
  File "/opt/dlami/nvme/DMLAB/shcho/miniforge3/envs/llm/lib/python3.13/site-packages/lm_eval/evaluator.py", line 230, in simple_evaluate
    lm = lm_eval.api.registry.get_model(model).create_from_arg_string(
        model_args,
    ...<4 lines>...
        },
    )
  File "/opt/dlami/nvme/DMLAB/shcho/miniforge3/envs/llm/lib/python3.13/site-packages/lm_eval/api/model.py", line 151, in create_from_arg_string
    return cls(**args, **args2)
  File "/opt/dlami/nvme/DMLAB/shcho/miniforge3/envs/llm/lib/python3.13/site-packages/lm_eval/models/huggingface.py", line 193, in __init__
    self._create_model(
    ~~~~~~~~~~~~~~~~~~^
        pretrained=pretrained,
        ^^^^^^^^^^^^^^^^^^^^^^
    ...<14 lines>...
        **kwargs,
        ^^^^^^^^^
    )
    ^
  File "/opt/dlami/nvme/DMLAB/shcho/miniforge3/envs/llm/lib/python3.13/site-packages/lm_eval/models/huggingface.py", line 594, in _create_model
    self._model = self.AUTO_MODEL_CLASS.from_pretrained(
                  ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^
        pretrained,
        ^^^^^^^^^^^
    ...<5 lines>...
        **model_kwargs,
        ^^^^^^^^^^^^^^^
    )
    ^
  File "/opt/dlami/nvme/DMLAB/shcho/miniforge3/envs/llm/lib/python3.13/site-packages/transformers/models/auto/auto_factory.py", line 604, in from_pretrained
    return model_class.from_pretrained(
           ~~~~~~~~~~~~~~~~~~~~~~~~~~~^
        pretrained_model_name_or_path, *model_args, config=config, **hub_kwargs, **kwargs
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/opt/dlami/nvme/DMLAB/shcho/miniforge3/envs/llm/lib/python3.13/site-packages/transformers/modeling_utils.py", line 277, in _wrapper
    return func(*args, **kwargs)
  File "/opt/dlami/nvme/DMLAB/shcho/miniforge3/envs/llm/lib/python3.13/site-packages/transformers/modeling_utils.py", line 5048, in from_pretrained
    ) = cls._load_pretrained_model(
        ~~~~~~~~~~~~~~~~~~~~~~~~~~^
        model,
        ^^^^^^
    ...<12 lines>...
        weights_only=weights_only,
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/opt/dlami/nvme/DMLAB/shcho/miniforge3/envs/llm/lib/python3.13/site-packages/transformers/modeling_utils.py", line 5468, in _load_pretrained_model
    _error_msgs, disk_offload_index = load_shard_file(args)
                                      ~~~~~~~~~~~~~~~^^^^^^
  File "/opt/dlami/nvme/DMLAB/shcho/miniforge3/envs/llm/lib/python3.13/site-packages/transformers/modeling_utils.py", line 831, in load_shard_file
    state_dict = load_state_dict(
        shard_file, is_quantized=is_quantized, map_location=map_location, weights_only=weights_only
    )
  File "/opt/dlami/nvme/DMLAB/shcho/miniforge3/envs/llm/lib/python3.13/site-packages/transformers/modeling_utils.py", line 484, in load_state_dict
    with safe_open(checkpoint_file, framework="pt") as f:
         ~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
safetensors_rust.SafetensorError: Error while deserializing header: incomplete metadata, file not fully covered
