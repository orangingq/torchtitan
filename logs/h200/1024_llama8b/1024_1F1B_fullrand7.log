
ðŸ”¥ðŸ”¥ðŸ”¥ðŸ”¥ðŸ”¥ðŸ”¥ðŸ”¥ðŸ”¥ðŸ”¥ðŸ”¥ðŸ”¥ðŸ”¥ðŸ”¥ðŸ”¥ðŸ”¥ðŸ”¥ðŸ”¥ðŸ”¥ðŸ”¥ðŸ”¥ðŸ”¥ðŸ”¥ðŸ”¥ðŸ”¥ðŸ”¥ðŸ”¥ðŸ”¥ðŸ”¥
âœ”ï¸Current Timestamp: Sat Oct 25 11:14:46 UTC 2025
âœ”ï¸SERVER: wbl-kaist-gpu-2 (172.16.131.118),  GPUs: 4,5,6,7
âœ”ï¸SCRIPT: /opt/dlami/nvme/DMLAB/shcho/torchtitan/logs/h200/1024_llama8b/run.sh
âœ”ï¸OUTPUT: /opt/dlami/nvme/DMLAB/shcho/torchtitan/logs/h200/1024_llama8b/1024_1F1B_fullrand7.log
âœ”ï¸Llama 3.1 8B Instruct Experiment
âœ”ï¸Running with fullrand7 x 1F1B ... 
â˜‘ï¸> torchrun --standalone --nnodes=1 --nproc_per_node=4 --local_addr=127.0.0.1 --local-ranks-filter=0,1,2,3 --role=rank --tee=3 -m timelyfreeze.train --job.config_file=/opt/dlami/nvme/DMLAB/shcho/torchtitan/logs/h200/1024_llama8b/config.toml --job.description="Llama 3.1 8B Instruct Experiment" --parallelism.pipeline_parallel_degree=4  --freezing.freeze --freezing.metric_type=fullrand7
ðŸ”¥ðŸ”¥ðŸ”¥ðŸ”¥ðŸ”¥ðŸ”¥ðŸ”¥ðŸ”¥ðŸ”¥ðŸ”¥ðŸ”¥ðŸ”¥ðŸ”¥ðŸ”¥ðŸ”¥ðŸ”¥ðŸ”¥ðŸ”¥ðŸ”¥ðŸ”¥ðŸ”¥ðŸ”¥ðŸ”¥ðŸ”¥ðŸ”¥ðŸ”¥ðŸ”¥ðŸ”¥
W1025 11:14:48.089000 1544377 site-packages/torch/distributed/run.py:811] 
W1025 11:14:48.089000 1544377 site-packages/torch/distributed/run.py:811] *****************************************
W1025 11:14:48.089000 1544377 site-packages/torch/distributed/run.py:811] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
W1025 11:14:48.089000 1544377 site-packages/torch/distributed/run.py:811] *****************************************
[rank2]:2025-10-25 11:14:53,983 - INFO - Starting job: "Llama 3.1 8B Instruct Experiment"
[rank1]:2025-10-25 11:14:54,124 - INFO - Starting job: "Llama 3.1 8B Instruct Experiment"
[rank0]:2025-10-25 11:14:54,170 - INFO - Starting job: "Llama 3.1 8B Instruct Experiment"
[rank3]:2025-10-25 11:14:54,253 - INFO - Starting job: "Llama 3.1 8B Instruct Experiment"
[rank2]:2025-10-25 11:14:54,556 - WARNING - ENV[TORCH_NCCL_ASYNC_ERROR_HANDLING] = 1 will be overridden to 3 based on job config
[rank2]:2025-10-25 11:14:54,559 - INFO - Building 1-D device mesh with ['pp'], [4]
[rank0]:2025-10-25 11:14:54,919 - WARNING - ENV[TORCH_NCCL_ASYNC_ERROR_HANDLING] = 1 will be overridden to 3 based on job config
[rank0]:2025-10-25 11:14:54,921 - INFO - Building 1-D device mesh with ['pp'], [4]
[rank0]:2025-10-25 11:14:54,927 - INFO - [GC] Initial GC collection 0.00 seconds
[rank1]:2025-10-25 11:14:54,872 - WARNING - ENV[TORCH_NCCL_ASYNC_ERROR_HANDLING] = 1 will be overridden to 3 based on job config
[rank1]:2025-10-25 11:14:54,875 - INFO - Building 1-D device mesh with ['pp'], [4]
[rank3]:2025-10-25 11:14:54,942 - WARNING - ENV[TORCH_NCCL_ASYNC_ERROR_HANDLING] = 1 will be overridden to 3 based on job config
[rank3]:2025-10-25 11:14:54,945 - INFO - Building 1-D device mesh with ['pp'], [4]
[rank0]:2025-10-25 11:14:56,668 - INFO - Loading tokenizer from tokenizer.json
[rank0]:2025-10-25 11:14:56,953 - INFO - Preparing alpaca dataset from tatsu-lab/alpaca
[rank0]:2025-10-25 11:14:58,609 - INFO - Building llama3 8B with TransformerModelArgs(_enforced='This field is used to enforce all fields have defaults.', dim=4096, n_layers=32, n_heads=32, n_kv_heads=8, vocab_size=128256, multiple_of=1024, ffn_dim_multiplier=1.3, norm_eps=1e-05, rope_theta=500000, max_seq_len=1024, depth_init=True, use_flex_attn=False, attn_mask_type='causal', eos_id=0)
[rank0]:2025-10-25 11:14:58,872 - INFO - CUDA capacity: NVIDIA H200 with 139.81GiB memory
[rank2]:2025-10-25 11:14:58,861 - INFO - CUDA capacity: NVIDIA H200 with 139.81GiB memory
[rank1]:2025-10-25 11:14:58,893 - INFO - CUDA capacity: NVIDIA H200 with 139.81GiB memory
[rank0]:2025-10-25 11:14:58,956 - INFO - Model llama3 8B size: 8,030,261,248 total parameters
[rank0]:2025-10-25 11:14:58,980 - INFO - PP rank 0 is building stage_idx 0 with modules ['tok_embeddings', 'layers.0', 'layers.1', 'layers.2', 'layers.3', 'layers.4', 'layers.5', 'layers.6', 'layers.7']
[rank0]:2025-10-25 11:14:58,980 - INFO - Using pipeline schedule 1F1B with 8 microbatches and 4 stages.
[rank2]:2025-10-25 11:14:58,964 - INFO - PP rank 2 is building stage_idx 2 with modules ['layers.17', 'layers.18', 'layers.19', 'layers.20', 'layers.21', 'layers.22', 'layers.23', 'layers.24']
[rank2]:2025-10-25 11:14:58,965 - INFO - Using pipeline schedule 1F1B with 8 microbatches and 4 stages.
[rank1]:2025-10-25 11:14:58,996 - INFO - PP rank 1 is building stage_idx 1 with modules ['layers.8', 'layers.9', 'layers.10', 'layers.11', 'layers.12', 'layers.13', 'layers.14', 'layers.15', 'layers.16']
[rank1]:2025-10-25 11:14:58,996 - INFO - Using pipeline schedule 1F1B with 8 microbatches and 4 stages.
[rank3]:/opt/dlami/nvme/DMLAB/shcho/miniforge3/envs/llm/lib/python3.13/site-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
[rank3]:  warnings.warn(
[rank3]:/opt/dlami/nvme/DMLAB/shcho/miniforge3/envs/llm/lib/python3.13/site-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
[rank3]:  warnings.warn(
[rank2]:2025-10-25 11:14:59,334 - INFO - Peak FLOPS used for computing MFU: 9.890e+14
[rank2]:2025-10-25 11:14:59,334 - INFO - CUDA memory usage for model: 6.51GiB(4.65%)
[rank0]:2025-10-25 11:14:59,374 - INFO - Peak FLOPS used for computing MFU: 9.890e+14
[rank0]:2025-10-25 11:14:59,374 - INFO - CUDA memory usage for model: 8.46GiB(6.05%)
[rank1]:2025-10-25 11:14:59,381 - INFO - Peak FLOPS used for computing MFU: 9.890e+14
[rank1]:2025-10-25 11:14:59,382 - INFO - CUDA memory usage for model: 7.33GiB(5.24%)
[rank3]:wandb: Currently logged in as: orangingq to https://api.wandb.ai. Use `wandb login --relogin` to force relogin
[rank3]:wandb: setting up run xav3snf2
[rank3]:wandb: Tracking run with wandb version 0.22.2
[rank3]:wandb: Run data is saved locally in /opt/dlami/nvme/DMLAB/shcho/torchtitan_data/tb/1024_1F1B_fullrand7_h200/20251025-1114/wandb/run-20251025_111459-xav3snf2
[rank3]:wandb: Run `wandb offline` to turn off syncing.
[rank3]:wandb: Syncing run 1024_1F1B_fullrand7_h200
[rank3]:wandb: â­ï¸ View project at https://wandb.ai/orangingq/torchtitan
[rank3]:wandb: ðŸš€ View run at https://wandb.ai/orangingq/torchtitan/runs/xav3snf2
[rank3]:2025-10-25 11:15:00,910 - INFO - WandB logging enabled
[rank3]:2025-10-25 11:15:00,911 - INFO - CUDA capacity: NVIDIA H200 with 139.81GiB memory
[rank3]:2025-10-25 11:15:00,987 - INFO - PP rank 3 is building stage_idx 3 with modules ['layers.25', 'layers.26', 'layers.27', 'layers.28', 'layers.29', 'layers.30', 'layers.31', 'norm', 'output']
[rank3]:2025-10-25 11:15:00,987 - INFO - Using pipeline schedule 1F1B with 8 microbatches and 4 stages.
[rank3]:2025-10-25 11:15:01,208 - INFO - Peak FLOPS used for computing MFU: 9.890e+14
[rank3]:2025-10-25 11:15:01,209 - INFO - CUDA memory usage for model: 7.66GiB(5.48%)
[rank3]:2025-10-25 11:15:01,221 - WARNING - checkpoint.initial_load_path is provided but the checkpoint.folder exists. Checkpointer will use the checkpoints from the checkpoint.folder /opt/dlami/nvme/DMLAB/shcho/torchtitan_data/checkpoint/1024_1F1B_fullrand7_h200.
[rank0]:2025-10-25 11:15:01,441 - INFO - Checkpointing active. Checkpoints will be loaded from and saved to /opt/dlami/nvme/DMLAB/shcho/torchtitan_data/checkpoint/1024_1F1B_fullrand7_h200
[rank0]:2025-10-25 11:15:01,441 - WARNING - Mixed precision training with TP or PP is only supported when FSDP/HSDP/CP is enabled.
[rank0]:2025-10-25 11:15:01,441 - INFO - Mixed precision training is disabled
[rank0]:2025-10-25 11:15:01,441 - INFO - Trainer is initialized with local batch size 16, global batch size 64, gradient accumulation steps 4, sequence length 1024, total steps 2000 (warmup 100)
[rank0]:2025-10-25 11:15:01,441 - WARNING - checkpoint.initial_load_path is provided but the checkpoint.folder exists. Checkpointer will use the checkpoints from the checkpoint.folder /opt/dlami/nvme/DMLAB/shcho/torchtitan_data/checkpoint/1024_1F1B_fullrand7_h200.
[rank0]:2025-10-25 11:15:01,441 - INFO - Loading the checkpoint from /opt/dlami/nvme/DMLAB/shcho/torchtitan_data/checkpoint/1024_1F1B_fullrand7_h200/step-500.
[rank1]:2025-10-25 11:15:01,441 - WARNING - checkpoint.initial_load_path is provided but the checkpoint.folder exists. Checkpointer will use the checkpoints from the checkpoint.folder /opt/dlami/nvme/DMLAB/shcho/torchtitan_data/checkpoint/1024_1F1B_fullrand7_h200.
[rank2]:2025-10-25 11:15:01,441 - WARNING - checkpoint.initial_load_path is provided but the checkpoint.folder exists. Checkpointer will use the checkpoints from the checkpoint.folder /opt/dlami/nvme/DMLAB/shcho/torchtitan_data/checkpoint/1024_1F1B_fullrand7_h200.
[rank0]:2025-10-25 11:15:08,206 - INFO - [GC] GC collection for checkpoint loading. 0.00 seconds
[rank0]:2025-10-25 11:15:08,207 - INFO - Finished loading the checkpoint in 6.77 seconds.
[rank0]:2025-10-25 11:15:08,207 - INFO - Training starts at step 1
[rank0]:/opt/dlami/nvme/DMLAB/shcho/miniforge3/envs/llm/lib/python3.13/site-packages/torch/autograd/graph.py:849: UserWarning: Attempting to run cuBLAS, but there was no current CUDA context! Attempting to set the primary context... (Triggered internally at /pytorch/aten/src/ATen/cuda/CublasHandlePool.cpp:270.)
[rank0]:  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
[rank0]:2025-10-25 11:15:32,503 - INFO -  step:  1  loss: -4.0000  grad_norm:  0.6191  memory: 39.86GiB(28.51%)  tps: 488  tflops: 22.78  mfu: 2.30%
[rank0]:2025-10-25 11:15:32,503 - INFO - Synchronizing and adjusting timeout for all ProcessGroups to 0:05:00
[rank1]:2025-10-25 11:15:32,485 - INFO -  step:  1  loss: -4.0000  grad_norm:  0.6191  memory: 34.42GiB(24.62%)  tps: 489  tflops: 22.80  mfu: 2.31%
[rank1]:2025-10-25 11:15:32,485 - INFO - Synchronizing and adjusting timeout for all ProcessGroups to 0:05:00
[rank3]:2025-10-25 11:15:32,591 - INFO -  step:  1  loss:  0.5502  grad_norm:  0.6191  memory: 38.77GiB(27.73%)  tps: 518  tflops: 24.16  mfu: 2.44%
[rank3]:2025-10-25 11:15:32,592 - INFO - Synchronizing and adjusting timeout for all ProcessGroups to 0:05:00
[rank2]:2025-10-25 11:15:32,578 - INFO -  step:  1  loss: -4.0000  grad_norm:  0.6191  memory: 26.61GiB(19.03%)  tps: 487  tflops: 22.72  mfu: 2.30%
[rank2]:2025-10-25 11:15:32,578 - INFO - Synchronizing and adjusting timeout for all ProcessGroups to 0:05:00
[rank3]:2025-10-25 11:16:10,574 - WARNING - Batch index 1 is larger than log time length 0. Filling with zeros.
[rank3]:2025-10-25 11:16:10,575 - WARNING - Batch index 1 is larger than log time length 0. Filling with zeros.
[rank3]:2025-10-25 11:16:10,575 - WARNING - Batch index 1 is larger than log time length 0. Filling with zeros.
[rank3]:2025-10-25 11:16:10,576 - WARNING - Batch index 1 is larger than log time length 0. Filling with zeros.
[rank3]:2025-10-25 11:16:10,576 - WARNING - Batch index 1 is larger than log time length 0. Filling with zeros.
[rank3]:2025-10-25 11:16:10,576 - WARNING - Batch index 1 is larger than log time length 0. Filling with zeros.
[rank3]:2025-10-25 11:16:10,576 - WARNING - Batch index 1 is larger than log time length 0. Filling with zeros.
[rank3]:2025-10-25 11:16:10,577 - WARNING - Batch index 1 is larger than log time length 0. Filling with zeros.
[rank3]:2025-10-25 11:16:10,577 - WARNING - Batch index 1 is larger than log time length 0. Filling with zeros.
[rank3]:2025-10-25 11:16:10,577 - WARNING - Batch index 1 is larger than log time length 0. Filling with zeros.
[rank3]:2025-10-25 11:16:10,577 - WARNING - Batch index 1 is larger than log time length 0. Filling with zeros.
[rank3]:2025-10-25 11:16:10,577 - WARNING - Batch index 1 is larger than log time length 0. Filling with zeros.
[rank3]:2025-10-25 11:16:10,578 - WARNING - Batch index 1 is larger than log time length 0. Filling with zeros.
[rank3]:2025-10-25 11:16:10,578 - WARNING - Batch index 1 is larger than log time length 0. Filling with zeros.
[rank3]:2025-10-25 11:16:10,578 - WARNING - Batch index 1 is larger than log time length 0. Filling with zeros.
[rank3]:2025-10-25 11:16:10,578 - WARNING - Batch index 1 is larger than log time length 0. Filling with zeros.
[rank2]:2025-10-25 11:16:10,876 - WARNING - Batch index 1 is larger than log time length 0. Filling with zeros.
[rank2]:2025-10-25 11:16:10,876 - WARNING - Batch index 1 is larger than log time length 0. Filling with zeros.
[rank2]:2025-10-25 11:16:10,876 - WARNING - Batch index 1 is larger than log time length 0. Filling with zeros.
[rank2]:2025-10-25 11:16:10,876 - WARNING - Batch index 1 is larger than log time length 0. Filling with zeros.
[rank2]:2025-10-25 11:16:10,876 - WARNING - Batch index 1 is larger than log time length 0. Filling with zeros.
[rank2]:2025-10-25 11:16:10,876 - WARNING - Batch index 1 is larger than log time length 0. Filling with zeros.
[rank2]:2025-10-25 11:16:10,876 - WARNING - Batch index 1 is larger than log time length 0. Filling with zeros.
[rank2]:2025-10-25 11:16:10,876 - WARNING - Batch index 1 is larger than log time length 0. Filling with zeros.
[rank2]:2025-10-25 11:16:10,877 - WARNING - Batch index 1 is larger than log time length 0. Filling with zeros.
[rank2]:2025-10-25 11:16:10,877 - WARNING - Batch index 1 is larger than log time length 0. Filling with zeros.
[rank2]:2025-10-25 11:16:10,877 - WARNING - Batch index 1 is larger than log time length 0. Filling with zeros.
[rank2]:2025-10-25 11:16:10,877 - WARNING - Batch index 1 is larger than log time length 0. Filling with zeros.
[rank2]:2025-10-25 11:16:10,877 - WARNING - Batch index 1 is larger than log time length 0. Filling with zeros.
[rank2]:2025-10-25 11:16:10,877 - WARNING - Batch index 1 is larger than log time length 0. Filling with zeros.
[rank2]:2025-10-25 11:16:10,877 - WARNING - Batch index 1 is larger than log time length 0. Filling with zeros.
[rank2]:2025-10-25 11:16:10,877 - WARNING - Batch index 1 is larger than log time length 0. Filling with zeros.
[rank1]:2025-10-25 11:16:11,212 - WARNING - Batch index 1 is larger than log time length 0. Filling with zeros.
[rank1]:2025-10-25 11:16:11,212 - WARNING - Batch index 1 is larger than log time length 0. Filling with zeros.
[rank1]:2025-10-25 11:16:11,212 - WARNING - Batch index 1 is larger than log time length 0. Filling with zeros.
[rank1]:2025-10-25 11:16:11,212 - WARNING - Batch index 1 is larger than log time length 0. Filling with zeros.
[rank1]:2025-10-25 11:16:11,212 - WARNING - Batch index 1 is larger than log time length 0. Filling with zeros.
[rank1]:2025-10-25 11:16:11,212 - WARNING - Batch index 1 is larger than log time length 0. Filling with zeros.
[rank1]:2025-10-25 11:16:11,212 - WARNING - Batch index 1 is larger than log time length 0. Filling with zeros.
[rank1]:2025-10-25 11:16:11,212 - WARNING - Batch index 1 is larger than log time length 0. Filling with zeros.
[rank1]:2025-10-25 11:16:11,212 - WARNING - Batch index 1 is larger than log time length 0. Filling with zeros.
[rank1]:2025-10-25 11:16:11,213 - WARNING - Batch index 1 is larger than log time length 0. Filling with zeros.
[rank1]:2025-10-25 11:16:11,213 - WARNING - Batch index 1 is larger than log time length 0. Filling with zeros.
[rank1]:2025-10-25 11:16:11,213 - WARNING - Batch index 1 is larger than log time length 0. Filling with zeros.
[rank1]:2025-10-25 11:16:11,213 - WARNING - Batch index 1 is larger than log time length 0. Filling with zeros.
[rank1]:2025-10-25 11:16:11,213 - WARNING - Batch index 1 is larger than log time length 0. Filling with zeros.
[rank1]:2025-10-25 11:16:11,213 - WARNING - Batch index 1 is larger than log time length 0. Filling with zeros.
[rank1]:2025-10-25 11:16:11,213 - WARNING - Batch index 1 is larger than log time length 0. Filling with zeros.
[rank0]:2025-10-25 11:16:11,513 - WARNING - Batch index 1 is larger than log time length 0. Filling with zeros.
[rank0]:2025-10-25 11:16:11,513 - WARNING - Batch index 1 is larger than log time length 0. Filling with zeros.
[rank0]:2025-10-25 11:16:11,513 - WARNING - Batch index 1 is larger than log time length 0. Filling with zeros.
[rank0]:2025-10-25 11:16:11,513 - WARNING - Batch index 1 is larger than log time length 0. Filling with zeros.
[rank0]:2025-10-25 11:16:11,513 - WARNING - Batch index 1 is larger than log time length 0. Filling with zeros.
[rank0]:2025-10-25 11:16:11,513 - WARNING - Batch index 1 is larger than log time length 0. Filling with zeros.
[rank0]:2025-10-25 11:16:11,513 - WARNING - Batch index 1 is larger than log time length 0. Filling with zeros.
[rank0]:2025-10-25 11:16:11,513 - WARNING - Batch index 1 is larger than log time length 0. Filling with zeros.
[rank0]:2025-10-25 11:16:11,513 - WARNING - Batch index 1 is larger than log time length 0. Filling with zeros.
[rank0]:2025-10-25 11:16:11,514 - WARNING - Batch index 1 is larger than log time length 0. Filling with zeros.
[rank0]:2025-10-25 11:16:11,514 - WARNING - Batch index 1 is larger than log time length 0. Filling with zeros.
[rank0]:2025-10-25 11:16:11,514 - WARNING - Batch index 1 is larger than log time length 0. Filling with zeros.
[rank0]:2025-10-25 11:16:11,514 - WARNING - Batch index 1 is larger than log time length 0. Filling with zeros.
[rank0]:2025-10-25 11:16:11,514 - WARNING - Batch index 1 is larger than log time length 0. Filling with zeros.
[rank0]:2025-10-25 11:16:11,514 - WARNING - Batch index 1 is larger than log time length 0. Filling with zeros.
[rank0]:2025-10-25 11:16:11,514 - WARNING - Batch index 1 is larger than log time length 0. Filling with zeros.
[rank0]:2025-10-25 11:22:34,976 - INFO -  step: 20  loss: -4.0000  grad_norm:  0.5453  memory: 56.85GiB(40.66%)  tps: 737  tflops: 34.37  mfu: 3.47%
[rank3]:2025-10-25 11:22:34,975 - INFO -  step: 20  loss:  0.5805  grad_norm:  0.5453  memory: 52.47GiB(37.53%)  tps: 737  tflops: 34.37  mfu: 3.48%
[rank1]:2025-10-25 11:22:34,972 - INFO -  step: 20  loss: -4.0000  grad_norm:  0.5453  memory: 48.97GiB(35.03%)  tps: 737  tflops: 34.37  mfu: 3.47%
[rank2]:2025-10-25 11:22:34,970 - INFO -  step: 20  loss: -4.0000  grad_norm:  0.5453  memory: 38.19GiB(27.32%)  tps: 737  tflops: 34.37  mfu: 3.48%
[rank3]:2025-10-25 11:22:39,594 - INFO - Avg. fwd time: 167.4075 / Avg. bwd time: 339.2972 / Avg. batch time: 4114.8107 (ms) / GPU bubble ratio: 1.49%
[rank2]:2025-10-25 11:22:39,893 - INFO - Avg. fwd time: 144.6945 / Avg. bwd time: 292.4543 / Avg. batch time: 4558.3945 (ms) / GPU bubble ratio: 23.28%
[rank1]:2025-10-25 11:22:40,229 - INFO - Avg. fwd time: 162.8779 / Avg. bwd time: 329.1581 / Avg. batch time: 5057.2473 (ms) / GPU bubble ratio: 22.17%
[rank0]:2025-10-25 11:22:40,530 - INFO - Avg. fwd time: 144.9499 / Avg. bwd time: 294.3910 / Avg. batch time: 5503.2029 (ms) / GPU bubble ratio: 36.13%
[rank2]:2025-10-25 11:29:59,549 - INFO -  step: 40  loss: -4.0000  grad_norm:  0.5148  memory: 38.19GiB(27.32%)  tps: 737  tflops: 34.38  mfu: 3.48%
[rank0]:2025-10-25 11:29:59,556 - INFO -  step: 40  loss: -4.0000  grad_norm:  0.5148  memory: 56.85GiB(40.66%)  tps: 737  tflops: 34.38  mfu: 3.48%
[rank3]:2025-10-25 11:29:59,554 - INFO -  step: 40  loss:  0.5703  grad_norm:  0.5148  memory: 52.47GiB(37.53%)  tps: 737  tflops: 34.38  mfu: 3.48%
[rank1]:2025-10-25 11:29:59,552 - INFO -  step: 40  loss: -4.0000  grad_norm:  0.5148  memory: 48.97GiB(35.03%)  tps: 737  tflops: 34.38  mfu: 3.48%
[rank3]:2025-10-25 11:30:04,177 - INFO - Avg. fwd time: 168.4475 / Avg. bwd time: 341.4028 / Avg. batch time: 4114.7963 (ms) / GPU bubble ratio: 0.87%
[rank2]:2025-10-25 11:30:04,476 - INFO - Avg. fwd time: 145.5813 / Avg. bwd time: 294.2614 / Avg. batch time: 4558.3628 (ms) / GPU bubble ratio: 22.81%
[rank1]:2025-10-25 11:30:04,811 - INFO - Avg. fwd time: 163.8964 / Avg. bwd time: 331.2173 / Avg. batch time: 5057.1875 (ms) / GPU bubble ratio: 21.68%
[rank0]:2025-10-25 11:30:05,112 - INFO - Avg. fwd time: 145.9059 / Avg. bwd time: 296.2172 / Avg. batch time: 5503.1395 (ms) / GPU bubble ratio: 35.73%
[rank0]:2025-10-25 11:33:19,593 - INFO - [GC] Peforming periodical GC collection 0.02 seconds
[rank3]:2025-10-25 11:37:24,162 - INFO -  step: 60  loss:  0.5455  grad_norm:  0.5878  memory: 52.47GiB(37.53%)  tps: 737  tflops: 34.37  mfu: 3.48%
[rank1]:2025-10-25 11:37:24,160 - INFO -  step: 60  loss: -4.0000  grad_norm:  0.5878  memory: 48.97GiB(35.03%)  tps: 737  tflops: 34.37  mfu: 3.48%
[rank2]:2025-10-25 11:37:24,157 - INFO -  step: 60  loss: -4.0000  grad_norm:  0.5878  memory: 38.19GiB(27.32%)  tps: 737  tflops: 34.37  mfu: 3.48%
[rank0]:2025-10-25 11:37:24,164 - INFO -  step: 60  loss: -4.0000  grad_norm:  0.5878  memory: 56.85GiB(40.66%)  tps: 737  tflops: 34.37  mfu: 3.48%
[rank3]:2025-10-25 11:37:28,784 - INFO - Avg. fwd time: 168.7984 / Avg. bwd time: 342.1072 / Avg. batch time: 4114.7770 (ms) / GPU bubble ratio: 0.67%
[rank2]:2025-10-25 11:37:29,083 - INFO - Avg. fwd time: 145.8815 / Avg. bwd time: 294.8678 / Avg. batch time: 4558.3348 (ms) / GPU bubble ratio: 22.65%
[rank1]:2025-10-25 11:37:29,419 - INFO - Avg. fwd time: 164.2366 / Avg. bwd time: 331.9054 / Avg. batch time: 5057.1459 (ms) / GPU bubble ratio: 21.51%
[rank0]:2025-10-25 11:37:29,720 - INFO - Avg. fwd time: 146.2344 / Avg. bwd time: 296.8311 / Avg. batch time: 5503.0867 (ms) / GPU bubble ratio: 35.59%
[rank2]:2025-10-25 11:44:48,712 - INFO -  step: 80  loss: -4.0000  grad_norm:  0.6237  memory: 38.19GiB(27.32%)  tps: 737  tflops: 34.38  mfu: 3.48%
[rank3]:2025-10-25 11:44:48,717 - INFO -  step: 80  loss:  0.5417  grad_norm:  0.6237  memory: 52.47GiB(37.53%)  tps: 737  tflops: 34.38  mfu: 3.48%
[rank0]:2025-10-25 11:44:48,718 - INFO -  step: 80  loss: -4.0000  grad_norm:  0.6237  memory: 56.85GiB(40.66%)  tps: 737  tflops: 34.38  mfu: 3.48%
[rank1]:2025-10-25 11:44:48,714 - INFO -  step: 80  loss: -4.0000  grad_norm:  0.6237  memory: 48.97GiB(35.03%)  tps: 737  tflops: 34.38  mfu: 3.48%
[rank3]:2025-10-25 11:44:53,337 - INFO - Avg. fwd time: 168.9735 / Avg. bwd time: 342.4593 / Avg. batch time: 4114.7501 (ms) / GPU bubble ratio: 0.57%
[rank2]:2025-10-25 11:44:53,636 - INFO - Avg. fwd time: 146.0358 / Avg. bwd time: 295.1761 / Avg. batch time: 4558.3107 (ms) / GPU bubble ratio: 22.57%
[rank1]:2025-10-25 11:44:53,971 - INFO - Avg. fwd time: 164.4049 / Avg. bwd time: 332.2576 / Avg. batch time: 5057.1178 (ms) / GPU bubble ratio: 21.43%
[rank0]:2025-10-25 11:44:54,272 - INFO - Avg. fwd time: 146.4002 / Avg. bwd time: 297.1380 / Avg. batch time: 5503.0511 (ms) / GPU bubble ratio: 35.52%
[rank3]:2025-10-25 11:45:36,775 - WARNING - Dataset alpaca is being re-looped
[rank2]:2025-10-25 11:45:38,109 - WARNING - Dataset alpaca is being re-looped
[rank1]:2025-10-25 11:45:38,442 - WARNING - Dataset alpaca is being re-looped
[rank0]:2025-10-25 11:45:38,741 - WARNING - Dataset alpaca is being re-looped
[rank3]:2025-10-25 11:50:21,071 - INFO - [Step 95] ã€°ï¸ Monitoring Upperbound
[rank0]:2025-10-25 11:51:51,613 - INFO - [GC] Peforming periodical GC collection 0.02 seconds
[rank3]:2025-10-25 11:52:12,249 - INFO - [Step 100] âœ”ï¸  Setting Upperbound
[rank2]:2025-10-25 11:52:13,874 - INFO -  step: 100  loss: -4.0000  grad_norm:  0.5789  memory: 38.19GiB(27.32%)  tps: 736  tflops: 34.33  mfu: 3.47%
[rank3]:2025-10-25 11:52:13,871 - INFO - [Step 100] ã€°ï¸ Monitoring Lowerbound
[rank3]:2025-10-25 11:52:13,875 - INFO -  step: 100  loss:  0.5810  grad_norm:  0.5789  memory: 52.47GiB(37.53%)  tps: 736  tflops: 34.33  mfu: 3.47%
[rank1]:2025-10-25 11:52:13,874 - INFO -  step: 100  loss: -4.0000  grad_norm:  0.5789  memory: 48.97GiB(35.03%)  tps: 736  tflops: 34.33  mfu: 3.47%
[rank0]:2025-10-25 11:52:13,875 - INFO -  step: 100  loss: -4.0000  grad_norm:  0.5789  memory: 56.85GiB(40.66%)  tps: 736  tflops: 34.33  mfu: 3.47%
[rank0]:2025-10-25 11:52:13,945 - INFO - Frozen Ratio History of Rank 0 (Stage 0)  is saved as: /opt/dlami/nvme/DMLAB/shcho/torchtitan_data/images/1024_1F1B_fullrand7_h200/freeze_ratio_history/rank0/251025_1152_stage0_step100.svg
[rank2]:2025-10-25 11:52:13,953 - INFO - Frozen Ratio History of Rank 2 (Stage 2)  is saved as: /opt/dlami/nvme/DMLAB/shcho/torchtitan_data/images/1024_1F1B_fullrand7_h200/freeze_ratio_history/rank2/251025_1152_stage2_step100.svg
[rank1]:2025-10-25 11:52:13,946 - INFO - Frozen Ratio History of Rank 1 (Stage 1)  is saved as: /opt/dlami/nvme/DMLAB/shcho/torchtitan_data/images/1024_1F1B_fullrand7_h200/freeze_ratio_history/rank1/251025_1152_stage1_step100.svg
[rank0]:2025-10-25 11:52:14,031 - WARNING - Batch index 401 is larger than freeze ratio history length 0. Filling with zeros.
[rank2]:2025-10-25 11:52:14,020 - WARNING - Batch index 401 is larger than freeze ratio history length 0. Filling with zeros.
[rank2]:2025-10-25 11:52:14,043 - WARNING - Batch index 401 is larger than freeze ratio history length 0. Filling with zeros.
[rank1]:2025-10-25 11:52:14,025 - WARNING - Batch index 401 is larger than freeze ratio history length 0. Filling with zeros.
[rank1]:2025-10-25 11:52:14,050 - WARNING - Batch index 401 is larger than freeze ratio history length 0. Filling with zeros.
[rank0]:2025-10-25 11:52:14,054 - WARNING - Batch index 401 is larger than freeze ratio history length 0. Filling with zeros.
[rank3]:2025-10-25 11:52:14,253 - INFO - Pipeline schedule is saved as: /opt/dlami/nvme/DMLAB/shcho/torchtitan_data/images/1024_1F1B_fullrand7_h200/pipeline_schedule/251025_1152_real_step100_rank3.svg
[rank3]:> Batch Time: 5491.50 ms, GPU Bubble Ratio: 35.16%, 27.41%, 35.50%, 25.23%
[rank3]:2025-10-25 11:52:14,310 - INFO - Frozen Ratio History of Rank 3 (Stage 3)  is saved as: /opt/dlami/nvme/DMLAB/shcho/torchtitan_data/images/1024_1F1B_fullrand7_h200/freeze_ratio_history/rank3/251025_1152_stage3_step100.svg
[rank3]:2025-10-25 11:52:14,369 - WARNING - Batch index 401 is larger than freeze ratio history length 0. Filling with zeros.
[rank3]:2025-10-25 11:52:14,388 - WARNING - Batch index 401 is larger than freeze ratio history length 0. Filling with zeros.
[rank3]:2025-10-25 11:52:14,405 - WARNING - Batch index 401 is larger than freeze ratio history length 0. Filling with zeros.
[rank0]:2025-10-25 11:52:14,454 - WARNING - Batch index 401 is larger than freeze ratio history length 0. Filling with zeros.
[rank2]:2025-10-25 11:52:14,477 - WARNING - Batch index 401 is larger than freeze ratio history length 0. Filling with zeros.
[rank1]:2025-10-25 11:52:14,610 - WARNING - Batch index 401 is larger than freeze ratio history length 0. Filling with zeros.
[rank3]:2025-10-25 11:52:14,772 - WARNING - Batch index 401 is larger than freeze ratio history length 0. Filling with zeros.
[rank3]:2025-10-25 11:52:15,091 - WARNING - Batch index 401 is larger than freeze ratio history length 0. Filling with zeros.
[rank2]:2025-10-25 11:52:15,212 - WARNING - Batch index 401 is larger than freeze ratio history length 0. Filling with zeros.
[rank2]:2025-10-25 11:52:15,577 - WARNING - Batch index 401 is larger than freeze ratio history length 0. Filling with zeros.
[rank3]:2025-10-25 11:52:15,529 - WARNING - Batch index 401 is larger than freeze ratio history length 0. Filling with zeros.
[rank1]:2025-10-25 11:52:15,719 - WARNING - Batch index 401 is larger than freeze ratio history length 0. Filling with zeros.
[rank0]:2025-10-25 11:52:15,892 - WARNING - Batch index 401 is larger than freeze ratio history length 0. Filling with zeros.
[rank2]:2025-10-25 11:52:15,966 - WARNING - Batch index 401 is larger than freeze ratio history length 0. Filling with zeros.
[rank3]:2025-10-25 11:52:16,022 - WARNING - Batch index 401 is larger than freeze ratio history length 0. Filling with zeros.
[rank1]:2025-10-25 11:52:16,132 - WARNING - Batch index 401 is larger than freeze ratio history length 0. Filling with zeros.
[rank0]:2025-10-25 11:52:16,385 - WARNING - Batch index 401 is larger than freeze ratio history length 0. Filling with zeros.
[rank0]:2025-10-25 11:52:16,386 - WARNING - Batch index 401 is larger than freeze ratio history length 0. Filling with zeros.
[rank0]:2025-10-25 11:52:16,387 - WARNING - Batch index 401 is larger than freeze ratio history length 0. Filling with zeros.
[rank0]:2025-10-25 11:52:16,387 - WARNING - Batch index 401 is larger than freeze ratio history length 0. Filling with zeros.
[rank2]:2025-10-25 11:52:16,460 - WARNING - Batch index 401 is larger than freeze ratio history length 0. Filling with zeros.
[rank3]:2025-10-25 11:52:16,515 - WARNING - Batch index 401 is larger than freeze ratio history length 0. Filling with zeros.
[rank1]:2025-10-25 11:52:16,562 - WARNING - Batch index 401 is larger than freeze ratio history length 0. Filling with zeros.
[rank1]:2025-10-25 11:52:16,789 - WARNING - Batch index 401 is larger than freeze ratio history length 0. Filling with zeros.
[rank2]:2025-10-25 11:52:16,828 - WARNING - Batch index 401 is larger than freeze ratio history length 0. Filling with zeros.
[rank1]:2025-10-25 11:52:17,071 - WARNING - Batch index 401 is larger than freeze ratio history length 0. Filling with zeros.
[rank3]:2025-10-25 11:52:18,111 - INFO - Avg. fwd time: 169.0792 / Avg. bwd time: 342.3127 / Avg. batch time: 4113.6145 (ms) / GPU bubble ratio: 0.55%
[rank2]:2025-10-25 11:52:18,268 - INFO - Avg. fwd time: 146.1303 / Avg. bwd time: 295.0964 / Avg. batch time: 4556.8230 (ms) / GPU bubble ratio: 22.54%
[rank0]:2025-10-25 11:52:18,447 - INFO - Avg. fwd time: 146.5055 / Avg. bwd time: 296.9458 / Avg. batch time: 5500.4225 (ms) / GPU bubble ratio: 35.50%
[rank1]:2025-10-25 11:52:18,444 - INFO - Avg. fwd time: 164.5079 / Avg. bwd time: 332.2179 / Avg. batch time: 5055.2266 (ms) / GPU bubble ratio: 21.39%
[rank3]:2025-10-25 11:53:27,298 - INFO - [Step 105] âœ”ï¸  Setting Lowerbound
[rank3]:2025-10-25 11:53:28,000 - INFO - Pipeline schedule is saved as: /opt/dlami/nvme/DMLAB/shcho/torchtitan_data/images/1024_1F1B_fullrand7_h200/pipeline_schedule/251025_1153_max_batch_time.svg
[rank3]:> Batch Time: 5491.62 ms, GPU Bubble Ratio: 35.16%, 27.41%, 35.50%, 25.24%
[rank3]:2025-10-25 11:53:28,293 - INFO - Pipeline schedule is saved as: /opt/dlami/nvme/DMLAB/shcho/torchtitan_data/images/1024_1F1B_fullrand7_h200/pipeline_schedule/251025_1153_min_batch_time.svg
[rank3]:> Batch Time: 3576.88 ms, GPU Bubble Ratio: 67.15%, 24.17%, 32.65%, 22.00%
[rank3]:2025-10-25 11:53:28,608 - INFO - Pipeline schedule is saved as: /opt/dlami/nvme/DMLAB/shcho/torchtitan_data/images/1024_1F1B_fullrand7_h200/pipeline_schedule/251025_1153_frozen_pipeline_schedule.svg
[rank3]:> Batch Time: 3576.88 ms, GPU Bubble Ratio: 22.99%, 17.43%, 20.71%, 22.00%
[rank3]:2025-10-25 11:53:28,609 - INFO - 	> Batch Time: 3576.88 ms (Average Freeze Ratio: 0.69, Time Reduction Rate: 0.35)
[rank3]:2025-10-25 11:57:40,470 - INFO - Current/Expected Freeze Ratio per Block: [MB0] 1.00/1.00, [MB1] 1.00/1.00, [MB2] 1.00/1.00, [MB3] 1.00/1.00, [MB4] 1.00/1.00, [MB5] 1.00/1.00, [MB6] 1.00/1.00, [MB7] 1.00/1.00
[rank2]:2025-10-25 11:57:41,602 - INFO - Current/Expected Freeze Ratio per Block: [MB0] 0.67/0.67, [MB1] 0.67/0.67, [MB2] 0.66/0.66, [MB3] 0.67/0.67, [MB4] 0.67/0.67, [MB5] 0.66/0.66, [MB6] 0.00/0.00, [MB7] 1.00/1.00
[rank1]:2025-10-25 11:57:41,820 - INFO - Current/Expected Freeze Ratio per Block: [MB0] 0.94/0.94, [MB1] 0.93/0.93, [MB2] 0.94/0.94, [MB3] 0.95/0.95, [MB4] 0.94/0.94, [MB5] 0.00/0.00, [MB6] 0.79/0.79, [MB7] 1.00/1.00
[rank0]:2025-10-25 11:57:42,079 - INFO - Current/Expected Freeze Ratio per Block: [MB0] 0.32/0.32, [MB1] 0.32/0.32, [MB2] 0.32/0.32, [MB3] 0.32/0.32, [MB4] 0.00/0.00, [MB5] 0.00/0.00, [MB6] 0.42/0.42, [MB7] 1.00/1.00
[rank0]:2025-10-25 11:57:42,104 - INFO -  step: 120  loss: -4.0000  grad_norm:  0.1890  memory: 57.77GiB(41.32%)  tps: 998  tflops: 46.56  mfu: 4.71%
[rank1]:2025-10-25 11:57:42,085 - INFO -  step: 120  loss: -4.0000  grad_norm:  0.1890  memory: 48.97GiB(35.03%)  tps: 998  tflops: 46.56  mfu: 4.71%
[rank2]:2025-10-25 11:57:42,093 - INFO -  step: 120  loss: -4.0000  grad_norm:  0.1890  memory: 38.19GiB(27.32%)  tps: 998  tflops: 46.56  mfu: 4.71%
[rank3]:2025-10-25 11:57:42,089 - INFO -  step: 120  loss:  0.5374  grad_norm:  0.1890  memory: 52.47GiB(37.53%)  tps: 998  tflops: 46.56  mfu: 4.71%
[rank3]:2025-10-25 11:57:45,520 - INFO - Avg. fwd time: 169.1714 / Avg. bwd time: 319.0408 / Avg. batch time: 3926.4300 (ms) / GPU bubble ratio: 0.53%
[rank2]:2025-10-25 11:57:45,711 - INFO - Avg. fwd time: 146.2025 / Avg. bwd time: 278.0818 / Avg. batch time: 4354.3238 (ms) / GPU bubble ratio: 22.05%
[rank1]:2025-10-25 11:57:45,898 - INFO - Avg. fwd time: 164.6071 / Avg. bwd time: 309.4064 / Avg. batch time: 4829.7436 (ms) / GPU bubble ratio: 21.48%
[rank0]:2025-10-25 11:57:46,134 - INFO - Avg. fwd time: 146.5457 / Avg. bwd time: 270.5243 / Avg. batch time: 5257.5875 (ms) / GPU bubble ratio: 36.54%
[rank1]:2025-10-25 12:02:58,660 - INFO - Observed values (freeze ratio vs time) with Trend Line is saved as: /opt/dlami/nvme/DMLAB/shcho/torchtitan_data/images/1024_1F1B_fullrand7_h200/pipeline_schedule_adjustment/251025_1202_rank1_trend_line.svg
[rank1]:2025-10-25 12:02:58,691 - INFO - Adjusted Freeze Ratio per Block: [MB0] 0.34/0.34, [MB1] 1.00/1.00, [MB2] 1.00/1.00, [MB3] 1.00/1.00, [MB4] 1.00/1.00, [MB5] 0.00/0.00, [MB6] 0.00/0.00, [MB7] 1.00/1.00
[rank1]:2025-10-25 12:02:58,692 - INFO - Current/Expected Freeze Ratio per Block: [MB0] 0.34/0.34, [MB1] 1.00/1.00, [MB2] 1.00/1.00, [MB3] 1.00/1.00, [MB4] 1.00/1.00, [MB5] 0.00/0.00, [MB6] 0.00/0.00, [MB7] 1.00/1.00
[rank1]:2025-10-25 12:02:58,692 - INFO -  step: 140  loss: -4.0000  grad_norm:  0.1980  memory: 48.97GiB(35.03%)  tps: 1,035  tflops: 48.27  mfu: 4.88%
[rank2]:2025-10-25 12:02:58,669 - INFO - Observed values (freeze ratio vs time) with Trend Line is saved as: /opt/dlami/nvme/DMLAB/shcho/torchtitan_data/images/1024_1F1B_fullrand7_h200/pipeline_schedule_adjustment/251025_1202_rank2_trend_line.svg
[rank2]:2025-10-25 12:02:58,690 - INFO - Adjusted Freeze Ratio per Block: [MB0] 1.00/1.00, [MB1] 0.37/0.37, [MB2] 0.36/0.36, [MB3] 0.35/0.35, [MB4] 0.34/0.34, [MB5] 0.33/0.33, [MB6] 0.00/0.00, [MB7] 1.00/1.00
[rank2]:2025-10-25 12:02:58,691 - INFO - Current/Expected Freeze Ratio per Block: [MB0] 1.00/1.00, [MB1] 0.37/0.37, [MB2] 0.36/0.36, [MB3] 0.35/0.35, [MB4] 0.34/0.34, [MB5] 0.33/0.33, [MB6] 0.00/0.00, [MB7] 1.00/1.00
[rank2]:2025-10-25 12:02:58,691 - INFO -  step: 140  loss: -4.0000  grad_norm:  0.1980  memory: 38.19GiB(27.32%)  tps: 1,035  tflops: 48.27  mfu: 4.88%
[rank3]:2025-10-25 12:02:58,663 - INFO - Observed values (freeze ratio vs time) with Trend Line is saved as: /opt/dlami/nvme/DMLAB/shcho/torchtitan_data/images/1024_1F1B_fullrand7_h200/pipeline_schedule_adjustment/251025_1202_rank3_trend_line.svg
[rank0]:2025-10-25 12:02:58,684 - INFO - Observed values (freeze ratio vs time) with Trend Line is saved as: /opt/dlami/nvme/DMLAB/shcho/torchtitan_data/images/1024_1F1B_fullrand7_h200/pipeline_schedule_adjustment/251025_1202_rank0_trend_line.svg
[rank0]:2025-10-25 12:02:58,690 - INFO - Adjusted Freeze Ratio per Block: [MB0] 0.00/0.00, [MB1] 0.00/0.00, [MB2] 0.00/0.00, [MB3] 0.00/0.00, [MB4] 0.00/0.00, [MB5] 0.00/0.00, [MB6] 0.00/0.00, [MB7] 1.00/1.00
[rank0]:2025-10-25 12:02:58,691 - INFO - Current/Expected Freeze Ratio per Block: [MB0] 0.00/0.00, [MB1] 0.00/0.00, [MB2] 0.00/0.00, [MB3] 0.00/0.00, [MB4] 0.00/0.00, [MB5] 0.00/0.00, [MB6] 0.00/0.00, [MB7] 1.00/1.00
[rank0]:2025-10-25 12:02:58,691 - INFO -  step: 140  loss: -4.0000  grad_norm:  0.1980  memory: 57.77GiB(41.32%)  tps: 1,035  tflops: 48.27  mfu: 4.88%
[rank3]:2025-10-25 12:02:59,008 - INFO - Pipeline schedule is saved as: /opt/dlami/nvme/DMLAB/shcho/torchtitan_data/images/1024_1F1B_fullrand7_h200/pipeline_schedule/251025_1202_adjusted_frozen_pipeline_schedule.svg
[rank3]:> Batch Time: 3769.75 ms, GPU Bubble Ratio: 36.40%, 24.22%, 26.54%, 25.83%
[rank3]:2025-10-25 12:02:59,008 - INFO - 	> Batch Time: 3769.75 ms (Average Freeze Ratio: 0.56)
[rank3]:2025-10-25 12:02:59,008 - INFO - Adjusted Freeze Ratio per Block: [MB0] 1.00/1.00, [MB1] 1.00/1.00, [MB2] 1.00/1.00, [MB3] 1.00/1.00, [MB4] 1.00/1.00, [MB5] 1.00/1.00, [MB6] 1.00/1.00, [MB7] 1.00/1.00
[rank3]:2025-10-25 12:02:59,010 - INFO - Current/Expected Freeze Ratio per Block: [MB0] 1.00/1.00, [MB1] 1.00/1.00, [MB2] 1.00/1.00, [MB3] 1.00/1.00, [MB4] 1.00/1.00, [MB5] 1.00/1.00, [MB6] 1.00/1.00, [MB7] 1.00/1.00
[rank3]:2025-10-25 12:02:59,012 - INFO -  step: 140  loss:  0.5169  grad_norm:  0.0000  memory: 52.47GiB(37.53%)  tps: 1,034  tflops: 48.22  mfu: 4.88%
[rank3]:2025-10-25 12:03:02,171 - INFO - Avg. fwd time: 169.2356 / Avg. bwd time: 299.0394 / Avg. batch time: 3767.2635 (ms) / GPU bubble ratio: 0.56%
[rank2]:2025-10-25 12:03:02,426 - INFO - Avg. fwd time: 146.2886 / Avg. bwd time: 265.6185 / Avg. batch time: 4184.0867 (ms) / GPU bubble ratio: 21.24%
[rank1]:2025-10-25 12:03:02,603 - INFO - Avg. fwd time: 164.6778 / Avg. bwd time: 291.0174 / Avg. batch time: 4641.4025 (ms) / GPU bubble ratio: 21.46%
[rank0]:2025-10-25 12:03:02,897 - INFO - Avg. fwd time: 146.5650 / Avg. bwd time: 249.7805 / Avg. batch time: 5064.3638 (ms) / GPU bubble ratio: 37.39%
[rank0]:2025-10-25 12:05:30,206 - INFO - [GC] Peforming periodical GC collection 0.02 seconds
[rank1]:2025-10-25 12:08:35,478 - INFO - Observed values (freeze ratio vs time) with Trend Line is saved as: /opt/dlami/nvme/DMLAB/shcho/torchtitan_data/images/1024_1F1B_fullrand7_h200/pipeline_schedule_adjustment/251025_1208_rank1_trend_line.svg
[rank1]:2025-10-25 12:08:35,509 - INFO - Adjusted Freeze Ratio per Block: [MB0] 0.00/0.00, [MB1] 0.00/0.00, [MB2] 0.00/0.00, [MB3] 0.00/0.00, [MB4] 0.00/0.00, [MB5] 0.00/0.00, [MB6] 0.00/0.00, [MB7] 0.00/0.00
[rank1]:2025-10-25 12:08:35,510 - INFO -  step: 160  loss: -4.0000  grad_norm:  0.0000  memory: 48.97GiB(35.03%)  tps: 973  tflops: 45.37  mfu: 4.59%
[rank0]:2025-10-25 12:08:35,503 - INFO - Observed values (freeze ratio vs time) with Trend Line is saved as: /opt/dlami/nvme/DMLAB/shcho/torchtitan_data/images/1024_1F1B_fullrand7_h200/pipeline_schedule_adjustment/251025_1208_rank0_trend_line.svg
[rank0]:2025-10-25 12:08:35,508 - INFO - Adjusted Freeze Ratio per Block: [MB0] 0.00/0.00, [MB1] 0.00/0.00, [MB2] 0.00/0.00, [MB3] 0.00/0.00, [MB4] 0.00/0.00, [MB5] 0.00/0.00, [MB6] 0.00/0.00, [MB7] 0.00/0.00
[rank0]:2025-10-25 12:08:35,509 - INFO -  step: 160  loss: -4.0000  grad_norm:  0.2803  memory: 57.77GiB(41.32%)  tps: 973  tflops: 45.37  mfu: 4.59%
[rank3]:2025-10-25 12:08:35,480 - INFO - Observed values (freeze ratio vs time) with Trend Line is saved as: /opt/dlami/nvme/DMLAB/shcho/torchtitan_data/images/1024_1F1B_fullrand7_h200/pipeline_schedule_adjustment/251025_1208_rank3_trend_line.svg
[rank2]:2025-10-25 12:08:35,496 - INFO - Observed values (freeze ratio vs time) with Trend Line is saved as: /opt/dlami/nvme/DMLAB/shcho/torchtitan_data/images/1024_1F1B_fullrand7_h200/pipeline_schedule_adjustment/251025_1208_rank2_trend_line.svg
[rank2]:2025-10-25 12:08:35,509 - INFO - Adjusted Freeze Ratio per Block: [MB0] 1.00/1.00, [MB1] 0.88/0.88, [MB2] 0.76/0.76, [MB3] 0.63/0.63, [MB4] 0.52/0.52, [MB5] 0.39/0.39, [MB6] 0.00/0.00, [MB7] 1.00/1.00
[rank2]:2025-10-25 12:08:35,510 - INFO -  step: 160  loss: -4.0000  grad_norm:  0.2803  memory: 38.19GiB(27.32%)  tps: 973  tflops: 45.37  mfu: 4.59%
[rank3]:2025-10-25 12:08:35,810 - INFO - Pipeline schedule is saved as: /opt/dlami/nvme/DMLAB/shcho/torchtitan_data/images/1024_1F1B_fullrand7_h200/pipeline_schedule/251025_1208_adjusted_frozen_pipeline_schedule.svg
[rank3]:> Batch Time: 3763.24 ms, GPU Bubble Ratio: 40.20%, 25.06%, 26.67%, 25.72%
[rank3]:2025-10-25 12:08:35,811 - INFO - 	> Batch Time: 3763.24 ms (Average Freeze Ratio: 0.41)
[rank3]:2025-10-25 12:08:35,811 - INFO - Adjusted Freeze Ratio per Block: [MB0] 1.00/1.00, [MB1] 1.00/1.00, [MB2] 1.00/1.00, [MB3] 1.00/1.00, [MB4] 1.00/1.00, [MB5] 1.00/1.00, [MB6] 0.98/0.98, [MB7] 1.00/1.00
[rank3]:2025-10-25 12:08:35,815 - INFO -  step: 160  loss:  0.4894  grad_norm:  0.0000  memory: 52.47GiB(37.53%)  tps: 973  tflops: 45.38  mfu: 4.59%
[rank3]:2025-10-25 12:08:39,069 - INFO - Avg. fwd time: 169.2807 / Avg. bwd time: 284.0279 / Avg. batch time: 3668.7358 (ms) / GPU bubble ratio: 1.15%
[rank2]:2025-10-25 12:08:39,308 - INFO - Avg. fwd time: 146.3155 / Avg. bwd time: 258.8263 / Avg. batch time: 4083.1381 (ms) / GPU bubble ratio: 20.62%
[rank1]:2025-10-25 12:08:39,644 - INFO - Avg. fwd time: 164.7084 / Avg. bwd time: 278.1690 / Avg. batch time: 4525.9636 (ms) / GPU bubble ratio: 21.72%
[rank0]:2025-10-25 12:08:39,945 - INFO - Avg. fwd time: 146.5946 / Avg. bwd time: 237.0940 / Avg. batch time: 4950.9796 (ms) / GPU bubble ratio: 38.00%
[rank3]:2025-10-25 12:10:00,620 - WARNING - Dataset alpaca is being re-looped
[rank2]:2025-10-25 12:10:02,361 - WARNING - Dataset alpaca is being re-looped
[rank1]:2025-10-25 12:10:02,696 - WARNING - Dataset alpaca is being re-looped
[rank0]:2025-10-25 12:10:02,995 - WARNING - Dataset alpaca is being re-looped
[rank3]:2025-10-25 12:15:06,864 - INFO -  step: 180  loss:  0.5001  grad_norm:  0.0000  memory: 52.47GiB(37.53%)  tps: 838  tflops: 39.08  mfu: 3.95%
[rank0]:2025-10-25 12:15:06,889 - INFO -  step: 180  loss: -4.0000  grad_norm:  0.5181  memory: 57.77GiB(41.32%)  tps: 837  tflops: 39.05  mfu: 3.95%
[rank2]:2025-10-25 12:15:06,873 - INFO -  step: 180  loss: -4.0000  grad_norm:  0.5181  memory: 38.19GiB(27.32%)  tps: 837  tflops: 39.05  mfu: 3.95%
[rank1]:2025-10-25 12:15:06,885 - INFO -  step: 180  loss: -4.0000  grad_norm:  0.5181  memory: 49.13GiB(35.14%)  tps: 837  tflops: 39.05  mfu: 3.95%
[rank3]:2025-10-25 12:15:10,901 - INFO - Avg. fwd time: 169.3046 / Avg. bwd time: 272.3463 / Avg. batch time: 3650.5218 (ms) / GPU bubble ratio: 3.21%
[rank2]:2025-10-25 12:15:11,140 - INFO - Avg. fwd time: 146.3327 / Avg. bwd time: 250.7824 / Avg. batch time: 4062.0152 (ms) / GPU bubble ratio: 21.79%
[rank1]:2025-10-25 12:15:11,476 - INFO - Avg. fwd time: 164.7865 / Avg. bwd time: 284.3919 / Avg. batch time: 4511.0604 (ms) / GPU bubble ratio: 20.34%
[rank0]:2025-10-25 12:15:11,777 - INFO - Avg. fwd time: 146.7010 / Avg. bwd time: 243.8804 / Avg. batch time: 4938.3948 (ms) / GPU bubble ratio: 36.73%
[rank0]:2025-10-25 12:21:18,234 - INFO - [GC] Peforming periodical GC collection 0.02 seconds
[rank3]:2025-10-25 12:21:37,833 - INFO - Observed values (freeze ratio vs time) with Trend Line is saved as: /opt/dlami/nvme/DMLAB/shcho/torchtitan_data/images/1024_1F1B_fullrand7_h200/pipeline_schedule_adjustment/251025_1221_rank3_trend_line.svg
[rank1]:2025-10-25 12:21:37,855 - INFO - Observed values (freeze ratio vs time) with Trend Line is saved as: /opt/dlami/nvme/DMLAB/shcho/torchtitan_data/images/1024_1F1B_fullrand7_h200/pipeline_schedule_adjustment/251025_1221_rank1_trend_line.svg
[rank1]:2025-10-25 12:21:37,863 - INFO - Adjusted Freeze Ratio per Block: [MB0] 1.00/1.00, [MB1] 0.96/0.96, [MB2] 0.96/0.96, [MB3] 0.95/0.95, [MB4] 0.96/0.96, [MB5] 0.00/0.00, [MB6] 0.25/0.25, [MB7] 1.00/1.00
[rank1]:2025-10-25 12:21:37,864 - INFO -  step: 200  loss: -4.0000  grad_norm:  0.6527  memory: 49.13GiB(35.14%)  tps: 838  tflops: 39.09  mfu: 3.95%
[rank2]:2025-10-25 12:21:37,843 - INFO - Observed values (freeze ratio vs time) with Trend Line is saved as: /opt/dlami/nvme/DMLAB/shcho/torchtitan_data/images/1024_1F1B_fullrand7_h200/pipeline_schedule_adjustment/251025_1221_rank2_trend_line.svg
[rank2]:2025-10-25 12:21:37,863 - INFO - Adjusted Freeze Ratio per Block: [MB0] 0.41/0.41, [MB1] 0.41/0.41, [MB2] 0.41/0.41, [MB3] 0.41/0.41, [MB4] 0.41/0.41, [MB5] 0.41/0.41, [MB6] 0.00/0.00, [MB7] 1.00/1.00
[rank2]:2025-10-25 12:21:37,864 - INFO -  step: 200  loss: -4.0000  grad_norm:  0.6527  memory: 38.19GiB(27.32%)  tps: 838  tflops: 39.09  mfu: 3.95%
[rank0]:2025-10-25 12:21:37,857 - INFO - Observed values (freeze ratio vs time) with Trend Line is saved as: /opt/dlami/nvme/DMLAB/shcho/torchtitan_data/images/1024_1F1B_fullrand7_h200/pipeline_schedule_adjustment/251025_1221_rank0_trend_line.svg
[rank0]:2025-10-25 12:21:37,862 - INFO - Adjusted Freeze Ratio per Block: [MB0] 0.17/0.17, [MB1] 0.25/0.25, [MB2] 0.25/0.25, [MB3] 0.25/0.25, [MB4] 0.00/0.00, [MB5] 0.00/0.00, [MB6] 0.00/0.00, [MB7] 1.00/1.00
[rank0]:2025-10-25 12:21:37,864 - INFO -  step: 200  loss: -4.0000  grad_norm:  0.6527  memory: 57.77GiB(41.32%)  tps: 838  tflops: 39.09  mfu: 3.95%
[rank3]:2025-10-25 12:21:38,159 - INFO - Pipeline schedule is saved as: /opt/dlami/nvme/DMLAB/shcho/torchtitan_data/images/1024_1F1B_fullrand7_h200/pipeline_schedule/251025_1221_adjusted_frozen_pipeline_schedule.svg
[rank3]:> Batch Time: 3751.94 ms, GPU Bubble Ratio: 25.49%, 20.58%, 25.88%, 25.69%
[rank3]:2025-10-25 12:21:38,159 - INFO - 	> Batch Time: 3751.94 ms (Average Freeze Ratio: 0.61)
[rank3]:2025-10-25 12:21:38,159 - INFO - Adjusted Freeze Ratio per Block: [MB0] 1.00/1.00, [MB1] 1.00/1.00, [MB2] 1.00/1.00, [MB3] 1.00/1.00, [MB4] 1.00/1.00, [MB5] 1.00/1.00, [MB6] 1.00/1.00, [MB7] 1.00/1.00
[rank3]:2025-10-25 12:21:38,163 - INFO -  step: 200  loss:  0.5356  grad_norm:  0.0000  memory: 52.47GiB(37.53%)  tps: 837  tflops: 39.06  mfu: 3.95%
[rank1]:2025-10-25 12:21:38,232 - INFO - Frozen Ratio History of Rank 1 (Stage 1)  is saved as: /opt/dlami/nvme/DMLAB/shcho/torchtitan_data/images/1024_1F1B_fullrand7_h200/freeze_ratio_history/rank1/251025_1221_stage1_step200.svg
[rank2]:2025-10-25 12:21:38,230 - INFO - Frozen Ratio History of Rank 2 (Stage 2)  is saved as: /opt/dlami/nvme/DMLAB/shcho/torchtitan_data/images/1024_1F1B_fullrand7_h200/freeze_ratio_history/rank2/251025_1221_stage2_step200.svg
[rank0]:2025-10-25 12:21:38,230 - INFO - Frozen Ratio History of Rank 0 (Stage 0)  is saved as: /opt/dlami/nvme/DMLAB/shcho/torchtitan_data/images/1024_1F1B_fullrand7_h200/freeze_ratio_history/rank0/251025_1221_stage0_step200.svg
[rank3]:2025-10-25 12:21:38,518 - INFO - Pipeline schedule is saved as: /opt/dlami/nvme/DMLAB/shcho/torchtitan_data/images/1024_1F1B_fullrand7_h200/pipeline_schedule/251025_1221_real_step200_rank3.svg
[rank3]:> Batch Time: 5484.00 ms, GPU Bubble Ratio: 35.07%, 27.31%, 35.51%, 25.27%
[rank3]:2025-10-25 12:21:38,582 - INFO - Frozen Ratio History of Rank 3 (Stage 3)  is saved as: /opt/dlami/nvme/DMLAB/shcho/torchtitan_data/images/1024_1F1B_fullrand7_h200/freeze_ratio_history/rank3/251025_1221_stage3_step200.svg
[rank3]:2025-10-25 12:21:42,118 - INFO - Avg. fwd time: 169.3224 / Avg. bwd time: 263.0118 / Avg. batch time: 3636.0303 (ms) / GPU bubble ratio: 4.88%
[rank2]:2025-10-25 12:21:42,362 - INFO - Avg. fwd time: 146.3454 / Avg. bwd time: 244.2898 / Avg. batch time: 4044.4141 (ms) / GPU bubble ratio: 22.73%
[rank1]:2025-10-25 12:21:42,541 - INFO - Avg. fwd time: 164.8554 / Avg. bwd time: 289.2552 / Avg. batch time: 4498.2342 (ms) / GPU bubble ratio: 19.24%
[rank0]:2025-10-25 12:21:42,805 - INFO - Avg. fwd time: 146.7964 / Avg. bwd time: 249.2957 / Avg. batch time: 4927.3801 (ms) / GPU bubble ratio: 35.69%
[rank2]:2025-10-25 12:27:09,092 - INFO -  step: 220  loss: -4.0000  grad_norm:  0.2470  memory: 38.19GiB(27.32%)  tps: 989  tflops: 46.14  mfu: 4.67%
[rank0]:2025-10-25 12:27:09,099 - INFO -  step: 220  loss: -4.0000  grad_norm:  0.2470  memory: 57.77GiB(41.32%)  tps: 989  tflops: 46.14  mfu: 4.67%
[rank1]:2025-10-25 12:27:09,074 - INFO -  step: 220  loss: -4.0000  grad_norm:  0.2470  memory: 49.13GiB(35.14%)  tps: 989  tflops: 46.14  mfu: 4.67%
[rank3]:2025-10-25 12:27:09,074 - INFO -  step: 220  loss:  0.4985  grad_norm:  0.0000  memory: 52.47GiB(37.53%)  tps: 990  tflops: 46.19  mfu: 4.67%
[rank3]:2025-10-25 12:27:12,531 - INFO - Avg. fwd time: 169.3411 / Avg. bwd time: 255.3516 / Avg. batch time: 3573.7596 (ms) / GPU bubble ratio: 4.93%
[rank2]:2025-10-25 12:27:12,780 - INFO - Avg. fwd time: 146.4059 / Avg. bwd time: 241.8947 / Avg. batch time: 3979.5161 (ms) / GPU bubble ratio: 21.94%
[rank1]:2025-10-25 12:27:12,971 - INFO - Avg. fwd time: 164.8588 / Avg. bwd time: 279.1241 / Avg. batch time: 4423.3989 (ms) / GPU bubble ratio: 19.70%
[rank0]:2025-10-25 12:27:13,233 - INFO - Avg. fwd time: 146.7898 / Avg. bwd time: 238.6872 / Avg. batch time: 4850.0306 (ms) / GPU bubble ratio: 36.42%
[rank3]:2025-10-25 12:32:41,487 - INFO - Observed values (freeze ratio vs time) with Trend Line is saved as: /opt/dlami/nvme/DMLAB/shcho/torchtitan_data/images/1024_1F1B_fullrand7_h200/pipeline_schedule_adjustment/251025_1232_rank3_trend_line.svg
[rank1]:2025-10-25 12:32:41,486 - INFO - Observed values (freeze ratio vs time) with Trend Line is saved as: /opt/dlami/nvme/DMLAB/shcho/torchtitan_data/images/1024_1F1B_fullrand7_h200/pipeline_schedule_adjustment/251025_1232_rank1_trend_line.svg
[rank1]:2025-10-25 12:32:41,515 - INFO - Adjusted Freeze Ratio per Block: [MB0] 0.93/0.93, [MB1] 0.93/0.93, [MB2] 0.93/0.93, [MB3] 0.93/0.93, [MB4] 0.93/0.93, [MB5] 0.00/0.00, [MB6] 0.00/0.00, [MB7] 1.00/1.00
[rank1]:2025-10-25 12:32:41,516 - INFO -  step: 240  loss: -4.0000  grad_norm:  0.2551  memory: 49.13GiB(35.14%)  tps: 986  tflops: 45.97  mfu: 4.65%
[rank2]:2025-10-25 12:32:41,502 - INFO - Observed values (freeze ratio vs time) with Trend Line is saved as: /opt/dlami/nvme/DMLAB/shcho/torchtitan_data/images/1024_1F1B_fullrand7_h200/pipeline_schedule_adjustment/251025_1232_rank2_trend_line.svg
[rank2]:2025-10-25 12:32:41,515 - INFO - Adjusted Freeze Ratio per Block: [MB0] 0.54/0.54, [MB1] 0.54/0.54, [MB2] 0.54/0.54, [MB3] 0.54/0.54, [MB4] 0.54/0.54, [MB5] 0.54/0.54, [MB6] 0.00/0.00, [MB7] 1.00/1.00
[rank2]:2025-10-25 12:32:41,516 - INFO -  step: 240  loss: -4.0000  grad_norm:  0.2551  memory: 38.19GiB(27.32%)  tps: 986  tflops: 45.97  mfu: 4.65%
[rank0]:2025-10-25 12:32:41,510 - INFO - Observed values (freeze ratio vs time) with Trend Line is saved as: /opt/dlami/nvme/DMLAB/shcho/torchtitan_data/images/1024_1F1B_fullrand7_h200/pipeline_schedule_adjustment/251025_1232_rank0_trend_line.svg
[rank0]:2025-10-25 12:32:41,515 - INFO - Adjusted Freeze Ratio per Block: [MB0] 0.00/0.00, [MB1] 0.00/0.00, [MB2] 0.00/0.00, [MB3] 0.00/0.00, [MB4] 0.00/0.00, [MB5] 0.00/0.00, [MB6] 0.00/0.00, [MB7] 1.00/1.00
[rank0]:2025-10-25 12:32:41,516 - INFO -  step: 240  loss: -4.0000  grad_norm:  0.2551  memory: 57.77GiB(41.32%)  tps: 986  tflops: 45.98  mfu: 4.65%
[rank3]:2025-10-25 12:32:41,822 - INFO - Pipeline schedule is saved as: /opt/dlami/nvme/DMLAB/shcho/torchtitan_data/images/1024_1F1B_fullrand7_h200/pipeline_schedule/251025_1232_adjusted_frozen_pipeline_schedule.svg
[rank3]:> Batch Time: 3739.40 ms, GPU Bubble Ratio: 27.43%, 20.15%, 25.40%, 25.47%
[rank3]:2025-10-25 12:32:41,823 - INFO - 	> Batch Time: 3739.40 ms (Average Freeze Ratio: 0.59)
[rank3]:2025-10-25 12:32:41,823 - INFO - Adjusted Freeze Ratio per Block: [MB0] 1.00/1.00, [MB1] 1.00/1.00, [MB2] 1.00/1.00, [MB3] 1.00/1.00, [MB4] 1.00/1.00, [MB5] 1.00/1.00, [MB6] 1.00/1.00, [MB7] 1.00/1.00
[rank3]:2025-10-25 12:32:41,828 - INFO -  step: 240  loss:  0.4571  grad_norm:  0.0000  memory: 52.47GiB(37.53%)  tps: 985  tflops: 45.93  mfu: 4.64%
[rank3]:2025-10-25 12:32:44,868 - INFO - Avg. fwd time: 169.3609 / Avg. bwd time: 248.9724 / Avg. batch time: 3522.2770 (ms) / GPU bubble ratio: 4.99%
[rank2]:2025-10-25 12:32:45,076 - INFO - Avg. fwd time: 146.4670 / Avg. bwd time: 239.9680 / Avg. batch time: 3926.2452 (ms) / GPU bubble ratio: 21.26%
[rank1]:2025-10-25 12:32:45,258 - INFO - Avg. fwd time: 164.8621 / Avg. bwd time: 270.7401 / Avg. batch time: 4362.3324 (ms) / GPU bubble ratio: 20.12%
[rank0]:2025-10-25 12:32:45,552 - INFO - Avg. fwd time: 146.7857 / Avg. bwd time: 229.8653 / Avg. batch time: 4787.4235 (ms) / GPU bubble ratio: 37.06%
[rank3]:2025-10-25 12:34:28,994 - WARNING - Dataset alpaca is being re-looped
[rank2]:2025-10-25 12:34:30,336 - WARNING - Dataset alpaca is being re-looped
[rank1]:2025-10-25 12:34:30,521 - WARNING - Dataset alpaca is being re-looped
[rank0]:2025-10-25 12:34:30,814 - WARNING - Dataset alpaca is being re-looped
[rank0]:2025-10-25 12:35:08,207 - INFO - [GC] Peforming periodical GC collection 0.03 seconds
[rank3]:2025-10-25 12:38:07,363 - INFO -  step: 260  loss:  0.4541  grad_norm:  0.0000  memory: 52.47GiB(37.53%)  tps: 1,007  tflops: 46.95  mfu: 4.75%
[rank1]:2025-10-25 12:38:07,363 - INFO -  step: 260  loss: -4.0000  grad_norm:  0.3000  memory: 49.13GiB(35.14%)  tps: 1,006  tflops: 46.90  mfu: 4.74%
[rank2]:2025-10-25 12:38:07,376 - INFO -  step: 260  loss: -4.0000  grad_norm:  0.3000  memory: 38.19GiB(27.32%)  tps: 1,006  tflops: 46.90  mfu: 4.74%
[rank0]:2025-10-25 12:38:07,388 - INFO -  step: 260  loss: -4.0000  grad_norm:  0.3000  memory: 57.77GiB(41.32%)  tps: 1,006  tflops: 46.90  mfu: 4.74%
[rank3]:2025-10-25 12:38:10,754 - INFO - Avg. fwd time: 169.3924 / Avg. bwd time: 243.5838 / Avg. batch time: 3471.4540 (ms) / GPU bubble ratio: 4.83%
[rank2]:2025-10-25 12:38:10,981 - INFO - Avg. fwd time: 146.5373 / Avg. bwd time: 237.0788 / Avg. batch time: 3872.1786 (ms) / GPU bubble ratio: 20.74%
[rank1]:2025-10-25 12:38:11,172 - INFO - Avg. fwd time: 164.8729 / Avg. bwd time: 263.8483 / Avg. batch time: 4301.5225 (ms) / GPU bubble ratio: 20.27%
[rank0]:2025-10-25 12:38:11,467 - INFO - Avg. fwd time: 146.8292 / Avg. bwd time: 223.5827 / Avg. batch time: 4727.7064 (ms) / GPU bubble ratio: 37.32%
[rank1]:2025-10-25 12:43:33,510 - INFO -  step: 280  loss: -4.0000  grad_norm:  0.2713  memory: 49.13GiB(35.14%)  tps: 1,005  tflops: 46.86  mfu: 4.74%
[rank3]:2025-10-25 12:43:33,508 - INFO -  step: 280  loss:  0.4784  grad_norm:  0.0000  memory: 52.47GiB(37.53%)  tps: 1,005  tflops: 46.86  mfu: 4.74%
[rank2]:2025-10-25 12:43:33,522 - INFO -  step: 280  loss: -4.0000  grad_norm:  0.2713  memory: 38.19GiB(27.32%)  tps: 1,005  tflops: 46.86  mfu: 4.74%
[rank0]:2025-10-25 12:43:33,534 - INFO -  step: 280  loss: -4.0000  grad_norm:  0.2713  memory: 57.77GiB(41.32%)  tps: 1,005  tflops: 46.86  mfu: 4.74%
[rank3]:2025-10-25 12:43:36,923 - INFO - Avg. fwd time: 169.4177 / Avg. bwd time: 238.9621 / Avg. batch time: 3428.2311 (ms) / GPU bubble ratio: 4.70%
[rank2]:2025-10-25 12:43:37,144 - INFO - Avg. fwd time: 146.5979 / Avg. bwd time: 234.6230 / Avg. batch time: 3826.3519 (ms) / GPU bubble ratio: 20.30%
[rank1]:2025-10-25 12:43:37,336 - INFO - Avg. fwd time: 164.8744 / Avg. bwd time: 257.9483 / Avg. batch time: 4250.2136 (ms) / GPU bubble ratio: 20.41%
[rank0]:2025-10-25 12:43:37,631 - INFO - Avg. fwd time: 146.8673 / Avg. bwd time: 218.1967 / Avg. batch time: 4677.3325 (ms) / GPU bubble ratio: 37.56%
[rank0]:2025-10-25 12:48:42,993 - INFO - [GC] Peforming periodical GC collection 0.02 seconds
[rank2]:2025-10-25 12:48:59,187 - INFO -  step: 300  loss: -4.0000  grad_norm:  0.3279  memory: 38.19GiB(27.32%)  tps: 1,006  tflops: 46.93  mfu: 4.75%
[rank3]:2025-10-25 12:48:59,175 - INFO -  step: 300  loss:  0.4773  grad_norm:  0.0000  memory: 52.47GiB(37.53%)  tps: 1,006  tflops: 46.93  mfu: 4.75%
[rank1]:2025-10-25 12:48:59,176 - INFO -  step: 300  loss: -4.0000  grad_norm:  0.3279  memory: 49.13GiB(35.14%)  tps: 1,006  tflops: 46.93  mfu: 4.75%
[rank2]:2025-10-25 12:48:59,268 - INFO - Frozen Ratio History of Rank 2 (Stage 2)  is saved as: /opt/dlami/nvme/DMLAB/shcho/torchtitan_data/images/1024_1F1B_fullrand7_h200/freeze_ratio_history/rank2/251025_1248_stage2_step300.svg
[rank0]:2025-10-25 12:48:59,200 - INFO -  step: 300  loss: -4.0000  grad_norm:  0.3279  memory: 57.77GiB(41.32%)  tps: 1,006  tflops: 46.93  mfu: 4.75%
[rank0]:2025-10-25 12:48:59,267 - INFO - Frozen Ratio History of Rank 0 (Stage 0)  is saved as: /opt/dlami/nvme/DMLAB/shcho/torchtitan_data/images/1024_1F1B_fullrand7_h200/freeze_ratio_history/rank0/251025_1248_stage0_step300.svg
[rank1]:2025-10-25 12:48:59,268 - INFO - Frozen Ratio History of Rank 1 (Stage 1)  is saved as: /opt/dlami/nvme/DMLAB/shcho/torchtitan_data/images/1024_1F1B_fullrand7_h200/freeze_ratio_history/rank1/251025_1248_stage1_step300.svg
[rank3]:2025-10-25 12:48:59,526 - INFO - Pipeline schedule is saved as: /opt/dlami/nvme/DMLAB/shcho/torchtitan_data/images/1024_1F1B_fullrand7_h200/pipeline_schedule/251025_1248_real_step300_rank3.svg
[rank3]:> Batch Time: 4166.00 ms, GPU Bubble Ratio: 31.51%, 27.51%, 30.62%, 33.12%
[rank3]:2025-10-25 12:48:59,587 - INFO - Frozen Ratio History of Rank 3 (Stage 3)  is saved as: /opt/dlami/nvme/DMLAB/shcho/torchtitan_data/images/1024_1F1B_fullrand7_h200/freeze_ratio_history/rank3/251025_1248_stage3_step300.svg
[rank3]:2025-10-25 12:49:02,643 - INFO - Avg. fwd time: 169.4405 / Avg. bwd time: 234.9577 / Avg. batch time: 3390.1811 (ms) / GPU bubble ratio: 4.57%
[rank2]:2025-10-25 12:49:02,868 - INFO - Avg. fwd time: 146.6504 / Avg. bwd time: 232.4527 / Avg. batch time: 3786.1723 (ms) / GPU bubble ratio: 19.90%
[rank1]:2025-10-25 12:49:03,057 - INFO - Avg. fwd time: 164.8860 / Avg. bwd time: 252.8423 / Avg. batch time: 4205.2593 (ms) / GPU bubble ratio: 20.53%
[rank0]:2025-10-25 12:49:03,352 - INFO - Avg. fwd time: 146.8991 / Avg. bwd time: 213.5285 / Avg. batch time: 4633.1897 (ms) / GPU bubble ratio: 37.77%
[rank1]:2025-10-25 12:54:26,721 - INFO - Observed values (freeze ratio vs time) with Trend Line is saved as: /opt/dlami/nvme/DMLAB/shcho/torchtitan_data/images/1024_1F1B_fullrand7_h200/pipeline_schedule_adjustment/251025_1254_rank1_trend_line.svg
[rank2]:2025-10-25 12:54:26,734 - INFO - Observed values (freeze ratio vs time) with Trend Line is saved as: /opt/dlami/nvme/DMLAB/shcho/torchtitan_data/images/1024_1F1B_fullrand7_h200/pipeline_schedule_adjustment/251025_1254_rank2_trend_line.svg
[rank3]:2025-10-25 12:54:26,721 - INFO - Observed values (freeze ratio vs time) with Trend Line is saved as: /opt/dlami/nvme/DMLAB/shcho/torchtitan_data/images/1024_1F1B_fullrand7_h200/pipeline_schedule_adjustment/251025_1254_rank3_trend_line.svg
[rank1]:2025-10-25 12:54:26,771 - INFO - Adjusted Freeze Ratio per Block: [MB0] 0.91/0.91, [MB1] 0.91/0.91, [MB2] 0.91/0.91, [MB3] 0.91/0.91, [MB4] 0.91/0.91, [MB5] 0.00/0.00, [MB6] 0.00/0.00, [MB7] 1.00/1.00
[rank1]:2025-10-25 12:54:26,772 - INFO -  step: 320  loss: -4.0000  grad_norm:  0.2543  memory: 49.13GiB(35.14%)  tps: 1,000  tflops: 46.65  mfu: 4.72%
[rank2]:2025-10-25 12:54:26,770 - INFO - Adjusted Freeze Ratio per Block: [MB0] 0.55/0.55, [MB1] 0.55/0.55, [MB2] 0.55/0.55, [MB3] 0.55/0.55, [MB4] 0.55/0.55, [MB5] 0.55/0.55, [MB6] 0.00/0.00, [MB7] 1.00/1.00
[rank2]:2025-10-25 12:54:26,772 - INFO -  step: 320  loss: -4.0000  grad_norm:  0.2543  memory: 38.19GiB(27.32%)  tps: 1,000  tflops: 46.65  mfu: 4.72%
[rank0]:2025-10-25 12:54:26,765 - INFO - Observed values (freeze ratio vs time) with Trend Line is saved as: /opt/dlami/nvme/DMLAB/shcho/torchtitan_data/images/1024_1F1B_fullrand7_h200/pipeline_schedule_adjustment/251025_1254_rank0_trend_line.svg
[rank0]:2025-10-25 12:54:26,770 - INFO - Adjusted Freeze Ratio per Block: [MB0] 0.00/0.00, [MB1] 0.00/0.00, [MB2] 0.00/0.00, [MB3] 0.00/0.00, [MB4] 0.00/0.00, [MB5] 0.00/0.00, [MB6] 0.00/0.00, [MB7] 0.00/0.00
[rank0]:2025-10-25 12:54:26,771 - INFO -  step: 320  loss: -4.0000  grad_norm:  0.2543  memory: 57.77GiB(41.32%)  tps: 1,000  tflops: 46.66  mfu: 4.72%
[rank3]:2025-10-25 12:54:27,079 - INFO - Pipeline schedule is saved as: /opt/dlami/nvme/DMLAB/shcho/torchtitan_data/images/1024_1F1B_fullrand7_h200/pipeline_schedule/251025_1254_adjusted_frozen_pipeline_schedule.svg
[rank3]:> Batch Time: 3778.22 ms, GPU Bubble Ratio: 33.43%, 22.33%, 26.16%, 26.24%
[rank3]:2025-10-25 12:54:27,080 - INFO - 	> Batch Time: 3778.22 ms (Average Freeze Ratio: 0.56)
[rank3]:2025-10-25 12:54:27,080 - INFO - Adjusted Freeze Ratio per Block: [MB0] 1.00/1.00, [MB1] 1.00/1.00, [MB2] 1.00/1.00, [MB3] 1.00/1.00, [MB4] 1.00/1.00, [MB5] 1.00/1.00, [MB6] 1.00/1.00, [MB7] 1.00/1.00
[rank3]:2025-10-25 12:54:27,084 - INFO -  step: 320  loss:  0.4449  grad_norm:  0.0000  memory: 52.47GiB(37.53%)  tps: 999  tflops: 46.61  mfu: 4.71%
[rank3]:2025-10-25 12:54:30,100 - INFO - Avg. fwd time: 169.4615 / Avg. bwd time: 231.4545 / Avg. batch time: 3358.2212 (ms) / GPU bubble ratio: 4.49%
[rank2]:2025-10-25 12:54:30,303 - INFO - Avg. fwd time: 146.6992 / Avg. bwd time: 230.7198 / Avg. batch time: 3752.2982 (ms) / GPU bubble ratio: 19.53%
[rank1]:2025-10-25 12:54:30,499 - INFO - Avg. fwd time: 164.8906 / Avg. bwd time: 248.3379 / Avg. batch time: 4167.2062 (ms) / GPU bubble ratio: 20.67%
[rank0]:2025-10-25 12:54:30,801 - INFO - Avg. fwd time: 146.9290 / Avg. bwd time: 209.4442 / Avg. batch time: 4595.8517 (ms) / GPU bubble ratio: 37.97%
[rank3]:2025-10-25 12:57:05,137 - WARNING - Dataset alpaca is being re-looped
[rank2]:2025-10-25 12:57:06,714 - WARNING - Dataset alpaca is being re-looped
[rank1]:2025-10-25 12:57:06,894 - WARNING - Dataset alpaca is being re-looped
[rank0]:2025-10-25 12:57:07,196 - WARNING - Dataset alpaca is being re-looped
[rank2]:2025-10-25 13:00:14,717 - INFO -  step: 340  loss: -4.0000  grad_norm:  0.6098  memory: 38.19GiB(27.32%)  tps: 942  tflops: 43.92  mfu: 4.44%
[rank0]:2025-10-25 13:00:14,729 - INFO -  step: 340  loss: -4.0000  grad_norm:  0.6098  memory: 57.77GiB(41.32%)  tps: 942  tflops: 43.92  mfu: 4.44%
[rank1]:2025-10-25 13:00:14,708 - INFO -  step: 340  loss: -4.0000  grad_norm:  0.6098  memory: 49.13GiB(35.14%)  tps: 942  tflops: 43.92  mfu: 4.44%
[rank3]:2025-10-25 13:00:14,704 - INFO -  step: 340  loss:  0.4448  grad_norm:  0.0000  memory: 52.47GiB(37.53%)  tps: 943  tflops: 43.97  mfu: 4.45%
[rank3]:2025-10-25 13:00:18,368 - INFO - Avg. fwd time: 169.4664 / Avg. bwd time: 228.3514 / Avg. batch time: 3345.0727 (ms) / GPU bubble ratio: 4.86%
[rank2]:2025-10-25 13:00:18,596 - INFO - Avg. fwd time: 146.6870 / Avg. bwd time: 228.8726 / Avg. batch time: 3737.0690 (ms) / GPU bubble ratio: 19.60%
[rank1]:2025-10-25 13:00:18,789 - INFO - Avg. fwd time: 164.8871 / Avg. bwd time: 244.4575 / Avg. batch time: 4148.3155 (ms) / GPU bubble ratio: 21.06%
[rank0]:2025-10-25 13:00:19,090 - INFO - Avg. fwd time: 146.9883 / Avg. bwd time: 214.7857 / Avg. batch time: 4577.9749 (ms) / GPU bubble ratio: 36.78%

ðŸ”¥ðŸ”¥ðŸ”¥ðŸ”¥ðŸ”¥ðŸ”¥ðŸ”¥ðŸ”¥ðŸ”¥ðŸ”¥ðŸ”¥ðŸ”¥ðŸ”¥ðŸ”¥ðŸ”¥ðŸ”¥ðŸ”¥ðŸ”¥ðŸ”¥ðŸ”¥ðŸ”¥ðŸ”¥ðŸ”¥ðŸ”¥ðŸ”¥ðŸ”¥ðŸ”¥ðŸ”¥
âœ”ï¸Current Timestamp: Sat Oct 25 13:02:38 UTC 2025
âœ”ï¸SERVER: wbl-kaist-gpu-2 (172.16.131.118),  GPUs: 0,1,2,3
âœ”ï¸SCRIPT: /opt/dlami/nvme/DMLAB/shcho/torchtitan/logs/h200/1024_llama8b/run.sh
âœ”ï¸OUTPUT: /opt/dlami/nvme/DMLAB/shcho/torchtitan/logs/h200/1024_llama8b/1024_1F1B_fullrand7.log
âœ”ï¸Llama 3.1 8B Instruct Experiment
âœ”ï¸Running with fullrand7 x 1F1B ... 
â˜‘ï¸> torchrun --standalone --nnodes=1 --nproc_per_node=4 --local_addr=127.0.0.1 --local-ranks-filter=0,1,2,3 --role=rank --tee=3 -m timelyfreeze.train --job.config_file=/opt/dlami/nvme/DMLAB/shcho/torchtitan/logs/h200/1024_llama8b/config.toml --job.description="Llama 3.1 8B Instruct Experiment" --parallelism.pipeline_parallel_degree=4  --freezing.freeze --freezing.metric_type=fullrand7
ðŸ”¥ðŸ”¥ðŸ”¥ðŸ”¥ðŸ”¥ðŸ”¥ðŸ”¥ðŸ”¥ðŸ”¥ðŸ”¥ðŸ”¥ðŸ”¥ðŸ”¥ðŸ”¥ðŸ”¥ðŸ”¥ðŸ”¥ðŸ”¥ðŸ”¥ðŸ”¥ðŸ”¥ðŸ”¥ðŸ”¥ðŸ”¥ðŸ”¥ðŸ”¥ðŸ”¥ðŸ”¥
W1025 13:02:40.326000 1614283 site-packages/torch/distributed/run.py:811] 
W1025 13:02:40.326000 1614283 site-packages/torch/distributed/run.py:811] *****************************************
W1025 13:02:40.326000 1614283 site-packages/torch/distributed/run.py:811] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
W1025 13:02:40.326000 1614283 site-packages/torch/distributed/run.py:811] *****************************************

ðŸ”¥ðŸ”¥ðŸ”¥ðŸ”¥ðŸ”¥ðŸ”¥ðŸ”¥ðŸ”¥ðŸ”¥ðŸ”¥ðŸ”¥ðŸ”¥ðŸ”¥ðŸ”¥ðŸ”¥ðŸ”¥ðŸ”¥ðŸ”¥ðŸ”¥ðŸ”¥ðŸ”¥ðŸ”¥ðŸ”¥ðŸ”¥ðŸ”¥ðŸ”¥ðŸ”¥ðŸ”¥
âœ”ï¸Current Timestamp: Sat Oct 25 13:29:16 UTC 2025
âœ”ï¸SERVER: wbl-kaist-gpu-2 (172.16.131.118),  GPUs: 4,5,6,7
âœ”ï¸SCRIPT: /opt/dlami/nvme/DMLAB/shcho/torchtitan/logs/h200/1024_llama8b/run.sh
âœ”ï¸OUTPUT: /opt/dlami/nvme/DMLAB/shcho/torchtitan/logs/h200/1024_llama8b/1024_1F1B_fullrand7.log
âœ”ï¸Llama 3.1 8B Instruct Experiment
âœ”ï¸Running with fullrand7 x 1F1B ... 
â˜‘ï¸> torchrun --standalone --nnodes=1 --nproc_per_node=4 --local_addr=127.0.0.1 --local-ranks-filter=0,1,2,3 --role=rank --tee=3 -m timelyfreeze.train --job.config_file=/opt/dlami/nvme/DMLAB/shcho/torchtitan/logs/h200/1024_llama8b/config.toml --job.description="Llama 3.1 8B Instruct Experiment" --parallelism.pipeline_parallel_degree=4  --freezing.freeze --freezing.metric_type=fullrand7
ðŸ”¥ðŸ”¥ðŸ”¥ðŸ”¥ðŸ”¥ðŸ”¥ðŸ”¥ðŸ”¥ðŸ”¥ðŸ”¥ðŸ”¥ðŸ”¥ðŸ”¥ðŸ”¥ðŸ”¥ðŸ”¥ðŸ”¥ðŸ”¥ðŸ”¥ðŸ”¥ðŸ”¥ðŸ”¥ðŸ”¥ðŸ”¥ðŸ”¥ðŸ”¥ðŸ”¥ðŸ”¥
W1025 13:29:18.046000 1636251 site-packages/torch/distributed/run.py:811] 
W1025 13:29:18.046000 1636251 site-packages/torch/distributed/run.py:811] *****************************************
W1025 13:29:18.046000 1636251 site-packages/torch/distributed/run.py:811] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
W1025 13:29:18.046000 1636251 site-packages/torch/distributed/run.py:811] *****************************************
[rank3]:2025-10-25 13:29:23,739 - INFO - Starting job: "Llama 3.1 8B Instruct Experiment"
[rank1]:2025-10-25 13:29:23,796 - INFO - Starting job: "Llama 3.1 8B Instruct Experiment"
[rank0]:2025-10-25 13:29:23,871 - INFO - Starting job: "Llama 3.1 8B Instruct Experiment"
[rank2]:2025-10-25 13:29:24,128 - INFO - Starting job: "Llama 3.1 8B Instruct Experiment"
[rank3]:2025-10-25 13:29:24,485 - WARNING - ENV[TORCH_NCCL_ASYNC_ERROR_HANDLING] = 1 will be overridden to 3 based on job config
[rank3]:2025-10-25 13:29:24,488 - INFO - Building 1-D device mesh with ['pp'], [4]
[rank1]:2025-10-25 13:29:24,798 - WARNING - ENV[TORCH_NCCL_ASYNC_ERROR_HANDLING] = 1 will be overridden to 3 based on job config
[rank1]:2025-10-25 13:29:24,801 - INFO - Building 1-D device mesh with ['pp'], [4]
[rank0]:Traceback (most recent call last):
[rank0]:  File "<frozen runpy>", line 198, in _run_module_as_main
[rank0]:  File "<frozen runpy>", line 88, in _run_code
[rank0]:  File "/opt/dlami/nvme/DMLAB/shcho/torchtitan/timelyfreeze/train.py", line 712, in <module>
[rank0]:    trainer = TrainerWithFreezer(config)
[rank0]:  File "/opt/dlami/nvme/DMLAB/shcho/miniforge3/envs/llm/lib/python3.13/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 362, in wrapper
[rank0]:    return f(*args, **kwargs)
[rank0]:  File "/opt/dlami/nvme/DMLAB/shcho/torchtitan/timelyfreeze/train.py", line 94, in __init__
[rank0]:    device_module.set_device(self.device)
[rank0]:    ~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^
[rank0]:  File "/opt/dlami/nvme/DMLAB/shcho/miniforge3/envs/llm/lib/python3.13/site-packages/torch/cuda/__init__.py", line 571, in set_device
[rank0]:    torch._C._cuda_setDevice(device)
[rank0]:    ~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^
[rank0]:torch.AcceleratorError: CUDA error: out of memory
[rank0]:Search for `cudaErrorMemoryAllocation' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.
[rank0]:CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
[rank0]:For debugging consider passing CUDA_LAUNCH_BLOCKING=1
[rank0]:Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.
[rank0]:
[rank2]:2025-10-25 13:29:25,729 - WARNING - ENV[TORCH_NCCL_ASYNC_ERROR_HANDLING] = 1 will be overridden to 3 based on job config
[rank2]:2025-10-25 13:29:25,732 - INFO - Building 1-D device mesh with ['pp'], [4]
W1025 13:29:28.121000 1636251 site-packages/torch/distributed/elastic/multiprocessing/api.py:940] Sending process 1636361 closing signal SIGTERM
W1025 13:29:28.122000 1636251 site-packages/torch/distributed/elastic/multiprocessing/api.py:940] Sending process 1636362 closing signal SIGTERM
W1025 13:29:28.123000 1636251 site-packages/torch/distributed/elastic/multiprocessing/api.py:940] Sending process 1636363 closing signal SIGTERM
E1025 13:29:29.813000 1636251 site-packages/torch/distributed/elastic/multiprocessing/api.py:914] failed (exitcode: 1) local_rank: 0 (pid: 1636360) of binary: /opt/dlami/nvme/DMLAB/shcho/miniforge3/envs/llm/bin/python3.13
E1025 13:29:29.829000 1636251 site-packages/torch/distributed/elastic/multiprocessing/errors/error_handler.py:141] no error file defined for parent, to copy child error file (/tmp/torchelastic_bf2e3e64/070ed5d7-a9e6-42e1-8796-7f297a77c42a_dccplps5/attempt_0/0/error.json)
Traceback (most recent call last):
  File "/opt/dlami/nvme/DMLAB/shcho/miniforge3/envs/llm/bin/torchrun", line 7, in <module>
    sys.exit(main())
             ~~~~^^
  File "/opt/dlami/nvme/DMLAB/shcho/miniforge3/envs/llm/lib/python3.13/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 362, in wrapper
    return f(*args, **kwargs)
  File "/opt/dlami/nvme/DMLAB/shcho/miniforge3/envs/llm/lib/python3.13/site-packages/torch/distributed/run.py", line 946, in main
    run(args)
    ~~~^^^^^^
  File "/opt/dlami/nvme/DMLAB/shcho/miniforge3/envs/llm/lib/python3.13/site-packages/torch/distributed/run.py", line 937, in run
    elastic_launch(
    ~~~~~~~~~~~~~~~
        config=config,
        ~~~~~~~~~~~~~~
        entrypoint=cmd,
        ~~~~~~~~~~~~~~~
    )(*cmd_args)
    ~^^^^^^^^^^^
  File "/opt/dlami/nvme/DMLAB/shcho/miniforge3/envs/llm/lib/python3.13/site-packages/torch/distributed/launcher/api.py", line 159, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/opt/dlami/nvme/DMLAB/shcho/miniforge3/envs/llm/lib/python3.13/site-packages/torch/distributed/launcher/api.py", line 300, in launch_agent
    raise ChildFailedError(
    ...<2 lines>...
    )
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
timelyfreeze.train FAILED
------------------------------------------------------------
Failures:
[1]:
  time      : 2025-10-25_13:29:29
  host      : ip-172-16-131-118.sa-east-1.compute.internal
  rank      : 1 (local_rank: 1)
  exitcode  : -15 (pid: 1636361)
  error_file: <N/A>
  traceback : Signal 15 (SIGTERM) received by PID 1636361
[2]:
  time      : 2025-10-25_13:29:29
  host      : ip-172-16-131-118.sa-east-1.compute.internal
  rank      : 2 (local_rank: 2)
  exitcode  : -15 (pid: 1636362)
  error_file: <N/A>
  traceback : Signal 15 (SIGTERM) received by PID 1636362
[3]:
  time      : 2025-10-25_13:29:29
  host      : ip-172-16-131-118.sa-east-1.compute.internal
  rank      : 3 (local_rank: 3)
  exitcode  : -15 (pid: 1636363)
  error_file: <N/A>
  traceback : Signal 15 (SIGTERM) received by PID 1636363
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2025-10-25_13:29:25
  host      : ip-172-16-131-118.sa-east-1.compute.internal
  rank      : 0 (local_rank: 0)
  exitcode  : 1 (pid: 1636360)
  error_file: /tmp/torchelastic_bf2e3e64/070ed5d7-a9e6-42e1-8796-7f297a77c42a_dccplps5/attempt_0/0/error.json
  traceback : Traceback (most recent call last):
    File "/opt/dlami/nvme/DMLAB/shcho/miniforge3/envs/llm/lib/python3.13/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 362, in wrapper
      return f(*args, **kwargs)
    File "/opt/dlami/nvme/DMLAB/shcho/torchtitan/timelyfreeze/train.py", line 94, in __init__
      device_module.set_device(self.device)
      ~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^
    File "/opt/dlami/nvme/DMLAB/shcho/miniforge3/envs/llm/lib/python3.13/site-packages/torch/cuda/__init__.py", line 571, in set_device
      torch._C._cuda_setDevice(device)
      ~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^
  torch.AcceleratorError: CUDA error: out of memory
  Search for `cudaErrorMemoryAllocation' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.
  CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
  For debugging consider passing CUDA_LAUNCH_BLOCKING=1
  Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.
  
  
============================================================
